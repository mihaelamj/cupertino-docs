{
  "abstract" : "Select the optimal LAPACK routine to solve a system of linear equations.",
  "codeExamples" : [
    {
      "code" : "let bValues: [Float] = [80, 180, 160,\n                        800, 1800, 1600]",
      "language" : "swift"
    },
    {
      "code" : "let aValues: [Float] = [1, 6, 11,\n                        2, 7, 12,\n                        3, 8, 13,\n                        4, 9, 14,\n                        5, 10, 15]\n\nlet dimension = (m: 3, n: 5)\n\n\/\/\/ The _b_ in _Ax = b_.\nlet bValues: [Float] = [355, 930, 1505]\n\n\/\/\/ Call `nonsymmetric_nonsquare` to compute the _x_ in _Ax = b_.\nlet x = nonsymmetric_nonsquare(a: aValues,\n                               dimension: dimension,\n                               b: bValues,\n                               rightHandSideCount: 1)\n\n\/\/\/ Calculate _b_ using the computed _x_.\nif let x = x {\n    let b = matrixVectorMultiply(matrix: aValues,\n                                 dimension: dimension,\n                                 vector: x)\n    \n    \/\/\/ Prints _b_ in _Ax = b_ using the computed _x_: `~[355, 930, 1505]`.\n    print(\"\\nnonsymmetric_nonsquare: ([355, 930, 1505]) b =\", b)\n}",
      "language" : "swift"
    },
    {
      "code" : "let aValues: [Float] = [1, 4, 7, 10,\n                        2, 5, 8, 11,\n                        3, 6, 9, 12]\nlet dimension = (m: 4, n: 3)\nlet bValues: [Float] = [194, 455, 716, 977]\n\n\/\/\/ Call `leastSquares_nonsquare` to compute the _x_ in _Ax = b_.\nlet x = leastSquares_nonsquare(a: aValues,\n                               dimension: dimension,\n                               b: bValues)\n\n\/\/\/ Calculate _b_ using the computed _x_.\nif let x = x {\n    let b = matrixVectorMultiply(matrix: aValues,\n                                 dimension: dimension,\n                                 vector: Array(x[0..<3]))\n    \n    \/\/\/ Prints _b_ in _Ax = b_ using the computed _x_: `~[194, 455, 716, 977]`.\n    print(\"\\nleastSquares_nonsquare: b =\", b)\n}",
      "language" : "swift"
    },
    {
      "code" : "var aValues: [Float] = [1, 2, 1,\n                        2, 1, 2,\n                        1, 2, 1]\n\nlet dimension = 3\nlet epsilon = sqrt(Float.ulpOfOne)\nfor i in 0 ..< dimension {\n    aValues[i * dimension + i] += epsilon\n}\n\nlet bValues: [Float] = [80, 100, 80]\n\n\/\/\/ Call `symmetric_indefinite_general` to compute the _x_ in _Ax = b_.\nlet x = symmetric_indefinite_general(a: aValues,\n                                     dimension: dimension,\n                                     b: bValues,\n                                     rightHandSideCount: 1)\n\n\/\/\/ Calculate _b_ using the computed _x_.\nif let x = x {\n    let b = matrixVectorMultiply(matrix: aValues,\n                                 dimension: (m: dimension, n: dimension),\n                                 vector: x)\n    \n    \/\/\/ Prints _b_ in _Ax = b_ using the computed _x_: `~[80, 100, 80]`.\n    print(\"\\nRank-Deficient: b =\", b)\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "2e06af1e2f965a339d1b50a369810724ac03e8415e5f955c0a279af39b89ef45",
  "crawledAt" : "2025-12-02T15:28:03Z",
  "id" : "2B0FCA5B-1632-4017-8087-8DA87D5D3D79",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThe Accelerate framework provides the LAPACK library for numerical linear algebra. A basic technique of linear algebra is to solve systems of simultaneous equations. For example, the following shows three equations that contain the unknowns *x*, *y*, and *z*:\n\n\n\nYou can solve this system by rewriting the simultaneous equations as a matrix equation with the following form:\n\n\n\nThis form is an *Ax = b* form, where *A* is the coefficient matrix, *x* is a column vector that contains the unknown values, and *b* is a column vector that contains the constant values. The number of elements in *x* is equal to the number of columns of *A*, and the number of elements in *b* is equal to the number of rows of *A*.\n\nThe process of solving this system computes the values for *x*, *y*, and *z* as `-2`, `24`, and `8`, respectively.\n\n\n\nFor an example of solving a linear system, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/finding-an-interpolating-polynomial-using-the-vandermonde-method].\n\nLAPACK includes routines for solving systems of linear equations as *Ax = b*. This sample code project includes wrapper functions that simplify calling the LAPACK routines, for example, by encapsulating multiple-step workflows into a single function call.\n\nRun the sample code app to see the results of each routine solve different example systems.\n\n### Determine the properties of the coefficient matrix\n\nLAPACK provides different solving routines depending on the properties of the coefficient matrix, *A*:\n\n\n\n\n\n\n\nIf the coefficient matrix is *sparse*, that is, most of the entries in the coefficient matrix are zero, Accelerate provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/sparse-solvers-library] library to help solve such systems.\n\n### Select LAPACK variants for data types\n\nThe LAPACK routines in this sample code project are all for real, single-precision matrices. All of the routines are available in single- and double-precision for real and complex values. The first character of a routine name defines the type of data the routine works on. For example:\n\nFor complex matrices, the LAPACK routine variant for real symmetric matrices requires [https:\/\/mathworld.wolfram.com\/HermitianMatrix.html]. For example, the `cptsv_()` routine computes the solution to *Ax = b* for a complex single-precision, Hermitian, tridiagonal coefficient matrix; and `sptsv_()`  computes the solution for a real single-precision, symmetric, tridiagonal coefficient matrix.\n\nThe routines in this sample code project are suitable for solving full rank systems, that is, they have a unique and exact solution.\n\n### Define values in column-major layout\n\nThe LAPACK routines in this article require the matrix data in column-major layout, which means specifying all the terms in the first column, then all of the terms in the second column, the third column, and so on. For example, if there are two columns with three row values each, the routine specifies the three row values for column one, then the three row values for column two, as the following example illustrates:\n\n\n\nThe routines return the result as column-major, for example, an array that contains `[10.0, 20.0, 30.0, 100.0, 200.0, 300.0]` represents the following matrix:\n\n\n\n### Select the solving routine for the coefficient matrix type\n\nThis sample code project provides Swift wrapper functions to each single-precision LAPACK solving routine. Select the routine that most closely matches the coefficient matrix for the highest performance. The following shows the Swift wrapper functions and the underlying LAPACK routines to solve systems with different coefficient matrices:\n\n### Solve for a nonsquare matrix using QR factorization\n\nA system of linear equations with a nonsquare coefficient matrix is either:\n\nIn these cases, the solution is either not exact (unless the overdetermined system is actually consistent) or not unique. In the case where LAPACK is unable to solve the system, the Swift wrapper functions return `nil`.\n\nThe Swift wrapper function `nonsymmetric_nonsquare(a:dimension:b:rightHandSideCount:)` wraps the LAPACK routine `sgels_(_:_:_:_:_:_:_:_:_:_:_:)`. This routine takes one of two approaches, depending on the system:\n\n\n\n\n\n\n\n\n\nThe `sgels_(_:_:_:_:_:_:_:_:_:_:_:)` routine uses [https:\/\/mathworld.wolfram.com\/QRDecomposition.html] for overdetermined systems, and [https:\/\/mathworld.wolfram.com\/LQDecomposition.html] for underdetermined systems.\n\nThe following is an example of an underdetermined system with a coefficient matrix that’s nonsquare:\n\n\n\nThe following code calls `nonsymmetric_nonsquare(a:dimension:b:rightHandSideCount:)` to compute the values of *x*:\n\n### Solve for a nonsquare matrix using Cholesky factorization\n\nWhere speed is more important than numerical accuracy, the sample code project provides an alternative to `sgels_(_:_:_:_:_:_:_:_:_:_:_:)`. The `leastSquares_nonsquare(a:dimension:b:)` function exploits the fact that the *x* in *AᵀAx = Aᵀb* equals the *x* in *Ax = b*. This technique creates the square coefficient matrix *AᵀA* and solves with either `symmetric_positiveDefinite_general(a:dimension:b:rightHandSideCount:)` or `symmetric_indefinite_general(a:dimension:b:rightHandSideCount:)`.\n\nThe `leastSquares_nonsquare(a:dimension:b:)` function uses the same problem as   `nonsymmetric_nonsquare(a:dimension:b:rightHandSideCount:)`, but uses [https:\/\/mathworld.wolfram.com\/CholeskyDecomposition.html] when *AᵀA* is positive definite.\n\nThe following is an example of an overdetermined system with a coefficient matrix that’s nonsquare:\n\n\n\nThe following code calls `leastSquares_nonsquare(a:dimension:b:)` to compute the values of *x*:\n\n### Solve for a rank-deficient matrix\n\nSystems with a symmetric matrix that’s not full rank, *rank-deficient matrices*, don’t have a single unique solution. For example, the following two multiplications contain different *x* matrices, but yield the same result in *b*:\n\n\n\nIn this case, passing matrix *A* to its most suitable function, `symmetric_indefinite_general(a:dimension:b:rightHandSideCount:)`, returns an error indicating that the routine can’t compute the solution.\n\nOne option to deal with rank-deficiency is to instead solve a nearby problem of full rank by adding a small epsilon value to the matrix to regularize it. The following code adds such an epsilon to diagonal elements in matrix *A*:\n\nOn return, *x* contains the values `[0.0, 20.0, 40.0]`:\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/solving-systems-of-linear-equations-with-lapack\ncrawled: 2025-12-02T15:28:03Z\n---\n\n# Solving systems of linear equations with LAPACK\n\n**Sample Code**\n\nSelect the optimal LAPACK routine to solve a system of linear equations.\n\n## Overview\n\nThe Accelerate framework provides the LAPACK library for numerical linear algebra. A basic technique of linear algebra is to solve systems of simultaneous equations. For example, the following shows three equations that contain the unknowns *x*, *y*, and *z*:\n\n\n\nYou can solve this system by rewriting the simultaneous equations as a matrix equation with the following form:\n\n\n\nThis form is an *Ax = b* form, where *A* is the coefficient matrix, *x* is a column vector that contains the unknown values, and *b* is a column vector that contains the constant values. The number of elements in *x* is equal to the number of columns of *A*, and the number of elements in *b* is equal to the number of rows of *A*.\n\nThe process of solving this system computes the values for *x*, *y*, and *z* as `-2`, `24`, and `8`, respectively.\n\n\n\nFor an example of solving a linear system, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/finding-an-interpolating-polynomial-using-the-vandermonde-method].\n\nLAPACK includes routines for solving systems of linear equations as *Ax = b*. This sample code project includes wrapper functions that simplify calling the LAPACK routines, for example, by encapsulating multiple-step workflows into a single function call.\n\nRun the sample code app to see the results of each routine solve different example systems.\n\n### Determine the properties of the coefficient matrix\n\nLAPACK provides different solving routines depending on the properties of the coefficient matrix, *A*:\n\n- Is the coefficient matrix *symmetric*? A symmetric matrix is one that’s equal to its transpose, that is, a matrix that’s identical when swapping its row and column indices. A symmetric matrix is necessarily square. The following is an example of a symmetric matrix:\n\n\n\n- Is the coefficient matrix *positive definite*? A matrix is positive definite if all of its [https:\/\/mathworld.wolfram.com\/Eigenvalue.html] are positive. Confirm whether a matrix is positive definite by calling `spotrf_(_:_:_:_:_:)` to try a [https:\/\/mathworld.wolfram.com\/CholeskyDecomposition.html]. If the factorization fails and returns a positive value, the matrix isn’t positive definite. This sample code project includes the function `isPositiveDefinite(_:dimension:)` to determine whether a matrix is positive definite.\n- Is the coefficient matrix *banded*? A banded matrix has all of its nonzero entries on its main diagonal and an arbitrary number of superdiagonals (above the main diagonal) and subdiagonals (below the main diagonal). The following is an example of a nonsymmetric, banded matrix with two superdiagonals and one subdiagonal:\n\n\n\n- Is the coefficient matrix *tridiagonal*? A tridiagonal matrix has all of its nonzero entries on its main diagonal, its first superdiagonal, and its first subdiagonal. The following is an example of a nonsymmetric, tridiagonal matrix:\n\n\n\nIf the coefficient matrix is *sparse*, that is, most of the entries in the coefficient matrix are zero, Accelerate provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/sparse-solvers-library] library to help solve such systems.\n\n### Select LAPACK variants for data types\n\nThe LAPACK routines in this sample code project are all for real, single-precision matrices. All of the routines are available in single- and double-precision for real and complex values. The first character of a routine name defines the type of data the routine works on. For example:\n\n- `sgels_(_:_:_:_:_:_:_:_:_:_:_:)` — single-precision, real values\n- `dgels_(_:_:_:_:_:_:_:_:_:_:_:)` — double-precision, real values\n- `cgels_(_:_:_:_:_:_:_:_:_:_:_:)` — single-precision, complex values\n- `zgels_(_:_:_:_:_:_:_:_:_:_:_:)` — double-precision, complex values\n\nFor complex matrices, the LAPACK routine variant for real symmetric matrices requires [https:\/\/mathworld.wolfram.com\/HermitianMatrix.html]. For example, the `cptsv_()` routine computes the solution to *Ax = b* for a complex single-precision, Hermitian, tridiagonal coefficient matrix; and `sptsv_()`  computes the solution for a real single-precision, symmetric, tridiagonal coefficient matrix.\n\nThe routines in this sample code project are suitable for solving full rank systems, that is, they have a unique and exact solution.\n\n### Define values in column-major layout\n\nThe LAPACK routines in this article require the matrix data in column-major layout, which means specifying all the terms in the first column, then all of the terms in the second column, the third column, and so on. For example, if there are two columns with three row values each, the routine specifies the three row values for column one, then the three row values for column two, as the following example illustrates:\n\n\n\n```swift\nlet bValues: [Float] = [80, 180, 160,\n                        800, 1800, 1600]\n```\n\nThe routines return the result as column-major, for example, an array that contains `[10.0, 20.0, 30.0, 100.0, 200.0, 300.0]` represents the following matrix:\n\n\n\n### Select the solving routine for the coefficient matrix type\n\nThis sample code project provides Swift wrapper functions to each single-precision LAPACK solving routine. Select the routine that most closely matches the coefficient matrix for the highest performance. The following shows the Swift wrapper functions and the underlying LAPACK routines to solve systems with different coefficient matrices:\n\n- Symmetric\n\n- Positive definite\n\n- Tridiagonal\n\n- Swift wrapper function: `symmetric_positiveDefinite_tridiagonal()`\n- Underlying LAPACK routine: `sptsv_()`\n- Other banded\n\n- Swift wrapper function: `symmetric_positiveDefinite_banded()`\n- Underlying LAPACK routine: `spbsv_()`\n- General\n\n- Swift wrapper function: `symmetric_positiveDefinite_general()`\n- Underlying LAPACK routine: `sposv_()`\n- Indefinite\n\n- General\n\n- Swift wrapper function: `symmetric_indefinite_general()`\n- Underlying LAPACK routine:  `ssysv_()`\n- Nonsymmetric\n\n- Square\n\n- Tridiagonal\n\n- Swift wrapper function: nonsymmetric_tridiagonal()\n- Underlying LAPACK routine: `sgtsv_()`\n- Other banded\n\n- Swift wrapper function: `nonsymmetric_banded()`\n- Underlying LAPACK routine: `sgbsv_()`\n- General\n\n- Swift wrapper function: `nonsymmetric_general()`\n- Underlying LAPACK routine: `sgesv_()`\n- Nonsquare\n\n- QR factorization\n\n- Swift wrapper function: `nonsymmetric_nonsquare()`\n- Underlying LAPACK routine: `sgels_()`\n- Cholesky factorization\n\n- Swift wrapper function: `leastSquares_nonsquare()`\n- Underlying LAPACK routines: `sposv_()` and `ssysv_()`\n\n### Solve for a nonsquare matrix using QR factorization\n\nA system of linear equations with a nonsquare coefficient matrix is either:\n\n- Overdetermined — there are more equations than unknowns, that is, the coefficient matrix has more rows than columns. In this case, the system may not have a solution.\n- Underdetermined — there are more unknowns than equations, that is, the coefficient matrix has more columns than rows. In this case, the system may have infinitely many solutions.\n\nIn these cases, the solution is either not exact (unless the overdetermined system is actually consistent) or not unique. In the case where LAPACK is unable to solve the system, the Swift wrapper functions return `nil`.\n\nThe Swift wrapper function `nonsymmetric_nonsquare(a:dimension:b:rightHandSideCount:)` wraps the LAPACK routine `sgels_(_:_:_:_:_:_:_:_:_:_:_:)`. This routine takes one of two approaches, depending on the system:\n\n- When the coefficient matrix, *A*, has more rows than columns (overdetermined), the routine minimizes the error in *Ax - b* by solving the least squares problem *‖ b-Ax ‖₂*. The following image shows the graph of an overdetermined system with two unknowns and three equations.  `nonsymmetric_nonsquare(a:dimension:b:rightHandSideCount:)`  returns `[1.4615387, 0.7692307, -1.1766968]`, indicating the *x* in *Ax=b* equals  `[1.4615387, 0.7692307]`, and the sum of the residuals squared (that is, `r0² + r1² + r2²` equals `-1.1766968²`). Selecting any other point in the triangle of the three intercepts yields a larger sum of residuals squared.\n\n\n\n\n\n- When the coefficient matrix, *A*, has more columns than rows (underdetermined), the routine finds the smallest *x* that solves the equation *min ‖ x ‖₂* such that *Ax = b*.  The following image shows the graph of *y=x+1*, which is the set of solutions to the illustrated system. The closest point on the line to the origin is at x = -0.5, y = 0.5.\n\n\n\n\n\nThe `sgels_(_:_:_:_:_:_:_:_:_:_:_:)` routine uses [https:\/\/mathworld.wolfram.com\/QRDecomposition.html] for overdetermined systems, and [https:\/\/mathworld.wolfram.com\/LQDecomposition.html] for underdetermined systems.\n\nThe following is an example of an underdetermined system with a coefficient matrix that’s nonsquare:\n\n\n\nThe following code calls `nonsymmetric_nonsquare(a:dimension:b:rightHandSideCount:)` to compute the values of *x*:\n\n```swift\nlet aValues: [Float] = [1, 6, 11,\n                        2, 7, 12,\n                        3, 8, 13,\n                        4, 9, 14,\n                        5, 10, 15]\n\nlet dimension = (m: 3, n: 5)\n\n\/\/\/ The _b_ in _Ax = b_.\nlet bValues: [Float] = [355, 930, 1505]\n\n\/\/\/ Call `nonsymmetric_nonsquare` to compute the _x_ in _Ax = b_.\nlet x = nonsymmetric_nonsquare(a: aValues,\n                               dimension: dimension,\n                               b: bValues,\n                               rightHandSideCount: 1)\n\n\/\/\/ Calculate _b_ using the computed _x_.\nif let x = x {\n    let b = matrixVectorMultiply(matrix: aValues,\n                                 dimension: dimension,\n                                 vector: x)\n    \n    \/\/\/ Prints _b_ in _Ax = b_ using the computed _x_: `~[355, 930, 1505]`.\n    print(\"\\nnonsymmetric_nonsquare: ([355, 930, 1505]) b =\", b)\n}\n```\n\n### Solve for a nonsquare matrix using Cholesky factorization\n\nWhere speed is more important than numerical accuracy, the sample code project provides an alternative to `sgels_(_:_:_:_:_:_:_:_:_:_:_:)`. The `leastSquares_nonsquare(a:dimension:b:)` function exploits the fact that the *x* in *AᵀAx = Aᵀb* equals the *x* in *Ax = b*. This technique creates the square coefficient matrix *AᵀA* and solves with either `symmetric_positiveDefinite_general(a:dimension:b:rightHandSideCount:)` or `symmetric_indefinite_general(a:dimension:b:rightHandSideCount:)`.\n\nThe `leastSquares_nonsquare(a:dimension:b:)` function uses the same problem as   `nonsymmetric_nonsquare(a:dimension:b:rightHandSideCount:)`, but uses [https:\/\/mathworld.wolfram.com\/CholeskyDecomposition.html] when *AᵀA* is positive definite.\n\nThe following is an example of an overdetermined system with a coefficient matrix that’s nonsquare:\n\n\n\nThe following code calls `leastSquares_nonsquare(a:dimension:b:)` to compute the values of *x*:\n\n```swift\nlet aValues: [Float] = [1, 4, 7, 10,\n                        2, 5, 8, 11,\n                        3, 6, 9, 12]\nlet dimension = (m: 4, n: 3)\nlet bValues: [Float] = [194, 455, 716, 977]\n\n\/\/\/ Call `leastSquares_nonsquare` to compute the _x_ in _Ax = b_.\nlet x = leastSquares_nonsquare(a: aValues,\n                               dimension: dimension,\n                               b: bValues)\n\n\/\/\/ Calculate _b_ using the computed _x_.\nif let x = x {\n    let b = matrixVectorMultiply(matrix: aValues,\n                                 dimension: dimension,\n                                 vector: Array(x[0..<3]))\n    \n    \/\/\/ Prints _b_ in _Ax = b_ using the computed _x_: `~[194, 455, 716, 977]`.\n    print(\"\\nleastSquares_nonsquare: b =\", b)\n}\n```\n\n### Solve for a rank-deficient matrix\n\nSystems with a symmetric matrix that’s not full rank, *rank-deficient matrices*, don’t have a single unique solution. For example, the following two multiplications contain different *x* matrices, but yield the same result in *b*:\n\n\n\nIn this case, passing matrix *A* to its most suitable function, `symmetric_indefinite_general(a:dimension:b:rightHandSideCount:)`, returns an error indicating that the routine can’t compute the solution.\n\nOne option to deal with rank-deficiency is to instead solve a nearby problem of full rank by adding a small epsilon value to the matrix to regularize it. The following code adds such an epsilon to diagonal elements in matrix *A*:\n\n```swift\nvar aValues: [Float] = [1, 2, 1,\n                        2, 1, 2,\n                        1, 2, 1]\n\nlet dimension = 3\nlet epsilon = sqrt(Float.ulpOfOne)\nfor i in 0 ..< dimension {\n    aValues[i * dimension + i] += epsilon\n}\n\nlet bValues: [Float] = [80, 100, 80]\n\n\/\/\/ Call `symmetric_indefinite_general` to compute the _x_ in _Ax = b_.\nlet x = symmetric_indefinite_general(a: aValues,\n                                     dimension: dimension,\n                                     b: bValues,\n                                     rightHandSideCount: 1)\n\n\/\/\/ Calculate _b_ using the computed _x_.\nif let x = x {\n    let b = matrixVectorMultiply(matrix: aValues,\n                                 dimension: (m: dimension, n: dimension),\n                                 vector: x)\n    \n    \/\/\/ Prints _b_ in _Ax = b_ using the computed _x_: `~[80, 100, 80]`.\n    print(\"\\nRank-Deficient: b =\", b)\n}\n```\n\nOn return, *x* contains the values `[0.0, 20.0, 40.0]`:\n\n\n\n## Linear Algebra\n\n- **Finding an interpolating polynomial using the Vandermonde method**: Use LAPACK to solve a linear system and find an interpolating polynomial to construct new points between a series of known data points.\n- **Compressing an image using linear algebra**: Reduce the storage size of an image using singular value decomposition (SVD).\n- **BLAS**: Perform common linear algebra operations with Apple’s implementation of the Basic Linear Algebra Subprograms (BLAS).\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use LAPACK to solve a linear system and find an interpolating polynomial to construct new points between a series of known data points.",
          "name" : "Finding an interpolating polynomial using the Vandermonde method",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/finding-an-interpolating-polynomial-using-the-vandermonde-method"
        },
        {
          "description" : "Reduce the storage size of an image using singular value decomposition (SVD).",
          "name" : "Compressing an image using linear algebra",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/compressing-an-image-using-linear-algebra"
        },
        {
          "description" : "Perform common linear algebra operations with Apple’s implementation of the Basic Linear Algebra Subprograms (BLAS).",
          "name" : "BLAS",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/blas-library"
        }
      ],
      "title" : "Linear Algebra"
    }
  ],
  "source" : "appleJSON",
  "title" : "Solving systems of linear equations with LAPACK",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/solving-systems-of-linear-equations-with-lapack"
}