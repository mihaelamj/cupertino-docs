{
  "abstract" : "Create and use a projective transformation to apply a perspective warp to an image.",
  "codeExamples" : [
    {
      "code" : "var format = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 4,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.noneSkipFirst.rawValue))!",
      "language" : "swift"
    },
    {
      "code" : "let backgroundImage =  imageLiteral(resourceName: \"background.jpg\").cgImage(\n    forProposedRect: nil,\n    context: nil,\n    hints: nil)!\nlet backgroundBuffer = try vImage.PixelBuffer<vImage.Interleaved8x4>(\n    cgImage: backgroundImage,\n    cgImageFormat: &format)\n\nlet foregroundImage =  imageLiteral(resourceName: \"foreground.jpg\").cgImage(\n    forProposedRect: nil,\n    context: nil,\n    hints: nil)!\nlet foregroundBuffer = try vImage.PixelBuffer<vImage.Interleaved8x4>(\n    cgImage: foregroundImage,\n    cgImageFormat: &format)\n",
      "language" : "swift"
    },
    {
      "code" : "let warpedBuffer = vImage.PixelBuffer<vImage.Interleaved8x4>(\n    size: backgroundBuffer.size)",
      "language" : "swift"
    },
    {
      "code" : "let imageRequestHandler = VNImageRequestHandler(cgImage: backgroundImage,\n                                                options: [:])\n\nlet requests: [VNRequest] = [VNDetectRectanglesRequest()]\n\ntry imageRequestHandler.perform(requests)\n\nguard let observation = requests.first?.results?.first as? VNRectangleObservation  else {\n    throw vImage.Error.internalError\n}",
      "language" : "swift"
    },
    {
      "code" : "typealias vImagePoint = (Float, Float)\n\nlet dstPoints: [vImagePoint] = {\n    func scalePoint(_ point: CGPoint) -> vImagePoint {\n        return (Float(point.x) * Float(backgroundImage.width),\n                Float(point.y) * Float(backgroundImage.height))\n    }\n    \n    let dstTopLeft: vImagePoint = scalePoint(observation.topLeft)\n    let dstTopRight: vImagePoint = scalePoint(observation.topRight)\n    let dstBottomLeft: vImagePoint = scalePoint(observation.bottomLeft)\n    let dstBottomRight: vImagePoint = scalePoint(observation.bottomRight)\n    \n    return [dstTopLeft, dstTopRight, dstBottomLeft, dstBottomRight]\n}()\n",
      "language" : "swift"
    },
    {
      "code" : "let srcPoints: [vImagePoint] = {\n    let foregroundWidth = Float(foregroundImage.width)\n    let foregroundHeight = Float(foregroundImage.height)\n    \n    let srcTopLeft: (Float, Float) = (0, foregroundHeight)\n    let srcTopRight: (Float, Float) = (foregroundWidth, foregroundHeight)\n    let srcBottomLeft: (Float, Float) = (0, 0)\n    let srcBottomRight: (Float, Float) = (foregroundWidth, 0)\n    \n    return [srcTopLeft, srcTopRight, srcBottomLeft, srcBottomRight]\n}()\n",
      "language" : "swift"
    },
    {
      "code" : "var transform = vImage_PerpsectiveTransform()\nvImageGetPerspectiveWarp(srcPoints, dstPoints, &transform, 0)\n",
      "language" : "swift"
    },
    {
      "code" : "foregroundBuffer.withUnsafePointerToVImageBuffer { src in\n    warpedBuffer.withUnsafePointerToVImageBuffer { dst in\n        \n        var bgColor: [UInt8] = [0, 0, 0, 0]\n        \n        vImagePerspectiveWarp_ARGB8888(\n            src, dst, nil,\n            &transform,\n            vImage_WarpInterpolation(kvImageInterpolationLinear),\n            &bgColor,\n            vImage_Flags(kvImageBackgroundColorFill))\n    }\n}\n",
      "language" : "swift"
    },
    {
      "code" : "backgroundBuffer.alphaComposite(.nonpremultiplied,\n                                topLayer: warpedBuffer,\n                                destination: backgroundBuffer)\n\nlet result = backgroundBuffer.makeCGImage(cgImageFormat: format)\n",
      "language" : "swift"
    }
  ],
  "contentHash" : "0ffcbe7c4f1ea1b900dadacb1c961d223a3ea9cda030212663424a8e42929998",
  "crawledAt" : "2025-12-02T02:01:06Z",
  "id" : "5F1E7EA1-2563-4CDE-8409-ED91959B6283",
  "kind" : "article",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThe vImage library provides a set of functions that allow you create projective-transformation structures and apply them to images. The following image shows the effect of a projective transformation that derives from the four corner points of a perspective distorted rectangle. The image demonstrates how the projective transformation warps the image to match the empty billboard rectangle.\n\n\n\n### Create the vImage buffers that represent the source images\n\nCreate a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure that describes the four-channel, 8-bit-per-channel images that this example uses.\n\nUse separate buffers to store the background and foreground images.\n\nBecause the perspective warp doesn’t work in place (that is, the source and destination buffers must point to different underlying memory), create a third destination buffer.\n\n### Use the Vision framework to find the rectangle corner points\n\nThe [doc:\/\/com.apple.documentation\/documentation\/Vision] framework allows you to find the corner points of the target rectangle. The code below is a simplified example. See [doc:\/\/com.apple.documentation\/documentation\/Vision\/detecting-objects-in-still-images] for additional information.\n\nOn return, `observation` contains the four corner points of the target rectangle.\n\n### Create the source and destination points\n\nUse the values in the Vision [doc:\/\/com.apple.documentation\/documentation\/Vision\/VNRectangleObservation] instance to create a set of points for the vImage warp function. The Vision framework returns normalized coordinates in the range `0...1` with `0` at the bottom-left of the image. The vImage warp function requires coordinates that represent pixel values with `0` at the top-left of the image.\n\nThe destination points refer to the corner points of the target rectangle.\n\nThe source points refer to the bounding box of the foreground image.\n\n### Calculate the projective transformation\n\nCall [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageGetPerspectiveWarp(_:_:_:_:)] to calculate the projective transformation to translate the foreground image to the target rectangle.\n\nOn return, `transform` contains the projective transformation to warp the source points to the destination points.\n\n### Apply the perspective warp\n\nCall [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImagePerspectiveWarp_ARGB8888(_:_:_:_:_:_:_:)] to warp the foreground image to the destination rectangle’s shape and position.\n\n### Composite the warped foreground over the background image\n\nFinally, composite the warped foreground image over the background image.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/transforming-an-image-in-three-dimensions\ncrawled: 2025-12-02T02:01:06Z\n---\n\n# Transforming an image in three dimensions\n\n**Article**\n\nCreate and use a projective transformation to apply a perspective warp to an image.\n\n## Overview\n\nThe vImage library provides a set of functions that allow you create projective-transformation structures and apply them to images. The following image shows the effect of a projective transformation that derives from the four corner points of a perspective distorted rectangle. The image demonstrates how the projective transformation warps the image to match the empty billboard rectangle.\n\n\n\n### Create the vImage buffers that represent the source images\n\nCreate a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure that describes the four-channel, 8-bit-per-channel images that this example uses.\n\n```swift\nvar format = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 4,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.noneSkipFirst.rawValue))!\n```\n\nUse separate buffers to store the background and foreground images.\n\n```swift\nlet backgroundImage =  imageLiteral(resourceName: \"background.jpg\").cgImage(\n    forProposedRect: nil,\n    context: nil,\n    hints: nil)!\nlet backgroundBuffer = try vImage.PixelBuffer<vImage.Interleaved8x4>(\n    cgImage: backgroundImage,\n    cgImageFormat: &format)\n\nlet foregroundImage =  imageLiteral(resourceName: \"foreground.jpg\").cgImage(\n    forProposedRect: nil,\n    context: nil,\n    hints: nil)!\nlet foregroundBuffer = try vImage.PixelBuffer<vImage.Interleaved8x4>(\n    cgImage: foregroundImage,\n    cgImageFormat: &format)\n\n```\n\nBecause the perspective warp doesn’t work in place (that is, the source and destination buffers must point to different underlying memory), create a third destination buffer.\n\n```swift\nlet warpedBuffer = vImage.PixelBuffer<vImage.Interleaved8x4>(\n    size: backgroundBuffer.size)\n```\n\n### Use the Vision framework to find the rectangle corner points\n\nThe [doc:\/\/com.apple.documentation\/documentation\/Vision] framework allows you to find the corner points of the target rectangle. The code below is a simplified example. See [doc:\/\/com.apple.documentation\/documentation\/Vision\/detecting-objects-in-still-images] for additional information.\n\n```swift\nlet imageRequestHandler = VNImageRequestHandler(cgImage: backgroundImage,\n                                                options: [:])\n\nlet requests: [VNRequest] = [VNDetectRectanglesRequest()]\n\ntry imageRequestHandler.perform(requests)\n\nguard let observation = requests.first?.results?.first as? VNRectangleObservation  else {\n    throw vImage.Error.internalError\n}\n```\n\nOn return, `observation` contains the four corner points of the target rectangle.\n\n### Create the source and destination points\n\nUse the values in the Vision [doc:\/\/com.apple.documentation\/documentation\/Vision\/VNRectangleObservation] instance to create a set of points for the vImage warp function. The Vision framework returns normalized coordinates in the range `0...1` with `0` at the bottom-left of the image. The vImage warp function requires coordinates that represent pixel values with `0` at the top-left of the image.\n\nThe destination points refer to the corner points of the target rectangle.\n\n```swift\ntypealias vImagePoint = (Float, Float)\n\nlet dstPoints: [vImagePoint] = {\n    func scalePoint(_ point: CGPoint) -> vImagePoint {\n        return (Float(point.x) * Float(backgroundImage.width),\n                Float(point.y) * Float(backgroundImage.height))\n    }\n    \n    let dstTopLeft: vImagePoint = scalePoint(observation.topLeft)\n    let dstTopRight: vImagePoint = scalePoint(observation.topRight)\n    let dstBottomLeft: vImagePoint = scalePoint(observation.bottomLeft)\n    let dstBottomRight: vImagePoint = scalePoint(observation.bottomRight)\n    \n    return [dstTopLeft, dstTopRight, dstBottomLeft, dstBottomRight]\n}()\n\n```\n\nThe source points refer to the bounding box of the foreground image.\n\n```swift\nlet srcPoints: [vImagePoint] = {\n    let foregroundWidth = Float(foregroundImage.width)\n    let foregroundHeight = Float(foregroundImage.height)\n    \n    let srcTopLeft: (Float, Float) = (0, foregroundHeight)\n    let srcTopRight: (Float, Float) = (foregroundWidth, foregroundHeight)\n    let srcBottomLeft: (Float, Float) = (0, 0)\n    let srcBottomRight: (Float, Float) = (foregroundWidth, 0)\n    \n    return [srcTopLeft, srcTopRight, srcBottomLeft, srcBottomRight]\n}()\n\n```\n\n### Calculate the projective transformation\n\nCall [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageGetPerspectiveWarp(_:_:_:_:)] to calculate the projective transformation to translate the foreground image to the target rectangle.\n\n```swift\nvar transform = vImage_PerpsectiveTransform()\nvImageGetPerspectiveWarp(srcPoints, dstPoints, &transform, 0)\n\n```\n\nOn return, `transform` contains the projective transformation to warp the source points to the destination points.\n\n### Apply the perspective warp\n\nCall [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImagePerspectiveWarp_ARGB8888(_:_:_:_:_:_:_:)] to warp the foreground image to the destination rectangle’s shape and position.\n\n```swift\nforegroundBuffer.withUnsafePointerToVImageBuffer { src in\n    warpedBuffer.withUnsafePointerToVImageBuffer { dst in\n        \n        var bgColor: [UInt8] = [0, 0, 0, 0]\n        \n        vImagePerspectiveWarp_ARGB8888(\n            src, dst, nil,\n            &transform,\n            vImage_WarpInterpolation(kvImageInterpolationLinear),\n            &bgColor,\n            vImage_Flags(kvImageBackgroundColorFill))\n    }\n}\n\n```\n\n### Composite the warped foreground over the background image\n\nFinally, composite the warped foreground image over the background image.\n\n```swift\nbackgroundBuffer.alphaComposite(.nonpremultiplied,\n                                topLayer: warpedBuffer,\n                                destination: backgroundBuffer)\n\nlet result = backgroundBuffer.makeCGImage(cgImageFormat: format)\n\n```\n\n## Computing a projective transformation from source and destination quadrilaterals\n\n- **vImageGetPerspectiveWarp(_:_:_:_:)**: Returns a projective-transformation structure that defines the mapping between a source quadrilateral and a destination quadrilateral.\n- **vImage_PerpsectiveTransform**: A projective-transformation matrix.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Returns a projective-transformation structure that defines the mapping between a source quadrilateral and a destination quadrilateral.",
          "name" : "vImageGetPerspectiveWarp(_:_:_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vImageGetPerspectiveWarp(_:_:_:_:)"
        },
        {
          "description" : "A projective-transformation matrix.",
          "name" : "vImage_PerpsectiveTransform",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vImage_PerpsectiveTransform"
        }
      ],
      "title" : "Computing a projective transformation from source and destination quadrilaterals"
    }
  ],
  "source" : "appleJSON",
  "title" : "Transforming an image in three dimensions",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/transforming-an-image-in-three-dimensions"
}