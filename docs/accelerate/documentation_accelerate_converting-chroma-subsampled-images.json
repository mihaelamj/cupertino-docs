{
  "abstract" : "Create vImage buffers with the correct dimensions to convert to and from images with subsampled chroma information.",
  "codeExamples" : [
    {
      "code" : "var cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 3,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue))!\n\nlet cvImageFormat = vImageCVImageFormat.make(\n    format: .format420YpCbCr8PlanarFullRange,\n    matrix: kvImage_ARGBToYpCbCrMatrix_ITU_R_601_4.pointee,\n    chromaSiting: .center,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    alphaIsOpaqueHint: true)!",
      "language" : "swift"
    },
    {
      "code" : "let cgToCvConverter = try vImageConverter.make(sourceFormat: cgImageFormat,\n                                               destinationFormat: cvImageFormat)",
      "language" : "swift"
    },
    {
      "code" : "let ypCbCr8PlanarBuffers = (0 ..< cgToCvConverter.destinationBufferCount).map { _ in\n    vImage.PixelBuffer<vImage.Planar8>(size: rgbSourceBuffer.size)\n}",
      "language" : "swift"
    },
    {
      "code" : "try cgToCvConverter.convert(from: [rgbSourceBuffer],\n                            to: ypCbCr8PlanarBuffers)",
      "language" : "swift"
    },
    {
      "code" : "let saturation = Float(0.25)\nlet preBias = -128\nlet divisor = 0x1000\nlet postBias = 128 * divisor\nlet factor = Int(saturation * Float(divisor))\n\n\/\/ Define a region of interest that's a quarter of the area of the\n\/\/ luminance channel.\nlet roi = CGRect(x: 0, y: 0,\n                 width: ypCbCr8PlanarBuffers[0].width \/ 2,\n                 height: ypCbCr8PlanarBuffers[0].height \/ 2)\n\n\/\/ Indices 1 and 2 refer to the Cb and Cr buffers, respectively.\nfor index in [1, 2] {\n    ypCbCr8PlanarBuffers[index].withUnsafeRegionOfInterest(roi) { buffer in\n        buffer.multiply(by: factor,\n                        divisor: divisor,\n                        preBias: preBias,\n                        postBias: postBias,\n                        destination: buffer)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "let cvToCgConverter = try vImageConverter.make(sourceFormat: cvImageFormat,\n                                               destinationFormat: cgImageFormat)\n\nlet rgbDestinationBuffer = vImage.PixelBuffer<vImage.Interleaved8x3>(\n    size: ypCbCr8PlanarBuffers.first!.size)\n\ntry cvToCgConverter.convert(from: ypCbCr8PlanarBuffers,\n                            to: [rgbDestinationBuffer])",
      "language" : "swift"
    }
  ],
  "contentHash" : "a872ac2be90a42645e69e502c15f6d82190b3ae0f3376c35e1021108106e7dfc",
  "crawledAt" : "2025-12-05T07:53:03Z",
  "id" : "941F78A0-04C8-4AB3-9AF2-90DEB6392769",
  "kind" : "article",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nWhen you work with video data, you often work with images represented by separate luminance (Y) and chrominance (CbCr) information at different resolutions. The vImage library provides functionality to convert images in this format to an interleaved RGB format, which simplifies applying some image-processing operations.\n\nAlternatively, other image transformations, such as adjusting saturation, require that you convert an RGB image to YCbCr. Reducing the resolution of the chrominance information can also improve the performance of your app because you’re only processing half or a quarter of the number of pixels.\n\n*Chroma subsampling* describes the encoding that compresses image data by reducing the resolution of the chrominance information. Chroma subsampling relies on the fact that human vision is less sensitive to color than luminance.\n\nThe code in this article uses the 4:2:0 subsampling scheme, which means there’s one Cb and one Cr pixel for every four luminance pixels. That is, each chrominance channel is half of the width and half of the height of the luminance channel. For example, 4:2:0 subsampling represents a 4 x 2 image with a 4 x 2 luminance channel and two 2 x 1 chrominance channels:\n\n\n\nThe images below show the 4:2:0 subsampling scheme applied to a photograph. The *Y* luminance channel has the same resolution as the original image. However, the *Cb* and *Cr* chrominance channels have a lower resolution. For each 2 x 2 square of pixels in the luminance channel, the chrominance channels only contain a single pixel. Therefore, the chrominance channels are a quarter of the size of the luminance channel.\n\n\n\n### Define the Core Video and Core Graphics image formats\n\nIf you’re working with [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e] objects, the vImage library provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat_CreateWithCVPixelBuffer(_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat\/make(buffer:)] functions that generate a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat] structure from a Core Video pixel buffer. However, the code in this article defines a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat\/Format\/format420YpCbCr8PlanarFullRange] Core Video image format that describes the YpCbCr image. The code below also defines an 8-bit-per-channel RGB Core Graphics image format:\n\n### Perform the Core Graphics to Core Video conversion\n\nUse the Core Video and Core Graphics image format descriptions to create an any-to-any [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance that converts from Core Graphics to Core Video image format.\n\nThe converter provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/destinationBufferCount] property that you use to generate the correct number of destination buffers. Although the chrominance size is a quarter of the luminance sizes, declare the sizes of all three pixel buffers as the source image size.\n\nIn the code below, `rgbSourceBuffer` is a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] with a format of [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/Interleaved8x3] (that matches the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure above) which contains a source image. Call the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/convert(from:to:)-587gc] method to populate the destination buffers.\n\nOn return, the three pixel buffers in the `ypCbCr8PlanarBuffers` array contain the luminance and two chrominance channels. The image below shows the luminance channel (left), the Cb channel (middle), and the Cr channel (right):\n\n\n\n### Apply an operation to the subsampled chrominance channels\n\nAlthough the two chrominance channels are the same size as the full-sized luminance channel, they only contain a quarter of the data. If you’re applying an image-processing operation to the Cb and Cr channels, use the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/withUnsafeRegionOfInterest(_:_:)] method. This ensures that you’re not processing unused pixels. The code below reduces the saturation of the image using the technique discussed in [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/adjusting-saturation-and-applying-tone-mapping]:\n\nFor more information about limiting the effect of vImage operations to rectangular regions of interest, see [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/applying-vimage-operations-to-regions-of-interest].\n\n### Perform the Core Video to Core Graphics conversion\n\nTo convert the YpCbCr buffers to an RGB buffer, create a converter with the Core Video image format as the source and the Core Graphics image format as the destination. Call the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/convert(from:to:)-587gc] method as above, but specify the `ypCbCr8PlanarBuffers` array as the source and an 8-bit-per-channel interleaved buffer as the destination.\n\nOn return, `rgbDestinationBuffer` contains the desaturated version (right) of the original image (left).\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/accelerate\/converting-chroma-subsampled-images\ncrawled: 2025-12-05T07:53:03Z\n---\n\n# Converting chroma-subsampled images\n\n**Article**\n\nCreate vImage buffers with the correct dimensions to convert to and from images with subsampled chroma information.\n\n## Overview\n\nWhen you work with video data, you often work with images represented by separate luminance (Y) and chrominance (CbCr) information at different resolutions. The vImage library provides functionality to convert images in this format to an interleaved RGB format, which simplifies applying some image-processing operations.\n\nAlternatively, other image transformations, such as adjusting saturation, require that you convert an RGB image to YCbCr. Reducing the resolution of the chrominance information can also improve the performance of your app because you’re only processing half or a quarter of the number of pixels.\n\n*Chroma subsampling* describes the encoding that compresses image data by reducing the resolution of the chrominance information. Chroma subsampling relies on the fact that human vision is less sensitive to color than luminance.\n\nThe code in this article uses the 4:2:0 subsampling scheme, which means there’s one Cb and one Cr pixel for every four luminance pixels. That is, each chrominance channel is half of the width and half of the height of the luminance channel. For example, 4:2:0 subsampling represents a 4 x 2 image with a 4 x 2 luminance channel and two 2 x 1 chrominance channels:\n\n\n\nThe images below show the 4:2:0 subsampling scheme applied to a photograph. The *Y* luminance channel has the same resolution as the original image. However, the *Cb* and *Cr* chrominance channels have a lower resolution. For each 2 x 2 square of pixels in the luminance channel, the chrominance channels only contain a single pixel. Therefore, the chrominance channels are a quarter of the size of the luminance channel.\n\n\n\n### Define the Core Video and Core Graphics image formats\n\nIf you’re working with [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e] objects, the vImage library provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat_CreateWithCVPixelBuffer(_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat\/make(buffer:)] functions that generate a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat] structure from a Core Video pixel buffer. However, the code in this article defines a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageCVImageFormat\/Format\/format420YpCbCr8PlanarFullRange] Core Video image format that describes the YpCbCr image. The code below also defines an 8-bit-per-channel RGB Core Graphics image format:\n\n```swift\nvar cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 3,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue))!\n\nlet cvImageFormat = vImageCVImageFormat.make(\n    format: .format420YpCbCr8PlanarFullRange,\n    matrix: kvImage_ARGBToYpCbCrMatrix_ITU_R_601_4.pointee,\n    chromaSiting: .center,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    alphaIsOpaqueHint: true)!\n```\n\n### Perform the Core Graphics to Core Video conversion\n\nUse the Core Video and Core Graphics image format descriptions to create an any-to-any [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance that converts from Core Graphics to Core Video image format.\n\n```swift\nlet cgToCvConverter = try vImageConverter.make(sourceFormat: cgImageFormat,\n                                               destinationFormat: cvImageFormat)\n```\n\nThe converter provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/destinationBufferCount] property that you use to generate the correct number of destination buffers. Although the chrominance size is a quarter of the luminance sizes, declare the sizes of all three pixel buffers as the source image size.\n\n```swift\nlet ypCbCr8PlanarBuffers = (0 ..< cgToCvConverter.destinationBufferCount).map { _ in\n    vImage.PixelBuffer<vImage.Planar8>(size: rgbSourceBuffer.size)\n}\n```\n\n\n\nIn the code below, `rgbSourceBuffer` is a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] with a format of [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/Interleaved8x3] (that matches the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure above) which contains a source image. Call the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/convert(from:to:)-587gc] method to populate the destination buffers.\n\n```swift\ntry cgToCvConverter.convert(from: [rgbSourceBuffer],\n                            to: ypCbCr8PlanarBuffers)\n```\n\nOn return, the three pixel buffers in the `ypCbCr8PlanarBuffers` array contain the luminance and two chrominance channels. The image below shows the luminance channel (left), the Cb channel (middle), and the Cr channel (right):\n\n\n\n### Apply an operation to the subsampled chrominance channels\n\nAlthough the two chrominance channels are the same size as the full-sized luminance channel, they only contain a quarter of the data. If you’re applying an image-processing operation to the Cb and Cr channels, use the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/withUnsafeRegionOfInterest(_:_:)] method. This ensures that you’re not processing unused pixels. The code below reduces the saturation of the image using the technique discussed in [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/adjusting-saturation-and-applying-tone-mapping]:\n\n```swift\nlet saturation = Float(0.25)\nlet preBias = -128\nlet divisor = 0x1000\nlet postBias = 128 * divisor\nlet factor = Int(saturation * Float(divisor))\n\n\/\/ Define a region of interest that's a quarter of the area of the\n\/\/ luminance channel.\nlet roi = CGRect(x: 0, y: 0,\n                 width: ypCbCr8PlanarBuffers[0].width \/ 2,\n                 height: ypCbCr8PlanarBuffers[0].height \/ 2)\n\n\/\/ Indices 1 and 2 refer to the Cb and Cr buffers, respectively.\nfor index in [1, 2] {\n    ypCbCr8PlanarBuffers[index].withUnsafeRegionOfInterest(roi) { buffer in\n        buffer.multiply(by: factor,\n                        divisor: divisor,\n                        preBias: preBias,\n                        postBias: postBias,\n                        destination: buffer)\n    }\n}\n```\n\nFor more information about limiting the effect of vImage operations to rectangular regions of interest, see [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/applying-vimage-operations-to-regions-of-interest].\n\n### Perform the Core Video to Core Graphics conversion\n\nTo convert the YpCbCr buffers to an RGB buffer, create a converter with the Core Video image format as the source and the Core Graphics image format as the destination. Call the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/convert(from:to:)-587gc] method as above, but specify the `ypCbCr8PlanarBuffers` array as the source and an 8-bit-per-channel interleaved buffer as the destination.\n\n```swift\nlet cvToCgConverter = try vImageConverter.make(sourceFormat: cvImageFormat,\n                                               destinationFormat: cgImageFormat)\n\nlet rgbDestinationBuffer = vImage.PixelBuffer<vImage.Interleaved8x3>(\n    size: ypCbCr8PlanarBuffers.first!.size)\n\ntry cvToCgConverter.convert(from: ypCbCr8PlanarBuffers,\n                            to: [rgbDestinationBuffer])\n```\n\nOn return, `rgbDestinationBuffer` contains the desaturated version (right) of the original image (left).\n\n\n\n## Converting any-to-any\n\n- **Building a basic image conversion workflow**: Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.\n- **Functions that perform any-to-any conversion**: Convert between Core Video or Core Graphics image data of arbitrary color spaces and bit depths.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.",
          "name" : "Building a basic image conversion workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/building-a-basic-image-conversion-workflow"
        },
        {
          "description" : "Convert between Core Video or Core Graphics image data of arbitrary color spaces and bit depths.",
          "name" : "Functions that perform any-to-any conversion",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/functions-that-perform-any-to-any-conversion"
        }
      ],
      "title" : "Converting any-to-any"
    }
  ],
  "source" : "appleJSON",
  "title" : "Converting chroma-subsampled images",
  "url" : "https:\/\/developer.apple.com\/documentation\/accelerate\/converting-chroma-subsampled-images"
}