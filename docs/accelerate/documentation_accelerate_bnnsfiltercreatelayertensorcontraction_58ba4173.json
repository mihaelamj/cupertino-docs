{
  "abstract" : "Returns a new tensor-contraction layer.",
  "codeExamples" : [
    {
      "code" : "\"a_ijp, b_ijq -> o_pq\" ",
      "language" : "c"
    },
    {
      "code" : "\"a_ij -> c_ji\"",
      "language" : "c"
    },
    {
      "code" : "\"a_ij*, b_ij -> c_*\"",
      "language" : "swift"
    },
    {
      "code" : "let aValues: [Float] = [1, 2]\nlet bValues: [Float] = [3, 4]\n\nlet inputDescriptor = BNNSNDArrayDescriptor(flags: BNNSNDArrayFlags(0),\n                                            layout: BNNSDataLayoutRowMajorMatrix,\n                                            size: (2, 1, 0, 0, 0, 0, 0, 0),\n                                            stride: (0, 0, 0, 0, 0, 0, 0, 0),\n                                            data: nil,\n                                            data_type: .float,\n                                            table_data: nil,\n                                            table_data_type: .float,\n                                            data_scale: 1,\n                                            data_bias: 0)\n\nvar outputValues = [Float](repeating: -1,\n                           count: aValues.count * bValues.count)\n\nlet outputDescriptor = BNNSNDArrayDescriptor(flags: BNNSNDArrayFlags(0),\n                                             layout: BNNSDataLayoutRowMajorMatrix,\n                                             size: (2, 2, 0, 0, 0, 0, 0, 0),\n                                             stride: (0, 0, 0, 0, 0, 0, 0, 0),\n                                             data: nil,\n                                             data_type: .float,\n                                             table_data: nil,\n                                             table_data_type: .float,\n                                             data_scale: 1,\n                                             data_bias: 0)",
      "language" : "swift"
    },
    {
      "code" : "let operation = \"a_ip, b_iq -> o_pq\"\n\noperation.withCString { operationPtr in\n    \n    var layer_params = BNNSLayerParametersTensorContraction(operation: operationPtr,\n                                                            alpha: 10,\n                                                            beta: 0,\n                                                            iA_desc: inputDescriptor,\n                                                            iB_desc: inputDescriptor,\n                                                            o_desc: outputDescriptor)\n    \n    let layer = BNNSFilterCreateLayerTensorContraction(&layer_params,\n                                                       nil)\n    \n    BNNSFilterApplyTwoInput(layer, aValues, bValues, &outputValues)\n}",
      "language" : "swift"
    },
    {
      "code" : "[ 30.0,    \/\/ 10.0 * (1.0 * 3.0) \n  40.0,    \/\/ 10.0 * (1.0 * 4.0)\n  60.0,    \/\/ 10.0 * (2.0 * 3.0)\n  80.0 ]   \/\/ 10.0 * (2.0 * 4.0)",
      "language" : "swift"
    }
  ],
  "contentHash" : "d4191eb6cefa4e4e9eda4fde25c8457b1bb0d4ec0f9dffe68f1b4b33e5d39d91",
  "crawledAt" : "2025-12-02T22:15:56Z",
  "declaration" : {
    "code" : "func BNNSFilterCreateLayerTensorContraction(_ layer_params: UnsafePointer<BNNSLayerParametersTensorContraction>, _ filter_params: UnsafePointer<BNNSFilterParameters>?) -> BNNSFilter?",
    "language" : "swift"
  },
  "id" : "A3D13188-AB54-47DE-945E-9C6735719EF1",
  "kind" : "function",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Discussion\n\nA tensor contraction is the summation of the elements of two tensors over one or more indices. BNNS represents this in the `operation` parameter of a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSLayerParametersTensorContraction] structure as a string using Einstein’s summation convention.\n\nFor example, the string:\n\nRepresents the operation:\n\n\n\nInputs may be either trained parameters or inputs.\n\nIf the name preceding the underscore is `“w”`, the operation assumes the tensor is a trained parameter (weights). Otherwise the operation assumes the tensor is an input (the letter has no other effect and may be whatever you wish). At most, one of the inputs may be a trained parameter.\n\nIf the names of the left-hand side inputs match, the operation assumes the contraction is of a tensor with itself, for example, to calculate the Gram matrix or a dot product.\n\nIn the case where one of the inputs is a weight or the operation is a contraction of a tensor with itself, use [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApply(_:_:_:)] or [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApplyBatch(_:_:_:_:_:_:)]. If the operation has two inputs, use [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApplyTwoInput(_:_:_:_:)] or [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApplyTwoInputBatch(_:_:_:_:_:_:_:_:)].\n\nUse a tensor contraction layer to also copy from one layer to another with a permutation of indices. For example, the string:\n\nRepresents the operation:\n\n\n\nBNNS tensor contraction supports broadcasting by using `“*”` as the final index, for example, the following string matches additional indices of `a` and `c`.\n\n`“*”` always represents indices that occur on both sides of the operation, and never an index over which contraction performs summation.\n\nA `“*”` on one side only matches indices represent by a `“*”` on the other side, and never indices represented by a letter.\n\nNote that where contraction matches index letters, the sizes of the corresponding dimensions for the tensors must also match, unless one tensor has size 1. In that case the operation repeats (broadcasts) to match the corresponding dimension.\n\n### Perform a Tensor Contraction\n\nThe following code performs a tensor contraction over two 2 x 1 row-major matrices, writing the result to a 2 x 2 row-major matrix.\n\nFirst, define the input and output matrices and their descriptors:\n\nUse the following code to perform the contraction:\n\nOn return, `outputValues` contains the following values:",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/accelerate\/bnnsfiltercreatelayertensorcontraction(_:_:)\ncrawled: 2025-12-02T22:15:56Z\n---\n\n# BNNSFilterCreateLayerTensorContraction(_:_:)\n\n**Function**\n\nReturns a new tensor-contraction layer.\n\n## Declaration\n\n```swift\nfunc BNNSFilterCreateLayerTensorContraction(_ layer_params: UnsafePointer<BNNSLayerParametersTensorContraction>, _ filter_params: UnsafePointer<BNNSFilterParameters>?) -> BNNSFilter?\n```\n\n## Parameters\n\n- **layer_params**: Layer parameters.\n- **filter_params**: The filter runtime parameters.\n\n## Discussion\n\nA tensor contraction is the summation of the elements of two tensors over one or more indices. BNNS represents this in the `operation` parameter of a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSLayerParametersTensorContraction] structure as a string using Einstein’s summation convention.\n\nFor example, the string:\n\n```c\n\"a_ijp, b_ijq -> o_pq\" \n```\n\nRepresents the operation:\n\n\n\nInputs may be either trained parameters or inputs.\n\nIf the name preceding the underscore is `“w”`, the operation assumes the tensor is a trained parameter (weights). Otherwise the operation assumes the tensor is an input (the letter has no other effect and may be whatever you wish). At most, one of the inputs may be a trained parameter.\n\nIf the names of the left-hand side inputs match, the operation assumes the contraction is of a tensor with itself, for example, to calculate the Gram matrix or a dot product.\n\nIn the case where one of the inputs is a weight or the operation is a contraction of a tensor with itself, use [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApply(_:_:_:)] or [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApplyBatch(_:_:_:_:_:_:)]. If the operation has two inputs, use [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApplyTwoInput(_:_:_:_:)] or [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSFilterApplyTwoInputBatch(_:_:_:_:_:_:_:_:)].\n\nUse a tensor contraction layer to also copy from one layer to another with a permutation of indices. For example, the string:\n\n```c\n\"a_ij -> c_ji\"\n```\n\nRepresents the operation:\n\n\n\nBNNS tensor contraction supports broadcasting by using `“*”` as the final index, for example, the following string matches additional indices of `a` and `c`.\n\n```swift\n\"a_ij*, b_ij -> c_*\"\n```\n\n`“*”` always represents indices that occur on both sides of the operation, and never an index over which contraction performs summation.\n\nA `“*”` on one side only matches indices represent by a `“*”` on the other side, and never indices represented by a letter.\n\nNote that where contraction matches index letters, the sizes of the corresponding dimensions for the tensors must also match, unless one tensor has size 1. In that case the operation repeats (broadcasts) to match the corresponding dimension.\n\n### Perform a Tensor Contraction\n\nThe following code performs a tensor contraction over two 2 x 1 row-major matrices, writing the result to a 2 x 2 row-major matrix.\n\nFirst, define the input and output matrices and their descriptors:\n\n```swift\nlet aValues: [Float] = [1, 2]\nlet bValues: [Float] = [3, 4]\n\nlet inputDescriptor = BNNSNDArrayDescriptor(flags: BNNSNDArrayFlags(0),\n                                            layout: BNNSDataLayoutRowMajorMatrix,\n                                            size: (2, 1, 0, 0, 0, 0, 0, 0),\n                                            stride: (0, 0, 0, 0, 0, 0, 0, 0),\n                                            data: nil,\n                                            data_type: .float,\n                                            table_data: nil,\n                                            table_data_type: .float,\n                                            data_scale: 1,\n                                            data_bias: 0)\n\nvar outputValues = [Float](repeating: -1,\n                           count: aValues.count * bValues.count)\n\nlet outputDescriptor = BNNSNDArrayDescriptor(flags: BNNSNDArrayFlags(0),\n                                             layout: BNNSDataLayoutRowMajorMatrix,\n                                             size: (2, 2, 0, 0, 0, 0, 0, 0),\n                                             stride: (0, 0, 0, 0, 0, 0, 0, 0),\n                                             data: nil,\n                                             data_type: .float,\n                                             table_data: nil,\n                                             table_data_type: .float,\n                                             data_scale: 1,\n                                             data_bias: 0)\n```\n\nUse the following code to perform the contraction:\n\n```swift\nlet operation = \"a_ip, b_iq -> o_pq\"\n\noperation.withCString { operationPtr in\n    \n    var layer_params = BNNSLayerParametersTensorContraction(operation: operationPtr,\n                                                            alpha: 10,\n                                                            beta: 0,\n                                                            iA_desc: inputDescriptor,\n                                                            iB_desc: inputDescriptor,\n                                                            o_desc: outputDescriptor)\n    \n    let layer = BNNSFilterCreateLayerTensorContraction(&layer_params,\n                                                       nil)\n    \n    BNNSFilterApplyTwoInput(layer, aValues, bValues, &outputValues)\n}\n```\n\nOn return, `outputValues` contains the following values:\n\n```swift\n[ 30.0,    \/\/ 10.0 * (1.0 * 3.0) \n  40.0,    \/\/ 10.0 * (1.0 * 4.0)\n  60.0,    \/\/ 10.0 * (2.0 * 3.0)\n  80.0 ]   \/\/ 10.0 * (2.0 * 4.0)\n```\n\n## Tensor contraction layers\n\n- **BNNSLayerParametersTensorContraction**: A structure that contains the parameters of a tensor-contraction layer.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A structure that contains the parameters of a tensor-contraction layer.",
          "name" : "BNNSLayerParametersTensorContraction",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSLayerParametersTensorContraction"
        }
      ],
      "title" : "Tensor contraction layers"
    }
  ],
  "source" : "appleJSON",
  "title" : "BNNSFilterCreateLayerTensorContraction(_:_:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/accelerate\/bnnsfiltercreatelayertensorcontraction(_:_:)"
}