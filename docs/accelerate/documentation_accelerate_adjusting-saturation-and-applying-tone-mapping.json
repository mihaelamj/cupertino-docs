{
  "abstract" : "Convert an RGB image to discrete luminance and chrominance channels, and apply color and contrast treatments.",
  "codeExamples" : [
    {
      "code" : "private lazy var argbSource: vImage.PixelBuffer<vImage.Interleaved8x4> = {\n    return try! vImage.PixelBuffer<vImage.Interleaved8x4>(cgImage: sourceCGImage,\n                                                          cgImageFormat: &format)\n}()\n\nprivate lazy var argbDestination: vImage.PixelBuffer<vImage.Interleaved8x4> = {\n    return vImage.PixelBuffer<vImage.Interleaved8x4>(width: self.width,\n                                                     height: self.height)\n}()",
      "language" : "swift"
    },
    {
      "code" : "struct Yp8CbCr8PixelBuffers {\n    \/\/\/ The luminance pixel buffer.\n    let yp: vImage.PixelBuffer<vImage.Planar8>\n    \n    \/\/\/ The chrominance pixel buffer.\n    let cbcr: vImage.PixelBuffer<vImage.Planar8>\n    \n    init(width: Int, height: Int) {\n        yp = vImage.PixelBuffer<vImage.Planar8>(width: width,\n                                                height: height)\n        \n        cbcr = vImage.PixelBuffer<vImage.Planar8>(width: width,\n                                                  height: height \/ 2)\n    }",
      "language" : "swift"
    },
    {
      "code" : "lazy private var ypCbCrPreTransformBuffers: Yp8CbCr8PixelBuffers = {\n    return Yp8CbCr8PixelBuffers(width: width, height: height)\n}()\n\nlazy private var ypCbCrPostTransformBuffers: Yp8CbCr8PixelBuffers = {\n    return Yp8CbCr8PixelBuffers(width: width, height: height)\n}()",
      "language" : "swift"
    },
    {
      "code" : "private let pixelRange = vImage_YpCbCrPixelRange(Yp_bias: 0,\n                                                 CbCr_bias: 128,\n                                                 YpRangeMax: 255,\n                                                 CbCrRangeMax: 255,\n                                                 YpMax: 255,\n                                                 YpMin: 0,\n                                                 CbCrMax: 255,\n                                                 CbCrMin: 0)",
      "language" : "swift"
    },
    {
      "code" : "private var argbToYpCbCr: vImage_ARGBToYpCbCr {\n    var outInfo = vImage_ARGBToYpCbCr()\n    \n    withUnsafePointer(to: pixelRange) { ptr in\n        _ = vImageConvert_ARGBToYpCbCr_GenerateConversion(\n            kvImage_ARGBToYpCbCrMatrix_ITU_R_709_2,\n            ptr,\n            &outInfo,\n            kvImageARGB8888,\n            kvImage420Yp8_CbCr8,\n            vImage_Flags(kvImageNoFlags))\n    }\n    return outInfo\n}",
      "language" : "swift"
    },
    {
      "code" : "func convert(from source: vImage.PixelBuffer<vImage.Interleaved8x4>) {\n    source.withUnsafePointerToVImageBuffer { src in\n        withUnsafePointer(to: argbToYpCbCr) { info in\n            self.yp.withUnsafePointerToVImageBuffer { yp in\n                self.cbcr.withUnsafePointerToVImageBuffer { cbcr in\n                    _ = vImageConvert_ARGB8888To420Yp8_CbCr8(\n                        src,\n                        yp,\n                        cbcr,\n                        info,\n                        [3, 2, 1, 0],\n                        vImage_Flags(kvImagePrintDiagnosticsToConsole))\n                }\n            }\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "if saturation > 1 {\n    applyGammaToCbCr(gamma: 1 \/ saturation)\n} else {\n    applyLinearToCbCr(saturation: saturation)\n}\n\napplyGammaToLuma(lumaGamma: lumaGamma)",
      "language" : "swift"
    },
    {
      "code" : "\/\/\/ Reduces saturation.\nprivate func applyLinearToCbCr(saturation: Float) {\n    let preBias = -128\n    let divisor = 0x1000\n    let postBias = 128 * divisor\n    \n    let factor = Int(saturation * Float(divisor))\n    \n    ypCbCrPreTransformBuffers.cbcr.multiply(by: factor,\n                                            divisor: divisor,\n                                            preBias: preBias,\n                                            postBias: postBias,\n                                            destination: ypCbCrPostTransformBuffers.cbcr)\n    \n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/\/ Increases saturation.\nprivate func applyGammaToCbCr(gamma: Float) {\n    \n    \/\/ Convert 8-bit CbCr values to 32-bit.\n    ypCbCrPreTransformBuffers.cbcr.convert(to: gammaDestination)\n    \n    \/\/ Scale 32-bit values from `0.0 ... 1.0` to `-1.0 ... 1.0`.\n    gammaDestination.multiply(by: 2,\n                              preBias: 0, postBias: -1,\n                              destination: gammaDestination)\n    \n    \/\/ Apply gamma to 32-bit values.\n    gammaDestination.applyGamma(.fullPrecision(gamma),\n                                destination: gammaDestination)\n    \n    \/\/ Scale 32-bit transformed values from `-1.0 ... 1.0` to `0 ... 1.0`.\n    gammaDestination.multiply(by: 0.5,\n                              preBias: 1, postBias: 0,\n                              destination: gammaDestination)\n    \n    \/\/ Convert 32-bit transformed CbCr values to 8-bit.\n    gammaDestination.convert(to: ypCbCrPostTransformBuffers.cbcr)\n}",
      "language" : "swift"
    },
    {
      "code" : "private func applyGammaToLuma(lumaGamma: Float) {\n    \n    ypCbCrPreTransformBuffers.yp.applyGamma(\n        linearParameters: (scale: 1, bias: 0),\n        exponentialParameters: (scale: 1, preBias: 0, gamma: lumaGamma, postBias: 0),\n        boundary: 0,\n        destination: ypCbCrPostTransformBuffers.yp)\n    \n}",
      "language" : "swift"
    },
    {
      "code" : "private var ypCbCrToARGB: vImage_YpCbCrToARGB {\n    var outInfo = vImage_YpCbCrToARGB()\n    \n    withUnsafePointer(to: pixelRange) { ptr in\n        _ = vImageConvert_YpCbCrToARGB_GenerateConversion(\n            kvImage_YpCbCrToARGBMatrix_ITU_R_709_2,\n            ptr,\n            &outInfo,\n            kvImage420Yp8_CbCr8,\n            kvImageARGB8888,\n            vImage_Flags(kvImageNoFlags))\n    }\n    \n    return outInfo\n}",
      "language" : "swift"
    },
    {
      "code" : "func convert(to destination: vImage.PixelBuffer<vImage.Interleaved8x4>) {\n    _ = withUnsafePointer(to: ypCbCrToARGB) { info in\n        self.cbcr.withUnsafePointerToVImageBuffer { cbcrDest in\n            self.yp.withUnsafePointerToVImageBuffer { ypDest in\n                destination.withUnsafePointerToVImageBuffer { argbDest in\n                    vImageConvert_420Yp8_CbCr8ToARGB8888(\n                        ypDest,\n                        cbcrDest,\n                        argbDest,\n                        info,\n                        [3, 2, 1, 0],\n                        255,\n                        vImage_Flags(kvImagePrintDiagnosticsToConsole))\n                }\n            }\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "extension vImage.PixelBuffer where Format == vImage.Interleaved8x4 {\n    \n    enum Remap {\n        case linearToSRGB\n        case sRGBToLinear\n        \n        var gammaType: vImage.Gamma {\n            switch self {\n                case .linearToSRGB:\n                    return .sRGBForwardHalfPrecision\n                case .sRGBToLinear:\n                    return .sRGBReverseHalfPrecision\n            }\n        }\n    }\n    \n    func remap(_ remap: Remap) {\n        self.applyGamma(remap.gammaType,\n                        intermediateBuffer: nil,\n                        destination: self)\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "0858dd52f025456058bf327dca66e44a96ae116329247f5f843b097788b7e18a",
  "crawledAt" : "2025-12-02T15:27:43Z",
  "id" : "5785665A-2920-47EA-954D-C16FB6879115",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThis sample code project allows you to apply saturation adjustments to an image without affecting luminosity, and change the luminance response curve without affecting color.\n\nMany image-processing techniques, such as saturation adjustment and tone mapping, are simpler to implement when you can work on an image’s luminance data separately from its color data. This article explains how you can convert an RGB image — with its pixels represented as red, green, and blue values — to YpCbCr, which stores luminance and chrominance discretely. The *Yp* in YpCbCr refers to the luminance, and the *Cb* and *Cr* refer to the blue-luminance difference, and red-luminance difference, respectively.\n\nThis sample app converts an ARGB image to YpCbCr and applies adjustments based on user-interface controls. When you decrease the saturation, the sample app applies gamma to the CbCr buffers. When you increase the saturation, the sample app scales the CbCr buffers, and when you change contrast, the sample app applies gamma to the Yp buffer.\n\nThe following images show two photographs with a range of saturation adjustments that illustrate the variety of color changes you can make using the sample code app:\n\n\n\nBefore exploring the code, try building and running the app to familiarize yourself with the effect of the different transformations on the image.\n\n### Create source and destination ARGB pixel buffers\n\nThe sample declares two 8-bit, four-channel pixel buffers. The `argbSource` pixel buffer stores the source image, and the `argbDestination` stores the transformed image.\n\n### Create the YpCbCr buffers\n\nThe conversion routine that this sample uses creates a YpCbCr result with a chroma of 4:2:0, which means there is one Cb and one Cr pixel for every four luminance pixels. That is, each chrominance buffer is half of the width, and half of the height of the luminance channel. Reducing the resolution for the chrominance channels is known as *chroma subsampling*, and it relies on the fact that human vision is less sensitive to color than luminance.\n\nThe image below shows that a 4 x 2 image is represented by a 4 x 2 luminance channel, but each chrominance channel is 2 x 1 pixels:\n\n\n\nTo support the 4:2:0 YpCbCr representation of the source image, the sample project defines a `Yp8CbCr8PixelBuffers` structure that contains two pixel buffers. The luminance buffer is the same size as the source buffer. The chrominance buffer’s height is half the source height, and its width is the same as the source width. This size enables the chrominance buffer to store both the Cb and Cr data as interleaved pixels.\n\nThe following code creates two `Yp8CbCr8PixelBuffers` structures that contain a representation of the source image before and after saturation adjustment and tone mapping:\n\n### Define the RGB-to-YpCbCr conversion\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_YpCbCrPixelRange] structure defines the range and clamping information for the destination YpCbCr format. The destination buffer is 8-bit, therefore, the minimum and maximum values for luminance and chrominance are `0` and `255`, respectively. `CbCr_bias` specifies the middle of the CbCr range (that is, where the blue-luminance difference or red-luminance difference is `0`), and the sample sets that to `128`.\n\nThe `Yp8CbCr8PixelBuffers` structure uses [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_ARGBToYpCbCr_GenerateConversion(_:_:_:_:_:_:)] to generate the conversion from ARGB to YpCbCr. The sample calculates the conversion of RGB values using the conversion matrix for ITU Recommendation BT.709-2.\n\n### Perform the RGB-to-YpCbCr conversion\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_ARGB8888To420Yp8_CbCr8(_:_:_:_:_:_:)] function populates two vImage buffers — one that contains luminance data and one that contains chrominance data — from the contents of a single ARGB buffer.\n\nThe following image shows the luminance result on the left and the interleaved chrominance result on the right. Because the interleaved chrominance result contains both the Cb and Cr information, it’s half the height of the luminance channel, but has the same width.\n\n\n\n### Apply saturation adjustment to the image\n\nThis sample uses two techniques to adjust saturation:\n\nIt performs the tone mapping by applying gamma to the luminance channel.\n\n### Multiply CbCr values to decrease saturation\n\nThe following formula describes how to adjust the color saturation of a YpCbCr image, without affecting its luminance:\n\n\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-4q614] function performs this math on the source chrominance buffer. The function passes the saturation to the matrix multiply function as a single-element matrix, and passes the chrominance buffer as the source and destination.\n\nThe following image shows two photographs, from left to right, with saturations of `0.25`, `0.75`, and `1.0` (that is, the rightmost image has an unchanged saturation).\n\n\n\n### Apply gamma to CbCr to increase saturation\n\nThe simple linear adjustment that [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v] provides is fine for desaturating an image, however, when increasing saturation, multiplication can clip the CbCr values, leading to areas of solid color. An alternative technique to increase saturation is to apply an exponential adjustment. The [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/applyGamma(_:destination:)] function applies a gamma value to the CbCr values to increase saturation.\n\nThe following image shows two photographs, from left to right, with a saturation of 1.0 (that is, the leftmost image has an unchanged saturation), 1.5, and 2.0:\n\n\n\nWhen decreasing the saturation, the gamma function is not appropriate because pixels with very saturated color will desaturate very little, or not at all.\n\n### Apply gamma to luminance to perform tone mapping\n\nThe sample app adjusts the contrast of an image, with a technique known as *tone mapping*, by applying a gamma adjustment to the luminance channel.\n\nAdjusting contrast is discussed in [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/adjusting-the-brightness-and-contrast-of-an-image], however, applying a gamma adjustment to red, green, and blue channels changes both the color and tonal values.\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/applyGamma(linearParameters:exponentialParameters:boundary:destination:)-8r0ro] function applies a piecewise gamma tranformation on the planar `ypDestination` buffer, which contains the luminance data.\n\nThe following image shows two photographs, from left to right, with a gamma applied to the luminance channel of 2.5, 0.0 (that is, the center image is unchanged), and 0.5:\n\n\n\n### Define the YpCbCr-to-RGB conversion\n\nAfter the sample app completes the YpCbCr representation, it converts the YpCbCr data to RGB. The process is very similar to the RGB to YpCbCr conversion and uses the same pixel range, but the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_YpCbCrToARGB_GenerateConversion(_:_:_:_:_:_:)] function generates the conversion.\n\nThe `Yp8CbCr8PixelBuffers` structure exposes a method for converting to ARGB.\n\n### Correct gamma before applying operations\n\nMany vImage operations provide optimal results when working on images with a linear response curve. The sample app includes a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Toggle] control that applies a reciprocal gamma to the sRGB image, performs the saturation adjustments and tone mapping, and applies the original gamma.\n\nvImage provides predefined gamma functions for converting from linear to sRGB, and from sRGB to linear. The sample implements the following function as an extension to [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] and remaps the buffer’s contents in-place in the specified direction:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-saturation-and-applying-tone-mapping\ncrawled: 2025-12-02T15:27:43Z\n---\n\n# Adjusting saturation and applying tone mapping\n\n**Sample Code**\n\nConvert an RGB image to discrete luminance and chrominance channels, and apply color and contrast treatments.\n\n## Overview\n\nThis sample code project allows you to apply saturation adjustments to an image without affecting luminosity, and change the luminance response curve without affecting color.\n\nMany image-processing techniques, such as saturation adjustment and tone mapping, are simpler to implement when you can work on an image’s luminance data separately from its color data. This article explains how you can convert an RGB image — with its pixels represented as red, green, and blue values — to YpCbCr, which stores luminance and chrominance discretely. The *Yp* in YpCbCr refers to the luminance, and the *Cb* and *Cr* refer to the blue-luminance difference, and red-luminance difference, respectively.\n\nThis sample app converts an ARGB image to YpCbCr and applies adjustments based on user-interface controls. When you decrease the saturation, the sample app applies gamma to the CbCr buffers. When you increase the saturation, the sample app scales the CbCr buffers, and when you change contrast, the sample app applies gamma to the Yp buffer.\n\nThe following images show two photographs with a range of saturation adjustments that illustrate the variety of color changes you can make using the sample code app:\n\n\n\nBefore exploring the code, try building and running the app to familiarize yourself with the effect of the different transformations on the image.\n\n### Create source and destination ARGB pixel buffers\n\nThe sample declares two 8-bit, four-channel pixel buffers. The `argbSource` pixel buffer stores the source image, and the `argbDestination` stores the transformed image.\n\n```swift\nprivate lazy var argbSource: vImage.PixelBuffer<vImage.Interleaved8x4> = {\n    return try! vImage.PixelBuffer<vImage.Interleaved8x4>(cgImage: sourceCGImage,\n                                                          cgImageFormat: &format)\n}()\n\nprivate lazy var argbDestination: vImage.PixelBuffer<vImage.Interleaved8x4> = {\n    return vImage.PixelBuffer<vImage.Interleaved8x4>(width: self.width,\n                                                     height: self.height)\n}()\n```\n\n### Create the YpCbCr buffers\n\nThe conversion routine that this sample uses creates a YpCbCr result with a chroma of 4:2:0, which means there is one Cb and one Cr pixel for every four luminance pixels. That is, each chrominance buffer is half of the width, and half of the height of the luminance channel. Reducing the resolution for the chrominance channels is known as *chroma subsampling*, and it relies on the fact that human vision is less sensitive to color than luminance.\n\nThe image below shows that a 4 x 2 image is represented by a 4 x 2 luminance channel, but each chrominance channel is 2 x 1 pixels:\n\n\n\nTo support the 4:2:0 YpCbCr representation of the source image, the sample project defines a `Yp8CbCr8PixelBuffers` structure that contains two pixel buffers. The luminance buffer is the same size as the source buffer. The chrominance buffer’s height is half the source height, and its width is the same as the source width. This size enables the chrominance buffer to store both the Cb and Cr data as interleaved pixels.\n\n```swift\nstruct Yp8CbCr8PixelBuffers {\n    \/\/\/ The luminance pixel buffer.\n    let yp: vImage.PixelBuffer<vImage.Planar8>\n    \n    \/\/\/ The chrominance pixel buffer.\n    let cbcr: vImage.PixelBuffer<vImage.Planar8>\n    \n    init(width: Int, height: Int) {\n        yp = vImage.PixelBuffer<vImage.Planar8>(width: width,\n                                                height: height)\n        \n        cbcr = vImage.PixelBuffer<vImage.Planar8>(width: width,\n                                                  height: height \/ 2)\n    }\n```\n\nThe following code creates two `Yp8CbCr8PixelBuffers` structures that contain a representation of the source image before and after saturation adjustment and tone mapping:\n\n```swift\nlazy private var ypCbCrPreTransformBuffers: Yp8CbCr8PixelBuffers = {\n    return Yp8CbCr8PixelBuffers(width: width, height: height)\n}()\n\nlazy private var ypCbCrPostTransformBuffers: Yp8CbCr8PixelBuffers = {\n    return Yp8CbCr8PixelBuffers(width: width, height: height)\n}()\n```\n\n### Define the RGB-to-YpCbCr conversion\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_YpCbCrPixelRange] structure defines the range and clamping information for the destination YpCbCr format. The destination buffer is 8-bit, therefore, the minimum and maximum values for luminance and chrominance are `0` and `255`, respectively. `CbCr_bias` specifies the middle of the CbCr range (that is, where the blue-luminance difference or red-luminance difference is `0`), and the sample sets that to `128`.\n\n```swift\nprivate let pixelRange = vImage_YpCbCrPixelRange(Yp_bias: 0,\n                                                 CbCr_bias: 128,\n                                                 YpRangeMax: 255,\n                                                 CbCrRangeMax: 255,\n                                                 YpMax: 255,\n                                                 YpMin: 0,\n                                                 CbCrMax: 255,\n                                                 CbCrMin: 0)\n```\n\nThe `Yp8CbCr8PixelBuffers` structure uses [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_ARGBToYpCbCr_GenerateConversion(_:_:_:_:_:_:)] to generate the conversion from ARGB to YpCbCr. The sample calculates the conversion of RGB values using the conversion matrix for ITU Recommendation BT.709-2.\n\n```swift\nprivate var argbToYpCbCr: vImage_ARGBToYpCbCr {\n    var outInfo = vImage_ARGBToYpCbCr()\n    \n    withUnsafePointer(to: pixelRange) { ptr in\n        _ = vImageConvert_ARGBToYpCbCr_GenerateConversion(\n            kvImage_ARGBToYpCbCrMatrix_ITU_R_709_2,\n            ptr,\n            &outInfo,\n            kvImageARGB8888,\n            kvImage420Yp8_CbCr8,\n            vImage_Flags(kvImageNoFlags))\n    }\n    return outInfo\n}\n```\n\n### Perform the RGB-to-YpCbCr conversion\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_ARGB8888To420Yp8_CbCr8(_:_:_:_:_:_:)] function populates two vImage buffers — one that contains luminance data and one that contains chrominance data — from the contents of a single ARGB buffer.\n\n```swift\nfunc convert(from source: vImage.PixelBuffer<vImage.Interleaved8x4>) {\n    source.withUnsafePointerToVImageBuffer { src in\n        withUnsafePointer(to: argbToYpCbCr) { info in\n            self.yp.withUnsafePointerToVImageBuffer { yp in\n                self.cbcr.withUnsafePointerToVImageBuffer { cbcr in\n                    _ = vImageConvert_ARGB8888To420Yp8_CbCr8(\n                        src,\n                        yp,\n                        cbcr,\n                        info,\n                        [3, 2, 1, 0],\n                        vImage_Flags(kvImagePrintDiagnosticsToConsole))\n                }\n            }\n        }\n    }\n}\n```\n\nThe following image shows the luminance result on the left and the interleaved chrominance result on the right. Because the interleaved chrominance result contains both the Cb and Cr information, it’s half the height of the luminance channel, but has the same width.\n\n\n\n### Apply saturation adjustment to the image\n\nThis sample uses two techniques to adjust saturation:\n\n- Multiply CbCr values to decrease saturation.\n- Apply gamma to CbCr to increase saturation.\n\nIt performs the tone mapping by applying gamma to the luminance channel.\n\n```swift\nif saturation > 1 {\n    applyGammaToCbCr(gamma: 1 \/ saturation)\n} else {\n    applyLinearToCbCr(saturation: saturation)\n}\n\napplyGammaToLuma(lumaGamma: lumaGamma)\n```\n\n### Multiply CbCr values to decrease saturation\n\nThe following formula describes how to adjust the color saturation of a YpCbCr image, without affecting its luminance:\n\n\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-4q614] function performs this math on the source chrominance buffer. The function passes the saturation to the matrix multiply function as a single-element matrix, and passes the chrominance buffer as the source and destination.\n\n```swift\n\/\/\/ Reduces saturation.\nprivate func applyLinearToCbCr(saturation: Float) {\n    let preBias = -128\n    let divisor = 0x1000\n    let postBias = 128 * divisor\n    \n    let factor = Int(saturation * Float(divisor))\n    \n    ypCbCrPreTransformBuffers.cbcr.multiply(by: factor,\n                                            divisor: divisor,\n                                            preBias: preBias,\n                                            postBias: postBias,\n                                            destination: ypCbCrPostTransformBuffers.cbcr)\n    \n}\n```\n\nThe following image shows two photographs, from left to right, with saturations of `0.25`, `0.75`, and `1.0` (that is, the rightmost image has an unchanged saturation).\n\n\n\n### Apply gamma to CbCr to increase saturation\n\nThe simple linear adjustment that [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v] provides is fine for desaturating an image, however, when increasing saturation, multiplication can clip the CbCr values, leading to areas of solid color. An alternative technique to increase saturation is to apply an exponential adjustment. The [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/applyGamma(_:destination:)] function applies a gamma value to the CbCr values to increase saturation.\n\n```swift\n\/\/\/ Increases saturation.\nprivate func applyGammaToCbCr(gamma: Float) {\n    \n    \/\/ Convert 8-bit CbCr values to 32-bit.\n    ypCbCrPreTransformBuffers.cbcr.convert(to: gammaDestination)\n    \n    \/\/ Scale 32-bit values from `0.0 ... 1.0` to `-1.0 ... 1.0`.\n    gammaDestination.multiply(by: 2,\n                              preBias: 0, postBias: -1,\n                              destination: gammaDestination)\n    \n    \/\/ Apply gamma to 32-bit values.\n    gammaDestination.applyGamma(.fullPrecision(gamma),\n                                destination: gammaDestination)\n    \n    \/\/ Scale 32-bit transformed values from `-1.0 ... 1.0` to `0 ... 1.0`.\n    gammaDestination.multiply(by: 0.5,\n                              preBias: 1, postBias: 0,\n                              destination: gammaDestination)\n    \n    \/\/ Convert 32-bit transformed CbCr values to 8-bit.\n    gammaDestination.convert(to: ypCbCrPostTransformBuffers.cbcr)\n}\n```\n\nThe following image shows two photographs, from left to right, with a saturation of 1.0 (that is, the leftmost image has an unchanged saturation), 1.5, and 2.0:\n\n\n\nWhen decreasing the saturation, the gamma function is not appropriate because pixels with very saturated color will desaturate very little, or not at all.\n\n### Apply gamma to luminance to perform tone mapping\n\nThe sample app adjusts the contrast of an image, with a technique known as *tone mapping*, by applying a gamma adjustment to the luminance channel.\n\nAdjusting contrast is discussed in [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/adjusting-the-brightness-and-contrast-of-an-image], however, applying a gamma adjustment to red, green, and blue channels changes both the color and tonal values.\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/applyGamma(linearParameters:exponentialParameters:boundary:destination:)-8r0ro] function applies a piecewise gamma tranformation on the planar `ypDestination` buffer, which contains the luminance data.\n\n```swift\nprivate func applyGammaToLuma(lumaGamma: Float) {\n    \n    ypCbCrPreTransformBuffers.yp.applyGamma(\n        linearParameters: (scale: 1, bias: 0),\n        exponentialParameters: (scale: 1, preBias: 0, gamma: lumaGamma, postBias: 0),\n        boundary: 0,\n        destination: ypCbCrPostTransformBuffers.yp)\n    \n}\n```\n\nThe following image shows two photographs, from left to right, with a gamma applied to the luminance channel of 2.5, 0.0 (that is, the center image is unchanged), and 0.5:\n\n\n\n### Define the YpCbCr-to-RGB conversion\n\nAfter the sample app completes the YpCbCr representation, it converts the YpCbCr data to RGB. The process is very similar to the RGB to YpCbCr conversion and uses the same pixel range, but the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_YpCbCrToARGB_GenerateConversion(_:_:_:_:_:_:)] function generates the conversion.\n\n```swift\nprivate var ypCbCrToARGB: vImage_YpCbCrToARGB {\n    var outInfo = vImage_YpCbCrToARGB()\n    \n    withUnsafePointer(to: pixelRange) { ptr in\n        _ = vImageConvert_YpCbCrToARGB_GenerateConversion(\n            kvImage_YpCbCrToARGBMatrix_ITU_R_709_2,\n            ptr,\n            &outInfo,\n            kvImage420Yp8_CbCr8,\n            kvImageARGB8888,\n            vImage_Flags(kvImageNoFlags))\n    }\n    \n    return outInfo\n}\n```\n\nThe `Yp8CbCr8PixelBuffers` structure exposes a method for converting to ARGB.\n\n```swift\nfunc convert(to destination: vImage.PixelBuffer<vImage.Interleaved8x4>) {\n    _ = withUnsafePointer(to: ypCbCrToARGB) { info in\n        self.cbcr.withUnsafePointerToVImageBuffer { cbcrDest in\n            self.yp.withUnsafePointerToVImageBuffer { ypDest in\n                destination.withUnsafePointerToVImageBuffer { argbDest in\n                    vImageConvert_420Yp8_CbCr8ToARGB8888(\n                        ypDest,\n                        cbcrDest,\n                        argbDest,\n                        info,\n                        [3, 2, 1, 0],\n                        255,\n                        vImage_Flags(kvImagePrintDiagnosticsToConsole))\n                }\n            }\n        }\n    }\n}\n```\n\n### Correct gamma before applying operations\n\nMany vImage operations provide optimal results when working on images with a linear response curve. The sample app includes a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Toggle] control that applies a reciprocal gamma to the sRGB image, performs the saturation adjustments and tone mapping, and applies the original gamma.\n\nvImage provides predefined gamma functions for converting from linear to sRGB, and from sRGB to linear. The sample implements the following function as an extension to [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] and remaps the buffer’s contents in-place in the specified direction:\n\n```swift\nextension vImage.PixelBuffer where Format == vImage.Interleaved8x4 {\n    \n    enum Remap {\n        case linearToSRGB\n        case sRGBToLinear\n        \n        var gammaType: vImage.Gamma {\n            switch self {\n                case .linearToSRGB:\n                    return .sRGBForwardHalfPrecision\n                case .sRGBToLinear:\n                    return .sRGBReverseHalfPrecision\n            }\n        }\n    }\n    \n    func remap(_ remap: Remap) {\n        self.applyGamma(remap.gammaType,\n                        intermediateBuffer: nil,\n                        destination: self)\n    }\n}\n```\n\n## Color and Tone Adjustment\n\n- **Adjusting the brightness and contrast of an image**: Use a gamma function to apply a linear or exponential curve.\n- **Applying tone curve adjustments to images**: Use the vImage library’s polynomial transform to apply tone curve adjustments to images.\n- **Adjusting the hue of an image**: Convert an image to L*a*b* color space and apply hue adjustment.\n- **Specifying histograms with vImage**: Calculate the histogram of one image, and apply it to a second image.\n- **Enhancing image contrast with histogram manipulation**: Enhance and adjust the contrast of an image with histogram equalization and contrast stretching.\n- **Histogram**: Calculate or manipulate an image’s histogram.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use a gamma function to apply a linear or exponential curve.",
          "name" : "Adjusting the brightness and contrast of an image",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-the-brightness-and-contrast-of-an-image"
        },
        {
          "description" : "Use the vImage library’s polynomial transform to apply tone curve adjustments to images.",
          "name" : "Applying tone curve adjustments to images",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-tone-curve-adjustments-to-images"
        },
        {
          "description" : "Convert an image to L*a*b* color space and apply hue adjustment.",
          "name" : "Adjusting the hue of an image",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-the-hue-of-an-image"
        },
        {
          "description" : "Calculate the histogram of one image, and apply it to a second image.",
          "name" : "Specifying histograms with vImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/specifying-histograms-with-vimage"
        },
        {
          "description" : "Enhance and adjust the contrast of an image with histogram equalization and contrast stretching.",
          "name" : "Enhancing image contrast with histogram manipulation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/enhancing-image-contrast-with-histogram-manipulation"
        },
        {
          "description" : "Calculate or manipulate an image’s histogram.",
          "name" : "Histogram",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/histogram"
        }
      ],
      "title" : "Color and Tone Adjustment"
    }
  ],
  "source" : "appleJSON",
  "title" : "Adjusting saturation and applying tone mapping",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-saturation-and-applying-tone-mapping"
}