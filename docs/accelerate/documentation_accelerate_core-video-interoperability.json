{
  "abstract" : "Pass image data between Core Video and vImage.",
  "codeExamples" : [
    {
      "code" : "class VerticalReflectImageProcessorKernelCopy: CIImageProcessorKernel {\n    \n    static var cgImageFormat = vImage_CGImageFormat(\n        bitsPerComponent: 8,\n        bitsPerPixel: 32,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.noneSkipLast.rawValue),\n        renderingIntent: .defaultIntent)!\n    \n    static let cvImageFormat = vImageCVImageFormat.make(\n        format: .format32BGRA,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        alphaIsOpaqueHint: true)!\n    \n    override class var outputFormat: CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func formatForInput(at input: Int32) -> CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func process(with inputs: [CIImageProcessorInput]?,\n                                arguments: [String: Any]?,\n                                output: CIImageProcessorOutput) throws {\n        \n        guard\n            let input = inputs?.first,\n            let inputPixelBuffer = input.pixelBuffer,\n            let outputPixelBuffer = output.pixelBuffer else {\n            return\n        }\n        \n        var sourceBuffer = vImage_Buffer()\n        vImageBuffer_InitWithCVPixelBuffer(&sourceBuffer,\n                                           &cgImageFormat,\n                                           inputPixelBuffer,\n                                           cvImageFormat,\n                                           nil,\n                                           vImage_Flags(kvImageNoFlags))\n        \n        var destinationBuffer = vImage_Buffer()\n        vImageBuffer_Init(&destinationBuffer,\n                          sourceBuffer.height,\n                          sourceBuffer.width,\n                          cgImageFormat.bitsPerPixel,\n                          vImage_Flags(kvImageNoFlags))\n        \n        defer {\n            sourceBuffer.free()\n            destinationBuffer.free()\n        }\n        \n        vImageVerticalReflect_ARGB8888(&sourceBuffer,\n                                       &destinationBuffer,\n                                       vImage_Flags(kvImageNoFlags))\n        \n        vImageBuffer_CopyToCVPixelBuffer(&destinationBuffer,\n                                         &cgImageFormat,\n                                         outputPixelBuffer,\n                                         cvImageFormat,\n                                         nil,\n                                         vImage_Flags(kvImageNoFlags))\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "class VerticalReflectImageProcessorKernelNoCopy: CIImageProcessorKernel {\n    \n    static var cgImageFormat = vImage_CGImageFormat(\n        bitsPerComponent: 8,\n        bitsPerPixel: 32,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.noneSkipLast.rawValue),\n        renderingIntent: .defaultIntent)!\n    \n    static let cvImageFormat = vImageCVImageFormat.make(\n        format: .format32BGRA,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        alphaIsOpaqueHint: true)!\n    \n    static let converterCVtoCG = try! vImageConverter\n        .make(sourceFormat: cvImageFormat,\n              destinationFormat: cgImageFormat)\n    \n    static let converterCGtoCV = try! vImageConverter\n        .make(sourceFormat: cgImageFormat,\n              destinationFormat: cvImageFormat)\n    \n    override class var outputFormat: CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func formatForInput(at input: Int32) -> CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func process(with inputs: [CIImageProcessorInput]?,\n                                arguments: [String: Any]?,\n                                output: CIImageProcessorOutput) throws {\n        \n        guard\n            let input = inputs?.first,\n            let inputPixelBuffer = input.pixelBuffer,\n            let outputPixelBuffer = output.pixelBuffer else {\n            return\n        }\n        \n        CVPixelBufferLockBaseAddress(inputPixelBuffer,\n                                     CVPixelBufferLockFlags.readOnly)\n        CVPixelBufferLockBaseAddress(outputPixelBuffer,\n                                     CVPixelBufferLockFlags(rawValue: 0))\n        \n        defer {\n            CVPixelBufferUnlockBaseAddress(inputPixelBuffer,\n                                           CVPixelBufferLockFlags.readOnly)\n            CVPixelBufferUnlockBaseAddress(outputPixelBuffer,\n                                           CVPixelBufferLockFlags(rawValue: 0))\n        }\n        \n        var sourceBuffer = vImage_Buffer()\n        vImageBuffer_InitForCopyFromCVPixelBuffer(\n            &sourceBuffer,\n            converterCVtoCG,\n            inputPixelBuffer,\n            vImage_Flags(kvImageNoAllocate))\n        \n        var destinationBuffer = vImage_Buffer()\n        vImageBuffer_InitForCopyToCVPixelBuffer(\n            &destinationBuffer,\n            converterCGtoCV,\n            outputPixelBuffer,\n            vImage_Flags(kvImageNoAllocate))\n        \n        \/\/ `CVPixelBufferGetBaseAddress(inputPixelBuffer) == sourceBuffer.data`.\n        \/\/ `CVPixelBufferGetBaseAddress(outputPixelBuffer) == destinationBuffer.data`\n        \n        vImageVerticalReflect_ARGB8888(&sourceBuffer,\n                                       &destinationBuffer,\n                                       vImage_Flags(kvImageNoFlags))\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "206e22c2909fad75ec26a8c002a3c78f9ab63c124080425d1194103f979021dd",
  "crawledAt" : "2025-12-02T15:37:24Z",
  "id" : "F997A43A-994A-46AA-8237-A2C90048797C",
  "kind" : "collection",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThe vImage library provides two approaches for working with Core Video pixel buffers:\n\n### Copying data between the vImage library and Core Video\n\nUse the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)] functions to copy and convert data between vImage and Core Video.\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)] function allocates new memory and, after you finish with the buffer, call [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_Buffer\/free()] to avoid memory leaks.\n\nThe following code shows an example of a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel] that reflects an image vertically. The example calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)] to initialize the source vImage buffer with a copy of the input [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e] instance’s data. The code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)] to copy the destination vImage buffer’s contents to the output [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e] instance.\n\nThe code uses a defer statement to deallocate the source and destination vImage buffers after the image-processing operation completes.\n\n### Sharing data between the vImage library and Core Video\n\nUse the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)] functions to share data between vImage and Core Video. Both of these functions require a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance that defines the vImage buffer’s Core Graphics image format and the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instance’s Core Video format.\n\nBecause the vImage functions don’t allocate any additional memory, you don’t need to deallocate the vImage buffer memory. However, you need to lock and unlock the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances during the image-processing operation using [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferLockBaseAddress(_:_:)] and [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferUnlockBaseAddress(_:_:)], respectively.\n\nThe following code shows an example of a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel] that reflects an image vertically. In this example, the base address of the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances and the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_Buffer\/data] property of their corresponding vImage buffer point to the same memory. The image data in the [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorInput] and [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorOutput] parameters don’t require conversion, and the code works directly on the pixel buffers.\n\nThe code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)] with a Core-Video-to-Core-Graphics converter to initialize the source vImage buffer.\n\nThe code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)] with a Core-Graphics-to-Core-Video converter to initialize the destination vImage buffer.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/core-video-interoperability\ncrawled: 2025-12-02T15:37:24Z\n---\n\n# Core Video interoperability\n\n**API Collection**\n\nPass image data between Core Video and vImage.\n\n## Overview\n\nThe vImage library provides two approaches for working with Core Video pixel buffers:\n\n- Use the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)] to copy and convert data between vImage buffers and Core Video pixel buffers with a single function call. This approach provides a simple API if you need to convert between image formats.\n- Use the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)] functions to create vImage buffers that reference the data in Core Video pixel buffers. This approach allows you to work directly with the underlying data if you don’t need to convert between image formats.\n\n### Copying data between the vImage library and Core Video\n\nUse the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)] functions to copy and convert data between vImage and Core Video.\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)] function allocates new memory and, after you finish with the buffer, call [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_Buffer\/free()] to avoid memory leaks.\n\nThe following code shows an example of a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel] that reflects an image vertically. The example calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)] to initialize the source vImage buffer with a copy of the input [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e] instance’s data. The code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)] to copy the destination vImage buffer’s contents to the output [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e] instance.\n\nThe code uses a defer statement to deallocate the source and destination vImage buffers after the image-processing operation completes.\n\n```swift\nclass VerticalReflectImageProcessorKernelCopy: CIImageProcessorKernel {\n    \n    static var cgImageFormat = vImage_CGImageFormat(\n        bitsPerComponent: 8,\n        bitsPerPixel: 32,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.noneSkipLast.rawValue),\n        renderingIntent: .defaultIntent)!\n    \n    static let cvImageFormat = vImageCVImageFormat.make(\n        format: .format32BGRA,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        alphaIsOpaqueHint: true)!\n    \n    override class var outputFormat: CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func formatForInput(at input: Int32) -> CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func process(with inputs: [CIImageProcessorInput]?,\n                                arguments: [String: Any]?,\n                                output: CIImageProcessorOutput) throws {\n        \n        guard\n            let input = inputs?.first,\n            let inputPixelBuffer = input.pixelBuffer,\n            let outputPixelBuffer = output.pixelBuffer else {\n            return\n        }\n        \n        var sourceBuffer = vImage_Buffer()\n        vImageBuffer_InitWithCVPixelBuffer(&sourceBuffer,\n                                           &cgImageFormat,\n                                           inputPixelBuffer,\n                                           cvImageFormat,\n                                           nil,\n                                           vImage_Flags(kvImageNoFlags))\n        \n        var destinationBuffer = vImage_Buffer()\n        vImageBuffer_Init(&destinationBuffer,\n                          sourceBuffer.height,\n                          sourceBuffer.width,\n                          cgImageFormat.bitsPerPixel,\n                          vImage_Flags(kvImageNoFlags))\n        \n        defer {\n            sourceBuffer.free()\n            destinationBuffer.free()\n        }\n        \n        vImageVerticalReflect_ARGB8888(&sourceBuffer,\n                                       &destinationBuffer,\n                                       vImage_Flags(kvImageNoFlags))\n        \n        vImageBuffer_CopyToCVPixelBuffer(&destinationBuffer,\n                                         &cgImageFormat,\n                                         outputPixelBuffer,\n                                         cvImageFormat,\n                                         nil,\n                                         vImage_Flags(kvImageNoFlags))\n    }\n}\n```\n\n### Sharing data between the vImage library and Core Video\n\nUse the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)] functions to share data between vImage and Core Video. Both of these functions require a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance that defines the vImage buffer’s Core Graphics image format and the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instance’s Core Video format.\n\nBecause the vImage functions don’t allocate any additional memory, you don’t need to deallocate the vImage buffer memory. However, you need to lock and unlock the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances during the image-processing operation using [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferLockBaseAddress(_:_:)] and [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferUnlockBaseAddress(_:_:)], respectively.\n\nThe following code shows an example of a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel] that reflects an image vertically. In this example, the base address of the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances and the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_Buffer\/data] property of their corresponding vImage buffer point to the same memory. The image data in the [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorInput] and [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorOutput] parameters don’t require conversion, and the code works directly on the pixel buffers.\n\nThe code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)] with a Core-Video-to-Core-Graphics converter to initialize the source vImage buffer.\n\nThe code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)] with a Core-Graphics-to-Core-Video converter to initialize the destination vImage buffer.\n\n```swift\nclass VerticalReflectImageProcessorKernelNoCopy: CIImageProcessorKernel {\n    \n    static var cgImageFormat = vImage_CGImageFormat(\n        bitsPerComponent: 8,\n        bitsPerPixel: 32,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.noneSkipLast.rawValue),\n        renderingIntent: .defaultIntent)!\n    \n    static let cvImageFormat = vImageCVImageFormat.make(\n        format: .format32BGRA,\n        colorSpace: CGColorSpaceCreateDeviceRGB(),\n        alphaIsOpaqueHint: true)!\n    \n    static let converterCVtoCG = try! vImageConverter\n        .make(sourceFormat: cvImageFormat,\n              destinationFormat: cgImageFormat)\n    \n    static let converterCGtoCV = try! vImageConverter\n        .make(sourceFormat: cgImageFormat,\n              destinationFormat: cvImageFormat)\n    \n    override class var outputFormat: CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func formatForInput(at input: Int32) -> CIFormat {\n        CIFormat.BGRA8\n    }\n    \n    override class func process(with inputs: [CIImageProcessorInput]?,\n                                arguments: [String: Any]?,\n                                output: CIImageProcessorOutput) throws {\n        \n        guard\n            let input = inputs?.first,\n            let inputPixelBuffer = input.pixelBuffer,\n            let outputPixelBuffer = output.pixelBuffer else {\n            return\n        }\n        \n        CVPixelBufferLockBaseAddress(inputPixelBuffer,\n                                     CVPixelBufferLockFlags.readOnly)\n        CVPixelBufferLockBaseAddress(outputPixelBuffer,\n                                     CVPixelBufferLockFlags(rawValue: 0))\n        \n        defer {\n            CVPixelBufferUnlockBaseAddress(inputPixelBuffer,\n                                           CVPixelBufferLockFlags.readOnly)\n            CVPixelBufferUnlockBaseAddress(outputPixelBuffer,\n                                           CVPixelBufferLockFlags(rawValue: 0))\n        }\n        \n        var sourceBuffer = vImage_Buffer()\n        vImageBuffer_InitForCopyFromCVPixelBuffer(\n            &sourceBuffer,\n            converterCVtoCG,\n            inputPixelBuffer,\n            vImage_Flags(kvImageNoAllocate))\n        \n        var destinationBuffer = vImage_Buffer()\n        vImageBuffer_InitForCopyToCVPixelBuffer(\n            &destinationBuffer,\n            converterCGtoCV,\n            outputPixelBuffer,\n            vImage_Flags(kvImageNoAllocate))\n        \n        \/\/ `CVPixelBufferGetBaseAddress(inputPixelBuffer) == sourceBuffer.data`.\n        \/\/ `CVPixelBufferGetBaseAddress(outputPixelBuffer) == destinationBuffer.data`\n        \n        vImageVerticalReflect_ARGB8888(&sourceBuffer,\n                                       &destinationBuffer,\n                                       vImage_Flags(kvImageNoFlags))\n    }\n}\n```\n\n## Copying Core Video pixel buffer data to vImage buffers\n\n- **vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)**: Initializes a vImage buffer with a copy of the contents of a Core Video pixel buffer.\n\n## Copying and converting data between vImage buffers and Core Video pixel buffers\n\n- **vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)**: Copies the contents of a vImage buffer to a Core Video pixel buffer.\n\n## Initializing vImage buffers that reference Core Video pixel buffer data\n\n- **vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)**: Initializes an array of vImage buffers in the order necessary to copy from a Core Video pixel buffer.\n- **vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)**: Initializes an array of vImage buffers in the order necessary to copy to a Core Video pixel buffer.\n\n## Managing Core Video image formats\n\n- **Core Video image format utilities**: Create, copy, and query Core Video image format descriptions.\n\n## Core Video Interoperation\n\n- **Using vImage pixel buffers to generate video effects**: Render real-time video effects with the vImage Pixel Buffer.\n- **Integrating vImage pixel buffers into a Core Image workflow**: Share image data between Core Video pixel buffers and vImage buffers to integrate vImage operations into a Core Image workflow.\n- **Applying vImage operations to video sample buffers**: Use the vImage convert-any-to-any functionality to perform real-time image processing of video frames streamed from your device’s camera.\n- **Improving the quality of quantized images with dithering**: Apply dithering to simulate colors that are unavailable in reduced bit depths.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Initializes a vImage buffer with a copy of the contents of a Core Video pixel buffer.",
          "name" : "vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vImageBuffer_InitWithCVPixelBuffer(_:_:_:_:_:_:)"
        }
      ],
      "title" : "Copying Core Video pixel buffer data to vImage buffers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Copies the contents of a vImage buffer to a Core Video pixel buffer.",
          "name" : "vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vImageBuffer_CopyToCVPixelBuffer(_:_:_:_:_:_:)"
        }
      ],
      "title" : "Copying and converting data between vImage buffers and Core Video pixel buffers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Initializes an array of vImage buffers in the order necessary to copy from a Core Video pixel buffer.",
          "name" : "vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vImageBuffer_InitForCopyFromCVPixelBuffer(_:_:_:_:)"
        },
        {
          "description" : "Initializes an array of vImage buffers in the order necessary to copy to a Core Video pixel buffer.",
          "name" : "vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vImageBuffer_InitForCopyToCVPixelBuffer(_:_:_:_:)"
        }
      ],
      "title" : "Initializing vImage buffers that reference Core Video pixel buffer data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create, copy, and query Core Video image format descriptions.",
          "name" : "Core Video image format utilities",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/core-video-image-format-utilities"
        }
      ],
      "title" : "Managing Core Video image formats"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render real-time video effects with the vImage Pixel Buffer.",
          "name" : "Using vImage pixel buffers to generate video effects",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/using-vimage-pixel-buffers-to-generate-video-effects"
        },
        {
          "description" : "Share image data between Core Video pixel buffers and vImage buffers to integrate vImage operations into a Core Image workflow.",
          "name" : "Integrating vImage pixel buffers into a Core Image workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/integrating-vimage-pixel-buffers-into-a-core-image-workflow"
        },
        {
          "description" : "Use the vImage convert-any-to-any functionality to perform real-time image processing of video frames streamed from your device’s camera.",
          "name" : "Applying vImage operations to video sample buffers",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-vimage-operations-to-video-sample-buffers"
        },
        {
          "description" : "Apply dithering to simulate colors that are unavailable in reduced bit depths.",
          "name" : "Improving the quality of quantized images with dithering",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/improving-the-quality-of-quantized-images-with-dithering"
        }
      ],
      "title" : "Core Video Interoperation"
    }
  ],
  "source" : "appleJSON",
  "title" : "Core Video interoperability",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/core-video-interoperability"
}