{
  "codeExamples" : [

  ],
  "contentHash" : "2011e2000dc0773614a3f5d773ce999c0502feebaae39c01fd4c69c2b8840cbf",
  "crawledAt" : "2025-12-02T01:41:12Z",
  "declaration" : {
    "code" : "var BNNSActivationFunctionReLU6: BNNSActivationFunction { get }",
    "language" : "swift"
  },
  "id" : "F06CC2A0-67EB-47B9-997B-CA80A2F0DFA8",
  "kind" : "unknown",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionReLU6\ncrawled: 2025-12-02T01:41:12Z\n---\n\n# BNNSActivationFunctionReLU6 | Apple Developer Documentation\n\n- [ Accelerate ](\/documentation\/accelerate)\n\n- [ BNNSActivationFunctionReLU6 ](\/documentation\/Accelerate\/BNNSActivationFunctionReLU6)\n\n-  BNNSActivationFunctionReLU6 \n\nGlobal Variable# BNNSActivationFunctionReLU6\n\niOS 16.4+iPadOS 16.4+Mac Catalyst 16.4+macOS 13.3+tvOS 16.4+visionOS 1.0+watchOS 9.4+\n\n```\nvar BNNSActivationFunctionReLU6: BNNSActivationFunction { get }\n```\n\n## [See Also](\/documentation\/Accelerate\/BNNSActivationFunctionReLU6#see-also)\n\n### [Raw Values](\/documentation\/Accelerate\/BNNSActivationFunctionReLU6#Raw-Values)\n\n[`init(UInt32)`](\/documentation\/accelerate\/bnnsactivationfunction\/init(_:))[`init(rawValue: UInt32)`](\/documentation\/accelerate\/bnnsactivationfunction\/init(rawvalue:))[`var rawValue: UInt32`](\/documentation\/accelerate\/bnnsactivationfunction\/rawvalue)[`var BNNSActivationFunctionAbs: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctionabs)Deprecated[`var BNNSActivationFunctionCELU: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctioncelu)An activation function that evaluates the continuously differentiable exponential linear units (CELU) on its input.[`var BNNSActivationFunctionClampedLeakyRectifiedLinear: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctionclampedleakyrectifiedlinear)An activation function that returns its input clamped to beta when that is greater than or equal to zero, otherwise it returns its input multiplied by alpha clamped to beta.[`var BNNSActivationFunctionELU: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctionelu)An activation function that evaluates the exponential linear units (ELU) on its input.[`var BNNSActivationFunctionErf: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctionerf)[`var BNNSActivationFunctionGELU: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctiongelu)[`var BNNSActivationFunctionGELUApproximation: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctiongeluapproximation)An activation function that evaluates the Gaussian error linear units (GELU) approximation on its input.[`var BNNSActivationFunctionGELUApproximation2: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctiongeluapproximation2)An activation function that provides a fast evaluation of the Gaussian error linear units (GELU) approximation on its input.[`var BNNSActivationFunctionGELUApproximationSigmoid: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctiongeluapproximationsigmoid)[`var BNNSActivationFunctionGumbel: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctiongumbel)An activation function that returns random numbers from the Gumbel distribution.[`var BNNSActivationFunctionGumbelMax: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctiongumbelmax)An activation function that returns random numbers from the Gumbel distribution.[`var BNNSActivationFunctionHardShrink: BNNSActivationFunction`](\/documentation\/accelerate\/bnnsactivationfunctionhardshrink)An activation function that returns zero when the absolute input is less than alpha, otherwise it returns its input.",
  "sections" : [
    {
      "content" : "",
      "title" : "See Also"
    }
  ],
  "source" : "appleWebKit",
  "title" : "BNNSActivationFunctionReLU6 | Apple Developer Documentation",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionReLU6"
}