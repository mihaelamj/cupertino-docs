{
  "abstract" : "Convert an image to L*a*b* color space and apply hue adjustment.",
  "codeExamples" : [
    {
      "code" : "var labImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 3,\n    colorSpace: CGColorSpace(name: CGColorSpace.genericLab)!,\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue),\n    renderingIntent: .defaultIntent)!",
      "language" : "swift"
    },
    {
      "code" : "let source = try vImage.PixelBuffer\n    .makeDynamicPixelBufferAndCGImageFormat(cgImage: sourceCGImage)",
      "language" : "swift"
    },
    {
      "code" : "let rgbToLab = try vImageConverter.make(sourceFormat: source.cgImageFormat,\n                                        destinationFormat: labImageFormat)",
      "language" : "swift"
    },
    {
      "code" : "labInterleavedSource = vImage.PixelBuffer<vImage.Interleaved8x3>(size: size)",
      "language" : "swift"
    },
    {
      "code" : "try rgbToLab.convert(from: source.pixelBuffer,\n                     to: labInterleavedSource)",
      "language" : "swift"
    },
    {
      "code" : "labPlanarDestination = vImage.PixelBuffer<vImage.Planar8x3>(size: size)",
      "language" : "swift"
    },
    {
      "code" : "labInterleavedSource.deinterleave(destination: labPlanarDestination)",
      "language" : "swift"
    },
    {
      "code" : "let divisor: Int = 0x1000\n\nlet rotationMatrix = [\n    1, 0,             0,\n    0, cos(hueAngle), -sin(hueAngle),\n    0, sin(hueAngle),  cos(hueAngle)\n].map {\n    return Int($0 * Float(divisor))\n}",
      "language" : "swift"
    },
    {
      "code" : "let preBias = [Int](repeating: -128, count: 3)\nlet postBias = [Int](repeating: 128 * divisor, count: 3)",
      "language" : "swift"
    },
    {
      "code" : "labPlanarDestination.multiply(\n    by: rotationMatrix,\n    divisor: divisor,\n    preBias: preBias,\n    postBias: postBias,\n    destination: labPlanarDestination)",
      "language" : "swift"
    },
    {
      "code" : "labPlanarDestination.interleave(destination: labInterleavedDestination)",
      "language" : "swift"
    },
    {
      "code" : "if let result = labInterleavedDestination\n    .makeCGImage(cgImageFormat: labImageFormat) {\n    \n    DispatchQueue.main.async {\n        self.outputImage = result\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "b9bec1729c3b21bc02815db6a0dfa9842cc9b4f7304bbfcb8f4954f4cc90fa6a",
  "crawledAt" : "2025-12-02T15:27:45Z",
  "id" : "83287118-3206-429B-8043-8996E94C156E",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThis sample code project allows you to adjust the hue of an image by treating the chrominance information as 2D coordinates, and transforming those values with a rotation matrix. You can convert an RGB image — with its pixels represented as red, green, and blue values — to L*a*b*, where luminance and chrominance are stored discretely. The *L** in L*a*b* refers to the lightness, and the *a** and *b** refer to the red-green and blue-yellow values, respectively.\n\nThe image below shows an approximation of an L*a*b* color chart. The *a** value transitions horizontally (left to right) from negative, through zero, to positive, and the *b** value transitions vertically (bottom to top) from negative, through zero, to positive. Because this sample code focuses on color rather than lightness, the image doesn’t consider L*.\n\n\n\nThe sample uses the vImage Any-to-Any converter to convert the source image’s color space to L*a*b*. The code converts the interleaved L*a*b* image data to multiple-plane image data that it passes to a matrix multiply operation to apply the hue adjustment.\n\nThe following image shows four photographs, from left to right, with a hue adjustment of -90º, 0º (an unchanged hue), 90º, and 180º:\n\n\n\n### Create the L*a*b* image format\n\nTo create the image format for the L*a*b* color space, the sample app uses the [doc:\/\/com.apple.documentation\/documentation\/CoreGraphics\/CGColorSpace\/genericLab] system-defined [doc:\/\/com.apple.documentation\/documentation\/CoreGraphics\/CGColorSpace].\n\nOn return, `labImageFormat` describes the interleaved L*a*b* pixels over which this sample works. The first channel in each pixel is the lightness, and the second and third channels are the *a** and *b**, respectively.\n\n### Generate the pixel buffer and image format from the source image\n\nThe converter that the sample uses to convert the source pixels to L*a*b* color space requires two [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structures that describe the source and destination images. The sample uses the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/makeDynamicPixelBufferAndCGImageFormat(cgImage:)] method to create a dynamic pixel buffer and image format structure from the source Core Graphics image.\n\nOn return, `source.cgImageFormat` contains the image format of the source image, and `source.pixelBuffer` is a pixel buffer that contains the source image data.\n\n### Create the source image color space to L*a*b* converter\n\nThe sample app uses the source and L*a*b* image formats to create a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance to convert between the two color spaces.\n\nFor more information about vImage’s convert-any-to-any functionality, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/building-a-basic-image-conversion-workflow].\n\n### Convert the source image to L*a*b*\n\nThe sample creates a pixel buffer that’s the same size as the source image.\n\nThe converter’s [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/convert(from:to:)-9s7p7] function performs the conversion.\n\nOn return, the `labInterleavedSource` contains the L*a*b* representation of the source image.\n\n### Convert the interleaved L*a*b* buffer to planar buffers\n\nThe function the sample app uses to apply the hue adjustment, [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v], operates on a multiple-plane pixel buffer. To convert the interleaved L*a*b* buffer to planar buffers, the app creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/Planar8x3] pixel buffer.\n\nIt then calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/deinterleave(destination:)-hrhz] to populate the planar buffers with the contents of the interleaved buffer.\n\nFor more information about working with planar buffers, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/optimizing-image-processing-performance].\n\n### Apply the hue adjustment\n\nThe app adjusts the hue of an image by rotating a two-element vector, described by *a** and *b**. For more information about working with rotation matrices, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/working-with-matrices].\n\nThe following visualizes a sample color (marked *A*) rotated by -90º (marked *C*) and 45º (marked *B*):\n\n\n\nThe following code generates the rotation matrix based on `hueAngle`:\n\nThe `preBias` and `postBias` values effectively shift the *a** and *b** values from `0...255` to `-128...127`, so the rotation is centered where *a** and *b** are zero.\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v] function multiplies each pixel in the source buffer by the matrix and writes the result to the destination buffers. The code performs the matrix multiplication in-place, so the source and destination point to the same buffers.\n\nThe following code performs the matrix multiply operation:\n\nOn return, `labPlanarDestination` contains the hue-adjusted *a** and *b** channels.\n\n### Display the image\n\nFinally, the sample code converts the hue-adjusted planar buffer back to an interleaved buffer.\n\nThe SwiftUI [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Image] view supports the L*a*b* color space. The following code creates a Core Graphics image from the interleaved pixel buffer and passes it to the published `outputImage` property that the app displays on the screen:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-the-hue-of-an-image\ncrawled: 2025-12-02T15:27:45Z\n---\n\n# Adjusting the hue of an image\n\n**Sample Code**\n\nConvert an image to L*a*b* color space and apply hue adjustment.\n\n## Overview\n\nThis sample code project allows you to adjust the hue of an image by treating the chrominance information as 2D coordinates, and transforming those values with a rotation matrix. You can convert an RGB image — with its pixels represented as red, green, and blue values — to L*a*b*, where luminance and chrominance are stored discretely. The *L** in L*a*b* refers to the lightness, and the *a** and *b** refer to the red-green and blue-yellow values, respectively.\n\nThe image below shows an approximation of an L*a*b* color chart. The *a** value transitions horizontally (left to right) from negative, through zero, to positive, and the *b** value transitions vertically (bottom to top) from negative, through zero, to positive. Because this sample code focuses on color rather than lightness, the image doesn’t consider L*.\n\n\n\nThe sample uses the vImage Any-to-Any converter to convert the source image’s color space to L*a*b*. The code converts the interleaved L*a*b* image data to multiple-plane image data that it passes to a matrix multiply operation to apply the hue adjustment.\n\nThe following image shows four photographs, from left to right, with a hue adjustment of -90º, 0º (an unchanged hue), 90º, and 180º:\n\n\n\n### Create the L*a*b* image format\n\nTo create the image format for the L*a*b* color space, the sample app uses the [doc:\/\/com.apple.documentation\/documentation\/CoreGraphics\/CGColorSpace\/genericLab] system-defined [doc:\/\/com.apple.documentation\/documentation\/CoreGraphics\/CGColorSpace].\n\n```swift\nvar labImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 3,\n    colorSpace: CGColorSpace(name: CGColorSpace.genericLab)!,\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue),\n    renderingIntent: .defaultIntent)!\n```\n\nOn return, `labImageFormat` describes the interleaved L*a*b* pixels over which this sample works. The first channel in each pixel is the lightness, and the second and third channels are the *a** and *b**, respectively.\n\n### Generate the pixel buffer and image format from the source image\n\nThe converter that the sample uses to convert the source pixels to L*a*b* color space requires two [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structures that describe the source and destination images. The sample uses the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/makeDynamicPixelBufferAndCGImageFormat(cgImage:)] method to create a dynamic pixel buffer and image format structure from the source Core Graphics image.\n\n```swift\nlet source = try vImage.PixelBuffer\n    .makeDynamicPixelBufferAndCGImageFormat(cgImage: sourceCGImage)\n```\n\nOn return, `source.cgImageFormat` contains the image format of the source image, and `source.pixelBuffer` is a pixel buffer that contains the source image data.\n\n### Create the source image color space to L*a*b* converter\n\nThe sample app uses the source and L*a*b* image formats to create a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance to convert between the two color spaces.\n\n```swift\nlet rgbToLab = try vImageConverter.make(sourceFormat: source.cgImageFormat,\n                                        destinationFormat: labImageFormat)\n```\n\nFor more information about vImage’s convert-any-to-any functionality, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/building-a-basic-image-conversion-workflow].\n\n### Convert the source image to L*a*b*\n\nThe sample creates a pixel buffer that’s the same size as the source image.\n\n```swift\nlabInterleavedSource = vImage.PixelBuffer<vImage.Interleaved8x3>(size: size)\n```\n\nThe converter’s [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter\/convert(from:to:)-9s7p7] function performs the conversion.\n\n```swift\ntry rgbToLab.convert(from: source.pixelBuffer,\n                     to: labInterleavedSource)\n```\n\nOn return, the `labInterleavedSource` contains the L*a*b* representation of the source image.\n\n### Convert the interleaved L*a*b* buffer to planar buffers\n\nThe function the sample app uses to apply the hue adjustment, [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v], operates on a multiple-plane pixel buffer. To convert the interleaved L*a*b* buffer to planar buffers, the app creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/Planar8x3] pixel buffer.\n\n```swift\nlabPlanarDestination = vImage.PixelBuffer<vImage.Planar8x3>(size: size)\n```\n\nIt then calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/deinterleave(destination:)-hrhz] to populate the planar buffers with the contents of the interleaved buffer.\n\n```swift\nlabInterleavedSource.deinterleave(destination: labPlanarDestination)\n```\n\nFor more information about working with planar buffers, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/optimizing-image-processing-performance].\n\n### Apply the hue adjustment\n\nThe app adjusts the hue of an image by rotating a two-element vector, described by *a** and *b**. For more information about working with rotation matrices, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/working-with-matrices].\n\nThe following visualizes a sample color (marked *A*) rotated by -90º (marked *C*) and 45º (marked *B*):\n\n\n\nThe following code generates the rotation matrix based on `hueAngle`:\n\n```swift\nlet divisor: Int = 0x1000\n\nlet rotationMatrix = [\n    1, 0,             0,\n    0, cos(hueAngle), -sin(hueAngle),\n    0, sin(hueAngle),  cos(hueAngle)\n].map {\n    return Int($0 * Float(divisor))\n}\n```\n\nThe `preBias` and `postBias` values effectively shift the *a** and *b** values from `0...255` to `-128...127`, so the rotation is centered where *a** and *b** are zero.\n\n```swift\nlet preBias = [Int](repeating: -128, count: 3)\nlet postBias = [Int](repeating: 128 * divisor, count: 3)\n```\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v] function multiplies each pixel in the source buffer by the matrix and writes the result to the destination buffers. The code performs the matrix multiplication in-place, so the source and destination point to the same buffers.\n\nThe following code performs the matrix multiply operation:\n\n```swift\nlabPlanarDestination.multiply(\n    by: rotationMatrix,\n    divisor: divisor,\n    preBias: preBias,\n    postBias: postBias,\n    destination: labPlanarDestination)\n```\n\nOn return, `labPlanarDestination` contains the hue-adjusted *a** and *b** channels.\n\n### Display the image\n\nFinally, the sample code converts the hue-adjusted planar buffer back to an interleaved buffer.\n\n```swift\nlabPlanarDestination.interleave(destination: labInterleavedDestination)\n```\n\nThe SwiftUI [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Image] view supports the L*a*b* color space. The following code creates a Core Graphics image from the interleaved pixel buffer and passes it to the published `outputImage` property that the app displays on the screen:\n\n```swift\nif let result = labInterleavedDestination\n    .makeCGImage(cgImageFormat: labImageFormat) {\n    \n    DispatchQueue.main.async {\n        self.outputImage = result\n    }\n}\n```\n\n## Color and Tone Adjustment\n\n- **Adjusting the brightness and contrast of an image**: Use a gamma function to apply a linear or exponential curve.\n- **Adjusting saturation and applying tone mapping**: Convert an RGB image to discrete luminance and chrominance channels, and apply color and contrast treatments.\n- **Applying tone curve adjustments to images**: Use the vImage library’s polynomial transform to apply tone curve adjustments to images.\n- **Specifying histograms with vImage**: Calculate the histogram of one image, and apply it to a second image.\n- **Enhancing image contrast with histogram manipulation**: Enhance and adjust the contrast of an image with histogram equalization and contrast stretching.\n- **Histogram**: Calculate or manipulate an image’s histogram.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use a gamma function to apply a linear or exponential curve.",
          "name" : "Adjusting the brightness and contrast of an image",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-the-brightness-and-contrast-of-an-image"
        },
        {
          "description" : "Convert an RGB image to discrete luminance and chrominance channels, and apply color and contrast treatments.",
          "name" : "Adjusting saturation and applying tone mapping",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-saturation-and-applying-tone-mapping"
        },
        {
          "description" : "Use the vImage library’s polynomial transform to apply tone curve adjustments to images.",
          "name" : "Applying tone curve adjustments to images",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-tone-curve-adjustments-to-images"
        },
        {
          "description" : "Calculate the histogram of one image, and apply it to a second image.",
          "name" : "Specifying histograms with vImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/specifying-histograms-with-vimage"
        },
        {
          "description" : "Enhance and adjust the contrast of an image with histogram equalization and contrast stretching.",
          "name" : "Enhancing image contrast with histogram manipulation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/enhancing-image-contrast-with-histogram-manipulation"
        },
        {
          "description" : "Calculate or manipulate an image’s histogram.",
          "name" : "Histogram",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/histogram"
        }
      ],
      "title" : "Color and Tone Adjustment"
    }
  ],
  "source" : "appleJSON",
  "title" : "Adjusting the hue of an image",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-the-hue-of-an-image"
}