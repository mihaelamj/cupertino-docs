{
  "abstract" : "Convert an RGB image to grayscale using matrix multiplication.",
  "codeExamples" : [
    {
      "code" : "let p = (sourcePixels[index].a + preBias.a) * matrix.a +\n        (sourcePixels[index].r + preBias.r) * matrix.r +\n        (sourcePixels[index].g + preBias.g) * matrix.g +\n        (sourcePixels[index].b + preBias.b) * matrix.b\n\nlet destinationPixels[index] = (p + postBias) \/ divisor",
      "language" : "swift"
    },
    {
      "code" : "\/\/\/ The 8-bit-per-channel, 4-channel source pixel buffer.\nlet sourceBuffer8 = try! vImage.PixelBuffer<vImage.Interleaved8x4>(\n    cgImage: sourceImage,\n    cgImageFormat: &GrayscaleConverter.sourceFormat8)\n\n\/\/\/ The 32-bit-per-channel, 4-channel source pixel buffer.\nlet sourceBufferF = try! vImage.PixelBuffer<vImage.InterleavedFx4>(\n    cgImage: sourceImage,\n    cgImageFormat: &GrayscaleConverter.sourceFormatF)\n\n\/\/\/ The 8-bit planar destination pixel buffer.\nlet destinationBuffer8 = vImage.PixelBuffer<vImage.Planar8>(width: sourceImage.width,\n                                                            height: sourceImage.height)\n\n\/\/\/ The 32-bit planar destination pixel buffer.\nlet destinationBufferF = vImage.PixelBuffer<vImage.PlanarF>(width: sourceImage.width,\n                                                            height: sourceImage.height)",
      "language" : "swift"
    },
    {
      "code" : "luminance = (red × 0.2126) + (green x 0.7152) + (blue × 0.0722)"
    },
    {
      "code" : "let scale = 1.0 \/ (redCoefficient + greenCoefficient + blueCoefficient)\n\nDispatchQueue.main.async { [self] in\n    normalizedRedCoefficient = redCoefficient * scale\n    normalizedGreenCoefficient = greenCoefficient * scale\n    normalizedBlueCoefficient = blueCoefficient * scale\n}",
      "language" : "swift"
    },
    {
      "code" : "let divisor: Int = 0x1000\nlet fDivisor = Float(divisor)\n\nsourceBuffer8.multiply(by: (0,\n                            Int(normalizedRedCoefficient * fDivisor),\n                            Int(normalizedGreenCoefficient * fDivisor),\n                            Int(normalizedBlueCoefficient * fDivisor)),\n                       divisor: divisor,\n                       preBias: (0, 0, 0, 0),\n                       postBias: 0,\n                       destination: destinationBuffer8)",
      "language" : "swift"
    },
    {
      "code" : "sourceBufferF.multiply(by: (0,\n                            normalizedRedCoefficient,\n                            normalizedGreenCoefficient,\n                            normalizedBlueCoefficient),\n                       preBias: (0, 0, 0, 0),\n                       postBias: 0,\n                       destination: destinationBufferF)",
      "language" : "swift"
    },
    {
      "code" : "static var destinationFormat8 = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8,\n    colorSpace: CGColorSpaceCreateDeviceGray(),\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue))!\n\nstatic var destinationFormatF = vImage_CGImageFormat(\n    bitsPerComponent: 32,\n    bitsPerPixel: 32,\n    colorSpace: CGColorSpaceCreateDeviceGray(),\n    bitmapInfo: CGBitmapInfo(\n        rawValue: kCGBitmapByteOrder32Host.rawValue |\n        CGBitmapInfo.floatComponents.rawValue |\n        CGImageAlphaInfo.none.rawValue))!",
      "language" : "swift"
    },
    {
      "code" : "let result = destinationBufferF.makeCGImage(\n    cgImageFormat: GrayscaleConverter.destinationFormatF)!",
      "language" : "swift"
    }
  ],
  "contentHash" : "500d287141e68e5c6cb4fc832041c27f68d8a38e23a0debfd2121092f12376be",
  "crawledAt" : "2025-12-02T15:27:53Z",
  "id" : "71C8F9DA-A2BA-4339-92F4-5F037ECA8204",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThe vImage [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v]) and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:preBias:postBias:destination:)-3bh2a] functions multiply each channel of an interleaved image with the corresponding value in a matrix and return the sum of the multiplications to generate a planar image. These functions wrap [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageMatrixMultiply_ARGB8888ToPlanar8(_:_:_:_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageMatrixMultiply_ARGBFFFFToPlanarF(_:_:_:_:_:_:)], respectively.\n\nThe following shows how the 8-bit matrix multiply operation calculates the result for each pixel:\n\nThe 8-bit matrix multiply operation creates a maximum of 255 gray tones. However, even with an 8-bit-per-channel source image, the 32-bit matrix multiply operation can create up to 255 x 255 x 255 (16,581,375) gray tones. This sample code project includes 8- and 32-bit color-to-grayscale conversion and provides a function to count the distinct tones in the output image.\n\nBefore exploring the code, build and run the app to familiarize yourself with the different visual results it generates from setting different coefficients for the red, green, and blue channels.\n\n### Define the source and destination pixel buffers\n\nTo support 8- and 32-bit matrix multiply, the sample code defines four pixel buffers: two ARGB source buffers and two grayscale destination buffers.\n\n### Define the coefficient values\n\nLuma coefficients model an eye’s response to red, green, and blue light. The following formula shows the Rec. 709 luma coefficients for the sample app’s default color-to-grayscale conversion.\n\nThe sample code app provides a user interface that allows a user to change the red, green, and blue coefficients. To ensure the grayscale image isn’t darker or brighter than the original image, the following code normalizes the coefficient values so that their sum equals `1.0`:\n\n### Perform the 8-bit matrix multiply operation\n\nThe 8-bit matrix multiply operation accepts integer matrix values. The following code defines a divisor that it uses to multiply the floating-point coefficient values and that the function uses to renormalize the image after scaling by the matrix:\n\nOn return, the `destinationBuffer8` pixel buffer contains a grayscale representation of the original image.\n\n### Perform the 32-bit matrix multiply operation\n\nThe 32-bit matrix multiply operation accepts floating-point matrix values and, therefore, doesn’t require a divisor. The following code performs the 32-bit color-to-grayscale conversion.\n\nOn return, the `destinationBufferF` pixel buffer contains a grayscale representation of the original image.\n\n### Create a grayscale Core Graphics image\n\nThe sample app displays the 8- and 32-bit grayscale images in the user interface. To support this, the following code defines two single-channel [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structures:\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/makeCGImage(cgImageFormat:)] function is available for both the 8- and 32-bit pixel buffers. The following code creates a [doc:\/\/com.apple.documentation\/documentation\/CoreGraphics\/CGImage] instance from the 32-bit grayscale pixel buffer:\n\nOn return, `result` contains the grayscale representation of the original image:\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/converting-color-images-to-grayscale\ncrawled: 2025-12-02T15:27:53Z\n---\n\n# Converting color images to grayscale\n\n**Sample Code**\n\nConvert an RGB image to grayscale using matrix multiplication.\n\n## Overview\n\nThe vImage [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:divisor:preBias:postBias:destination:)-7jo6v]) and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/multiply(by:preBias:postBias:destination:)-3bh2a] functions multiply each channel of an interleaved image with the corresponding value in a matrix and return the sum of the multiplications to generate a planar image. These functions wrap [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageMatrixMultiply_ARGB8888ToPlanar8(_:_:_:_:_:_:_:)] and [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageMatrixMultiply_ARGBFFFFToPlanarF(_:_:_:_:_:_:)], respectively.\n\nThe following shows how the 8-bit matrix multiply operation calculates the result for each pixel:\n\n```swift\nlet p = (sourcePixels[index].a + preBias.a) * matrix.a +\n        (sourcePixels[index].r + preBias.r) * matrix.r +\n        (sourcePixels[index].g + preBias.g) * matrix.g +\n        (sourcePixels[index].b + preBias.b) * matrix.b\n\nlet destinationPixels[index] = (p + postBias) \/ divisor\n```\n\nThe 8-bit matrix multiply operation creates a maximum of 255 gray tones. However, even with an 8-bit-per-channel source image, the 32-bit matrix multiply operation can create up to 255 x 255 x 255 (16,581,375) gray tones. This sample code project includes 8- and 32-bit color-to-grayscale conversion and provides a function to count the distinct tones in the output image.\n\nBefore exploring the code, build and run the app to familiarize yourself with the different visual results it generates from setting different coefficients for the red, green, and blue channels.\n\n### Define the source and destination pixel buffers\n\nTo support 8- and 32-bit matrix multiply, the sample code defines four pixel buffers: two ARGB source buffers and two grayscale destination buffers.\n\n```swift\n\/\/\/ The 8-bit-per-channel, 4-channel source pixel buffer.\nlet sourceBuffer8 = try! vImage.PixelBuffer<vImage.Interleaved8x4>(\n    cgImage: sourceImage,\n    cgImageFormat: &GrayscaleConverter.sourceFormat8)\n\n\/\/\/ The 32-bit-per-channel, 4-channel source pixel buffer.\nlet sourceBufferF = try! vImage.PixelBuffer<vImage.InterleavedFx4>(\n    cgImage: sourceImage,\n    cgImageFormat: &GrayscaleConverter.sourceFormatF)\n\n\/\/\/ The 8-bit planar destination pixel buffer.\nlet destinationBuffer8 = vImage.PixelBuffer<vImage.Planar8>(width: sourceImage.width,\n                                                            height: sourceImage.height)\n\n\/\/\/ The 32-bit planar destination pixel buffer.\nlet destinationBufferF = vImage.PixelBuffer<vImage.PlanarF>(width: sourceImage.width,\n                                                            height: sourceImage.height)\n```\n\n### Define the coefficient values\n\nLuma coefficients model an eye’s response to red, green, and blue light. The following formula shows the Rec. 709 luma coefficients for the sample app’s default color-to-grayscale conversion.\n\n```\nluminance = (red × 0.2126) + (green x 0.7152) + (blue × 0.0722)\n```\n\nThe sample code app provides a user interface that allows a user to change the red, green, and blue coefficients. To ensure the grayscale image isn’t darker or brighter than the original image, the following code normalizes the coefficient values so that their sum equals `1.0`:\n\n```swift\nlet scale = 1.0 \/ (redCoefficient + greenCoefficient + blueCoefficient)\n\nDispatchQueue.main.async { [self] in\n    normalizedRedCoefficient = redCoefficient * scale\n    normalizedGreenCoefficient = greenCoefficient * scale\n    normalizedBlueCoefficient = blueCoefficient * scale\n}\n```\n\n### Perform the 8-bit matrix multiply operation\n\nThe 8-bit matrix multiply operation accepts integer matrix values. The following code defines a divisor that it uses to multiply the floating-point coefficient values and that the function uses to renormalize the image after scaling by the matrix:\n\n```swift\nlet divisor: Int = 0x1000\nlet fDivisor = Float(divisor)\n\nsourceBuffer8.multiply(by: (0,\n                            Int(normalizedRedCoefficient * fDivisor),\n                            Int(normalizedGreenCoefficient * fDivisor),\n                            Int(normalizedBlueCoefficient * fDivisor)),\n                       divisor: divisor,\n                       preBias: (0, 0, 0, 0),\n                       postBias: 0,\n                       destination: destinationBuffer8)\n```\n\nOn return, the `destinationBuffer8` pixel buffer contains a grayscale representation of the original image.\n\n### Perform the 32-bit matrix multiply operation\n\nThe 32-bit matrix multiply operation accepts floating-point matrix values and, therefore, doesn’t require a divisor. The following code performs the 32-bit color-to-grayscale conversion.\n\n```swift\nsourceBufferF.multiply(by: (0,\n                            normalizedRedCoefficient,\n                            normalizedGreenCoefficient,\n                            normalizedBlueCoefficient),\n                       preBias: (0, 0, 0, 0),\n                       postBias: 0,\n                       destination: destinationBufferF)\n```\n\nOn return, the `destinationBufferF` pixel buffer contains a grayscale representation of the original image.\n\n### Create a grayscale Core Graphics image\n\nThe sample app displays the 8- and 32-bit grayscale images in the user interface. To support this, the following code defines two single-channel [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structures:\n\n```swift\nstatic var destinationFormat8 = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8,\n    colorSpace: CGColorSpaceCreateDeviceGray(),\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue))!\n\nstatic var destinationFormatF = vImage_CGImageFormat(\n    bitsPerComponent: 32,\n    bitsPerPixel: 32,\n    colorSpace: CGColorSpaceCreateDeviceGray(),\n    bitmapInfo: CGBitmapInfo(\n        rawValue: kCGBitmapByteOrder32Host.rawValue |\n        CGBitmapInfo.floatComponents.rawValue |\n        CGImageAlphaInfo.none.rawValue))!\n```\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/makeCGImage(cgImageFormat:)] function is available for both the 8- and 32-bit pixel buffers. The following code creates a [doc:\/\/com.apple.documentation\/documentation\/CoreGraphics\/CGImage] instance from the 32-bit grayscale pixel buffer:\n\n```swift\nlet result = destinationBufferF.makeCGImage(\n    cgImageFormat: GrayscaleConverter.destinationFormatF)!\n```\n\nOn return, `result` contains the grayscale representation of the original image:\n\n\n\n## Conversion Between Image Formats\n\n- **Building a basic image conversion workflow**: Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.\n- **Applying color transforms to images with a multidimensional lookup table**: Precompute translation values to optimize color space conversion and other pointwise operations.\n- **Building a basic image conversion workflow**: Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.\n- **Converting luminance and chrominance planes to an ARGB image**: Create a displayable ARGB image using the luminance and chrominance information from your device’s camera.\n- **Conversion**: Convert an image to a different format.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.",
          "name" : "Building a basic image conversion workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/building-a-basic-image-conversion-workflow"
        },
        {
          "description" : "Precompute translation values to optimize color space conversion and other pointwise operations.",
          "name" : "Applying color transforms to images with a multidimensional lookup table",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-color-transforms-to-images-with-a-multidimensional-lookup-table"
        },
        {
          "description" : "Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.",
          "name" : "Building a basic image conversion workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/building-a-basic-image-conversion-workflow"
        },
        {
          "description" : "Create a displayable ARGB image using the luminance and chrominance information from your device’s camera.",
          "name" : "Converting luminance and chrominance planes to an ARGB image",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/converting-luminance-and-chrominance-planes-to-an-argb-image"
        },
        {
          "description" : "Convert an image to a different format.",
          "name" : "Conversion",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/conversion"
        }
      ],
      "title" : "Conversion Between Image Formats"
    }
  ],
  "source" : "appleJSON",
  "title" : "Converting color images to grayscale",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/converting-color-images-to-grayscale"
}