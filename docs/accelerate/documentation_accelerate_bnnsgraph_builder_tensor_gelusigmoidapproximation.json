{
  "abstract" : "Adds a Gaussian Error Linear Unit (GELU) sigmoid approximation activation operation to the current graph.",
  "codeExamples" : [

  ],
  "contentHash" : "e5abe06896c08044a20bb701f10bc9c041ad9576a7f8b6f193e7b5c1a6dfff1f",
  "crawledAt" : "2025-11-30T22:02:11Z",
  "declaration" : {
    "code" : "func geluSigmoidApproximation() -> BNNSGraph.Builder.Tensor<T>",
    "language" : "swift"
  },
  "id" : "C34B3922-7D3D-4C1D-B295-AB666B60700D",
  "kind" : "method",
  "module" : "Accelerate",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/geluSigmoidApproximation()\ncrawled: 2025-11-30T22:02:11Z\n---\n\n# geluSigmoidApproximation()\n\n**Instance Method**\n\nAdds a Gaussian Error Linear Unit (GELU) sigmoid approximation activation operation to the current graph.\n\n## Declaration\n\n```swift\nfunc geluSigmoidApproximation() -> BNNSGraph.Builder.Tensor<T>\n```\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "geluSigmoidApproximation()",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/geluSigmoidApproximation()"
}