{
  "abstract" : "Returns a new Adam optimizer object.",
  "codeExamples" : [

  ],
  "contentHash" : "edd72c79e6ab3304a04932de8b2efef9411961a17bbb4745e5ad5a66b6f4bb8b",
  "crawledAt" : "2025-12-02T01:23:41Z",
  "declaration" : {
    "code" : "init(learningRate: Float, beta1: Float, beta2: Float, timeStep: Float, epsilon: Float, gradientScale: Float, regularizationScale: Float, clipsGradientsTo gradientBounds: ClosedRange<Float>? = nil, regularizationFunction: BNNSOptimizerRegularizationFunction)",
    "language" : "swift"
  },
  "id" : "F317B346-564B-4B5A-896F-BCC605C373D3",
  "kind" : "unknown",
  "module" : "Accelerate",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNS\/AdamOptimizer\/init(learningRate:beta1:beta2:timeStep:epsilon:gradientScale:regularizationScale:clipsGradientsTo:regularizationFunction:)\ncrawled: 2025-12-02T01:23:41Z\n---\n\n# init(learningRate:beta1:beta2:timeStep:epsilon:gradientScale:regularizationScale:clipsGradientsTo:regularizationFunction:)\n\n**Initializer**\n\nReturns a new Adam optimizer object.\n\n## Declaration\n\n```swift\ninit(learningRate: Float, beta1: Float, beta2: Float, timeStep: Float, epsilon: Float, gradientScale: Float, regularizationScale: Float, clipsGradientsTo gradientBounds: ClosedRange<Float>? = nil, regularizationFunction: BNNSOptimizerRegularizationFunction)\n```\n\n## Parameters\n\n- **learningRate**: A value that specifies the learning rate.\n- **beta1**: A value that specifies the first-moment constant, in the range `0` to `1`.\n- **beta2**: A value that specifies the second-moment constant, in the range `0` to `1`.\n- **timeStep**: A value that’s at least `1` and represents the optimizer’s current time.\n- **epsilon**: The epsilon value you use to improve numerical stability.\n- **gradientScale**: A value that specifies the gradient scaling factor.\n- **regularizationScale**: A value that specifies the regularization scaling factor.\n- **gradientBounds**: The values for the minimum and maximum gradients.\n- **regularizationFunction**: The variable that specifies the regularization function.\n\n## Creating an Adam Optimizer\n\n- **init(learningRate:beta1:beta2:timeStep:epsilon:gradientScale:regularizationScale:gradientClipping:regularizationFunction:usesAMSGrad:)**: Returns a new Adam optimizer object with gradient clipped by value or clipped by norm.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Returns a new Adam optimizer object with gradient clipped by value or clipped by norm.",
          "name" : "init(learningRate:beta1:beta2:timeStep:epsilon:gradientScale:regularizationScale:gradientClipping:regularizationFunction:usesAMSGrad:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNS\/AdamOptimizer\/init(learningRate:beta1:beta2:timeStep:epsilon:gradientScale:regularizationScale:gradientClipping:regularizationFunction:usesAMSGrad:)"
        }
      ],
      "title" : "Creating an Adam Optimizer"
    }
  ],
  "source" : "appleJSON",
  "title" : "init(learningRate:beta1:beta2:timeStep:epsilon:gradientScale:regularizationScale:clipsGradientsTo:regularizationFunction:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNS\/AdamOptimizer\/init(learningRate:beta1:beta2:timeStep:epsilon:gradientScale:regularizationScale:clipsGradientsTo:regularizationFunction:)"
}