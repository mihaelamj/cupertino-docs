{
  "abstract" : "An activation function that returns its input clamped to the specified range.",
  "codeExamples" : [
    {
      "code" : "min(max(x, alpha), beta)",
      "language" : "c"
    },
    {
      "code" : "var activation = BNNSActivation(function: .clamp, \n                                alpha: -5, \n                                beta: 5)",
      "language" : "swift"
    }
  ],
  "contentHash" : "30d7c1a51d4d53313c1ec03677ac379bd676c795ae65f5315e1ba8222e5fc120",
  "crawledAt" : "2025-12-07T13:47:46Z",
  "declaration" : {
    "code" : "BNNSActivationFunctionClamp",
    "language" : "swift"
  },
  "id" : "04813A98-D863-45F8-B12B-5F2B3E964BCD",
  "kind" : "unknown",
  "language" : "occ",
  "module" : "Accelerate",
  "overview" : "## Discussion\n\nThis constant defines an activation function that returns values using the following operation:\n\nUse `alpha` and `beta` to specify the clamping range:\n\nThe following illustrates the output that the activation function generates from inputs in the range `-10...10`:\n\n",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunction\/BNNSActivationFunctionClamp\ncrawled: 2025-12-07T13:47:46Z\n---\n\n# BNNSActivationFunctionClamp\n\n**Enumeration Case**\n\nAn activation function that returns its input clamped to the specified range.\n\n## Declaration\n\n```swift\nBNNSActivationFunctionClamp\n```\n\n## Discussion\n\nThis constant defines an activation function that returns values using the following operation:\n\n```c\nmin(max(x, alpha), beta)\n```\n\nUse `alpha` and `beta` to specify the clamping range:\n\n```swift\nvar activation = BNNSActivation(function: .clamp, \n                                alpha: -5, \n                                beta: 5)\n```\n\nThe following illustrates the output that the activation function generates from inputs in the range `-10...10`:\n\n\n\n## Raw Values\n\n- **BNNSActivationFunctionCELU**: An activation function that evaluates the continuously differentiable exponential linear units (CELU) on its input.\n- **BNNSActivationFunctionClampedLeakyRectifiedLinear**: An activation function that returns its input clamped to beta when that is greater than or equal to zero, otherwise it returns its input multiplied by alpha clamped to beta.\n- **BNNSActivationFunctionELU**: An activation function that evaluates the exponential linear units (ELU) on its input.\n- **BNNSActivationFunctionErf**\n- **BNNSActivationFunctionGELU**\n- **BNNSActivationFunctionGELUApproximation**: An activation function that evaluates the Gaussian error linear units (GELU) approximation on its input.\n- **BNNSActivationFunctionGELUApproximation2**: An activation function that provides a fast evaluation of the Gaussian error linear units (GELU) approximation on its input.\n- **BNNSActivationFunctionGELUApproximationSigmoid**\n- **BNNSActivationFunctionGumbel**: An activation function that returns random numbers from the Gumbel distribution.\n- **BNNSActivationFunctionGumbelMax**: An activation function that returns random numbers from the Gumbel distribution.\n- **BNNSActivationFunctionHardShrink**: An activation function that returns zero when the absolute input is less than alpha, otherwise it returns its input.\n- **BNNSActivationFunctionHardSigmoid**: An activation function that returns the hard sigmoid function of its input.\n- **BNNSActivationFunctionHardSwish**: An activation function that returns the hard swish function of its input.\n- **BNNSActivationFunctionIntegerLinearSaturate**: An activation function that returns an arithmetic shift, preserving sign.\n- **BNNSActivationFunctionIntegerLinearSaturatePerChannel**: An activation function that returns an arithmetic shift, preserving sign for each channel.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An activation function that evaluates the continuously differentiable exponential linear units (CELU) on its input.",
          "name" : "BNNSActivationFunctionCELU",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionCELU"
        },
        {
          "description" : "An activation function that returns its input clamped to beta when that is greater than or equal to zero, otherwise it returns its input multiplied by alpha clamped to beta.",
          "name" : "BNNSActivationFunctionClampedLeakyRectifiedLinear",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionClampedLeakyRectifiedLinear"
        },
        {
          "description" : "An activation function that evaluates the exponential linear units (ELU) on its input.",
          "name" : "BNNSActivationFunctionELU",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionELU"
        },
        {
          "description" : "",
          "name" : "BNNSActivationFunctionErf",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionErf"
        },
        {
          "description" : "",
          "name" : "BNNSActivationFunctionGELU",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionGELU"
        },
        {
          "description" : "An activation function that evaluates the Gaussian error linear units (GELU) approximation on its input.",
          "name" : "BNNSActivationFunctionGELUApproximation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionGELUApproximation"
        },
        {
          "description" : "An activation function that provides a fast evaluation of the Gaussian error linear units (GELU) approximation on its input.",
          "name" : "BNNSActivationFunctionGELUApproximation2",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionGELUApproximation2"
        },
        {
          "description" : "",
          "name" : "BNNSActivationFunctionGELUApproximationSigmoid",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionGELUApproximationSigmoid"
        },
        {
          "description" : "An activation function that returns random numbers from the Gumbel distribution.",
          "name" : "BNNSActivationFunctionGumbel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionGumbel"
        },
        {
          "description" : "An activation function that returns random numbers from the Gumbel distribution.",
          "name" : "BNNSActivationFunctionGumbelMax",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionGumbelMax"
        },
        {
          "description" : "An activation function that returns zero when the absolute input is less than alpha, otherwise it returns its input.",
          "name" : "BNNSActivationFunctionHardShrink",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionHardShrink"
        },
        {
          "description" : "An activation function that returns the hard sigmoid function of its input.",
          "name" : "BNNSActivationFunctionHardSigmoid",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionHardSigmoid"
        },
        {
          "description" : "An activation function that returns the hard swish function of its input.",
          "name" : "BNNSActivationFunctionHardSwish",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunctionHardSwish"
        },
        {
          "description" : "An activation function that returns an arithmetic shift, preserving sign.",
          "name" : "BNNSActivationFunctionIntegerLinearSaturate",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunction\/BNNSActivationFunctionIntegerLinearSaturate"
        },
        {
          "description" : "An activation function that returns an arithmetic shift, preserving sign for each channel.",
          "name" : "BNNSActivationFunctionIntegerLinearSaturatePerChannel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunction\/BNNSActivationFunctionIntegerLinearSaturatePerChannel"
        }
      ],
      "title" : "Raw Values"
    }
  ],
  "source" : "appleJSON",
  "title" : "BNNSActivationFunctionClamp",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSActivationFunction\/BNNSActivationFunctionClamp"
}