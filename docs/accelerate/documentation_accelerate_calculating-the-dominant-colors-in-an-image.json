{
  "abstract" : "Find the main colors in an image by implementing k-means clustering using the Accelerate framework.",
  "codeExamples" : [
    {
      "code" : "\/\/\/ The storage and pixel buffer for each red value.\nlet redStorage = UnsafeMutableBufferPointer<Float>.allocate(capacity: dimension * dimension)\nlet redBuffer: vImage.PixelBuffer<vImage.PlanarF>\n\n\/\/\/ The storage and pixel buffer for each green value.\nlet greenStorage = UnsafeMutableBufferPointer<Float>.allocate(capacity: dimension * dimension)\nlet greenBuffer: vImage.PixelBuffer<vImage.PlanarF>\n\n\/\/\/ The storage and pixel buffer for each blue value.\nlet blueStorage = UnsafeMutableBufferPointer<Float>.allocate(capacity: dimension * dimension)\nlet blueBuffer: vImage.PixelBuffer<vImage.PlanarF>",
      "language" : "swift"
    },
    {
      "code" : "redBuffer = vImage.PixelBuffer<vImage.PlanarF>(\n    data: redStorage.baseAddress!,\n    width: dimension,\n    height: dimension,\n    byteCountPerRow: dimension * MemoryLayout<Float>.stride)\n\ngreenBuffer = vImage.PixelBuffer<vImage.PlanarF>(\n    data: greenStorage.baseAddress!,\n    width: dimension,\n    height: dimension,\n    byteCountPerRow: dimension * MemoryLayout<Float>.stride)\n\nblueBuffer = vImage.PixelBuffer<vImage.PlanarF>(\n    data: blueStorage.baseAddress!,\n    width: dimension,\n    height: dimension,\n    byteCountPerRow: dimension * MemoryLayout<Float>.stride)",
      "language" : "swift"
    },
    {
      "code" : "let randomIndex = Int.random(in: 0 ..< dimension * dimension)\ncentroids.append(Centroid(red: redStorage[randomIndex],\n                          green: greenStorage[randomIndex],\n                          blue: blueStorage[randomIndex]))",
      "language" : "swift"
    },
    {
      "code" : "for i in 1 ..< k {\n    distanceSquared(x0: greenStorage.baseAddress!, x1: centroids[i - 1].green,\n                    y0: blueStorage.baseAddress!, y1: centroids[i - 1].blue,\n                    z0: redStorage.baseAddress!, z1: centroids[i - 1].red,\n                    n: greenStorage.count,\n                    result: tmp.baseAddress!)\n    \n    let randomIndex = weightedRandomIndex(tmp)\n    \n    centroids.append(Centroid(red: redStorage[randomIndex],\n                              green: greenStorage[randomIndex],\n                              blue: blueStorage[randomIndex]))\n}",
      "language" : "swift"
    },
    {
      "code" : "for centroid in centroids.enumerated() {\n    distanceSquared(x0: greenStorage.baseAddress!, x1: centroid.element.green,\n                    y0: blueStorage.baseAddress!, y1: centroid.element.blue,\n                    z0: redStorage.baseAddress!, z1: centroid.element.red,\n                    n: greenStorage.count,\n                    result: distances.baseAddress!.advanced(by: dimension * dimension * centroid.offset))\n}",
      "language" : "swift"
    },
    {
      "code" : "[ 0.0, 0.0, 2.0, 3.0, 7.0, 5.0, 6.0, 4.0 ]    \/\/ Red color values for colors 0...7.\n[ 6.0, 1.0, 0.0, 2.0, 7.0, 5.0, 2.0, 3.0 ]    \/\/ Green-blue color values for colors 0...7."
    },
    {
      "code" : "[ 9.0, 34.0, 37.0, 16.0, 17.0,  5.0, 25.0, 10.0,        \/\/ For centroid _A_.\n 50.0, 25.0, 10.0,  5.0, 40.0, 16.0,  2.0,  5.0 ]       \/\/ For centroid _B_."
    },
    {
      "code" : "func makeCentroidIndices() -> [Int32] {\n    let distancesDescriptor = BNNSNDArrayDescriptor(\n        data: distances,\n        shape: .matrixRowMajor(dimension * dimension, k))!\n    \n    let reductionLayer = BNNS.ReductionLayer(function: .argMin,\n                                             input: distancesDescriptor,\n                                             output: centroidIndicesDescriptor,\n                                             weights: nil)\n    \n    try! reductionLayer?.apply(batchSize: 1,\n                               input: distancesDescriptor,\n                               output: centroidIndicesDescriptor)\n    \n    return centroidIndicesDescriptor.makeArray(of: Int32.self)!\n}",
      "language" : "swift"
    },
    {
      "code" : "[ 0, 1, 1, 1, 0, 0, 1, 1 ]      \/\/ 0 represents centroid _A_, and 1 represents centroid _B_."
    },
    {
      "code" : "let indices = centroidIndices.enumerated().filter {\n    $0.element == centroid.offset\n}.map {\n    \/\/ `vDSP.gather` uses one-based indices.\n    UInt($0.offset + 1)\n}",
      "language" : "swift"
    },
    {
      "code" : "[ 0,          4, 5 ]          \/\/ For centroid _A_.\n[    1, 2, 3,       6, 7 ]    \/\/ For centroid _B_."
    },
    {
      "code" : "let gatheredRed = vDSP.gather(redStorage,\n                              indices: indices)\n\nlet gatheredGreen = vDSP.gather(greenStorage,\n                                indices: indices)\n\nlet gatheredBlue = vDSP.gather(blueStorage,\n                               indices: indices)",
      "language" : "swift"
    },
    {
      "code" : "[ 0.0,               7.0, 5.0 ]             \/\/ Gathered red values for centroid _A_.   \n[ 6.0,               7.0, 5.0 ]             \/\/ Gathered green-blue values for centroid _A_.\n\n[     0.0, 2.0, 3.0,           6.0, 4.0 ]   \/\/ Gathered red values for centroid _B_.\n[     1.0, 0.0, 2.0,           2.0, 3.0 ]   \/\/ Gathered green-blue values for centroid _B_."
    },
    {
      "code" : "centroids[centroid.offset].red = vDSP.mean(gatheredRed)\ncentroids[centroid.offset].green = vDSP.mean(gatheredGreen)\ncentroids[centroid.offset].blue = vDSP.mean(gatheredBlue)",
      "language" : "swift"
    },
    {
      "code" : "4.0    \/\/ Mean red value for centroid _A_.\n6.0    \/\/ Mean green-blue value for centroid _A_.\n\n3.0    \/\/ Mean red value for centroid _B_.\n1.6    \/\/ Mean green-blue value for centroid _B_."
    },
    {
      "code" : "let indicesDescriptor = BNNSNDArrayDescriptor.allocate(\n    initializingFrom: indices,\n    shape: .vector(indices.count))\n\ndefer {\n    indicesDescriptor.deallocate()\n}\n\nscatter(value: centroid.element.red, to: redQuantizedStorage)\nscatter(value: centroid.element.green, to: greenQuantizedStorage)\nscatter(value: centroid.element.blue, to: blueQuantizedStorage)\n\n\/\/\/ Scatters the repeated `value` to the `destination` using the `indicesDescriptor`.\nfunc scatter(value: Float,\n             to destination: UnsafeMutableBufferPointer<Float>) {\n    let srcDescriptor = BNNSNDArrayDescriptor.allocate(repeating: value,\n                                                       shape: .vector(indices.count))\n    let dstDescriptor = BNNSNDArrayDescriptor(data: destination,\n                                              shape: .vector(dimension * dimension))!\n    \n    try! BNNS.scatter(input: srcDescriptor,\n                      indices: indicesDescriptor,\n                      output: dstDescriptor,\n                      axis: 0,\n                      reductionFunction: .sum)\n    \n    srcDescriptor.deallocate()\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "4cf93894abb0ff2a431fd7b7ad75b191aedd2986f03e32b857e1deafa3d00ce6",
  "crawledAt" : "2025-12-02T22:13:59Z",
  "id" : "72C71A98-A599-4366-AC6D-1F8C5BB6CAD7",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThe Accelerate framework provides libraries that allow you to extract a specified number (`k`) of average colors in an image. This sample code app computes these colors using the *k-means algorithm*. The k-means algorithm finds the `k` dominant colors by `k` random centroids that define the centers of color clusters in the source image. The algorithm finds the closest colors to each centroid and updates each centroid to the average value of the closest colors. The process iterates over this step until the solution converges.\n\nThe image below shows the sample code app. The source image is on the left and a 3D point cloud of the color distribution is on the right. At the bottom of the image is a set of swatches that show the `k` dominant colors in the image.\n\n\n\nCalculating the dominant colors in an image is useful for applications such as creating color palettes for GIF image creation.\n\n### Store the pixel values\n\nThe sample app stores the pixel values in [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] structures with external storage. This approach ensures that the vImage library doesn’t add any additional padding to the image rows that could interfere with the k-means clustering result. For more information about row padding, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_Buffer].\n\nThe `init()` function initializes the three pixel buffers:\n\nThe sample code app scales all images to `dimension * dimension` pixels.\n\n### Initialize the cluster centroids\n\nThe `KMeansCalculator.initializeCentroids()` function initializes the centroids from the red, green, and blue source pixels. The function initializes the first centroid as a random color in the source image.\n\nThe code below uses the distance from the previous centroid as a weight to initialize subsequent centroids. This ensures that centroids are distributed across the image colors.\n\n### Calculate the distances between centroids and image colors\n\nThe `KMeansCalculator.updateCentroids()` function is responsible for updating the `k` centroids. The sample code app works in three dimensions with red, green, and blue as the axes.\n\nThe first step that the sample code project takes is to calculate the distance in 3D RGB space between each color in the source image and each of the `k` centroids. Because the distances are used for comparisons only, the code below calculates the distance squared and avoids the overhead of calculating square roots:\n\nThe image below is an example 8 x 1 pixel image. The image’s colors are such that the green and blue values in each color are the same.\n\n\n\nThe following graphic shows a 2D representation of the distribution of the eight pixel colors in the small image above. The simplified version uses red as the horizontal axis and green-blue as the vertical axis. The illustration represents the eight pixel colors as circles and represents two centroids as squares.\n\n\n\nGiven the following two rows represent the eight 2D colors:\n\nThe following matrix shows the distances squared. The top row represents the distances to centroid *A* and the bottom row represents the distances to centroid *B*:\n\n### Calculate the closest centroid to each image color\n\nThe BNNS library’s [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNS\/ReductionLayer] provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNS\/ReductionFunction\/argMin] reduction function that reduces the distances matrix to a vector that contains the index of the closest centroid for each color.\n\nBefore performing the reduction, the code below creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSNDArrayDescriptor] structure that references the distances data so that the app doesn’t perform a copy:\n\nUsing the simplified example above, the `centroidIndicesDescriptor` contains the following values after the code applies reduction:\n\n### Gather the color data for each centroid\n\nThe sample code app uses the data in the `centroidIndices` array to gather the color data into vectors for each centroid.  For each centroid in the `centroids` array, the code below creates an array that contains the indices into the color arrays of the colors nearest to that centroid:\n\nFor the 2D colors example, the `indices` array contains the following values:\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vDSP\/gather(_:indices:)-4yt3o] function returns arrays that contain `indices.count` color values.\n\nUsing the simplified example above, the following shows the gathered red and green-blue values for the two centroids:\n\nThe code updates each centroid with the average of their corresponding gathered colors:\n\nThe following image shows the example 2D centroids after the update:\n\n\n\nThe code repeats these steps until the updates to each centroid fall within a specified tolerance. Once the centroid changes become negligible, the app treats the k-means process as converged.\n\n### Generate a quantized image using the dominant colors\n\nAfter the sample code app calculates the `k` dominant colors, it uses that data to quantize the source image. That is, the app replaces each color in the image with the color of the nearest centroid.\n\nThe quantization step uses the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNS\/scatter(input:indices:output:axis:reductionFunction:filterParameters:)] that performs an operation that’s the inverse of the gather function the app uses for calculating k-means.\n\nFor each centroid, the sample finds the indices of the nearest colors and replaces the color values with that of the centroid:\n\nThe image below shows an original image of some oranges and the quantized version rendered with the five dominant colors:\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/accelerate\/calculating-the-dominant-colors-in-an-image\ncrawled: 2025-12-02T22:13:59Z\n---\n\n# Calculating the dominant colors in an image\n\n**Sample Code**\n\nFind the main colors in an image by implementing k-means clustering using the Accelerate framework.\n\n## Overview\n\nThe Accelerate framework provides libraries that allow you to extract a specified number (`k`) of average colors in an image. This sample code app computes these colors using the *k-means algorithm*. The k-means algorithm finds the `k` dominant colors by `k` random centroids that define the centers of color clusters in the source image. The algorithm finds the closest colors to each centroid and updates each centroid to the average value of the closest colors. The process iterates over this step until the solution converges.\n\nThe image below shows the sample code app. The source image is on the left and a 3D point cloud of the color distribution is on the right. At the bottom of the image is a set of swatches that show the `k` dominant colors in the image.\n\n\n\nCalculating the dominant colors in an image is useful for applications such as creating color palettes for GIF image creation.\n\n### Store the pixel values\n\nThe sample app stores the pixel values in [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] structures with external storage. This approach ensures that the vImage library doesn’t add any additional padding to the image rows that could interfere with the k-means clustering result. For more information about row padding, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_Buffer].\n\n```swift\n\/\/\/ The storage and pixel buffer for each red value.\nlet redStorage = UnsafeMutableBufferPointer<Float>.allocate(capacity: dimension * dimension)\nlet redBuffer: vImage.PixelBuffer<vImage.PlanarF>\n\n\/\/\/ The storage and pixel buffer for each green value.\nlet greenStorage = UnsafeMutableBufferPointer<Float>.allocate(capacity: dimension * dimension)\nlet greenBuffer: vImage.PixelBuffer<vImage.PlanarF>\n\n\/\/\/ The storage and pixel buffer for each blue value.\nlet blueStorage = UnsafeMutableBufferPointer<Float>.allocate(capacity: dimension * dimension)\nlet blueBuffer: vImage.PixelBuffer<vImage.PlanarF>\n```\n\nThe `init()` function initializes the three pixel buffers:\n\n```swift\nredBuffer = vImage.PixelBuffer<vImage.PlanarF>(\n    data: redStorage.baseAddress!,\n    width: dimension,\n    height: dimension,\n    byteCountPerRow: dimension * MemoryLayout<Float>.stride)\n\ngreenBuffer = vImage.PixelBuffer<vImage.PlanarF>(\n    data: greenStorage.baseAddress!,\n    width: dimension,\n    height: dimension,\n    byteCountPerRow: dimension * MemoryLayout<Float>.stride)\n\nblueBuffer = vImage.PixelBuffer<vImage.PlanarF>(\n    data: blueStorage.baseAddress!,\n    width: dimension,\n    height: dimension,\n    byteCountPerRow: dimension * MemoryLayout<Float>.stride)\n```\n\nThe sample code app scales all images to `dimension * dimension` pixels.\n\n### Initialize the cluster centroids\n\nThe `KMeansCalculator.initializeCentroids()` function initializes the centroids from the red, green, and blue source pixels. The function initializes the first centroid as a random color in the source image.\n\n```swift\nlet randomIndex = Int.random(in: 0 ..< dimension * dimension)\ncentroids.append(Centroid(red: redStorage[randomIndex],\n                          green: greenStorage[randomIndex],\n                          blue: blueStorage[randomIndex]))\n```\n\nThe code below uses the distance from the previous centroid as a weight to initialize subsequent centroids. This ensures that centroids are distributed across the image colors.\n\n```swift\nfor i in 1 ..< k {\n    distanceSquared(x0: greenStorage.baseAddress!, x1: centroids[i - 1].green,\n                    y0: blueStorage.baseAddress!, y1: centroids[i - 1].blue,\n                    z0: redStorage.baseAddress!, z1: centroids[i - 1].red,\n                    n: greenStorage.count,\n                    result: tmp.baseAddress!)\n    \n    let randomIndex = weightedRandomIndex(tmp)\n    \n    centroids.append(Centroid(red: redStorage[randomIndex],\n                              green: greenStorage[randomIndex],\n                              blue: blueStorage[randomIndex]))\n}\n```\n\n### Calculate the distances between centroids and image colors\n\nThe `KMeansCalculator.updateCentroids()` function is responsible for updating the `k` centroids. The sample code app works in three dimensions with red, green, and blue as the axes.\n\nThe first step that the sample code project takes is to calculate the distance in 3D RGB space between each color in the source image and each of the `k` centroids. Because the distances are used for comparisons only, the code below calculates the distance squared and avoids the overhead of calculating square roots:\n\n```swift\nfor centroid in centroids.enumerated() {\n    distanceSquared(x0: greenStorage.baseAddress!, x1: centroid.element.green,\n                    y0: blueStorage.baseAddress!, y1: centroid.element.blue,\n                    z0: redStorage.baseAddress!, z1: centroid.element.red,\n                    n: greenStorage.count,\n                    result: distances.baseAddress!.advanced(by: dimension * dimension * centroid.offset))\n}\n```\n\nThe image below is an example 8 x 1 pixel image. The image’s colors are such that the green and blue values in each color are the same.\n\n\n\nThe following graphic shows a 2D representation of the distribution of the eight pixel colors in the small image above. The simplified version uses red as the horizontal axis and green-blue as the vertical axis. The illustration represents the eight pixel colors as circles and represents two centroids as squares.\n\n\n\nGiven the following two rows represent the eight 2D colors:\n\n```\n[ 0.0, 0.0, 2.0, 3.0, 7.0, 5.0, 6.0, 4.0 ]    \/\/ Red color values for colors 0...7.\n[ 6.0, 1.0, 0.0, 2.0, 7.0, 5.0, 2.0, 3.0 ]    \/\/ Green-blue color values for colors 0...7.\n```\n\nThe following matrix shows the distances squared. The top row represents the distances to centroid *A* and the bottom row represents the distances to centroid *B*:\n\n```\n[ 9.0, 34.0, 37.0, 16.0, 17.0,  5.0, 25.0, 10.0,        \/\/ For centroid _A_.\n 50.0, 25.0, 10.0,  5.0, 40.0, 16.0,  2.0,  5.0 ]       \/\/ For centroid _B_.\n```\n\n### Calculate the closest centroid to each image color\n\nThe BNNS library’s [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNS\/ReductionLayer] provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNS\/ReductionFunction\/argMin] reduction function that reduces the distances matrix to a vector that contains the index of the closest centroid for each color.\n\nBefore performing the reduction, the code below creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSNDArrayDescriptor] structure that references the distances data so that the app doesn’t perform a copy:\n\n```swift\nfunc makeCentroidIndices() -> [Int32] {\n    let distancesDescriptor = BNNSNDArrayDescriptor(\n        data: distances,\n        shape: .matrixRowMajor(dimension * dimension, k))!\n    \n    let reductionLayer = BNNS.ReductionLayer(function: .argMin,\n                                             input: distancesDescriptor,\n                                             output: centroidIndicesDescriptor,\n                                             weights: nil)\n    \n    try! reductionLayer?.apply(batchSize: 1,\n                               input: distancesDescriptor,\n                               output: centroidIndicesDescriptor)\n    \n    return centroidIndicesDescriptor.makeArray(of: Int32.self)!\n}\n```\n\nUsing the simplified example above, the `centroidIndicesDescriptor` contains the following values after the code applies reduction:\n\n```\n[ 0, 1, 1, 1, 0, 0, 1, 1 ]      \/\/ 0 represents centroid _A_, and 1 represents centroid _B_.\n```\n\n### Gather the color data for each centroid\n\nThe sample code app uses the data in the `centroidIndices` array to gather the color data into vectors for each centroid.  For each centroid in the `centroids` array, the code below creates an array that contains the indices into the color arrays of the colors nearest to that centroid:\n\n```swift\nlet indices = centroidIndices.enumerated().filter {\n    $0.element == centroid.offset\n}.map {\n    \/\/ `vDSP.gather` uses one-based indices.\n    UInt($0.offset + 1)\n}\n```\n\nFor the 2D colors example, the `indices` array contains the following values:\n\n```\n[ 0,          4, 5 ]          \/\/ For centroid _A_.\n[    1, 2, 3,       6, 7 ]    \/\/ For centroid _B_.\n```\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vDSP\/gather(_:indices:)-4yt3o] function returns arrays that contain `indices.count` color values.\n\n```swift\nlet gatheredRed = vDSP.gather(redStorage,\n                              indices: indices)\n\nlet gatheredGreen = vDSP.gather(greenStorage,\n                                indices: indices)\n\nlet gatheredBlue = vDSP.gather(blueStorage,\n                               indices: indices)\n```\n\nUsing the simplified example above, the following shows the gathered red and green-blue values for the two centroids:\n\n```\n[ 0.0,               7.0, 5.0 ]             \/\/ Gathered red values for centroid _A_.   \n[ 6.0,               7.0, 5.0 ]             \/\/ Gathered green-blue values for centroid _A_.\n\n[     0.0, 2.0, 3.0,           6.0, 4.0 ]   \/\/ Gathered red values for centroid _B_.\n[     1.0, 0.0, 2.0,           2.0, 3.0 ]   \/\/ Gathered green-blue values for centroid _B_.\n```\n\nThe code updates each centroid with the average of their corresponding gathered colors:\n\n```swift\ncentroids[centroid.offset].red = vDSP.mean(gatheredRed)\ncentroids[centroid.offset].green = vDSP.mean(gatheredGreen)\ncentroids[centroid.offset].blue = vDSP.mean(gatheredBlue)\n```\n\nThe following image shows the example 2D centroids after the update:\n\n\n\n```\n4.0    \/\/ Mean red value for centroid _A_.\n6.0    \/\/ Mean green-blue value for centroid _A_.\n\n3.0    \/\/ Mean red value for centroid _B_.\n1.6    \/\/ Mean green-blue value for centroid _B_.\n```\n\nThe code repeats these steps until the updates to each centroid fall within a specified tolerance. Once the centroid changes become negligible, the app treats the k-means process as converged.\n\n### Generate a quantized image using the dominant colors\n\nAfter the sample code app calculates the `k` dominant colors, it uses that data to quantize the source image. That is, the app replaces each color in the image with the color of the nearest centroid.\n\nThe quantization step uses the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNS\/scatter(input:indices:output:axis:reductionFunction:filterParameters:)] that performs an operation that’s the inverse of the gather function the app uses for calculating k-means.\n\nFor each centroid, the sample finds the indices of the nearest colors and replaces the color values with that of the centroid:\n\n```swift\nlet indicesDescriptor = BNNSNDArrayDescriptor.allocate(\n    initializingFrom: indices,\n    shape: .vector(indices.count))\n\ndefer {\n    indicesDescriptor.deallocate()\n}\n\nscatter(value: centroid.element.red, to: redQuantizedStorage)\nscatter(value: centroid.element.green, to: greenQuantizedStorage)\nscatter(value: centroid.element.blue, to: blueQuantizedStorage)\n\n\/\/\/ Scatters the repeated `value` to the `destination` using the `indicesDescriptor`.\nfunc scatter(value: Float,\n             to destination: UnsafeMutableBufferPointer<Float>) {\n    let srcDescriptor = BNNSNDArrayDescriptor.allocate(repeating: value,\n                                                       shape: .vector(indices.count))\n    let dstDescriptor = BNNSNDArrayDescriptor(data: destination,\n                                              shape: .vector(dimension * dimension))!\n    \n    try! BNNS.scatter(input: srcDescriptor,\n                      indices: indicesDescriptor,\n                      output: dstDescriptor,\n                      axis: 0,\n                      reductionFunction: .sum)\n    \n    srcDescriptor.deallocate()\n}\n```\n\nThe image below shows an original image of some oranges and the quantized version rendered with the five dominant colors:\n\n\n\n## vImage Pixel Buffers\n\n- **Using vImage pixel buffers to generate video effects**: Render real-time video effects with the vImage Pixel Buffer.\n- **Applying tone curve adjustments to images**: Use the vImage library’s polynomial transform to apply tone curve adjustments to images.\n- **Adjusting the brightness and contrast of an image**: Use a gamma function to apply a linear or exponential curve.\n- **Adjusting the hue of an image**: Convert an image to L*a*b* color space and apply hue adjustment.\n- **Sharing texture data between the Model I\/O framework and the vImage library**: Use Model I\/O and vImage to composite a photograph over a computer-generated sky.\n- **vImage.PixelBuffer**: An image buffer that stores an image’s pixel data, dimensions, bit depth, and number of channels.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render real-time video effects with the vImage Pixel Buffer.",
          "name" : "Using vImage pixel buffers to generate video effects",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/using-vimage-pixel-buffers-to-generate-video-effects"
        },
        {
          "description" : "Use the vImage library’s polynomial transform to apply tone curve adjustments to images.",
          "name" : "Applying tone curve adjustments to images",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-tone-curve-adjustments-to-images"
        },
        {
          "description" : "Use a gamma function to apply a linear or exponential curve.",
          "name" : "Adjusting the brightness and contrast of an image",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-the-brightness-and-contrast-of-an-image"
        },
        {
          "description" : "Convert an image to L*a*b* color space and apply hue adjustment.",
          "name" : "Adjusting the hue of an image",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/adjusting-the-hue-of-an-image"
        },
        {
          "description" : "Use Model I\/O and vImage to composite a photograph over a computer-generated sky.",
          "name" : "Sharing texture data between the Model I\/O framework and the vImage library",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/sharing-texture-data-between-the-model-io-framework-and-the-vimage-library"
        },
        {
          "description" : "An image buffer that stores an image’s pixel data, dimensions, bit depth, and number of channels.",
          "name" : "vImage.PixelBuffer",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vImage\/PixelBuffer"
        }
      ],
      "title" : "vImage Pixel Buffers"
    }
  ],
  "source" : "appleJSON",
  "title" : "Calculating the dominant colors in an image",
  "url" : "https:\/\/developer.apple.com\/documentation\/accelerate\/calculating-the-dominant-colors-in-an-image"
}