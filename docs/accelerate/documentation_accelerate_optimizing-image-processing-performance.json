{
  "abstract" : "Improve your app’s performance by converting image buffer formats from interleaved to planar.",
  "codeExamples" : [
    {
      "code" : "var cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 4,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue:\n                                CGImageAlphaInfo.noneSkipLast.rawValue))!\n\nlet sourceBuffer = try vImage.PixelBuffer(cgImage: sourceImage,\n                                          cgImageFormat: &cgImageFormat,\n                                          pixelFormat: vImage.Interleaved8x4.self)\n\nlet destinationBuffer = vImage.PixelBuffer(size: .init(width: sourceBuffer.width \/ 10,\n                                                       height: sourceBuffer.height \/ 10),\n                                           pixelFormat: vImage.Interleaved8x4.self)\n\nlet time = ContinuousClock().measure {\n    sourceBuffer.scale(destination: destinationBuffer)\n}",
      "language" : "swift"
    },
    {
      "code" : "var cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 3,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue:\n                                CGImageAlphaInfo.none.rawValue))!\n\nlet sourceBuffer = try vImage.PixelBuffer(cgImage: sourceImage,\n                                          cgImageFormat: &cgImageFormat,\n                                          pixelFormat: vImage.Interleaved8x3.self)\nlet sourceRedBuffer = vImage.PixelBuffer(size: sourceBuffer.size,\n                                         pixelFormat: vImage.Planar8.self)\nlet sourceGreenBuffer = vImage.PixelBuffer(size: sourceBuffer.size,\n                                           pixelFormat: vImage.Planar8.self)\nlet sourceBlueBuffer = vImage.PixelBuffer(size: sourceBuffer.size,\n                                          pixelFormat: vImage.Planar8.self)\n\nsourceBuffer.deinterleave(planarDestinationBuffers: [sourceRedBuffer,\n                                                     sourceGreenBuffer,\n                                                     sourceBlueBuffer])",
      "language" : "swift"
    },
    {
      "code" : "let destinationBuffer = vImage.PixelBuffer(size: .init(width: sourceBuffer.width \/ 10,\n                                                       height: sourceBuffer.height \/ 10),\n                                           pixelFormat: vImage.Interleaved8x3.self)\n\nlet destinationRedBuffer = vImage.PixelBuffer(size: destinationBuffer.size,\n                                              pixelFormat: vImage.Planar8.self)\nlet destinationGreenBuffer = vImage.PixelBuffer(size: destinationBuffer.size,\n                                                pixelFormat: vImage.Planar8.self)\nlet destinationBlueBuffer = vImage.PixelBuffer(size: destinationBuffer.size,\n                                               pixelFormat: vImage.Planar8.self)",
      "language" : "swift"
    },
    {
      "code" : "let time = await ContinuousClock().measure {\n    \n    await withTaskGroup(of: Void.self) { group in\n        \n        group.addTask(priority: .userInitiated) {\n            sourceRedBuffer.scale(destination: destinationRedBuffer)\n        }\n        \n        group.addTask(priority: .userInitiated) {\n            sourceGreenBuffer.scale(destination: destinationGreenBuffer)\n        }\n        \n        group.addTask(priority: .userInitiated) {\n            sourceBlueBuffer.scale(destination: destinationBlueBuffer)\n        }\n    }\n    \n    destinationBuffer.interleave(planarSourceBuffers: [destinationRedBuffer,\n                                                       destinationGreenBuffer,\n                                                       destinationBlueBuffer])\n}",
      "language" : "swift"
    },
    {
      "code" : "let scaledImage = destinationBuffer.makeCGImage(cgImageFormat: cgImageFormat)",
      "language" : "swift"
    }
  ],
  "contentHash" : "ae70d27d2199a3b5469a56cc26fa935818b4dba5e60600e909d3dc2ac9d873d3",
  "crawledAt" : "2025-12-02T15:37:12Z",
  "id" : "CDAED987-CDD8-4A5A-BBB7-5137C266485C",
  "kind" : "article",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nThe vImage library operates on image data with two memory layouts:\n\n**Interleaved** stores each pixel’s color data consecutively in a single buffer. For example, the data that describes a 4-channel image (red, green, blue, and alpha) would be stored as RGBARGBARGBA…\n\n**Planar** stores each color channel in separate buffers. For example, a 4-channel image would be stored as four individual buffers containing red, green, blue, and alpha data.\n\n\n\nBecause many vImage functions operate on a single color channel at a time — by converting an interleaved buffer to planar buffers — you can often improve your app’s performance by doing this conversion manually. However, most vImage functions are available in both the interleaved and planar variants, so before you do the conversion, try both to see which works better in your context.\n\nIn some cases, you may not want to apply a vImage operation to all four channels of an image. For example, you may know beforehand that the alpha channel is irrelevant in the images that you’re dealing with, or perhaps all of your images are grayscale and you need to operate on only one channel. Using planar formats makes it possible to isolate and work with only the channels you need.\n\n### Review interleaved performance\n\nTypically, your source imagery is in interleaved format, and your default option will be to use the interleaved variant of a vImage function. For example, the following code scales a Core Graphics image to one tenth of its original size. Note that the 4-channel, 8-bit-per-channel interleaved pixel buffer [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/scale(destination:)-5euvc] function calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageScale_ARGB8888(_:_:_:_:)].\n\nYou can use [doc:\/\/com.apple.documentation\/documentation\/Swift\/ContinuousClock] to measure the execution time.\n\n### Convert an interleaved source buffer to planar buffers\n\nThe pixel buffer [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/init(cgImage:cgImageFormat:pixelFormat:)] initializer and the vImage buffer [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCGImage(_:_:_:_:_:)] function both populate a buffer based on the properties of a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure.\n\nFor example, the following code creates an interleaved 3-channel, 8-bit-per-channel [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] structure from the source Core Graphics image. The code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/deinterleave(destination:)-hrhz] to deinterleave the image data and populate the individual red, green, and blue planar pixel buffers.\n\n### Initialize the destination buffers\n\nCreate an interleaved 3-channel, 8-bit-per-channel destination buffer and three planar destination buffers:\n\n### Apply the scale operation to the planar buffers\n\nUse the `withTaskGroup(of:returning:body:)` function to start a new scope that contains the three planar scale operations. Note that the 8-bit planar [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/scale(destination:)-5euvc] function calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageScale_Planar8(_:_:_:_:)].\n\nIn the code below, the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/interleave(destination:)-46cgi] function interleaves the three planar buffers and populates the interleaved destination buffer with the scaled image:\n\nThe following code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/makeCGImage(cgImageFormat:)] to create a Core Graphics image from the result of the scale operation:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/optimizing-image-processing-performance\ncrawled: 2025-12-02T15:37:12Z\n---\n\n# Optimizing image-processing performance\n\n**Article**\n\nImprove your app’s performance by converting image buffer formats from interleaved to planar.\n\n## Overview\n\nThe vImage library operates on image data with two memory layouts:\n\n**Interleaved** stores each pixel’s color data consecutively in a single buffer. For example, the data that describes a 4-channel image (red, green, blue, and alpha) would be stored as RGBARGBARGBA…\n\n**Planar** stores each color channel in separate buffers. For example, a 4-channel image would be stored as four individual buffers containing red, green, blue, and alpha data.\n\n\n\nBecause many vImage functions operate on a single color channel at a time — by converting an interleaved buffer to planar buffers — you can often improve your app’s performance by doing this conversion manually. However, most vImage functions are available in both the interleaved and planar variants, so before you do the conversion, try both to see which works better in your context.\n\nIn some cases, you may not want to apply a vImage operation to all four channels of an image. For example, you may know beforehand that the alpha channel is irrelevant in the images that you’re dealing with, or perhaps all of your images are grayscale and you need to operate on only one channel. Using planar formats makes it possible to isolate and work with only the channels you need.\n\n### Review interleaved performance\n\nTypically, your source imagery is in interleaved format, and your default option will be to use the interleaved variant of a vImage function. For example, the following code scales a Core Graphics image to one tenth of its original size. Note that the 4-channel, 8-bit-per-channel interleaved pixel buffer [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/scale(destination:)-5euvc] function calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageScale_ARGB8888(_:_:_:_:)].\n\n```swift\nvar cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 4,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue:\n                                CGImageAlphaInfo.noneSkipLast.rawValue))!\n\nlet sourceBuffer = try vImage.PixelBuffer(cgImage: sourceImage,\n                                          cgImageFormat: &cgImageFormat,\n                                          pixelFormat: vImage.Interleaved8x4.self)\n\nlet destinationBuffer = vImage.PixelBuffer(size: .init(width: sourceBuffer.width \/ 10,\n                                                       height: sourceBuffer.height \/ 10),\n                                           pixelFormat: vImage.Interleaved8x4.self)\n\nlet time = ContinuousClock().measure {\n    sourceBuffer.scale(destination: destinationBuffer)\n}\n```\n\nYou can use [doc:\/\/com.apple.documentation\/documentation\/Swift\/ContinuousClock] to measure the execution time.\n\n### Convert an interleaved source buffer to planar buffers\n\nThe pixel buffer [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/init(cgImage:cgImageFormat:pixelFormat:)] initializer and the vImage buffer [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageBuffer_InitWithCGImage(_:_:_:_:_:)] function both populate a buffer based on the properties of a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure.\n\nFor example, the following code creates an interleaved 3-channel, 8-bit-per-channel [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] structure from the source Core Graphics image. The code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/deinterleave(destination:)-hrhz] to deinterleave the image data and populate the individual red, green, and blue planar pixel buffers.\n\n```swift\nvar cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 8 * 3,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(rawValue:\n                                CGImageAlphaInfo.none.rawValue))!\n\nlet sourceBuffer = try vImage.PixelBuffer(cgImage: sourceImage,\n                                          cgImageFormat: &cgImageFormat,\n                                          pixelFormat: vImage.Interleaved8x3.self)\nlet sourceRedBuffer = vImage.PixelBuffer(size: sourceBuffer.size,\n                                         pixelFormat: vImage.Planar8.self)\nlet sourceGreenBuffer = vImage.PixelBuffer(size: sourceBuffer.size,\n                                           pixelFormat: vImage.Planar8.self)\nlet sourceBlueBuffer = vImage.PixelBuffer(size: sourceBuffer.size,\n                                          pixelFormat: vImage.Planar8.self)\n\nsourceBuffer.deinterleave(planarDestinationBuffers: [sourceRedBuffer,\n                                                     sourceGreenBuffer,\n                                                     sourceBlueBuffer])\n```\n\n### Initialize the destination buffers\n\nCreate an interleaved 3-channel, 8-bit-per-channel destination buffer and three planar destination buffers:\n\n```swift\nlet destinationBuffer = vImage.PixelBuffer(size: .init(width: sourceBuffer.width \/ 10,\n                                                       height: sourceBuffer.height \/ 10),\n                                           pixelFormat: vImage.Interleaved8x3.self)\n\nlet destinationRedBuffer = vImage.PixelBuffer(size: destinationBuffer.size,\n                                              pixelFormat: vImage.Planar8.self)\nlet destinationGreenBuffer = vImage.PixelBuffer(size: destinationBuffer.size,\n                                                pixelFormat: vImage.Planar8.self)\nlet destinationBlueBuffer = vImage.PixelBuffer(size: destinationBuffer.size,\n                                               pixelFormat: vImage.Planar8.self)\n```\n\n### Apply the scale operation to the planar buffers\n\nUse the `withTaskGroup(of:returning:body:)` function to start a new scope that contains the three planar scale operations. Note that the 8-bit planar [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/scale(destination:)-5euvc] function calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageScale_Planar8(_:_:_:_:)].\n\nIn the code below, the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/interleave(destination:)-46cgi] function interleaves the three planar buffers and populates the interleaved destination buffer with the scaled image:\n\n```swift\nlet time = await ContinuousClock().measure {\n    \n    await withTaskGroup(of: Void.self) { group in\n        \n        group.addTask(priority: .userInitiated) {\n            sourceRedBuffer.scale(destination: destinationRedBuffer)\n        }\n        \n        group.addTask(priority: .userInitiated) {\n            sourceGreenBuffer.scale(destination: destinationGreenBuffer)\n        }\n        \n        group.addTask(priority: .userInitiated) {\n            sourceBlueBuffer.scale(destination: destinationBlueBuffer)\n        }\n    }\n    \n    destinationBuffer.interleave(planarSourceBuffers: [destinationRedBuffer,\n                                                       destinationGreenBuffer,\n                                                       destinationBlueBuffer])\n}\n```\n\nThe following code calls [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/makeCGImage(cgImageFormat:)] to create a Core Graphics image from the result of the scale operation:\n\n```swift\nlet scaledImage = destinationBuffer.makeCGImage(cgImageFormat: cgImageFormat)\n```\n\n## Image Processing Essentials\n\n- **Converting bitmap data between Core Graphics images and vImage buffers**: Pass image data between Core Graphics and vImage to create and manipulate images.\n- **Creating and Populating Buffers from Core Graphics Images**: Initialize vImage buffers from Core Graphics images.\n- **Creating a Core Graphics Image from a vImage Buffer**: Create displayable representations of vImage buffers.\n- **Building a Basic Image-Processing Workflow**: Resize an image with vImage.\n- **Applying geometric transforms to images**: Reflect, shear, rotate, and scale image buffers using vImage.\n- **Compositing images with alpha blending**: Combine two images by using alpha blending to create a single output.\n- **Compositing images with vImage blend modes**: Combine two images by using blend modes to create a single output.\n- **Applying vImage operations to regions of interest**: Limit the effect of vImage operations to rectangular regions of interest.\n- **vImage**: Manipulate large images using the CPU’s vector processor.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Pass image data between Core Graphics and vImage to create and manipulate images.",
          "name" : "Converting bitmap data between Core Graphics images and vImage buffers",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/converting-bitmap-data-between-core-graphics-images-and-vimage-buffers"
        },
        {
          "description" : "Initialize vImage buffers from Core Graphics images.",
          "name" : "Creating and Populating Buffers from Core Graphics Images",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/creating-and-populating-buffers-from-core-graphics-images"
        },
        {
          "description" : "Create displayable representations of vImage buffers.",
          "name" : "Creating a Core Graphics Image from a vImage Buffer",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/creating-a-core-graphics-image-from-a-vimage-buffer"
        },
        {
          "description" : "Resize an image with vImage.",
          "name" : "Building a Basic Image-Processing Workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/building-a-basic-image-processing-workflow"
        },
        {
          "description" : "Reflect, shear, rotate, and scale image buffers using vImage.",
          "name" : "Applying geometric transforms to images",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-geometric-transforms-to-images"
        },
        {
          "description" : "Combine two images by using alpha blending to create a single output.",
          "name" : "Compositing images with alpha blending",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/compositing-images-with-alpha-blending"
        },
        {
          "description" : "Combine two images by using blend modes to create a single output.",
          "name" : "Compositing images with vImage blend modes",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/compositing-images-with-vimage-blend-modes"
        },
        {
          "description" : "Limit the effect of vImage operations to rectangular regions of interest.",
          "name" : "Applying vImage operations to regions of interest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-vimage-operations-to-regions-of-interest"
        },
        {
          "description" : "Manipulate large images using the CPU’s vector processor.",
          "name" : "vImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/vimage-library"
        }
      ],
      "title" : "Image Processing Essentials"
    }
  ],
  "source" : "appleJSON",
  "title" : "Optimizing image-processing performance",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/optimizing-image-processing-performance"
}