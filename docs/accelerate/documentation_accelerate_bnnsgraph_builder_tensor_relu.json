{
  "abstract" : "Adds a Rectified Linear Unit (ReLU) activation operation to the current graph.",
  "codeExamples" : [

  ],
  "contentHash" : "8d24c26595d348ca01dc36cecb7f261045d2e51400360e45ecac7fb2190fc50f",
  "crawledAt" : "2025-11-30T22:02:34Z",
  "declaration" : {
    "code" : "func relu() -> BNNSGraph.Builder.Tensor<T>",
    "language" : "swift"
  },
  "id" : "0DED4FAD-C5EB-40A3-B936-6A9810129BC9",
  "kind" : "method",
  "module" : "Accelerate",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/relu()\ncrawled: 2025-11-30T22:02:34Z\n---\n\n# relu()\n\n**Instance Method**\n\nAdds a Rectified Linear Unit (ReLU) activation operation to the current graph.\n\n## Declaration\n\n```swift\nfunc relu() -> BNNSGraph.Builder.Tensor<T>\n```\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "relu()",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/relu()"
}