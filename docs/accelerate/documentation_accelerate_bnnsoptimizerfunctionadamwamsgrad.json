{
  "abstract" : "An optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm.",
  "codeExamples" : [

  ],
  "contentHash" : "7d121227a4f30da5eb5afc80a95a480c6fe8398c383213a76e8f6e6fe8b8c0cb",
  "crawledAt" : "2025-12-02T01:50:55Z",
  "declaration" : {
    "code" : "var BNNSOptimizerFunctionAdamWAMSGrad: BNNSOptimizerFunction { get }",
    "language" : "swift"
  },
  "id" : "B09F8364-0219-4370-AA8D-C51288853499",
  "kind" : "unknown",
  "module" : "Accelerate",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSOptimizerFunctionAdamWAMSGrad\ncrawled: 2025-12-02T01:50:55Z\n---\n\n# BNNSOptimizerFunctionAdamWAMSGrad\n\n**Global Variable**\n\nAn optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm.\n\n## Declaration\n\n```swift\nvar BNNSOptimizerFunctionAdamWAMSGrad: BNNSOptimizerFunction { get }\n```\n\n## AdamW Optimizer Functions\n\n- **BNNSOptimizerFunctionAdamW**: An optimizer function that updates parameters according to the AdamW algorithm.\n- **BNNSOptimizerFunctionAdamWWithClipping**: An optimizer function that updates parameters according to the AdamW algorithm and optionally clips the gradient by value or by norm.\n- **BNNSOptimizerFunctionAdamWAMSGradWithClipping**: An optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm and optionally clips the gradient by value or by norm.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An optimizer function that updates parameters according to the AdamW algorithm.",
          "name" : "BNNSOptimizerFunctionAdamW",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSOptimizerFunctionAdamW"
        },
        {
          "description" : "An optimizer function that updates parameters according to the AdamW algorithm and optionally clips the gradient by value or by norm.",
          "name" : "BNNSOptimizerFunctionAdamWWithClipping",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSOptimizerFunctionAdamWWithClipping"
        },
        {
          "description" : "An optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm and optionally clips the gradient by value or by norm.",
          "name" : "BNNSOptimizerFunctionAdamWAMSGradWithClipping",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSOptimizerFunctionAdamWAMSGradWithClipping"
        }
      ],
      "title" : "AdamW Optimizer Functions"
    }
  ],
  "source" : "appleJSON",
  "title" : "BNNSOptimizerFunctionAdamWAMSGrad",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSOptimizerFunctionAdamWAMSGrad"
}