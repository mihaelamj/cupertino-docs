{
  "abstract" : "Adds a Parametric ReLU (PReLU) activation operation to the current graph.",
  "codeExamples" : [

  ],
  "contentHash" : "0dd0627545c3eb00285f5a0d1effb94d2f376ad8cf5526903cc0630b0a99936d",
  "crawledAt" : "2025-11-30T22:02:31Z",
  "declaration" : {
    "code" : "func prelu(alpha: [Float]) -> BNNSGraph.Builder.Tensor<T>",
    "language" : "swift"
  },
  "id" : "590DC736-CAF6-422C-B25F-B6E0D413F9BF",
  "kind" : "method",
  "module" : "Accelerate",
  "overview" : "## Discussion\n\nPerforms the operation `prelu(self) = max(0, self) + alpha[i] * min(0, self)`, for each channel `i`.\n\n`self` must have at least two dimensions.\n\nThe number of elements in `alpha` must be either 1 or `self.shape[1]`.\n\nThe operation applies the weight `alpha[i]` to channel `i` while performing the activation.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/prelu(alpha:)\ncrawled: 2025-11-30T22:02:31Z\n---\n\n# prelu(alpha:)\n\n**Instance Method**\n\nAdds a Parametric ReLU (PReLU) activation operation to the current graph.\n\n## Declaration\n\n```swift\nfunc prelu(alpha: [Float]) -> BNNSGraph.Builder.Tensor<T>\n```\n\n## Discussion\n\nPerforms the operation `prelu(self) = max(0, self) + alpha[i] * min(0, self)`, for each channel `i`.\n\n`self` must have at least two dimensions.\n\nThe number of elements in `alpha` must be either 1 or `self.shape[1]`.\n\nThe operation applies the weight `alpha[i]` to channel `i` while performing the activation.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "prelu(alpha:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/prelu(alpha:)"
}