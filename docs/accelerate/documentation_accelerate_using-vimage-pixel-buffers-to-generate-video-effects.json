{
  "abstract" : "Render real-time video effects with the vImage Pixel Buffer.",
  "codeExamples" : [
    {
      "code" : "let cvImageFormat = vImageCVImageFormat.make(\n    format: .format422YpCbCr8,\n    matrix: kvImage_ARGBToYpCbCrMatrix_ITU_R_601_4.pointee,\n    chromaSiting: .center,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    alphaIsOpaqueHint: true)!\n\nlet cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 32,\n    bitsPerPixel: 32 * 3,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(\n        rawValue: kCGBitmapByteOrder32Host.rawValue |\n        CGBitmapInfo.floatComponents.rawValue |\n        CGImageAlphaInfo.none.rawValue),\n    renderingIntent: .defaultIntent)!\n\nlazy var converter: vImageConverter = {\n    guard let converter = try? vImageConverter.make(\n        sourceFormat: cvImageFormat,\n        destinationFormat: cgImageFormat) else {\n        fatalError(\"Unable to create converter\")\n    }\n    \n    return converter\n}()",
      "language" : "swift"
    },
    {
      "code" : "func populateDestinationBuffer(pixelBuffer: CVPixelBuffer) {\n    \n    let sourceBuffer = vImage.PixelBuffer(\n        referencing: pixelBuffer,\n        converter: converter,\n        destinationPixelFormat: vImage.DynamicPixelFormat.self)\n    \n    do {\n        try converter.convert(\n            from: sourceBuffer,\n            to: destinationBuffer)\n    } catch {\n        fatalError(\"Any-to-any conversion failure.\")\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "func applyNoise() {\n    \n    noiseBuffer.withUnsafeMutableBufferPointer { noisePtr in\n        \n        if var descriptor = BNNSNDArrayDescriptor(\n            data: noisePtr,\n            shape: BNNS.Shape.tensor3DFirstMajor(\n                noiseBuffer.width,\n                noiseBuffer.height,\n                noiseBuffer.channelCount)) {\n            \n            \/\/\/ Fill `noiseBuffer` with random values mapped to a normal distribution with a mean\n            \/\/\/ of `0` and a standard deviation of `0.125`.\n            let mean: Float = 0\n            let stdDev: Float = 0.125\n            \n            BNNSRandomFillNormalFloat(\n                randomNumberGenerator,\n                &descriptor,\n                mean,\n                stdDev)\n        }\n    }\n    \n    \/\/\/ Fill `mutableDestinationPtr` with the sum of the corresponding pixels\n    \/\/\/ in `destinationBuffer` and `noiseBuffer`.\n    destinationBuffer.withUnsafeMutableBufferPointer { mutablDestinationPtr in\n        \n        vDSP.add(destinationBuffer, noiseBuffer,\n                 result: &mutablDestinationPtr)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "func applyTemporalBlur() {\n    \n    let interpolationConstant: Float = 0.925\n    \n    destinationBuffer.linearInterpolate(\n        bufferB: temporalBuffer,\n        interpolationConstant: interpolationConstant,\n        destination: temporalBuffer)\n    \n    temporalBuffer.copy(to: destinationBuffer)\n}",
      "language" : "swift"
    },
    {
      "code" : "func applyPosterization() {\n    \n    destinationBuffer.deinterleave(\n        destination: histogramBuffer)\n    \n    let histogram = histogramBuffer.histogram(\n        binCount: 4)\n    \n    histogramBuffer.specifyHistogram(\n        histogram,\n        destination: histogramBuffer)\n    \n    histogramBuffer.interleave(\n        destination: destinationBuffer)\n}",
      "language" : "swift"
    },
    {
      "code" : "func applyColorThreshold() {\n    \n    let threshold: Float = 0.5\n    \n    destinationBuffer.colorThreshold(\n        threshold,\n        destination: destinationBuffer)\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "509e60b20d0c3522ee136eeaa4f9fe45111805b84c05e38ff1375c20a8a80a81",
  "crawledAt" : "2025-12-02T15:46:13Z",
  "id" : "32F2EEE3-B322-4CCE-A1A7-EB94278B8635",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\n\n\nThis sample code project captures video from a macOS device’s camera and applies video effects in real time. The sample converts the 8-bit YpCbCr video frames to 32-bit RGB [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] images and demonstrates image-processing techniques that are available only for 32-bit data.\n\nBefore exploring the code, build and run the app to familiarize yourself with the different visual results the app generates from the camera.\n\n### Create the any-to-any converter\n\nThe code creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance that converts the YpCbCr video frames to three-channel, 32-bit-per-channel, floating-point interleaved image data.\n\n### Convert a Core Video pixel buffer to RGB\n\nThe code defines `destinationBuffer` as a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/InterleavedFx3] pixel buffer. The conversion function creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/DynamicPixelFormat] source buffer that references the locked [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instance and passes that to the any-to-any converter.\n\nOn return, `destinationBuffer` contains the RGB representation of the YpCbCr video frame.\n\n### Apply the noise effect\n\nThe sample simulates noise or film grain by adding Gaussian noise (with a mean of zero) to each frame. The image below shows an example of the noise effect:\n\n\n\nAccelerate’s BNNS library provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSRandomFillNormalFloat(_:_:_:_:)] function that fills an array descriptor with random floating-point values mapped to a normal distribution. Use the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/withUnsafeMutableBufferPointer(_:)] function to pass a pointer to the pixel buffer’s underlying data to a  [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSNDArrayDescriptor].\n\nThe following code generates the noise effect:\n\n### Apply the temporal blur effect\n\nThe temporal blur effect blurs the image over time by calculating a weighted average of the current frame and previous frames. The effect is analogous to an exaggerated motion blur.\n\nThe image below shows an example of a rotating image with the temporal blur effect:\n\n\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/linearInterpolate(bufferB:interpolationConstant:destination:)] function calls the vDSP function [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vDSP_vintb] to calculate the linear interpolation between the current frame and the previous interpolated frame.\n\nThe following code generates the temporal blur effect:\n\n### Apply the posterization effect\n\nThe posterization effect reduces the continuous colors of an image to fewer tones. The effect produces results with regions of solid colors. The image below shows an example of the posterization effect:\n\n\n\nThe sample generates the posterization effect using histogram specification. The code achieves the reduced color count by calculating and specifying a histogram that has a low bin count. For more information about histogram specification, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/specifying-histograms-with-vimage].\n\nThe code populates a multiple-plane pixel buffer from the interleaved destination buffer. The multiple-plane pixel buffer contains three discrete planar buffers, and the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/Histogram888] function returns the histogram for the individual red, green, and blue channels. Specifying a bin count of `4` returns a result that contains a maximum of `4 * 4 * 4` (`64`) colors.\n\nThe following code generates the posterization effect:\n\n### Apply the color threshold effect\n\nThe color threshold effect is similar to the posterization effect, but reduces each color channel to a single-bit, so each color is either `0` or `1`. The image below shows the color threshold effect:\n\n\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/colorThreshold(_:destination:)] function sets pixel values equal to or greater than the specified threshold to `1` and other pixel values to `0`. Because the function works over the individual red, green, and blue values, the result contains a maximum of `2 * 2 * 2` (`8`) colors. The effect is identical to the posterization effect with `binCount` set to `2`.\n\nThe following code generates the color threshold effect:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/using-vimage-pixel-buffers-to-generate-video-effects\ncrawled: 2025-12-02T15:46:13Z\n---\n\n# Using vImage pixel buffers to generate video effects\n\n**Sample Code**\n\nRender real-time video effects with the vImage Pixel Buffer.\n\n## Overview\n\n\n\nThis sample code project captures video from a macOS device’s camera and applies video effects in real time. The sample converts the 8-bit YpCbCr video frames to 32-bit RGB [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] images and demonstrates image-processing techniques that are available only for 32-bit data.\n\nBefore exploring the code, build and run the app to familiarize yourself with the different visual results the app generates from the camera.\n\n### Create the any-to-any converter\n\nThe code creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance that converts the YpCbCr video frames to three-channel, 32-bit-per-channel, floating-point interleaved image data.\n\n```swift\nlet cvImageFormat = vImageCVImageFormat.make(\n    format: .format422YpCbCr8,\n    matrix: kvImage_ARGBToYpCbCrMatrix_ITU_R_601_4.pointee,\n    chromaSiting: .center,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    alphaIsOpaqueHint: true)!\n\nlet cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 32,\n    bitsPerPixel: 32 * 3,\n    colorSpace: CGColorSpaceCreateDeviceRGB(),\n    bitmapInfo: CGBitmapInfo(\n        rawValue: kCGBitmapByteOrder32Host.rawValue |\n        CGBitmapInfo.floatComponents.rawValue |\n        CGImageAlphaInfo.none.rawValue),\n    renderingIntent: .defaultIntent)!\n\nlazy var converter: vImageConverter = {\n    guard let converter = try? vImageConverter.make(\n        sourceFormat: cvImageFormat,\n        destinationFormat: cgImageFormat) else {\n        fatalError(\"Unable to create converter\")\n    }\n    \n    return converter\n}()\n```\n\n### Convert a Core Video pixel buffer to RGB\n\nThe code defines `destinationBuffer` as a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/InterleavedFx3] pixel buffer. The conversion function creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/DynamicPixelFormat] source buffer that references the locked [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instance and passes that to the any-to-any converter.\n\n```swift\nfunc populateDestinationBuffer(pixelBuffer: CVPixelBuffer) {\n    \n    let sourceBuffer = vImage.PixelBuffer(\n        referencing: pixelBuffer,\n        converter: converter,\n        destinationPixelFormat: vImage.DynamicPixelFormat.self)\n    \n    do {\n        try converter.convert(\n            from: sourceBuffer,\n            to: destinationBuffer)\n    } catch {\n        fatalError(\"Any-to-any conversion failure.\")\n    }\n}\n```\n\nOn return, `destinationBuffer` contains the RGB representation of the YpCbCr video frame.\n\n### Apply the noise effect\n\nThe sample simulates noise or film grain by adding Gaussian noise (with a mean of zero) to each frame. The image below shows an example of the noise effect:\n\n\n\nAccelerate’s BNNS library provides the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSRandomFillNormalFloat(_:_:_:_:)] function that fills an array descriptor with random floating-point values mapped to a normal distribution. Use the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/withUnsafeMutableBufferPointer(_:)] function to pass a pointer to the pixel buffer’s underlying data to a  [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/BNNSNDArrayDescriptor].\n\nThe following code generates the noise effect:\n\n```swift\nfunc applyNoise() {\n    \n    noiseBuffer.withUnsafeMutableBufferPointer { noisePtr in\n        \n        if var descriptor = BNNSNDArrayDescriptor(\n            data: noisePtr,\n            shape: BNNS.Shape.tensor3DFirstMajor(\n                noiseBuffer.width,\n                noiseBuffer.height,\n                noiseBuffer.channelCount)) {\n            \n            \/\/\/ Fill `noiseBuffer` with random values mapped to a normal distribution with a mean\n            \/\/\/ of `0` and a standard deviation of `0.125`.\n            let mean: Float = 0\n            let stdDev: Float = 0.125\n            \n            BNNSRandomFillNormalFloat(\n                randomNumberGenerator,\n                &descriptor,\n                mean,\n                stdDev)\n        }\n    }\n    \n    \/\/\/ Fill `mutableDestinationPtr` with the sum of the corresponding pixels\n    \/\/\/ in `destinationBuffer` and `noiseBuffer`.\n    destinationBuffer.withUnsafeMutableBufferPointer { mutablDestinationPtr in\n        \n        vDSP.add(destinationBuffer, noiseBuffer,\n                 result: &mutablDestinationPtr)\n    }\n}\n```\n\n### Apply the temporal blur effect\n\nThe temporal blur effect blurs the image over time by calculating a weighted average of the current frame and previous frames. The effect is analogous to an exaggerated motion blur.\n\nThe image below shows an example of a rotating image with the temporal blur effect:\n\n\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/linearInterpolate(bufferB:interpolationConstant:destination:)] function calls the vDSP function [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vDSP_vintb] to calculate the linear interpolation between the current frame and the previous interpolated frame.\n\nThe following code generates the temporal blur effect:\n\n```swift\nfunc applyTemporalBlur() {\n    \n    let interpolationConstant: Float = 0.925\n    \n    destinationBuffer.linearInterpolate(\n        bufferB: temporalBuffer,\n        interpolationConstant: interpolationConstant,\n        destination: temporalBuffer)\n    \n    temporalBuffer.copy(to: destinationBuffer)\n}\n```\n\n### Apply the posterization effect\n\nThe posterization effect reduces the continuous colors of an image to fewer tones. The effect produces results with regions of solid colors. The image below shows an example of the posterization effect:\n\n\n\nThe sample generates the posterization effect using histogram specification. The code achieves the reduced color count by calculating and specifying a histogram that has a low bin count. For more information about histogram specification, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/specifying-histograms-with-vimage].\n\nThe code populates a multiple-plane pixel buffer from the interleaved destination buffer. The multiple-plane pixel buffer contains three discrete planar buffers, and the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/Histogram888] function returns the histogram for the individual red, green, and blue channels. Specifying a bin count of `4` returns a result that contains a maximum of `4 * 4 * 4` (`64`) colors.\n\nThe following code generates the posterization effect:\n\n```swift\nfunc applyPosterization() {\n    \n    destinationBuffer.deinterleave(\n        destination: histogramBuffer)\n    \n    let histogram = histogramBuffer.histogram(\n        binCount: 4)\n    \n    histogramBuffer.specifyHistogram(\n        histogram,\n        destination: histogramBuffer)\n    \n    histogramBuffer.interleave(\n        destination: destinationBuffer)\n}\n```\n\n### Apply the color threshold effect\n\nThe color threshold effect is similar to the posterization effect, but reduces each color channel to a single-bit, so each color is either `0` or `1`. The image below shows the color threshold effect:\n\n\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/colorThreshold(_:destination:)] function sets pixel values equal to or greater than the specified threshold to `1` and other pixel values to `0`. Because the function works over the individual red, green, and blue values, the result contains a maximum of `2 * 2 * 2` (`8`) colors. The effect is identical to the posterization effect with `binCount` set to `2`.\n\nThe following code generates the color threshold effect:\n\n```swift\nfunc applyColorThreshold() {\n    \n    let threshold: Float = 0.5\n    \n    destinationBuffer.colorThreshold(\n        threshold,\n        destination: destinationBuffer)\n}\n```\n\n## Core Video Interoperation\n\n- **Integrating vImage pixel buffers into a Core Image workflow**: Share image data between Core Video pixel buffers and vImage buffers to integrate vImage operations into a Core Image workflow.\n- **Applying vImage operations to video sample buffers**: Use the vImage convert-any-to-any functionality to perform real-time image processing of video frames streamed from your device’s camera.\n- **Improving the quality of quantized images with dithering**: Apply dithering to simulate colors that are unavailable in reduced bit depths.\n- **Core Video interoperability**: Pass image data between Core Video and vImage.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Share image data between Core Video pixel buffers and vImage buffers to integrate vImage operations into a Core Image workflow.",
          "name" : "Integrating vImage pixel buffers into a Core Image workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/integrating-vimage-pixel-buffers-into-a-core-image-workflow"
        },
        {
          "description" : "Use the vImage convert-any-to-any functionality to perform real-time image processing of video frames streamed from your device’s camera.",
          "name" : "Applying vImage operations to video sample buffers",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-vimage-operations-to-video-sample-buffers"
        },
        {
          "description" : "Apply dithering to simulate colors that are unavailable in reduced bit depths.",
          "name" : "Improving the quality of quantized images with dithering",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/improving-the-quality-of-quantized-images-with-dithering"
        },
        {
          "description" : "Pass image data between Core Video and vImage.",
          "name" : "Core Video interoperability",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/core-video-interoperability"
        }
      ],
      "title" : "Core Video Interoperation"
    }
  ],
  "source" : "appleJSON",
  "title" : "Using vImage pixel buffers to generate video effects",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/using-vimage-pixel-buffers-to-generate-video-effects"
}