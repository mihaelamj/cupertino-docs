{
  "abstract" : "Adds a Leaky Rectified Linear Unit (ReLU) activation operation to the current graph.",
  "codeExamples" : [

  ],
  "contentHash" : "2f229d866904a59d94fc4c8611f1d945734113cd92f391a0e8b4093ac0cd3344",
  "crawledAt" : "2025-11-30T22:02:19Z",
  "declaration" : {
    "code" : "func leakyReLU(alpha: Float = 0.01) -> BNNSGraph.Builder.Tensor<T>",
    "language" : "swift"
  },
  "id" : "8C351D20-173C-413D-83D7-97BB94D61632",
  "kind" : "method",
  "module" : "Accelerate",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/leakyReLU(alpha:)\ncrawled: 2025-11-30T22:02:19Z\n---\n\n# leakyReLU(alpha:)\n\n**Instance Method**\n\nAdds a Leaky Rectified Linear Unit (ReLU) activation operation to the current graph.\n\n## Declaration\n\n```swift\nfunc leakyReLU(alpha: Float = 0.01) -> BNNSGraph.Builder.Tensor<T>\n```\n\n## Parameters\n\n- **alpha**: The `alpha` value.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "leakyReLU(alpha:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSGraph\/Builder\/Tensor\/leakyReLU(alpha:)"
}