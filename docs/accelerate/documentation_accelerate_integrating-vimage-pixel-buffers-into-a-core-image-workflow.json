{
  "abstract" : "Share image data between Core Video pixel buffers and vImage buffers to integrate vImage operations into a Core Image workflow.",
  "codeExamples" : [
    {
      "code" : "static var cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 32,\n    colorSpace: nil,\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.last.rawValue),\n    version: 0,\n    decode: nil,\n    renderingIntent: .defaultIntent)\n\noverride class var outputFormat: CIFormat {\n    return CIFormat.BGRA8\n}\n\noverride class func formatForInput(at input: Int32) -> CIFormat {\n    return CIFormat.BGRA8\n}",
      "language" : "swift"
    },
    {
      "code" : "guard\n    let input = inputs?.first,\n    let inputPixelBuffer = input.pixelBuffer,\n    let outputPixelBuffer = output.pixelBuffer else {\n        return\n}",
      "language" : "swift"
    },
    {
      "code" : "CVPixelBufferLockBaseAddress(inputPixelBuffer,\n                             CVPixelBufferLockFlags.readOnly)\ndefer {\n    CVPixelBufferUnlockBaseAddress(inputPixelBuffer,\n                                   CVPixelBufferLockFlags.readOnly)\n}\n\nguard let cvImageFormat = vImageCVImageFormat.make(buffer: inputPixelBuffer) else {\n    throw ContrastStretchImageProcessorKernelError.unableToDeriveImageFormat\n}\n\nif cvImageFormat.colorSpace == nil {\n    cvImageFormat.colorSpace = CGColorSpaceCreateDeviceRGB()\n}\n\nguard let converter = try? vImageConverter.make(\n    sourceFormat: cvImageFormat,\n    destinationFormat: cgImageFormat) else {\n    throw ContrastStretchImageProcessorKernelError.vImageConverterCreationFailed\n}\n\nlet sourcePixelBuffer = vImage.PixelBuffer<vImage.Interleaved8x4>(\n    referencing: inputPixelBuffer,\n    converter: converter)",
      "language" : "swift"
    },
    {
      "code" : "CVPixelBufferLockBaseAddress(outputPixelBuffer,\n                             CVPixelBufferLockFlags.readOnly)\ndefer {\n    CVPixelBufferUnlockBaseAddress(outputPixelBuffer,\n                                   CVPixelBufferLockFlags.readOnly)\n}\n\nlet destinationPixelBuffer = vImage.PixelBuffer<vImage.Interleaved8x4>(\n    referencing: outputPixelBuffer,\n    converter: converter)",
      "language" : "swift"
    },
    {
      "code" : "let error = sourcePixelBuffer.withUnsafePointerToVImageBuffer { src in\n    destinationPixelBuffer.withUnsafePointerToVImageBuffer { dst in\n\n        return vImageEndsInContrastStretch_ARGB8888(\n            src,\n            dst,\n            [UInt32](repeating: UInt32(percentLow), count: 4),\n            [UInt32](repeating: UInt32(percentHigh), count: 4),\n            vImage_Flags(kvImageNoFlags))\n        \n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "let ciResult = try? ContrastStretchImageProcessorKernel.apply(\n    withExtent: ciImage.extent,\n    inputs: [ciImage],\n    arguments: [\"percentLow\": Int(percentLow),\n                \"percentHigh\": Int(percentHigh)])",
      "language" : "swift"
    }
  ],
  "contentHash" : "fa69a9299117f95e8d3536ec0d5698d3dfc51f856b7f1534bc18c438eebe37b3",
  "crawledAt" : "2025-12-02T15:46:07Z",
  "id" : "E5D1880E-0F64-4A68-8097-7FA80A67C3A3",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nvImage supports reading from and writing to Core Video pixel buffers. This sample implements ends-in contrast stretching using vImage and makes that operation available to Core Image workflows by subclassing [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel]. An image processor kernel uses Core Video pixel buffers for input and output, so the app creates vImage pixel buffers that share data with [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances.\n\nThe example below shows a photograph before (left) and after (right) the app has applied ends-in contrast stretching:\n\n\n\nTo learn more about ends-in contrast stretching, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/enhancing-image-contrast-with-histogram-manipulation].\n\nBefore exploring the code, try building and running the app to familiarize yourself with the effect of the different parameters on the image.\n\n### Define an ends-in contrast-stretch image processor kernel\n\nThe `ContrastStretchImageProcessorKernel` inherits from the Core Image [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel] class.\n\nThe sample code defines a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure that represents a four-channel, 8-bit-per-channel interleaved image format. The image processor kernel supports [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/R8], [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/BGRA8], [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/RGBAh], and [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/RGBAf] input and output formats. For this sample project, the code overrides [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel\/outputFormat] and [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel\/formatForInput(at:)] to return a `BGRA8` that’s the same as the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat\/bitmapInfo] property of the `vImage_CGImageFormat` structure.\n\n### Create the source pixel buffer\n\nWhen the app applies ends-in contrast stretching, Core Image calls the processor kernel’s [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel\/process(with:arguments:output:)] function. The following code ensures that the input and output [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances are available:\n\nThe source [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/vImage\/PixelBuffer] shares its memory with the input [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer]. The following code creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] that allows the pixel buffer to reference the Core Video buffer’s memory:\n\n### Create the destination pixel buffer\n\nThe sample code app uses the same [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] to create the destination pixel buffer, which shares memory with the output Core Video buffer’s memory.\n\n### Apply ends-in contrast stretching\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageEndsInContrastStretch_ARGB8888(_:_:_:_:_:)] function applies an ends-in contrast-stretch operation to the source pixel buffer and writes the result to the destination pixel buffer. This function works equally well on all channel orderings; for example, RGBA or BGRA.\n\nBecause the destination pixel buffer shares memory with the output Core Video pixel buffer, the operation is complete after the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageEndsInContrastStretch_ARGB8888(_:_:_:_:_:)] returns.\n\n### Apply the ends-in contrast stretching operation to an image\n\nThe  `apply(withExtent:inputs:arguments:)` method generates a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage] instance based on the output of the processor’s `process(with:arguments:output:)` function.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/integrating-vimage-pixel-buffers-into-a-core-image-workflow\ncrawled: 2025-12-02T15:46:07Z\n---\n\n# Integrating vImage pixel buffers into a Core Image workflow\n\n**Sample Code**\n\nShare image data between Core Video pixel buffers and vImage buffers to integrate vImage operations into a Core Image workflow.\n\n## Overview\n\nvImage supports reading from and writing to Core Video pixel buffers. This sample implements ends-in contrast stretching using vImage and makes that operation available to Core Image workflows by subclassing [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel]. An image processor kernel uses Core Video pixel buffers for input and output, so the app creates vImage pixel buffers that share data with [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances.\n\nThe example below shows a photograph before (left) and after (right) the app has applied ends-in contrast stretching:\n\n\n\nTo learn more about ends-in contrast stretching, see [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/enhancing-image-contrast-with-histogram-manipulation].\n\nBefore exploring the code, try building and running the app to familiarize yourself with the effect of the different parameters on the image.\n\n### Define an ends-in contrast-stretch image processor kernel\n\nThe `ContrastStretchImageProcessorKernel` inherits from the Core Image [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel] class.\n\nThe sample code defines a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat] structure that represents a four-channel, 8-bit-per-channel interleaved image format. The image processor kernel supports [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/R8], [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/BGRA8], [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/RGBAh], and [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/RGBAf] input and output formats. For this sample project, the code overrides [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel\/outputFormat] and [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel\/formatForInput(at:)] to return a `BGRA8` that’s the same as the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_CGImageFormat\/bitmapInfo] property of the `vImage_CGImageFormat` structure.\n\n```swift\nstatic var cgImageFormat = vImage_CGImageFormat(\n    bitsPerComponent: 8,\n    bitsPerPixel: 32,\n    colorSpace: nil,\n    bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.last.rawValue),\n    version: 0,\n    decode: nil,\n    renderingIntent: .defaultIntent)\n\noverride class var outputFormat: CIFormat {\n    return CIFormat.BGRA8\n}\n\noverride class func formatForInput(at input: Int32) -> CIFormat {\n    return CIFormat.BGRA8\n}\n```\n\n### Create the source pixel buffer\n\nWhen the app applies ends-in contrast stretching, Core Image calls the processor kernel’s [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImageProcessorKernel\/process(with:arguments:output:)] function. The following code ensures that the input and output [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer] instances are available:\n\n```swift\nguard\n    let input = inputs?.first,\n    let inputPixelBuffer = input.pixelBuffer,\n    let outputPixelBuffer = output.pixelBuffer else {\n        return\n}\n```\n\nThe source [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/vImage\/PixelBuffer] shares its memory with the input [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBuffer]. The following code creates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] that allows the pixel buffer to reference the Core Video buffer’s memory:\n\n```swift\nCVPixelBufferLockBaseAddress(inputPixelBuffer,\n                             CVPixelBufferLockFlags.readOnly)\ndefer {\n    CVPixelBufferUnlockBaseAddress(inputPixelBuffer,\n                                   CVPixelBufferLockFlags.readOnly)\n}\n\nguard let cvImageFormat = vImageCVImageFormat.make(buffer: inputPixelBuffer) else {\n    throw ContrastStretchImageProcessorKernelError.unableToDeriveImageFormat\n}\n\nif cvImageFormat.colorSpace == nil {\n    cvImageFormat.colorSpace = CGColorSpaceCreateDeviceRGB()\n}\n\nguard let converter = try? vImageConverter.make(\n    sourceFormat: cvImageFormat,\n    destinationFormat: cgImageFormat) else {\n    throw ContrastStretchImageProcessorKernelError.vImageConverterCreationFailed\n}\n\nlet sourcePixelBuffer = vImage.PixelBuffer<vImage.Interleaved8x4>(\n    referencing: inputPixelBuffer,\n    converter: converter)\n```\n\n### Create the destination pixel buffer\n\nThe sample code app uses the same [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] to create the destination pixel buffer, which shares memory with the output Core Video buffer’s memory.\n\n```swift\nCVPixelBufferLockBaseAddress(outputPixelBuffer,\n                             CVPixelBufferLockFlags.readOnly)\ndefer {\n    CVPixelBufferUnlockBaseAddress(outputPixelBuffer,\n                                   CVPixelBufferLockFlags.readOnly)\n}\n\nlet destinationPixelBuffer = vImage.PixelBuffer<vImage.Interleaved8x4>(\n    referencing: outputPixelBuffer,\n    converter: converter)\n```\n\n### Apply ends-in contrast stretching\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageEndsInContrastStretch_ARGB8888(_:_:_:_:_:)] function applies an ends-in contrast-stretch operation to the source pixel buffer and writes the result to the destination pixel buffer. This function works equally well on all channel orderings; for example, RGBA or BGRA.\n\n```swift\nlet error = sourcePixelBuffer.withUnsafePointerToVImageBuffer { src in\n    destinationPixelBuffer.withUnsafePointerToVImageBuffer { dst in\n\n        return vImageEndsInContrastStretch_ARGB8888(\n            src,\n            dst,\n            [UInt32](repeating: UInt32(percentLow), count: 4),\n            [UInt32](repeating: UInt32(percentHigh), count: 4),\n            vImage_Flags(kvImageNoFlags))\n        \n    }\n}\n```\n\nBecause the destination pixel buffer shares memory with the output Core Video pixel buffer, the operation is complete after the [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageEndsInContrastStretch_ARGB8888(_:_:_:_:_:)] returns.\n\n### Apply the ends-in contrast stretching operation to an image\n\nThe  `apply(withExtent:inputs:arguments:)` method generates a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage] instance based on the output of the processor’s `process(with:arguments:output:)` function.\n\n```swift\nlet ciResult = try? ContrastStretchImageProcessorKernel.apply(\n    withExtent: ciImage.extent,\n    inputs: [ciImage],\n    arguments: [\"percentLow\": Int(percentLow),\n                \"percentHigh\": Int(percentHigh)])\n```\n\n## Core Video Interoperation\n\n- **Using vImage pixel buffers to generate video effects**: Render real-time video effects with the vImage Pixel Buffer.\n- **Applying vImage operations to video sample buffers**: Use the vImage convert-any-to-any functionality to perform real-time image processing of video frames streamed from your device’s camera.\n- **Improving the quality of quantized images with dithering**: Apply dithering to simulate colors that are unavailable in reduced bit depths.\n- **Core Video interoperability**: Pass image data between Core Video and vImage.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render real-time video effects with the vImage Pixel Buffer.",
          "name" : "Using vImage pixel buffers to generate video effects",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/using-vimage-pixel-buffers-to-generate-video-effects"
        },
        {
          "description" : "Use the vImage convert-any-to-any functionality to perform real-time image processing of video frames streamed from your device’s camera.",
          "name" : "Applying vImage operations to video sample buffers",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-vimage-operations-to-video-sample-buffers"
        },
        {
          "description" : "Apply dithering to simulate colors that are unavailable in reduced bit depths.",
          "name" : "Improving the quality of quantized images with dithering",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/improving-the-quality-of-quantized-images-with-dithering"
        },
        {
          "description" : "Pass image data between Core Video and vImage.",
          "name" : "Core Video interoperability",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/core-video-interoperability"
        }
      ],
      "title" : "Core Video Interoperation"
    }
  ],
  "source" : "appleJSON",
  "title" : "Integrating vImage pixel buffers into a Core Image workflow",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/integrating-vimage-pixel-buffers-into-a-core-image-workflow"
}