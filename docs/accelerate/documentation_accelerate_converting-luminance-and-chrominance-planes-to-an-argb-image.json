{
  "abstract" : "Create a displayable ARGB image using the luminance and chrominance information from your device’s camera.",
  "codeExamples" : [
    {
      "code" : "var infoYpCbCrToARGB = vImage_YpCbCrToARGB()\n\nfunc configureYpCbCrToARGBInfo() {\n    var pixelRange = vImage_YpCbCrPixelRange(Yp_bias: 16,\n                                             CbCr_bias: 128,\n                                             YpRangeMax: 235,\n                                             CbCrRangeMax: 240,\n                                             YpMax: 235,\n                                             YpMin: 16,\n                                             CbCrMax: 240,\n                                             CbCrMin: 16)\n\n    var ypCbCrToARGBMatrix = vImage_YpCbCrToARGBMatrix(Yp: 1.0,\n                                                       Cr_R: 1.402, Cr_G: -0.7141363,\n                                                       Cb_G: -0.3441363, Cb_B: 1.772)\n    \n    _ = vImageConvert_YpCbCrToARGB_GenerateConversion(\n        &ypCbCrToARGBMatrix,\n        &pixelRange,\n        &infoYpCbCrToARGB,\n        kvImage422CbYpCrYp8,\n        kvImageARGB8888,\n        vImage_Flags(kvImageNoFlags))\n}",
      "language" : "swift"
    },
    {
      "code" : "CVPixelBufferLockBaseAddress(\n    pixelBuffer,\n    CVPixelBufferLockFlags.readOnly)\n\nconvertYpCbCrToRGB(cvPixelBuffer: pixelBuffer)\n\nCVPixelBufferUnlockBaseAddress(\n    pixelBuffer,\n    CVPixelBufferLockFlags.readOnly)",
      "language" : "swift"
    },
    {
      "code" : "let lumaPixelBuffer = vImage.PixelBuffer(referencing: cvPixelBuffer,\n                                         planeIndex: 0,\n                                         pixelFormat: vImage.Planar8.self)\n\nlet chromaPixelBuffer = vImage.PixelBuffer(referencing: cvPixelBuffer,\n                                           planeIndex: 1,\n                                           pixelFormat: vImage.Interleaved8x2.self)",
      "language" : "swift"
    },
    {
      "code" : "if contrast != 1 {\n    lumaPixelBuffer.applyGamma(.halfPrecision(contrast),\n                               destination: lumaPixelBuffer)\n}",
      "language" : "swift"
    },
    {
      "code" : "argbPixelBuffer.convert(lumaSource: lumaPixelBuffer,\n                        chromaSource: chromaPixelBuffer,\n                        conversionInfo: infoYpCbCrToARGB)",
      "language" : "swift"
    }
  ],
  "contentHash" : "9c2b4a7ab6a74fb27e725eae3999ad06365888f63b42053d666635f2792023fd",
  "crawledAt" : "2025-12-02T15:27:53Z",
  "id" : "CF4A0F97-65EF-4E98-8EE8-22D1060B09DA",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Accelerate",
  "overview" : "## Overview\n\nAs an alternative to the any-to-any conversion technique that [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/using-vimage-pixel-buffers-to-generate-video-effects] describes, vImage provides low-level functions for creating RGB images from the separate luminance and chrominance planes that an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureSession] instance provides. These functions offer better performance and more granular configuration than using a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance.\n\n### Configure the YpCbCr-to-ARGB information\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_YpCbCrToARGB_GenerateConversion(_:_:_:_:_:_:)] function generates the information that vImage requires to convert the luminance and chrominance planes to a single ARGB image.\n\nVideo-range YpCbCr formats often don’t use very low and very high values. For example, an 8-bit video range format typically uses the range `16...235` for luminance and `16...240` for chrominance. The generate conversion function accepts a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_YpCbCrPixelRange] structure that defines the pixel range.\n\nThe following code example populates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_YpCbCrToARGB] structure with the required conversion information for video-range 8-bit pixels:\n\n### Lock the Core Video pixel buffer\n\nBefore the sample app accesses the pixel data that AVFoundation supplies as a [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e], it calls [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferLockBaseAddress(_:_:)] to lock the pixel buffer and make the underlying memory available.\n\nAfter the YpCbCr-to-RGB conversion is complete, the code calls [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferUnlockBaseAddress(_:_:)] to unlock the pixel buffer.\n\nThe `convertYpCbCrToRGB(cvPixelBuffer:)` function performs the YpCbCr-to-RGB conversion.\n\n### Create the source luminance and chrominance pixel buffers\n\nThe `convertYpCbCrToRGB(cvPixelBuffer:)` function creates two pixel buffers that share memory with the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e]. The Core Video pixel buffer contains two planes: the plane at index `0` contains one channel that represents the luminance component, the plane at index `1` contains two interleaved channels that represent the two chrominance components.\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/init(referencing:planeIndex:overrideSize:pixelFormat:)] function initializes a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] that references a single plane of a multiple-plane Core Video pixel buffer.\n\n### Adjust the contrast of the image\n\nThe sample app provides a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Slider] for changing the contrast of the final image. The following code example uses the tone-mapping technique that [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/adjusting-saturation-and-applying-tone-mapping] describes:\n\n### Convert the YpCbCr image to an ARGB image\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/convert(lumaSource:chromaSource:conversionInfo:)] converts the luminance and chrominance information in `lumaPixelBuffer` and `chromaPixelBuffer` to an ARGB image. This pixel buffer method calls the underlying vImage [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_420Yp8_CbCr8ToARGB8888(_:_:_:_:_:_:_:)] function.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Accelerate\/converting-luminance-and-chrominance-planes-to-an-argb-image\ncrawled: 2025-12-02T15:27:53Z\n---\n\n# Converting luminance and chrominance planes to an ARGB image\n\n**Sample Code**\n\nCreate a displayable ARGB image using the luminance and chrominance information from your device’s camera.\n\n## Overview\n\nAs an alternative to the any-to-any conversion technique that [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/using-vimage-pixel-buffers-to-generate-video-effects] describes, vImage provides low-level functions for creating RGB images from the separate luminance and chrominance planes that an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureSession] instance provides. These functions offer better performance and more granular configuration than using a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConverter] instance.\n\n### Configure the YpCbCr-to-ARGB information\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_YpCbCrToARGB_GenerateConversion(_:_:_:_:_:_:)] function generates the information that vImage requires to convert the luminance and chrominance planes to a single ARGB image.\n\nVideo-range YpCbCr formats often don’t use very low and very high values. For example, an 8-bit video range format typically uses the range `16...235` for luminance and `16...240` for chrominance. The generate conversion function accepts a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_YpCbCrPixelRange] structure that defines the pixel range.\n\nThe following code example populates a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage_YpCbCrToARGB] structure with the required conversion information for video-range 8-bit pixels:\n\n```swift\nvar infoYpCbCrToARGB = vImage_YpCbCrToARGB()\n\nfunc configureYpCbCrToARGBInfo() {\n    var pixelRange = vImage_YpCbCrPixelRange(Yp_bias: 16,\n                                             CbCr_bias: 128,\n                                             YpRangeMax: 235,\n                                             CbCrRangeMax: 240,\n                                             YpMax: 235,\n                                             YpMin: 16,\n                                             CbCrMax: 240,\n                                             CbCrMin: 16)\n\n    var ypCbCrToARGBMatrix = vImage_YpCbCrToARGBMatrix(Yp: 1.0,\n                                                       Cr_R: 1.402, Cr_G: -0.7141363,\n                                                       Cb_G: -0.3441363, Cb_B: 1.772)\n    \n    _ = vImageConvert_YpCbCrToARGB_GenerateConversion(\n        &ypCbCrToARGBMatrix,\n        &pixelRange,\n        &infoYpCbCrToARGB,\n        kvImage422CbYpCrYp8,\n        kvImageARGB8888,\n        vImage_Flags(kvImageNoFlags))\n}\n```\n\n### Lock the Core Video pixel buffer\n\nBefore the sample app accesses the pixel data that AVFoundation supplies as a [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e], it calls [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferLockBaseAddress(_:_:)] to lock the pixel buffer and make the underlying memory available.\n\nAfter the YpCbCr-to-RGB conversion is complete, the code calls [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferUnlockBaseAddress(_:_:)] to unlock the pixel buffer.\n\nThe `convertYpCbCrToRGB(cvPixelBuffer:)` function performs the YpCbCr-to-RGB conversion.\n\n```swift\nCVPixelBufferLockBaseAddress(\n    pixelBuffer,\n    CVPixelBufferLockFlags.readOnly)\n\nconvertYpCbCrToRGB(cvPixelBuffer: pixelBuffer)\n\nCVPixelBufferUnlockBaseAddress(\n    pixelBuffer,\n    CVPixelBufferLockFlags.readOnly)\n```\n\n### Create the source luminance and chrominance pixel buffers\n\nThe `convertYpCbCrToRGB(cvPixelBuffer:)` function creates two pixel buffers that share memory with the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e]. The Core Video pixel buffer contains two planes: the plane at index `0` contains one channel that represents the luminance component, the plane at index `1` contains two interleaved channels that represent the two chrominance components.\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/init(referencing:planeIndex:overrideSize:pixelFormat:)] function initializes a [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer] that references a single plane of a multiple-plane Core Video pixel buffer.\n\n```swift\nlet lumaPixelBuffer = vImage.PixelBuffer(referencing: cvPixelBuffer,\n                                         planeIndex: 0,\n                                         pixelFormat: vImage.Planar8.self)\n\nlet chromaPixelBuffer = vImage.PixelBuffer(referencing: cvPixelBuffer,\n                                           planeIndex: 1,\n                                           pixelFormat: vImage.Interleaved8x2.self)\n```\n\n### Adjust the contrast of the image\n\nThe sample app provides a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Slider] for changing the contrast of the final image. The following code example uses the tone-mapping technique that [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/adjusting-saturation-and-applying-tone-mapping] describes:\n\n```swift\nif contrast != 1 {\n    lumaPixelBuffer.applyGamma(.halfPrecision(contrast),\n                               destination: lumaPixelBuffer)\n}\n```\n\n### Convert the YpCbCr image to an ARGB image\n\nThe [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImage\/PixelBuffer\/convert(lumaSource:chromaSource:conversionInfo:)] converts the luminance and chrominance information in `lumaPixelBuffer` and `chromaPixelBuffer` to an ARGB image. This pixel buffer method calls the underlying vImage [doc:\/\/com.apple.accelerate\/documentation\/Accelerate\/vImageConvert_420Yp8_CbCr8ToARGB8888(_:_:_:_:_:_:_:)] function.\n\n```swift\nargbPixelBuffer.convert(lumaSource: lumaPixelBuffer,\n                        chromaSource: chromaPixelBuffer,\n                        conversionInfo: infoYpCbCrToARGB)\n```\n\n## Conversion Between Image Formats\n\n- **Building a basic image conversion workflow**: Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.\n- **Converting color images to grayscale**: Convert an RGB image to grayscale using matrix multiplication.\n- **Applying color transforms to images with a multidimensional lookup table**: Precompute translation values to optimize color space conversion and other pointwise operations.\n- **Building a basic image conversion workflow**: Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.\n- **Conversion**: Convert an image to a different format.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.",
          "name" : "Building a basic image conversion workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/building-a-basic-image-conversion-workflow"
        },
        {
          "description" : "Convert an RGB image to grayscale using matrix multiplication.",
          "name" : "Converting color images to grayscale",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/converting-color-images-to-grayscale"
        },
        {
          "description" : "Precompute translation values to optimize color space conversion and other pointwise operations.",
          "name" : "Applying color transforms to images with a multidimensional lookup table",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/applying-color-transforms-to-images-with-a-multidimensional-lookup-table"
        },
        {
          "description" : "Learn the fundamentals of the convert-any-to-any function by converting a CMYK image to an RGB image.",
          "name" : "Building a basic image conversion workflow",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/building-a-basic-image-conversion-workflow"
        },
        {
          "description" : "Convert an image to a different format.",
          "name" : "Conversion",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/conversion"
        }
      ],
      "title" : "Conversion Between Image Formats"
    }
  ],
  "source" : "appleJSON",
  "title" : "Converting luminance and chrominance planes to an ARGB image",
  "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/converting-luminance-and-chrominance-planes-to-an-argb-image"
}