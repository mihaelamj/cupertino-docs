{
  "abstract" : "Dequantizes the input tensor and writes the result to the output tensor.",
  "codeExamples" : [
    {
      "code" : "static func dequantize() {\n    \n    let inputValues = [1000, 2000, 3000, 4000,\n                       5000, 6000, 7000, 8000] as [Int16]\n    \n    let input = BNNSNDArrayDescriptor.allocate(\n        initializingFrom: inputValues,\n        shape: .matrixRowMajor(4, 2))\n    \n    let output = BNNSNDArrayDescriptor.allocateUninitialized(\n        scalarType: Float.self,\n        shape: input.shape)\n    \n    let scale = BNNSNDArrayDescriptor.allocate(\n        initializingFrom: [1, 10, 100, 1000] as [Int16],\n        shape: .vector(4))\n    \n    try? BNNS.dequantize(batchSize: 1,\n                         input: input,\n                         output: output,\n                         axis: 0,\n                         scale: scale,\n                         bias: nil)\n    \n    \/\/ Prints:\n    \/\/  [1000.0, 200.0, 30.0, 4.0,\n    \/\/   5000.0, 600.0, 70.0, 8.0]\n    print(output.makeArray(of: Float.self)!)\n    \n    input.deallocate()\n    output.deallocate()\n    scale.deallocate()\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "0d67293f23c73f08c79bb7a9132aa7544e8715a72f4ab27c8feb52f4e54b16da",
  "crawledAt" : "2025-12-01T03:05:44Z",
  "declaration" : {
    "code" : "static func dequantize(batchSize: Int, input: BNNSNDArrayDescriptor, output: BNNSNDArrayDescriptor, axis: Int? = nil, scale: BNNSNDArrayDescriptor?, bias: BNNSNDArrayDescriptor?, filterParameters: BNNSFilterParameters? = nil) throws",
    "language" : "swift"
  },
  "id" : "6FFD42E9-E99B-48B1-9CC5-F62644F55B5E",
  "kind" : "method",
  "module" : "Accelerate",
  "overview" : "## Discussion\n\nThe following code dequantizes a 16-bit integer matrix to a single-precision matrix. The code applies the scale along the zeroth axis and, therefore, the scale tensor contains four elements.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/accelerate\/bnns\/dequantize(batchsize:input:output:axis:scale:bias:filterparameters:)\ncrawled: 2025-12-01T03:05:44Z\n---\n\n# dequantize(batchSize:input:output:axis:scale:bias:filterParameters:)\n\n**Type Method**\n\nDequantizes the input tensor and writes the result to the output tensor.\n\n## Declaration\n\n```swift\nstatic func dequantize(batchSize: Int, input: BNNSNDArrayDescriptor, output: BNNSNDArrayDescriptor, axis: Int? = nil, scale: BNNSNDArrayDescriptor?, bias: BNNSNDArrayDescriptor?, filterParameters: BNNSFilterParameters? = nil) throws\n```\n\n## Parameters\n\n- **batchSize**: The number of input-output pairs to process.\n- **input**: The descriptor of the input.\n- **output**: The descriptor of the output.\n- **axis**: The index of the axis to which the function applies scale and bias. Set to `nil` to dequantize the entire tensor using scale and bias.\n- **scale**: The scale, set to `nil` for a scale of `1.0`.\n- **bias**: The bias, set to `nil` for a bias of `0.0`.\n- **filterParameters**: Runtime filter parameters.\n\n## Discussion\n\nThe following code dequantizes a 16-bit integer matrix to a single-precision matrix. The code applies the scale along the zeroth axis and, therefore, the scale tensor contains four elements.\n\n```swift\nstatic func dequantize() {\n    \n    let inputValues = [1000, 2000, 3000, 4000,\n                       5000, 6000, 7000, 8000] as [Int16]\n    \n    let input = BNNSNDArrayDescriptor.allocate(\n        initializingFrom: inputValues,\n        shape: .matrixRowMajor(4, 2))\n    \n    let output = BNNSNDArrayDescriptor.allocateUninitialized(\n        scalarType: Float.self,\n        shape: input.shape)\n    \n    let scale = BNNSNDArrayDescriptor.allocate(\n        initializingFrom: [1, 10, 100, 1000] as [Int16],\n        shape: .vector(4))\n    \n    try? BNNS.dequantize(batchSize: 1,\n                         input: input,\n                         output: output,\n                         axis: 0,\n                         scale: scale,\n                         bias: nil)\n    \n    \/\/ Prints:\n    \/\/  [1000.0, 200.0, 30.0, 4.0,\n    \/\/   5000.0, 600.0, 70.0, 8.0]\n    print(output.makeArray(of: Float.self)!)\n    \n    input.deallocate()\n    output.deallocate()\n    scale.deallocate()\n}\n```\n\n## Related Documentation\n\n- **BNNSQuantizerFunctionDequantize**: A constant that specifes conversion to a higher precision.\n\n## Quantization functions\n\n- **quantize(batchSize:input:output:axis:scale:bias:filterParameters:)**: Quantizes the input tensor and writes the result to the output tensor.\n- **BNNSQuantizerFunction**: Constants that describe quantization functions.\n- **BNNSLayerParametersQuantization**: A structure that contains the parameters of a quantization layer.\n- **BNNSDirectApplyQuantizer(_:_:_:_:_:)**: Applies a quantization layer directly to two input matrices.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A constant that specifes conversion to a higher precision.",
          "name" : "BNNSQuantizerFunctionDequantize",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSQuantizerFunctionDequantize"
        }
      ],
      "title" : "Related Documentation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Quantizes the input tensor and writes the result to the output tensor.",
          "name" : "quantize(batchSize:input:output:axis:scale:bias:filterParameters:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNS\/quantize(batchSize:input:output:axis:scale:bias:filterParameters:)"
        },
        {
          "description" : "Constants that describe quantization functions.",
          "name" : "BNNSQuantizerFunction",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSQuantizerFunction"
        },
        {
          "description" : "A structure that contains the parameters of a quantization layer.",
          "name" : "BNNSLayerParametersQuantization",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSLayerParametersQuantization"
        },
        {
          "description" : "Applies a quantization layer directly to two input matrices.",
          "name" : "BNNSDirectApplyQuantizer(_:_:_:_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Accelerate\/BNNSDirectApplyQuantizer(_:_:_:_:_:)"
        }
      ],
      "title" : "Quantization functions"
    }
  ],
  "source" : "appleJSON",
  "title" : "dequantize(batchSize:input:output:axis:scale:bias:filterParameters:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/accelerate\/bnns\/dequantize(batchsize:input:output:axis:scale:bias:filterparameters:)"
}