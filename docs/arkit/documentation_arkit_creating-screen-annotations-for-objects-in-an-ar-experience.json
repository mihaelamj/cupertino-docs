{
  "abstract" : "Annotate an AR experience with virtual sticky notes that you display onscreen over real and virtual objects.",
  "codeExamples" : [
    {
      "code" : "func arViewGestureSetup() {\n    let tapGesture = UITapGestureRecognizer(target: self, action: #selector(tappedOnARView))\n    arView.addGestureRecognizer(tapGesture)\n    \n    let swipeGesture = UISwipeGestureRecognizer(target: self, action: #selector(swipedDownOnARView))\n    swipeGesture.direction = .down\n    arView.addGestureRecognizer(swipeGesture)\n}",
      "language" : "swift"
    },
    {
      "code" : "let touchLocation = sender.location(in: arView)",
      "language" : "swift"
    },
    {
      "code" : "guard let raycastResult = arView.raycast(from: touchLocation, allowing: .estimatedPlane, alignment: .any).first else {\n    messageLabel.displayMessage(\"No surface detected, try getting closer.\", duration: 2.0)\n    return\n}",
      "language" : "swift"
    },
    {
      "code" : "class StickyNoteEntity: Entity, HasAnchoring, HasScreenSpaceView {\n    \/\/ ...",
      "language" : "swift"
    },
    {
      "code" : "let note = StickyNoteEntity(frame: frame, worldTransform: raycastResult.worldTransform)",
      "language" : "swift"
    },
    {
      "code" : "init(frame: CGRect, worldTransform: simd_float4x4) {\n    super.init()\n    self.transform.matrix = worldTransform\n    \/\/ ...",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Add the sticky note to the scene's entity hierarchy.\narView.scene.addAnchor(note)",
      "language" : "swift"
    },
    {
      "code" : "struct ScreenSpaceComponent: Component {\n    var view: StickyNoteView?\n    \/\/...",
      "language" : "swift"
    },
    {
      "code" : "class StickyNoteView: UIView {\n    var textView: UITextView!\n    \/\/ ...",
      "language" : "swift"
    },
    {
      "code" : "protocol HasScreenSpaceView: Entity {\n    var screenSpaceComponent: ScreenSpaceComponent { get set }\n}",
      "language" : "swift"
    },
    {
      "code" : "class StickyNoteEntity: Entity, HasAnchoring, HasScreenSpaceView {\n    \/\/ ...",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Add the sticky note's view to the view hierarchy.\nguard let stickyView = note.view else { return }\narView.insertSubview(stickyView, belowSubview: trashZone)",
      "language" : "swift"
    },
    {
      "code" : "guard let projectedPoint = arView.project(note.position) else { return }",
      "language" : "swift"
    },
    {
      "code" : "setPositionCenter(projectedPoint)",
      "language" : "swift"
    },
    {
      "code" : "view.frame.origin = CGPoint(x: centerPoint.x, y: centerPoint.y)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Updates the screen position of the note based on its visibility\nnote.projection = Projection(projectedPoint: projectedPoint, isVisible: isVisible)\nnote.updateScreenPosition()",
      "language" : "swift"
    },
    {
      "code" : "@objc\nfunc tappedOnARView(_ sender: UITapGestureRecognizer) {\n    \n    \/\/ Ignore the tap if the user is editing a sticky note.\n    for note in stickyNotes where note.isEditing { return }\n    \n    \/\/ Create a new sticky note at the tap location.\n    insertNewSticky(sender)\n}",
      "language" : "swift"
    },
    {
      "code" : "extension ViewController: UITextViewDelegate {\n    \n    \/\/ - Tag: TextViewDidBeginEditing\n    func textViewDidBeginEditing(_ textView: UITextView) {\n\n\n        \/\/ Get the main view for this sticky note.\n        guard let stickyView = textView.firstSuperViewOfType(StickyNoteView.self) else { return }\n        \/\/ ...\n",
      "language" : "swift"
    },
    {
      "code" : "@objc\nfunc panOnStickyView(_ sender: UIPanGestureRecognizer) {\n    \n    guard let stickyView = sender.view as? StickyNoteView else { return }\n    \n    let panLocation = sender.location(in: arView)\n    \n    \/\/ Ignore the pan if any StickyViews are being edited.\n    for note in stickyNotes where note.isEditing { return }\n    \n    panStickyNote(sender, stickyView, panLocation)\n}",
      "language" : "swift"
    },
    {
      "code" : "fileprivate func attemptRepositioning(_ stickyView: StickyNoteView) {\n    \/\/ Conducts a ray-cast for feature points using the panned position of the StickyNoteView\n    let point = CGPoint(x: stickyView.frame.midX, y: stickyView.frame.midY)\n    if let result = arView.raycast(from: point, allowing: .estimatedPlane, alignment: .any).first {\n        stickyView.stickyNote.transform.matrix = result.worldTransform\n    } else {\n        messageLabel.displayMessage(\"No surface detected, unable to reposition note.\", duration: 2.0)\n        stickyView.stickyNote.shouldAnimate = true\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "if stickyView.isInTrashZone {\n    deleteStickyNote(stickyView.stickyNote)\n    \/\/ ...",
      "language" : "swift"
    },
    {
      "code" : "func animateStickyViewToEditingFrame(_ stickyView: StickyNoteView, keyboardHeight: Double) {\n    let safeFrame = view.safeAreaLayoutGuide.layoutFrame\n    let height = safeFrame.height - keyboardHeight\n    let inset = height * 0.05\n    let editingFrame = CGRect(origin: safeFrame.origin, size: CGSize(width: safeFrame.width, height: height)).insetBy(dx: inset, dy: inset)\n    UIViewPropertyAnimator(duration: 0.2, curve: .easeIn) {\n        stickyView.frame = editingFrame\n        \/\/...",
      "language" : "swift"
    },
    {
      "code" : "stickyView.blurView.effect = UIBlurEffect(style: .light)",
      "language" : "swift"
    },
    {
      "code" : "if shouldAnimate {\n    animateTo(projectedPoint)\n    \/\/ ...",
      "language" : "swift"
    },
    {
      "code" : "func animateTo(_ point: CGPoint) {\n\n    let animator = UIViewPropertyAnimator(duration: 0.3, curve: .linear) {\n        self.setPositionCenter(point)\n    }\n    \/\/ ...",
      "language" : "swift"
    }
  ],
  "contentHash" : "cc579f9ca1eb4f7bd63020c116af80b56aaf1c4b988452e30ba2e38e7c6e4e46",
  "crawledAt" : "2025-12-02T15:47:23Z",
  "id" : "6313C161-37A1-4F1C-804F-47DB75C9DFF6",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nAt times, the user may want to annotate real or virtual objects in your AR experience. For example, they might want to place a virtual name plate on paintings at a museum. By fixing annotations to the screen, you enable the user to annotate their AR experience in *screen space*. To demonstrate screen-space annotations, this sample app enables the capability to tap the screen to place one or more virtual sticky notes with text in the real world.\n\nText displayed in screen space remains readable at all viewing angles and distances. The sample app implements sticky notes using a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView] that’s flush with the screen, which allows the user to quickly define the note’s text using regular touch input. Using UIKit to annotate an AR experience also provides the benefits of localization and accessibility.\n\nTo display text that’s anchored in world space instead, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/recognizing-and-labeling-arbitrary-objects].\n\n## Resolve the User’s Tap to a 3D Location\n\nTo annotate an object in an AR experience, you first determine where it is in the physical environment. This sample app enables the user to tap the screen to place a sticky note by first adding a tap gesture recognizer to the view.\n\nWhen the input handler is called, you read the tap screen coordinates by calling [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIGestureRecognizer\/location(in:)].\n\nTo get a 3D world position that corresponds to the tap location, cast a ray from the camera’s origin through the touch location to check for intersection with any real-world surfaces along that ray.\n\nIf ARKit finds a planar surface where the user tapped, the ray-cast result provides you the 3D intersection point in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARRaycastResult\/worldTransform].\n\n## Anchor a sticky note in the environment\n\nTo keep track of a real-world location, you create an anchor positioned there. RealityKit implements an anchor as an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity] conforming to [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/HasAnchoring]. Thus, you implement those protocols when designing a sticky note in RealityKit.\n\nCreate the entity by calling its initializer and passing in the ray-cast result’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARRaycastResult\/worldTransform].\n\nIn the sticky note entity’s `init` function, position the entity at the tap location by setting its transformation matrix to the argument [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARRaycastResult\/worldTransform].\n\nLet RealityKit know about your entity by adding it to the scene hierarchy. RealityKit then registers an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] for your entity with ARKit.\n\n## Display the sticky note’s annotation\n\nFor the purposes of this sample app, the sticky note entity has no geometry and thus, no appearance. Its anchor provides a 3D location only, and it’s the sticky note’s screen-space annotation that has an appearance. To display it, you define the sticky note’s annotation. Following RealityKit’s entity-component model, design a component that houses the annotation, which in this case is a view. See `ScreenSpaceComponent.swift`.\n\nAs a prepackaged UI element that renders text for you, [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView] is useful as a screen-space annotation.\n\nExpose the screen-space component in its own protocol.\n\nImplement the protocol in your entity; see `StickyNoteEntity.swift`.\n\nTo display the entity’s annotation, add the sticky-note view to the view hierarchy.\n\nTo put the annotation in the right place on the screen, ask the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView] to convert its entity’s world location to a 2D screen point.\n\nTo enhance visual accuracy, center the note’s view around the anchor’s projected world location.\n\nTo do that, calculate the midpoint and set the view’s origin.\n\n## Update the annotation’s position\n\nBecause users move their device during an AR experience, the annotation’s screen position quickly becomes out of sync with its anchor’s world position. To keep the annotation’s screen position accurate, call [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView]‘s `project` function every frame, updating the annotation’s position with the result.\n\n## Handle user interaction\n\nA benefit of using [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIView] types for screen annotations is that they simplify user interaction. The sample implements sticky notes using [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView], which enables users to more easily edit their text. The sample implements minimal gesture recognizer code to manage sticky notes.\n\nThe following code enables the capability to create a note by tapping the screen.\n\nBy implementing its own tap gesture recognizer to control editing, [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView]  enables the user to tap an existing note to edit its text. To be notified when the user edits a note, override [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView]’s `textViewDidBeginEditing(_ textView:)` delegate callback.\n\nThe following code enables the capability to move a note by panning the screen.\n\nWhen the user pans to reposition a sticky note, you convert the screen touch location to a 3D world position using [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView\/raycast(from:allowing:alignment:)]. The user can then reposition the sticky note’s anchor in the real world versus simply moving the annotation to a new arbitrary screen location. If a ray cast from the final screen location in the pan gesture doesn’t produce an intersection with a 3D world location, don’t move the sticky note there.\n\nThe following portion of the pan gesture handler enables the capability to remove a sticky note when the user drags it to the text that says “delete” at the top of the screen.\n\n## Enhance the experience with animation\n\nKeeping screen-space annotations to a minimum will maximize the user’s immersion in the AR experience. The sample app makes sticky notes small when the user isn’t editing text, minimizing distractions so they can focus on the real-world environment. But for similar reasons, you should enlarge a sticky note when the user is editing text. To create a seamless transition between editing and nonediting states, animate the sticky note’s size instead of changing it abruptly. See the   `animateStickyViewToEditingFrame` function.\n\nBring even more focus to the editing experience by dimming the background and by lighting the sticky note that the user is editing.\n\nTo prevent the user from losing track of a sticky note’s real-world location, animate the note smoothly from one position to the next. For example, if an annotation fails to reposition, animate the sticky note back to its original screen position. This increases the user’s ability to track the annotation if they want to try moving it again.\n\nTo animate the note’s movement, you continually set its location using a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIViewPropertyAnimator].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/creating-screen-annotations-for-objects-in-an-ar-experience\ncrawled: 2025-12-02T15:47:23Z\n---\n\n# Creating screen annotations for objects in an AR experience\n\n**Sample Code**\n\nAnnotate an AR experience with virtual sticky notes that you display onscreen over real and virtual objects.\n\n## Overview\n\nAt times, the user may want to annotate real or virtual objects in your AR experience. For example, they might want to place a virtual name plate on paintings at a museum. By fixing annotations to the screen, you enable the user to annotate their AR experience in *screen space*. To demonstrate screen-space annotations, this sample app enables the capability to tap the screen to place one or more virtual sticky notes with text in the real world.\n\nText displayed in screen space remains readable at all viewing angles and distances. The sample app implements sticky notes using a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView] that’s flush with the screen, which allows the user to quickly define the note’s text using regular touch input. Using UIKit to annotate an AR experience also provides the benefits of localization and accessibility.\n\n\n\nTo display text that’s anchored in world space instead, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/recognizing-and-labeling-arbitrary-objects].\n\n## Resolve the User’s Tap to a 3D Location\n\nTo annotate an object in an AR experience, you first determine where it is in the physical environment. This sample app enables the user to tap the screen to place a sticky note by first adding a tap gesture recognizer to the view.\n\n```swift\nfunc arViewGestureSetup() {\n    let tapGesture = UITapGestureRecognizer(target: self, action: #selector(tappedOnARView))\n    arView.addGestureRecognizer(tapGesture)\n    \n    let swipeGesture = UISwipeGestureRecognizer(target: self, action: #selector(swipedDownOnARView))\n    swipeGesture.direction = .down\n    arView.addGestureRecognizer(swipeGesture)\n}\n```\n\nWhen the input handler is called, you read the tap screen coordinates by calling [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIGestureRecognizer\/location(in:)].\n\n```swift\nlet touchLocation = sender.location(in: arView)\n```\n\nTo get a 3D world position that corresponds to the tap location, cast a ray from the camera’s origin through the touch location to check for intersection with any real-world surfaces along that ray.\n\n```swift\nguard let raycastResult = arView.raycast(from: touchLocation, allowing: .estimatedPlane, alignment: .any).first else {\n    messageLabel.displayMessage(\"No surface detected, try getting closer.\", duration: 2.0)\n    return\n}\n```\n\nIf ARKit finds a planar surface where the user tapped, the ray-cast result provides you the 3D intersection point in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARRaycastResult\/worldTransform].\n\n## Anchor a sticky note in the environment\n\nTo keep track of a real-world location, you create an anchor positioned there. RealityKit implements an anchor as an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity] conforming to [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/HasAnchoring]. Thus, you implement those protocols when designing a sticky note in RealityKit.\n\n```swift\nclass StickyNoteEntity: Entity, HasAnchoring, HasScreenSpaceView {\n    \/\/ ...\n```\n\nCreate the entity by calling its initializer and passing in the ray-cast result’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARRaycastResult\/worldTransform].\n\n```swift\nlet note = StickyNoteEntity(frame: frame, worldTransform: raycastResult.worldTransform)\n```\n\nIn the sticky note entity’s `init` function, position the entity at the tap location by setting its transformation matrix to the argument [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARRaycastResult\/worldTransform].\n\n```swift\ninit(frame: CGRect, worldTransform: simd_float4x4) {\n    super.init()\n    self.transform.matrix = worldTransform\n    \/\/ ...\n```\n\nLet RealityKit know about your entity by adding it to the scene hierarchy. RealityKit then registers an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] for your entity with ARKit.\n\n```swift\n\/\/ Add the sticky note to the scene's entity hierarchy.\narView.scene.addAnchor(note)\n```\n\n## Display the sticky note’s annotation\n\nFor the purposes of this sample app, the sticky note entity has no geometry and thus, no appearance. Its anchor provides a 3D location only, and it’s the sticky note’s screen-space annotation that has an appearance. To display it, you define the sticky note’s annotation. Following RealityKit’s entity-component model, design a component that houses the annotation, which in this case is a view. See `ScreenSpaceComponent.swift`.\n\n```swift\nstruct ScreenSpaceComponent: Component {\n    var view: StickyNoteView?\n    \/\/...\n```\n\nAs a prepackaged UI element that renders text for you, [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView] is useful as a screen-space annotation.\n\n```swift\nclass StickyNoteView: UIView {\n    var textView: UITextView!\n    \/\/ ...\n```\n\nExpose the screen-space component in its own protocol.\n\n```swift\nprotocol HasScreenSpaceView: Entity {\n    var screenSpaceComponent: ScreenSpaceComponent { get set }\n}\n```\n\nImplement the protocol in your entity; see `StickyNoteEntity.swift`.\n\n```swift\nclass StickyNoteEntity: Entity, HasAnchoring, HasScreenSpaceView {\n    \/\/ ...\n```\n\nTo display the entity’s annotation, add the sticky-note view to the view hierarchy.\n\n```swift\n\/\/ Add the sticky note's view to the view hierarchy.\nguard let stickyView = note.view else { return }\narView.insertSubview(stickyView, belowSubview: trashZone)\n```\n\nTo put the annotation in the right place on the screen, ask the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView] to convert its entity’s world location to a 2D screen point.\n\n```swift\nguard let projectedPoint = arView.project(note.position) else { return }\n```\n\nTo enhance visual accuracy, center the note’s view around the anchor’s projected world location.\n\n```swift\nsetPositionCenter(projectedPoint)\n```\n\nTo do that, calculate the midpoint and set the view’s origin.\n\n```swift\nview.frame.origin = CGPoint(x: centerPoint.x, y: centerPoint.y)\n```\n\n## Update the annotation’s position\n\nBecause users move their device during an AR experience, the annotation’s screen position quickly becomes out of sync with its anchor’s world position. To keep the annotation’s screen position accurate, call [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView]‘s `project` function every frame, updating the annotation’s position with the result.\n\n```swift\n\/\/ Updates the screen position of the note based on its visibility\nnote.projection = Projection(projectedPoint: projectedPoint, isVisible: isVisible)\nnote.updateScreenPosition()\n```\n\n## Handle user interaction\n\nA benefit of using [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIView] types for screen annotations is that they simplify user interaction. The sample implements sticky notes using [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView], which enables users to more easily edit their text. The sample implements minimal gesture recognizer code to manage sticky notes.\n\nThe following code enables the capability to create a note by tapping the screen.\n\n```swift\n@objc\nfunc tappedOnARView(_ sender: UITapGestureRecognizer) {\n    \n    \/\/ Ignore the tap if the user is editing a sticky note.\n    for note in stickyNotes where note.isEditing { return }\n    \n    \/\/ Create a new sticky note at the tap location.\n    insertNewSticky(sender)\n}\n```\n\nBy implementing its own tap gesture recognizer to control editing, [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView]  enables the user to tap an existing note to edit its text. To be notified when the user edits a note, override [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITextView]’s `textViewDidBeginEditing(_ textView:)` delegate callback.\n\n```swift\nextension ViewController: UITextViewDelegate {\n    \n    \/\/ - Tag: TextViewDidBeginEditing\n    func textViewDidBeginEditing(_ textView: UITextView) {\n\n\n        \/\/ Get the main view for this sticky note.\n        guard let stickyView = textView.firstSuperViewOfType(StickyNoteView.self) else { return }\n        \/\/ ...\n\n```\n\nThe following code enables the capability to move a note by panning the screen.\n\n```swift\n@objc\nfunc panOnStickyView(_ sender: UIPanGestureRecognizer) {\n    \n    guard let stickyView = sender.view as? StickyNoteView else { return }\n    \n    let panLocation = sender.location(in: arView)\n    \n    \/\/ Ignore the pan if any StickyViews are being edited.\n    for note in stickyNotes where note.isEditing { return }\n    \n    panStickyNote(sender, stickyView, panLocation)\n}\n```\n\nWhen the user pans to reposition a sticky note, you convert the screen touch location to a 3D world position using [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView\/raycast(from:allowing:alignment:)]. The user can then reposition the sticky note’s anchor in the real world versus simply moving the annotation to a new arbitrary screen location. If a ray cast from the final screen location in the pan gesture doesn’t produce an intersection with a 3D world location, don’t move the sticky note there.\n\n```swift\nfileprivate func attemptRepositioning(_ stickyView: StickyNoteView) {\n    \/\/ Conducts a ray-cast for feature points using the panned position of the StickyNoteView\n    let point = CGPoint(x: stickyView.frame.midX, y: stickyView.frame.midY)\n    if let result = arView.raycast(from: point, allowing: .estimatedPlane, alignment: .any).first {\n        stickyView.stickyNote.transform.matrix = result.worldTransform\n    } else {\n        messageLabel.displayMessage(\"No surface detected, unable to reposition note.\", duration: 2.0)\n        stickyView.stickyNote.shouldAnimate = true\n    }\n}\n```\n\nThe following portion of the pan gesture handler enables the capability to remove a sticky note when the user drags it to the text that says “delete” at the top of the screen.\n\n```swift\nif stickyView.isInTrashZone {\n    deleteStickyNote(stickyView.stickyNote)\n    \/\/ ...\n```\n\n## Enhance the experience with animation\n\nKeeping screen-space annotations to a minimum will maximize the user’s immersion in the AR experience. The sample app makes sticky notes small when the user isn’t editing text, minimizing distractions so they can focus on the real-world environment. But for similar reasons, you should enlarge a sticky note when the user is editing text. To create a seamless transition between editing and nonediting states, animate the sticky note’s size instead of changing it abruptly. See the   `animateStickyViewToEditingFrame` function.\n\n```swift\nfunc animateStickyViewToEditingFrame(_ stickyView: StickyNoteView, keyboardHeight: Double) {\n    let safeFrame = view.safeAreaLayoutGuide.layoutFrame\n    let height = safeFrame.height - keyboardHeight\n    let inset = height * 0.05\n    let editingFrame = CGRect(origin: safeFrame.origin, size: CGSize(width: safeFrame.width, height: height)).insetBy(dx: inset, dy: inset)\n    UIViewPropertyAnimator(duration: 0.2, curve: .easeIn) {\n        stickyView.frame = editingFrame\n        \/\/...\n```\n\nBring even more focus to the editing experience by dimming the background and by lighting the sticky note that the user is editing.\n\n```swift\nstickyView.blurView.effect = UIBlurEffect(style: .light)\n```\n\nTo prevent the user from losing track of a sticky note’s real-world location, animate the note smoothly from one position to the next. For example, if an annotation fails to reposition, animate the sticky note back to its original screen position. This increases the user’s ability to track the annotation if they want to try moving it again.\n\n```swift\nif shouldAnimate {\n    animateTo(projectedPoint)\n    \/\/ ...\n```\n\nTo animate the note’s movement, you continually set its location using a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIViewPropertyAnimator].\n\n```swift\nfunc animateTo(_ point: CGPoint) {\n\n    let animator = UIViewPropertyAnimator(duration: 0.3, curve: .linear) {\n        self.setPositionCenter(point)\n    }\n    \/\/ ...\n```\n\n## Text Annotations\n\n- **Recognizing and Labeling Arbitrary Objects**: Create anchors that track objects you recognize in the camera feed, using a custom optical-recognition algorithm.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create anchors that track objects you recognize in the camera feed, using a custom optical-recognition algorithm.",
          "name" : "Recognizing and Labeling Arbitrary Objects",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/recognizing-and-labeling-arbitrary-objects"
        }
      ],
      "title" : "Text Annotations"
    }
  ],
  "source" : "appleJSON",
  "title" : "Creating screen annotations for objects in an AR experience",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/creating-screen-annotations-for-objects-in-an-ar-experience"
}