{
  "abstract" : "Data on the distance between a device’s rear camera and real-world objects in an AR experience.",
  "codeExamples" : [

  ],
  "contentHash" : "f352e6fdf26b7a0845fc816a3f04afdca9c1259ea3f4165fcb4ca4cc03b2cd21",
  "crawledAt" : "2025-12-02T18:34:14Z",
  "declaration" : {
    "code" : "var sceneDepth: ARDepthData? { get }",
    "language" : "swift"
  },
  "id" : "635C5389-EE2F-40AB-A0A3-473F56CF1140",
  "kind" : "property",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Discussion\n\nThis property describes the distance between a device’s camera and objects or areas in the real world, including ARKit’s confidence in the estimated distance.\n\nThis property is `nil` by default. Add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/sceneDepth] frame semantic to your configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] to instruct the framework to populate this value with [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData] captured by the LiDAR scanner.\n\nCall [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)] on your app’s configuration to support scene depth on select devices and configurations.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/sceneDepth\ncrawled: 2025-12-02T18:34:14Z\n---\n\n# sceneDepth\n\n**Instance Property**\n\nData on the distance between a device’s rear camera and real-world objects in an AR experience.\n\n## Declaration\n\n```swift\nvar sceneDepth: ARDepthData? { get }\n```\n\n## Discussion\n\nThis property describes the distance between a device’s camera and objects or areas in the real world, including ARKit’s confidence in the estimated distance.\n\nThis property is `nil` by default. Add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/sceneDepth] frame semantic to your configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] to instruct the framework to populate this value with [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData] captured by the LiDAR scanner.\n\nCall [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)] on your app’s configuration to support scene depth on select devices and configurations.\n\n## Accessing scene data\n\n- **lightEstimate**: An estimate of lighting conditions based on the camera image.\n- **displayTransform(for:viewportSize:)**: Returns an affine transform for converting between normalized image coordinates and a coordinate space appropriate for rendering the camera image onscreen.\n- **rawFeaturePoints**: The current intermediate results of the scene analysis ARKit uses to perform world tracking.\n- **capturedDepthData**: Depth data captured in front-camera experiences.\n- **capturedDepthDataTimestamp**: The time at which depth data for the frame (if any) was captured.\n- **smoothedSceneDepth**: An average of distance measurements between a device’s rear camera and real-world objects that creates smoother visuals in an AR experience.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An estimate of lighting conditions based on the camera image.",
          "name" : "lightEstimate",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/lightEstimate"
        },
        {
          "description" : "Returns an affine transform for converting between normalized image coordinates and a coordinate space appropriate for rendering the camera image onscreen.",
          "name" : "displayTransform(for:viewportSize:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/displayTransform(for:viewportSize:)"
        },
        {
          "description" : "The current intermediate results of the scene analysis ARKit uses to perform world tracking.",
          "name" : "rawFeaturePoints",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/rawFeaturePoints"
        },
        {
          "description" : "Depth data captured in front-camera experiences.",
          "name" : "capturedDepthData",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/capturedDepthData"
        },
        {
          "description" : "The time at which depth data for the frame (if any) was captured.",
          "name" : "capturedDepthDataTimestamp",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/capturedDepthDataTimestamp"
        },
        {
          "description" : "An average of distance measurements between a device’s rear camera and real-world objects that creates smoother visuals in an AR experience.",
          "name" : "smoothedSceneDepth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/smoothedSceneDepth"
        }
      ],
      "title" : "Accessing scene data"
    }
  ],
  "source" : "appleJSON",
  "title" : "sceneDepth",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/sceneDepth"
}