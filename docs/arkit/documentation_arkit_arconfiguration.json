{
  "abstract" : "The base object that contains information about how to configure an augmented reality session.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol"
  ],
  "contentHash" : "57ad63b7f575c705b1d202ca5927b538f248dbc89e51f7b47c52bd4d7019364c",
  "crawledAt" : "2025-12-07T17:39:00Z",
  "declaration" : {
    "code" : "class ARConfiguration",
    "language" : "swift"
  },
  "id" : "40E4ACA6-6DF9-4A41-94B5-A88BAB90F8CD",
  "inheritedBy" : [
    "ARBodyTrackingConfiguration",
    "ARFaceTrackingConfiguration",
    "ARGeoTrackingConfiguration",
    "ARImageTrackingConfiguration",
    "ARObjectScanningConfiguration",
    "AROrientationTrackingConfiguration",
    "ARPositionalTrackingConfiguration",
    "ARWorldTrackingConfiguration"
  ],
  "kind" : "class",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\n[doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration] defines a base class for the different options you can configure in your AR experience.\n\nAll AR configurations establish a correspondence between the real world that the device inhabits and the virtual 3D-coordinate space, where you model content. When your app mixes virtual content with a live-camera image, the user experiences the illusion that your virtual content is part of the real world.\n\nTo acquire the live-camera imagery, ARKit manages a camera-capture pipeline for you. Depending on the configuration you choose, it determines the cameras that capture imagery, and which camera feed the app displays.\n\nAR apps recognize real-world regions of interest. At runtime, ARKit generates an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] for a real-world object it recognizes, which allows an app to refer to its details, such as size and physical location. The configuration you choose determines the kinds of real-world objects ARKit recognizes and makes available to your app.\n\nDon’t allocate [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration] yourself; instead, instantiate one of its subclasses.\n\nFor more information about the camera-capture pipeline, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/choosing-which-camera-feed-to-augment].",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/arkit\/arconfiguration\ncrawled: 2025-12-07T17:39:00Z\n---\n\n# ARConfiguration\n\n**Class**\n\nThe base object that contains information about how to configure an augmented reality session.\n\n## Declaration\n\n```swift\nclass ARConfiguration\n```\n\n## Overview\n\n[doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration] defines a base class for the different options you can configure in your AR experience.\n\nAll AR configurations establish a correspondence between the real world that the device inhabits and the virtual 3D-coordinate space, where you model content. When your app mixes virtual content with a live-camera image, the user experiences the illusion that your virtual content is part of the real world.\n\nTo acquire the live-camera imagery, ARKit manages a camera-capture pipeline for you. Depending on the configuration you choose, it determines the cameras that capture imagery, and which camera feed the app displays.\n\nAR apps recognize real-world regions of interest. At runtime, ARKit generates an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] for a real-world object it recognizes, which allows an app to refer to its details, such as size and physical location. The configuration you choose determines the kinds of real-world objects ARKit recognizes and makes available to your app.\n\nDon’t allocate [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration] yourself; instead, instantiate one of its subclasses.\n\nFor more information about the camera-capture pipeline, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/choosing-which-camera-feed-to-augment].\n\n## Verifying device support\n\n- **isSupported**: A Boolean value indicating whether the current device supports this session configuration class.\n\n## Enabling frame features\n\n- **frameSemantics**: The set of active semantics on the frame.\n- **ARConfiguration.FrameSemantics**: Types of optional frame features you can enable in your app.\n- **supportsFrameSemantics(_:)**: Checks whether a particular feature is supported.\n\n## Configuring the AR session\n\n- **isLightEstimationEnabled**: A Boolean value specifying whether ARKit analyzes scene lighting in captured camera images.\n- **worldAlignment**: A value specifying how the session maps real-world device motion into a 3D scene coordinate system.\n- **ARConfiguration.WorldAlignment**: Options for how ARKit constructs a scene coordinate system based on real-world device motion.\n\n## Managing video capture options\n\n- **videoFormat**: Video format of the session output.\n- **supportedVideoFormats**: The set of video capture formats available on the current device.\n- **ARConfiguration.VideoFormat**: A video size and frame rate specification for use with an AR session.\n- **videoHDRAllowed**: Enables high dynamic range (HDR) for the session’s camera feed.\n- **configurableCaptureDeviceForPrimaryCamera**: An object that enables you to alter the appearance of a frame’s captured image.\n- **recommendedVideoFormatFor4KResolution**: Provides a 4K video format if the device and configuration support it.\n- **recommendedVideoFormatForHighResolutionFrameCapturing**: Returns a video format that the framework recommends for high-resolution-still-image capture.\n\n## Recording Audio\n\n- **providesAudioData**: A Boolean value that specifies whether to capture audio during the AR session.\n\n## Reconstructing the Scene\n\n- **ARConfiguration.SceneReconstruction**: Options that enable ARKit to detect the shape of the physical environment.\n\n## Inherits From\n\n- NSObject\n\n## Inherited By\n\n- ARBodyTrackingConfiguration\n- ARFaceTrackingConfiguration\n- ARGeoTrackingConfiguration\n- ARImageTrackingConfiguration\n- ARObjectScanningConfiguration\n- AROrientationTrackingConfiguration\n- ARPositionalTrackingConfiguration\n- ARWorldTrackingConfiguration\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value indicating whether the current device supports this session configuration class.",
          "name" : "isSupported",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/isSupported"
        }
      ],
      "title" : "Verifying device support"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The set of active semantics on the frame.",
          "name" : "frameSemantics",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property"
        },
        {
          "description" : "Types of optional frame features you can enable in your app.",
          "name" : "ARConfiguration.FrameSemantics",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct"
        },
        {
          "description" : "Checks whether a particular feature is supported.",
          "name" : "supportsFrameSemantics(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)"
        }
      ],
      "title" : "Enabling frame features"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value specifying whether ARKit analyzes scene lighting in captured camera images.",
          "name" : "isLightEstimationEnabled",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/isLightEstimationEnabled"
        },
        {
          "description" : "A value specifying how the session maps real-world device motion into a 3D scene coordinate system.",
          "name" : "worldAlignment",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/worldAlignment-swift.property"
        },
        {
          "description" : "Options for how ARKit constructs a scene coordinate system based on real-world device motion.",
          "name" : "ARConfiguration.WorldAlignment",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/WorldAlignment-swift.enum"
        }
      ],
      "title" : "Configuring the AR session"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Video format of the session output.",
          "name" : "videoFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/videoFormat-swift.property"
        },
        {
          "description" : "The set of video capture formats available on the current device.",
          "name" : "supportedVideoFormats",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/supportedVideoFormats"
        },
        {
          "description" : "A video size and frame rate specification for use with an AR session.",
          "name" : "ARConfiguration.VideoFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/VideoFormat-swift.class"
        },
        {
          "description" : "Enables high dynamic range (HDR) for the session’s camera feed.",
          "name" : "videoHDRAllowed",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/videoHDRAllowed"
        },
        {
          "description" : "An object that enables you to alter the appearance of a frame’s captured image.",
          "name" : "configurableCaptureDeviceForPrimaryCamera",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/configurableCaptureDeviceForPrimaryCamera"
        },
        {
          "description" : "Provides a 4K video format if the device and configuration support it.",
          "name" : "recommendedVideoFormatFor4KResolution",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/recommendedVideoFormatFor4KResolution"
        },
        {
          "description" : "Returns a video format that the framework recommends for high-resolution-still-image capture.",
          "name" : "recommendedVideoFormatForHighResolutionFrameCapturing",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/recommendedVideoFormatForHighResolutionFrameCapturing"
        }
      ],
      "title" : "Managing video capture options"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that specifies whether to capture audio during the AR session.",
          "name" : "providesAudioData",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/providesAudioData"
        }
      ],
      "title" : "Recording Audio"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Options that enable ARKit to detect the shape of the physical environment.",
          "name" : "ARConfiguration.SceneReconstruction",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/SceneReconstruction"
        }
      ],
      "title" : "Reconstructing the Scene"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "ARConfiguration",
  "url" : "https:\/\/developer.apple.com\/documentation\/arkit\/arconfiguration"
}