{
  "abstract" : "Identify items in the physical environment, including planar surfaces, images, physical objects, body positions, and faces.",
  "codeExamples" : [

  ],
  "contentHash" : "e801d4cfec92ede3c14a358e08b316e0e45e5ef6f660ea704c5c72fa9d169207",
  "crawledAt" : "2025-12-03T15:29:00Z",
  "id" : "AFD54FAD-225E-4EEF-912B-EE3D42579231",
  "kind" : "collection",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nAnchors identify the position of items in your augmented reality session. Use anchors to obtain information about the item itself, or about the thing it represents. For example, use an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor] to determine the location of a planar surface.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/content-anchors\ncrawled: 2025-12-03T15:29:00Z\n---\n\n# Content Anchors\n\n**API Collection**\n\nIdentify items in the physical environment, including planar surfaces, images, physical objects, body positions, and faces.\n\n## Overview\n\nAnchors identify the position of items in your augmented reality session. Use anchors to obtain information about the item itself, or about the thing it represents. For example, use an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor] to determine the location of a planar surface.\n\n## Surface Detection\n\n- **Tracking and visualizing planes**: Detect surfaces in the physical environment and visualize their shape and location in 3D space.\n- **ARPlaneAnchor**: An anchor for a 2D planar surface that ARKit detects in the physical environment.\n- **ARMeshAnchor**: An anchor for a physical object that ARKit detects and recreates virtually using a polygonal mesh.\n\n## Image Detection\n\n- **Tracking and altering images**: Create images from rectangular shapes found in the user’s environment, and augment their appearance.\n- **Detecting Images in an AR Experience**: React to known 2D images in the user’s environment, and use their positions to place AR content.\n- **ARImageAnchor**: An anchor for a known image that ARKit detects in the physical environment.\n- **ARReferenceImage**: A 2D image that you want ARKit to detect in the physical environment.\n\n## Physical Objects\n\n- **Visualizing and interacting with a reconstructed scene**: Estimate the shape of the physical environment using a polygonal mesh.\n- **Scanning and Detecting 3D Objects**: Record spatial features of real-world objects, then use the results to find those objects in the user’s environment and trigger AR content.\n- **ARObjectAnchor**: An anchor for a real-world 3D object that ARKit detects in the physical environment.\n- **ARReferenceObject**: The description of a 3D object that you want ARKit to detect in the physical environment.\n\n## Body Position Tracking\n\n- **Capturing Body Motion in 3D**: Track a person in the physical environment and visualize their motion by applying the same body movements to a virtual character.\n- **Rigging a Model for Motion Capture**: Configure custom 3D models so ARKit’s human body-tracking feature can control them.\n- **Validating a Model for Motion Capture**: Verify that your character model matches ARKit’s Motion Capture requirements.\n- **ARBodyAnchor**: An anchor that tracks the position and movement of a human body in the rear-facing camera.\n\n## Face Tracking\n\n- **Tracking and visualizing faces**: Detect faces in a front-camera AR experience, overlay virtual content, and animate facial expressions in real-time.\n- **Combining user face-tracking and world tracking**: Track the user’s face in an app that displays an AR experience with the rear camera.\n- **ARFaceAnchor**: An anchor for a unique face that is visible in the front-facing camera.\n\n## Geotracking\n\n- **Tracking geographic locations in AR**: Track specific geographic areas of interest and render them in an AR experience.\n- **ARGeoAnchor**: An anchor that identifies a geographic location using latitude, longitude, and altitude data.\n\n## Multiuser Experiences\n\n- **ARParticipantAnchor**: An anchor for another user in multiuser augmented reality experiences.\n\n## App Clip Codes\n\n- **Interacting with App Clip Codes in AR**: Display content and provide services in an AR experience with App Clip Codes.\n- **ARAppClipCodeAnchor**: An anchor that tracks the position and orientation of an App Clip Code in the physical environment.\n\n## Text Annotations\n\n- **Creating screen annotations for objects in an AR experience**: Annotate an AR experience with virtual sticky notes that you display onscreen over real and virtual objects.\n- **Recognizing and Labeling Arbitrary Objects**: Create anchors that track objects you recognize in the camera feed, using a custom optical-recognition algorithm.\n\n## Common Types\n\n- **ARAnchor**: An object that specifies the position and orientation of an item in the physical environment.\n- **ARAnchorCopying**: Support for custom anchor subclasses.\n- **ARTrackable**: An interface for objects that track the location of real-world objects or locations.\n\n## Virtual Content\n\n- **Environmental Analysis**: Analyze the video from the cameras and the accompanying data, and use ray-casting and depth-map information to determine the location of items.\n- **Camera, Lighting, and Effects**: Determine the camera position and lighting for the current session, and apply effects, such as occlusion, to elements of the environment.\n- **Data Management**: Obtain detailed information about skeletal and face geometry, and saved world data.\n- **Creating USD files for Apple devices**: Generate 3D assets that render as expected.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Detect surfaces in the physical environment and visualize their shape and location in 3D space.",
          "name" : "Tracking and visualizing planes",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-visualizing-planes"
        },
        {
          "description" : "An anchor for a 2D planar surface that ARKit detects in the physical environment.",
          "name" : "ARPlaneAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARPlaneAnchor"
        },
        {
          "description" : "An anchor for a physical object that ARKit detects and recreates virtually using a polygonal mesh.",
          "name" : "ARMeshAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARMeshAnchor"
        }
      ],
      "title" : "Surface Detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create images from rectangular shapes found in the user’s environment, and augment their appearance.",
          "name" : "Tracking and altering images",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-altering-images"
        },
        {
          "description" : "React to known 2D images in the user’s environment, and use their positions to place AR content.",
          "name" : "Detecting Images in an AR Experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/detecting-images-in-an-ar-experience"
        },
        {
          "description" : "An anchor for a known image that ARKit detects in the physical environment.",
          "name" : "ARImageAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARImageAnchor"
        },
        {
          "description" : "A 2D image that you want ARKit to detect in the physical environment.",
          "name" : "ARReferenceImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARReferenceImage"
        }
      ],
      "title" : "Image Detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Estimate the shape of the physical environment using a polygonal mesh.",
          "name" : "Visualizing and interacting with a reconstructed scene",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/visualizing-and-interacting-with-a-reconstructed-scene"
        },
        {
          "description" : "Record spatial features of real-world objects, then use the results to find those objects in the user’s environment and trigger AR content.",
          "name" : "Scanning and Detecting 3D Objects",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/scanning-and-detecting-3d-objects"
        },
        {
          "description" : "An anchor for a real-world 3D object that ARKit detects in the physical environment.",
          "name" : "ARObjectAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARObjectAnchor"
        },
        {
          "description" : "The description of a 3D object that you want ARKit to detect in the physical environment.",
          "name" : "ARReferenceObject",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARReferenceObject"
        }
      ],
      "title" : "Physical Objects"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Track a person in the physical environment and visualize their motion by applying the same body movements to a virtual character.",
          "name" : "Capturing Body Motion in 3D",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/capturing-body-motion-in-3d"
        },
        {
          "description" : "Configure custom 3D models so ARKit’s human body-tracking feature can control them.",
          "name" : "Rigging a Model for Motion Capture",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/rigging-a-model-for-motion-capture"
        },
        {
          "description" : "Verify that your character model matches ARKit’s Motion Capture requirements.",
          "name" : "Validating a Model for Motion Capture",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/validating-a-model-for-motion-capture"
        },
        {
          "description" : "An anchor that tracks the position and movement of a human body in the rear-facing camera.",
          "name" : "ARBodyAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyAnchor"
        }
      ],
      "title" : "Body Position Tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Detect faces in a front-camera AR experience, overlay virtual content, and animate facial expressions in real-time.",
          "name" : "Tracking and visualizing faces",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-visualizing-faces"
        },
        {
          "description" : "Track the user’s face in an app that displays an AR experience with the rear camera.",
          "name" : "Combining user face-tracking and world tracking",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/combining-user-face-tracking-and-world-tracking"
        },
        {
          "description" : "An anchor for a unique face that is visible in the front-facing camera.",
          "name" : "ARFaceAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceAnchor"
        }
      ],
      "title" : "Face Tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Track specific geographic areas of interest and render them in an AR experience.",
          "name" : "Tracking geographic locations in AR",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-geographic-locations-in-ar"
        },
        {
          "description" : "An anchor that identifies a geographic location using latitude, longitude, and altitude data.",
          "name" : "ARGeoAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARGeoAnchor"
        }
      ],
      "title" : "Geotracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An anchor for another user in multiuser augmented reality experiences.",
          "name" : "ARParticipantAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARParticipantAnchor"
        }
      ],
      "title" : "Multiuser Experiences"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Display content and provide services in an AR experience with App Clip Codes.",
          "name" : "Interacting with App Clip Codes in AR",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppClip\/interacting-with-app-clip-codes-in-ar"
        },
        {
          "description" : "An anchor that tracks the position and orientation of an App Clip Code in the physical environment.",
          "name" : "ARAppClipCodeAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARAppClipCodeAnchor"
        }
      ],
      "title" : "App Clip Codes"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Annotate an AR experience with virtual sticky notes that you display onscreen over real and virtual objects.",
          "name" : "Creating screen annotations for objects in an AR experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/creating-screen-annotations-for-objects-in-an-ar-experience"
        },
        {
          "description" : "Create anchors that track objects you recognize in the camera feed, using a custom optical-recognition algorithm.",
          "name" : "Recognizing and Labeling Arbitrary Objects",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/recognizing-and-labeling-arbitrary-objects"
        }
      ],
      "title" : "Text Annotations"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that specifies the position and orientation of an item in the physical environment.",
          "name" : "ARAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARAnchor"
        },
        {
          "description" : "Support for custom anchor subclasses.",
          "name" : "ARAnchorCopying",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARAnchorCopying"
        },
        {
          "description" : "An interface for objects that track the location of real-world objects or locations.",
          "name" : "ARTrackable",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARTrackable"
        }
      ],
      "title" : "Common Types"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Analyze the video from the cameras and the accompanying data, and use ray-casting and depth-map information to determine the location of items.",
          "name" : "Environmental Analysis",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/environmental-analysis"
        },
        {
          "description" : "Determine the camera position and lighting for the current session, and apply effects, such as occlusion, to elements of the environment.",
          "name" : "Camera, Lighting, and Effects",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/camera-lighting-and-effects"
        },
        {
          "description" : "Obtain detailed information about skeletal and face geometry, and saved world data.",
          "name" : "Data Management",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/data-management"
        },
        {
          "description" : "Generate 3D assets that render as expected.",
          "name" : "Creating USD files for Apple devices",
          "url" : "https:\/\/developer.apple.com\/documentation\/USD\/creating-usd-files-for-apple-devices"
        }
      ],
      "title" : "Virtual Content"
    }
  ],
  "source" : "appleJSON",
  "title" : "Content Anchors",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/content-anchors"
}