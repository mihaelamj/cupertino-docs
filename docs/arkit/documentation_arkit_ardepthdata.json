{
  "abstract" : "An object that describes the distance to regions of the real world from the plane of the camera.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "dca7887b1867e98c7d53b7966336f329fd6553fa82741d1f0ebcadc5db956a35",
  "crawledAt" : "2025-12-02T15:49:48Z",
  "declaration" : {
    "code" : "class ARDepthData",
    "language" : "swift"
  },
  "id" : "A20F690B-C109-4E54-8D1C-22F466B6D1B4",
  "kind" : "class",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nThis object contains the following depth information that the LiDAR scanner captures at runtime:\n\n[doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] exposes this depth information in the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/sceneDepth] property which it updates every frame. To enable scene depth, add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/sceneDepth] frame semantic to a world-tracking configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] and frames vended by the session contain [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData] captured by the LiDAR scanner.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARDepthData\ncrawled: 2025-12-02T15:49:48Z\n---\n\n# ARDepthData\n\n**Class**\n\nAn object that describes the distance to regions of the real world from the plane of the camera.\n\n## Declaration\n\n```swift\nclass ARDepthData\n```\n\n## Overview\n\nThis object contains the following depth information that the LiDAR scanner captures at runtime:\n\n- Every pixel in the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData\/depthMap] maps to a region of the visible scene ([doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/capturedImage]), where the pixel value defines that region’s distance from the plane of the camera in meters.\n- The [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData\/confidenceMap] property measures the accuracy of the corresponding depth data in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData\/depthMap], and is useful in filtering out lower-accuracy depth values if an app’s algorithm required it.\n\n[doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] exposes this depth information in the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/sceneDepth] property which it updates every frame. To enable scene depth, add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/sceneDepth] frame semantic to a world-tracking configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] and frames vended by the session contain [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData] captured by the LiDAR scanner.\n\n## Depth Information\n\n- **depthMap**: The estimated distance from the device to its environment, in meters.\n- **confidenceMap**: The framework’s confidence in the accuracy of the depth-map data.\n- **ARConfidenceLevel**: Degrees to which the framework is confident about depth-data accuracy.\n\n## Video Frame Analysis\n\n- **Displaying a point cloud using scene depth**: Present a visualization of the physical environment by placing points based a scene’s depth data.\n- **Creating a fog effect using scene depth**: Apply virtual fog to the physical environment.\n- **ARFrame**: A video image captured as part of a session with position-tracking information.\n- **ARPointCloud**: A collection of points in the world coordinate space of the AR session.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The estimated distance from the device to its environment, in meters.",
          "name" : "depthMap",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARDepthData\/depthMap"
        },
        {
          "description" : "The framework’s confidence in the accuracy of the depth-map data.",
          "name" : "confidenceMap",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARDepthData\/confidenceMap"
        },
        {
          "description" : "Degrees to which the framework is confident about depth-data accuracy.",
          "name" : "ARConfidenceLevel",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfidenceLevel"
        }
      ],
      "title" : "Depth Information"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Present a visualization of the physical environment by placing points based a scene’s depth data.",
          "name" : "Displaying a point cloud using scene depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/displaying-a-point-cloud-using-scene-depth"
        },
        {
          "description" : "Apply virtual fog to the physical environment.",
          "name" : "Creating a fog effect using scene depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/creating-a-fog-effect-using-scene-depth"
        },
        {
          "description" : "A video image captured as part of a session with position-tracking information.",
          "name" : "ARFrame",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame"
        },
        {
          "description" : "A collection of points in the world coordinate space of the AR session.",
          "name" : "ARPointCloud",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARPointCloud"
        }
      ],
      "title" : "Video Frame Analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "ARDepthData",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARDepthData"
}