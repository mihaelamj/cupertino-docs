{
  "abstract" : "Obtain detailed information about skeletal and face geometry, and saved world data.",
  "codeExamples" : [

  ],
  "contentHash" : "c215ba96d7e79c918209421f03112f3fbc23bda86d2471965e0a511255f06164",
  "crawledAt" : "2025-12-03T15:48:14Z",
  "id" : "25F1BEA2-7E8C-4B5F-8828-AFAF0158560B",
  "kind" : "collection",
  "language" : "swift",
  "module" : "ARKit",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/data-management\ncrawled: 2025-12-03T15:48:14Z\n---\n\n# Data Management\n\n**API Collection**\n\nObtain detailed information about skeletal and face geometry, and saved world data.\n\n## Body Data\n\n- **Capturing Body Motion in 3D**: Track a person in the physical environment and visualize their motion by applying the same body movements to a virtual character.\n- **ARBody2D**: The screen-space representation of a person ARKit recognizes in the camera feed.\n- **ARSkeleton3D**: The skeleton of a human body that ARKit tracks in 3D space.\n- **ARSkeleton2D**: An object that describes the locations of a body’s joints in the camera feed.\n- **ARSkeleton**: The interface for the skeleton of a tracked body.\n- **ARSkeletonDefinition**: The hierarchy of joints and their names.\n\n## Face Data\n\n- **Tracking and visualizing faces**: Detect faces in a front-camera AR experience, overlay virtual content, and animate facial expressions in real-time.\n- **Combining user face-tracking and world tracking**: Track the user’s face in an app that displays an AR experience with the rear camera.\n- **ARFaceGeometry**: A 3D mesh describing face topology for use in face-tracking AR sessions.\n- **ARSCNFaceGeometry**: A SceneKit representation of face topology for use with face information that an AR session provides.\n\n## World Data\n\n- **Saving and loading world data**: Serialize a world-tracking session to resume it later on.\n- **ARWorldMap**: The state in a world-tracking AR session during which a device maps the user’s position in physical space and proximity to anchor objects.\n\n## Virtual Content\n\n- **Content Anchors**: Identify items in the physical environment, including planar surfaces, images, physical objects, body positions, and faces.\n- **Environmental Analysis**: Analyze the video from the cameras and the accompanying data, and use ray-casting and depth-map information to determine the location of items.\n- **Camera, Lighting, and Effects**: Determine the camera position and lighting for the current session, and apply effects, such as occlusion, to elements of the environment.\n- **Creating USD files for Apple devices**: Generate 3D assets that render as expected.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Track a person in the physical environment and visualize their motion by applying the same body movements to a virtual character.",
          "name" : "Capturing Body Motion in 3D",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/capturing-body-motion-in-3d"
        },
        {
          "description" : "The screen-space representation of a person ARKit recognizes in the camera feed.",
          "name" : "ARBody2D",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBody2D"
        },
        {
          "description" : "The skeleton of a human body that ARKit tracks in 3D space.",
          "name" : "ARSkeleton3D",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSkeleton3D"
        },
        {
          "description" : "An object that describes the locations of a body’s joints in the camera feed.",
          "name" : "ARSkeleton2D",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSkeleton2D"
        },
        {
          "description" : "The interface for the skeleton of a tracked body.",
          "name" : "ARSkeleton",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSkeleton"
        },
        {
          "description" : "The hierarchy of joints and their names.",
          "name" : "ARSkeletonDefinition",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSkeletonDefinition"
        }
      ],
      "title" : "Body Data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Detect faces in a front-camera AR experience, overlay virtual content, and animate facial expressions in real-time.",
          "name" : "Tracking and visualizing faces",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-visualizing-faces"
        },
        {
          "description" : "Track the user’s face in an app that displays an AR experience with the rear camera.",
          "name" : "Combining user face-tracking and world tracking",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/combining-user-face-tracking-and-world-tracking"
        },
        {
          "description" : "A 3D mesh describing face topology for use in face-tracking AR sessions.",
          "name" : "ARFaceGeometry",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry"
        },
        {
          "description" : "A SceneKit representation of face topology for use with face information that an AR session provides.",
          "name" : "ARSCNFaceGeometry",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSCNFaceGeometry"
        }
      ],
      "title" : "Face Data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Serialize a world-tracking session to resume it later on.",
          "name" : "Saving and loading world data",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/saving-and-loading-world-data"
        },
        {
          "description" : "The state in a world-tracking AR session during which a device maps the user’s position in physical space and proximity to anchor objects.",
          "name" : "ARWorldMap",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARWorldMap"
        }
      ],
      "title" : "World Data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Identify items in the physical environment, including planar surfaces, images, physical objects, body positions, and faces.",
          "name" : "Content Anchors",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/content-anchors"
        },
        {
          "description" : "Analyze the video from the cameras and the accompanying data, and use ray-casting and depth-map information to determine the location of items.",
          "name" : "Environmental Analysis",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/environmental-analysis"
        },
        {
          "description" : "Determine the camera position and lighting for the current session, and apply effects, such as occlusion, to elements of the environment.",
          "name" : "Camera, Lighting, and Effects",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/camera-lighting-and-effects"
        },
        {
          "description" : "Generate 3D assets that render as expected.",
          "name" : "Creating USD files for Apple devices",
          "url" : "https:\/\/developer.apple.com\/documentation\/USD\/creating-usd-files-for-apple-devices"
        }
      ],
      "title" : "Virtual Content"
    }
  ],
  "source" : "appleJSON",
  "title" : "Data Management",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/data-management"
}