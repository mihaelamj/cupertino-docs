{
  "abstract" : "Add visual effects to the user’s environment in an AR experience through the front or rear camera.",
  "codeExamples" : [

  ],
  "contentHash" : "08a14313ba6c4b1da1ca760a775d1c45bfedc9c7299f1d07d8c99119a8501f0a",
  "crawledAt" : "2025-12-03T15:48:08Z",
  "id" : "4446029C-E508-4F1A-9CDA-1BCBB3CC1EA2",
  "kind" : "article",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\niOS devices come equipped with multiple cameras, and for each ARKit session you need to choose which camera’s feed to augment. ARKit 3 and later provide simultaneous anchors from all cameras (see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/combining-user-face-tracking-and-world-tracking]), but you still must choose one camera feed to show to the user at a time.\n\n### Augmented Reality with the Rear Camera\n\nThe most common kinds of AR experience display a view from the device’s rear camera, augmented by other visual content, giving the user a new way to see and interact with the world around them.\n\n[doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] provides this kind of experience: ARKit tracks the real-world the user inhabits, and matches it with a coordinate space for you to place virtual content. World tracking also offers features to make AR experiences more immersive, like the ability to recognize objects and images in the user’s environment and respond to real-world lighting conditions.\n\n### Augmented Reality with the Front Camera\n\nFor iOS devices that have a TrueDepth camera, [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceTrackingConfiguration] enables you to augment the front-camera feed, while providing you with real-time tracking for the pose and expression of faces. With that information,  that you might, for example, choose to overlay realistic virtual masks. Or, you might omit the camera view and use facial expression data to animate virtual characters, as in the Animoji app for iMessage.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/choosing-which-camera-feed-to-augment\ncrawled: 2025-12-03T15:48:08Z\n---\n\n# Choosing Which Camera Feed to Augment\n\n**Article**\n\nAdd visual effects to the user’s environment in an AR experience through the front or rear camera.\n\n## Overview\n\niOS devices come equipped with multiple cameras, and for each ARKit session you need to choose which camera’s feed to augment. ARKit 3 and later provide simultaneous anchors from all cameras (see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/combining-user-face-tracking-and-world-tracking]), but you still must choose one camera feed to show to the user at a time.\n\n### Augmented Reality with the Rear Camera\n\nThe most common kinds of AR experience display a view from the device’s rear camera, augmented by other visual content, giving the user a new way to see and interact with the world around them.\n\n[doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] provides this kind of experience: ARKit tracks the real-world the user inhabits, and matches it with a coordinate space for you to place virtual content. World tracking also offers features to make AR experiences more immersive, like the ability to recognize objects and images in the user’s environment and respond to real-world lighting conditions.\n\n### Augmented Reality with the Front Camera\n\nFor iOS devices that have a TrueDepth camera, [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceTrackingConfiguration] enables you to augment the front-camera feed, while providing you with real-time tracking for the pose and expression of faces. With that information,  that you might, for example, choose to overlay realistic virtual masks. Or, you might omit the camera view and use facial expression data to animate virtual characters, as in the Animoji app for iMessage.\n\n## Setup\n\n- **Managing Session Life Cycle and Tracking Quality**: Keep the user informed on the current session state and recover from interruptions.\n- **Displaying an AR Experience with Metal**: Control rendering of your app’s virtual content on top of a camera feed.\n- **ARSession**: The object that manages the major tasks associated with every AR experience, such as motion tracking, camera passthrough, and image analysis.\n- **Configuration Objects**: Configure your augmented reality session to detect and track specific types of content.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Keep the user informed on the current session state and recover from interruptions.",
          "name" : "Managing Session Life Cycle and Tracking Quality",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/managing-session-life-cycle-and-tracking-quality"
        },
        {
          "description" : "Control rendering of your app’s virtual content on top of a camera feed.",
          "name" : "Displaying an AR Experience with Metal",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/displaying-an-ar-experience-with-metal"
        },
        {
          "description" : "The object that manages the major tasks associated with every AR experience, such as motion tracking, camera passthrough, and image analysis.",
          "name" : "ARSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSession"
        },
        {
          "description" : "Configure your augmented reality session to detect and track specific types of content.",
          "name" : "Configuration Objects",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/configuration-objects"
        }
      ],
      "title" : "Setup"
    }
  ],
  "source" : "appleJSON",
  "title" : "Choosing Which Camera Feed to Augment",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/choosing-which-camera-feed-to-augment"
}