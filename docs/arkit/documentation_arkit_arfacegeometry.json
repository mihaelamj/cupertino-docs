{
  "abstract" : "A 3D mesh describing face topology for use in face-tracking AR sessions.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCoding",
    "NSCopying",
    "NSObjectProtocol",
    "NSSecureCoding",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "5fb933ac2ec06034752443837c7bd0b5cab48eb7c416a451721738c648f20853",
  "crawledAt" : "2025-12-05T01:39:06Z",
  "declaration" : {
    "code" : "class ARFaceGeometry",
    "language" : "swift"
  },
  "id" : "93068799-63DD-4FCB-9ACF-B9A408C37FF8",
  "kind" : "class",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nThis class provides a general model for the detailed topology of a face, in the form of a 3D mesh appropriate for use with various rendering technologies or for exporting 3D assets. (For a quick way to visualize a face geometry using SceneKit, see the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNFaceGeometry] class.)\n\nWhen you obtain a face geometry from an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceAnchor] object in a face-tracking AR session, the model conforms to match the dimensions, shape, and current expression of the detected face. You can also create a face mesh using a dictionary of named blend shape coefficients, which provides a detailed, but more efficient, description of the face’s current expression.\n\nIn an AR session, you can use this model as the basis for overlaying content that follows the shape of the user’s face—for example, to apply virtual makeup or tattoos. You can also use this model to create occlusion geometry, which hides other virtual content behind the 3D shape of the detected face in the camera image.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry\ncrawled: 2025-12-05T01:39:06Z\n---\n\n# ARFaceGeometry\n\n**Class**\n\nA 3D mesh describing face topology for use in face-tracking AR sessions.\n\n## Declaration\n\n```swift\nclass ARFaceGeometry\n```\n\n## Overview\n\nThis class provides a general model for the detailed topology of a face, in the form of a 3D mesh appropriate for use with various rendering technologies or for exporting 3D assets. (For a quick way to visualize a face geometry using SceneKit, see the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNFaceGeometry] class.)\n\nWhen you obtain a face geometry from an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceAnchor] object in a face-tracking AR session, the model conforms to match the dimensions, shape, and current expression of the detected face. You can also create a face mesh using a dictionary of named blend shape coefficients, which provides a detailed, but more efficient, description of the face’s current expression.\n\nIn an AR session, you can use this model as the basis for overlaying content that follows the shape of the user’s face—for example, to apply virtual makeup or tattoos. You can also use this model to create occlusion geometry, which hides other virtual content behind the 3D shape of the detected face in the camera image.\n\n\n\n## Accessing Mesh Data\n\n- **vertices**: An array of vertex positions for each point in the face mesh.\n- **textureCoordinates**: An array of texture coordinate values for each point in the face mesh.\n- **triangleCount**: The number of triangles described by the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceGeometry\/triangleIndices-3tb1o] buffer.\n- **triangleIndices**: An array of indices describing the triangle mesh formed by the face geometry’s vertex data.\n\n## Creating a Mesh from Blend Shapes\n\n- **init(blendShapes:)**: Creates a face geometry matching the facial expression described in the specified dictionary.\n\n## Face Data\n\n- **Tracking and visualizing faces**: Detect faces in a front-camera AR experience, overlay virtual content, and animate facial expressions in real-time.\n- **Combining user face-tracking and world tracking**: Track the user’s face in an app that displays an AR experience with the rear camera.\n- **ARSCNFaceGeometry**: A SceneKit representation of face topology for use with face information that an AR session provides.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCoding\n- NSCopying\n- NSObjectProtocol\n- NSSecureCoding\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An array of vertex positions for each point in the face mesh.",
          "name" : "vertices",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry\/vertices-7qq1y"
        },
        {
          "description" : "An array of texture coordinate values for each point in the face mesh.",
          "name" : "textureCoordinates",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry\/textureCoordinates-u42d"
        },
        {
          "description" : "The number of triangles described by the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceGeometry\/triangleIndices-3tb1o] buffer.",
          "name" : "triangleCount",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry\/triangleCount"
        },
        {
          "description" : "An array of indices describing the triangle mesh formed by the face geometry’s vertex data.",
          "name" : "triangleIndices",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry\/triangleIndices-8isy8"
        }
      ],
      "title" : "Accessing Mesh Data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a face geometry matching the facial expression described in the specified dictionary.",
          "name" : "init(blendShapes:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry\/init(blendShapes:)"
        }
      ],
      "title" : "Creating a Mesh from Blend Shapes"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Detect faces in a front-camera AR experience, overlay virtual content, and animate facial expressions in real-time.",
          "name" : "Tracking and visualizing faces",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-visualizing-faces"
        },
        {
          "description" : "Track the user’s face in an app that displays an AR experience with the rear camera.",
          "name" : "Combining user face-tracking and world tracking",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/combining-user-face-tracking-and-world-tracking"
        },
        {
          "description" : "A SceneKit representation of face topology for use with face information that an AR session provides.",
          "name" : "ARSCNFaceGeometry",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSCNFaceGeometry"
        }
      ],
      "title" : "Face Data"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "ARFaceGeometry",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceGeometry"
}