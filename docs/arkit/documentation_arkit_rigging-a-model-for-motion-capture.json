{
  "abstract" : "Configure custom 3D models so ARKit’s human body-tracking feature can control them.",
  "codeExamples" : [

  ],
  "contentHash" : "ead5b277eafb369b8d203f2574c65b40960ae1683058e6891e3352d1b828e7e7",
  "crawledAt" : "2025-12-02T16:08:35Z",
  "id" : "4D61CBAC-E486-48BD-A0D8-EFDAE2728BE6",
  "kind" : "article",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nARKit recognizes and tracks a person’s movements using an iOS device’s rear camera. RealityKit applies the detected motion to a 3D character model in real time, allowing the person on camera to control the movement of the 3D model, much like a virtual puppet. You can try out this feature by downloading sample code in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/capturing-body-motion-in-3d].\n\n### Configure Your Model\n\nYou can configure your own models so RealityKit’s puppeteering functionality can control them. Your character model must be a skeletal mesh exported as a USDZ file and must conform to a specific joint hierarchy and naming convention. Models that don’t conform may behave unexpectedly or fail to work at all. Learn more about the specific joint hierarchy and required names for puppeteering models at [doc:\/\/com.apple.arkit\/documentation\/ARKit\/validating-a-model-for-motion-capture].\n\n### Download the Robot Model\n\nThe easiest way to configure your model for puppeteering is to rig it to the skeleton from the robot model in the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/capturing-body-motion-in-3d] sample. By using the robot model’s skeleton to rig your own model, you’ll start with the correct bone names and hierarchy. You can download a zip file containing both the USDZ and FBX versions of the [https:\/\/developer.apple.com\/sample-code\/ar\/Biped-Robot.zip].\n\n### Import the Skeleton into Your 3D-Modeling Program\n\nIn your 3D-modeling software package (such as Maya, Cinema4D, or Modo), import the provided skeleton and the custom mesh model that you want to use with ARKit’s Motion Capture functionality. You should model your mesh in a standard T-pose.\n\nIt’s very important that you configure your import settings so that they don’t change the orientation of the imported character or any of the skeleton’s individual joints. After import, the character should be oriented facing the +Z axis, with the top of its head oriented toward the +Y axis, and the character’s left hand pointing along the +X axis. Your scene should also be configured with +Y as the up axis. In some software packages, this orientation requires changing the default scene configuration.\n\n\n\nOnce you’ve imported the robot character file, unbind and delete the robot mesh. You only need the skeleton from the imported file, since you’ll be binding your own mesh to it. Make sure you don’t change the joint names or relationships, and hang your custom geometry to the same node as the he skeleton and your custom geometry must be parented in separate hierarchies in order to export a valid USDZ for puppeteering. There should be no geometry descending from joints, and no joints descending from geometry.\n\n### Match the T-Pose Rest Position\n\nNext, align your mesh to the imported skeleton, then scale, translate, and rotate it until it matches the imported skeleton as closely as you can get it. Finally, freeze transformations on the mesh.\n\n\n\nFinish matching the mesh and armature by moving any joints of the armature that don’t line up correctly with the mesh, making sure that the X axis still points down the length of the bone after you’re done moving it. Many 3D software packages include tools to automatically re-orient joints based on the location of their children. If a re-orienting feature is available in your software package, use it when you’re done moving joints into new locations.\n\n### Bind Your Mesh to the Imported Skeleton\n\nOnce you’ve aligned your mesh with the skeleton, bind your mesh to it. For best performance, you should use no more than four skin influences per vertex. You character should be modeled in a T-pose, your scene should contain only one bind pose, and the rotational values of each joint in your hierarchy should match the values in the provided example skeleton.\n\n### Export the Model\n\nAfter you’ve tested your bound mesh and are happy with your vertex weights and joint deformations, export your model to a USDZ file. If your 3D package doesn’t support exporting directly to USDZ, you can export as a GLTF or USD file and then use Reality Converter to convert that file to USDZ. Reality Converter will also convert FBX files if you manually install the Autodesk FBX Python SDK available from Autodesk’s website.\n\nXcode automatically configures USDZ files imported into an AR application target and adds them to your app bundle when building so they become available to load at runtime.\n\nFor more information on loading and using the model once it’s in your Xcode project, see the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/capturing-body-motion-in-3d] sample code project, which demonstrates how to load and display a skeletal model contained in a USDZ file as a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/BodyTrackedEntity].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/rigging-a-model-for-motion-capture\ncrawled: 2025-12-02T16:08:35Z\n---\n\n# Rigging a Model for Motion Capture\n\n**Article**\n\nConfigure custom 3D models so ARKit’s human body-tracking feature can control them.\n\n## Overview\n\nARKit recognizes and tracks a person’s movements using an iOS device’s rear camera. RealityKit applies the detected motion to a 3D character model in real time, allowing the person on camera to control the movement of the 3D model, much like a virtual puppet. You can try out this feature by downloading sample code in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/capturing-body-motion-in-3d].\n\n### Configure Your Model\n\nYou can configure your own models so RealityKit’s puppeteering functionality can control them. Your character model must be a skeletal mesh exported as a USDZ file and must conform to a specific joint hierarchy and naming convention. Models that don’t conform may behave unexpectedly or fail to work at all. Learn more about the specific joint hierarchy and required names for puppeteering models at [doc:\/\/com.apple.arkit\/documentation\/ARKit\/validating-a-model-for-motion-capture].\n\n### Download the Robot Model\n\nThe easiest way to configure your model for puppeteering is to rig it to the skeleton from the robot model in the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/capturing-body-motion-in-3d] sample. By using the robot model’s skeleton to rig your own model, you’ll start with the correct bone names and hierarchy. You can download a zip file containing both the USDZ and FBX versions of the [https:\/\/developer.apple.com\/sample-code\/ar\/Biped-Robot.zip].\n\n\n\n### Import the Skeleton into Your 3D-Modeling Program\n\nIn your 3D-modeling software package (such as Maya, Cinema4D, or Modo), import the provided skeleton and the custom mesh model that you want to use with ARKit’s Motion Capture functionality. You should model your mesh in a standard T-pose.\n\nIt’s very important that you configure your import settings so that they don’t change the orientation of the imported character or any of the skeleton’s individual joints. After import, the character should be oriented facing the +Z axis, with the top of its head oriented toward the +Y axis, and the character’s left hand pointing along the +X axis. Your scene should also be configured with +Y as the up axis. In some software packages, this orientation requires changing the default scene configuration.\n\n\n\n\n\nOnce you’ve imported the robot character file, unbind and delete the robot mesh. You only need the skeleton from the imported file, since you’ll be binding your own mesh to it. Make sure you don’t change the joint names or relationships, and hang your custom geometry to the same node as the he skeleton and your custom geometry must be parented in separate hierarchies in order to export a valid USDZ for puppeteering. There should be no geometry descending from joints, and no joints descending from geometry.\n\n### Match the T-Pose Rest Position\n\nNext, align your mesh to the imported skeleton, then scale, translate, and rotate it until it matches the imported skeleton as closely as you can get it. Finally, freeze transformations on the mesh.\n\n\n\nFinish matching the mesh and armature by moving any joints of the armature that don’t line up correctly with the mesh, making sure that the X axis still points down the length of the bone after you’re done moving it. Many 3D software packages include tools to automatically re-orient joints based on the location of their children. If a re-orienting feature is available in your software package, use it when you’re done moving joints into new locations.\n\n\n\n### Bind Your Mesh to the Imported Skeleton\n\nOnce you’ve aligned your mesh with the skeleton, bind your mesh to it. For best performance, you should use no more than four skin influences per vertex. You character should be modeled in a T-pose, your scene should contain only one bind pose, and the rotational values of each joint in your hierarchy should match the values in the provided example skeleton.\n\n### Export the Model\n\nAfter you’ve tested your bound mesh and are happy with your vertex weights and joint deformations, export your model to a USDZ file. If your 3D package doesn’t support exporting directly to USDZ, you can export as a GLTF or USD file and then use Reality Converter to convert that file to USDZ. Reality Converter will also convert FBX files if you manually install the Autodesk FBX Python SDK available from Autodesk’s website.\n\nXcode automatically configures USDZ files imported into an AR application target and adds them to your app bundle when building so they become available to load at runtime.\n\nFor more information on loading and using the model once it’s in your Xcode project, see the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/capturing-body-motion-in-3d] sample code project, which demonstrates how to load and display a skeletal model contained in a USDZ file as a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/BodyTrackedEntity].\n\n## Body Position Tracking\n\n- **Capturing Body Motion in 3D**: Track a person in the physical environment and visualize their motion by applying the same body movements to a virtual character.\n- **Validating a Model for Motion Capture**: Verify that your character model matches ARKit’s Motion Capture requirements.\n- **ARBodyAnchor**: An anchor that tracks the position and movement of a human body in the rear-facing camera.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Track a person in the physical environment and visualize their motion by applying the same body movements to a virtual character.",
          "name" : "Capturing Body Motion in 3D",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/capturing-body-motion-in-3d"
        },
        {
          "description" : "Verify that your character model matches ARKit’s Motion Capture requirements.",
          "name" : "Validating a Model for Motion Capture",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/validating-a-model-for-motion-capture"
        },
        {
          "description" : "An anchor that tracks the position and movement of a human body in the rear-facing camera.",
          "name" : "ARBodyAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyAnchor"
        }
      ],
      "title" : "Body Position Tracking"
    }
  ],
  "source" : "appleJSON",
  "title" : "Rigging a Model for Motion Capture",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/rigging-a-model-for-motion-capture"
}