{
  "abstract" : "A configuration that tracks facial movement and expressions using the front camera.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol"
  ],
  "contentHash" : "76027f3215d963018cf0d9035bfe2693ef091f4998de80658e5d0c4b9c66969b",
  "crawledAt" : "2025-12-04T02:45:07Z",
  "declaration" : {
    "code" : "class ARFaceTrackingConfiguration",
    "language" : "swift"
  },
  "id" : "3BFB1F9E-BEA0-4795-B78B-F253837AFAAC",
  "kind" : "class",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nA face-tracking configuration detects faces within 3 meters of the device’s front camera. When ARKit detects a face, it creates an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceAnchor] object that provides information about a person’s facial position, orientation, topology, and expressions.\n\nFace tracking supports devices with Apple Neural Engine in iOS 14 and iPadOS 14 and requires a device with a TrueDepth camera on iOS 13 and iPadOS 13 and earlier. To determine whether the device supports face tracking, call [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/isSupported] on [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceTrackingConfiguration] before attempting to use this configuration.\n\nWhen you enable the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/isLightEstimationEnabled] setting, a face-tracking configuration estimates directional and environmental lighting (an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDirectionalLightEstimate] object) by referring to the detected face as a light probe.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration\ncrawled: 2025-12-04T02:45:07Z\n---\n\n# ARFaceTrackingConfiguration\n\n**Class**\n\nA configuration that tracks facial movement and expressions using the front camera.\n\n## Declaration\n\n```swift\nclass ARFaceTrackingConfiguration\n```\n\n## Overview\n\nA face-tracking configuration detects faces within 3 meters of the device’s front camera. When ARKit detects a face, it creates an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceAnchor] object that provides information about a person’s facial position, orientation, topology, and expressions.\n\nFace tracking supports devices with Apple Neural Engine in iOS 14 and iPadOS 14 and requires a device with a TrueDepth camera on iOS 13 and iPadOS 13 and earlier. To determine whether the device supports face tracking, call [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/isSupported] on [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceTrackingConfiguration] before attempting to use this configuration.\n\nWhen you enable the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/isLightEstimationEnabled] setting, a face-tracking configuration estimates directional and environmental lighting (an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDirectionalLightEstimate] object) by referring to the detected face as a light probe.\n\n\n\n## Creating a Configuration\n\n- **init()**: Creates a new face-tracking configuration.\n\n## Enabling World Tracking\n\n- **supportsWorldTracking**: A Boolean value that indicates whether the iOS device supports tracking the user’s facial features in a world-tracking session.\n- **isWorldTrackingEnabled**: A Boolean value that instructs a session to provide the app with the device’s six degrees of freedom pose during a face-tracking session.\n\n## Tracking Multiple Faces\n\n- **maximumNumberOfTrackedFaces**: The number of faces to track during the session.\n- **supportedNumberOfTrackedFaces**: The maximum number of faces that the framework can track.\n\n## Body and Face Tracking\n\n- **ARBodyTrackingConfiguration**: A configuration that tracks human body poses, planar surfaces, and images using the rear-facing camera.\n\n## Inherits From\n\n- ARConfiguration\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a new face-tracking configuration.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration\/init()"
        }
      ],
      "title" : "Creating a Configuration"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the iOS device supports tracking the user’s facial features in a world-tracking session.",
          "name" : "supportsWorldTracking",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration\/supportsWorldTracking"
        },
        {
          "description" : "A Boolean value that instructs a session to provide the app with the device’s six degrees of freedom pose during a face-tracking session.",
          "name" : "isWorldTrackingEnabled",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration\/isWorldTrackingEnabled"
        }
      ],
      "title" : "Enabling World Tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The number of faces to track during the session.",
          "name" : "maximumNumberOfTrackedFaces",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration\/maximumNumberOfTrackedFaces"
        },
        {
          "description" : "The maximum number of faces that the framework can track.",
          "name" : "supportedNumberOfTrackedFaces",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration\/supportedNumberOfTrackedFaces"
        }
      ],
      "title" : "Tracking Multiple Faces"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A configuration that tracks human body poses, planar surfaces, and images using the rear-facing camera.",
          "name" : "ARBodyTrackingConfiguration",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration"
        }
      ],
      "title" : "Body and Face Tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "ARConfiguration"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "ARFaceTrackingConfiguration",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration"
}