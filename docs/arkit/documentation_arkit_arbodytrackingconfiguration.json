{
  "abstract" : "A configuration that tracks human body poses, planar surfaces, and images using the rear-facing camera.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol"
  ],
  "contentHash" : "f749b357ab750bdeb0fe50ab06bf1524ab5449903c44b5e1ab3e946f35438eb2",
  "crawledAt" : "2025-12-02T07:49:54Z",
  "declaration" : {
    "code" : "class ARBodyTrackingConfiguration",
    "language" : "swift"
  },
  "id" : "DC9AC6AC-B574-41D2-B0BD-F09CEF72B6EE",
  "kind" : "class",
  "module" : "ARKit",
  "overview" : "## Overview\n\nWhen ARKit identifies a person in the rear camera’s feed, it calls [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)], passing an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARBodyAnchor] you can use to track the body’s movement.\n\nWhen you enable plane detection and image detection, you can use a body anchor to display a virtual character and set the character on a surface or image that you choose.\n\nBy default, [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] includes [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/bodyDetection], which gives you access to the joint positions of a person that ARKit detects in the camera feed via the frame’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/detectedBody].",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\ncrawled: 2025-12-02T07:49:54Z\n---\n\n# ARBodyTrackingConfiguration\n\n**Class**\n\nA configuration that tracks human body poses, planar surfaces, and images using the rear-facing camera.\n\n## Declaration\n\n```swift\nclass ARBodyTrackingConfiguration\n```\n\n## Overview\n\nWhen ARKit identifies a person in the rear camera’s feed, it calls [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)], passing an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARBodyAnchor] you can use to track the body’s movement.\n\nWhen you enable plane detection and image detection, you can use a body anchor to display a virtual character and set the character on a surface or image that you choose.\n\nBy default, [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] includes [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/bodyDetection], which gives you access to the joint positions of a person that ARKit detects in the camera feed via the frame’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/detectedBody].\n\n## Creating a Configuration\n\n- **init()**: Creates a new body tracking configuration.\n- **initialWorldMap**: The state from a previous AR session to attempt to resume with this session configuration.\n\n## Estimating Body Scale\n\n- **automaticSkeletonScaleEstimationEnabled**: A flag that determines whether ARKit estimates the height of a body that it’s tracking.\n\n## Enabling Auto Focus\n\n- **isAutoFocusEnabled**: A Boolean value that determines whether the device camera uses fixed focus or autofocus behavior.\n\n## Enabling Plane Detection\n\n- **planeDetection**: A value specifying whether and how the session attempts to automatically detect flat surfaces in the camera-captured image.\n- **ARWorldTrackingConfiguration.PlaneDetection**: Options for whether and how the framework detects flat surfaces in captured images.\n\n## Enabling Image Tracking\n\n- **automaticImageScaleEstimationEnabled**: A flag that instructs ARKit to estimate and set the scale of a tracked image on your behalf.\n- **detectionImages**: A set of images that ARKit searches for in the user’s environment.\n- **maximumNumberOfTrackedImages**: The number of image anchors to monitor closely for position and orientation updates.\n\n## Adding Realistic Reflections\n\n- **wantsHDREnvironmentTextures**: A flag that instructs ARKit to create environment textures in HDR format.\n- **environmentTexturing**: The behavior ARKit uses for generating environment textures.\n\n## Accessing App Clip Codes\n\n- **Interacting with App Clip Codes in AR**: Display content and provide services in an AR experience with App Clip Codes.\n- **supportsAppClipCodeTracking**: A flag that indicates if the device tracks App Clip Codes.\n- **appClipCodeTrackingEnabled**: A Boolean value that indicates if the framework searches the physical environment for App Clip Codes.\n- **ARAppClipCodeAnchor**: An anchor that tracks the position and orientation of an App Clip Code in the physical environment.\n\n## Body and Face Tracking\n\n- **ARFaceTrackingConfiguration**: A configuration that tracks facial movement and expressions using the front camera.\n\n## Inherits From\n\n- ARConfiguration\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a new body tracking configuration.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/init()"
        },
        {
          "description" : "The state from a previous AR session to attempt to resume with this session configuration.",
          "name" : "initialWorldMap",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/initialWorldMap"
        }
      ],
      "title" : "Creating a Configuration"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A flag that determines whether ARKit estimates the height of a body that it’s tracking.",
          "name" : "automaticSkeletonScaleEstimationEnabled",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/automaticSkeletonScaleEstimationEnabled"
        }
      ],
      "title" : "Estimating Body Scale"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that determines whether the device camera uses fixed focus or autofocus behavior.",
          "name" : "isAutoFocusEnabled",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/isAutoFocusEnabled"
        }
      ],
      "title" : "Enabling Auto Focus"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A value specifying whether and how the session attempts to automatically detect flat surfaces in the camera-captured image.",
          "name" : "planeDetection",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/planeDetection"
        },
        {
          "description" : "Options for whether and how the framework detects flat surfaces in captured images.",
          "name" : "ARWorldTrackingConfiguration.PlaneDetection",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARWorldTrackingConfiguration\/PlaneDetection-swift.struct"
        }
      ],
      "title" : "Enabling Plane Detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A flag that instructs ARKit to estimate and set the scale of a tracked image on your behalf.",
          "name" : "automaticImageScaleEstimationEnabled",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/automaticImageScaleEstimationEnabled"
        },
        {
          "description" : "A set of images that ARKit searches for in the user’s environment.",
          "name" : "detectionImages",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/detectionImages"
        },
        {
          "description" : "The number of image anchors to monitor closely for position and orientation updates.",
          "name" : "maximumNumberOfTrackedImages",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/maximumNumberOfTrackedImages"
        }
      ],
      "title" : "Enabling Image Tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A flag that instructs ARKit to create environment textures in HDR format.",
          "name" : "wantsHDREnvironmentTextures",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/wantsHDREnvironmentTextures"
        },
        {
          "description" : "The behavior ARKit uses for generating environment textures.",
          "name" : "environmentTexturing",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/environmentTexturing"
        }
      ],
      "title" : "Adding Realistic Reflections"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Display content and provide services in an AR experience with App Clip Codes.",
          "name" : "Interacting with App Clip Codes in AR",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppClip\/interacting-with-app-clip-codes-in-ar"
        },
        {
          "description" : "A flag that indicates if the device tracks App Clip Codes.",
          "name" : "supportsAppClipCodeTracking",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/supportsAppClipCodeTracking"
        },
        {
          "description" : "A Boolean value that indicates if the framework searches the physical environment for App Clip Codes.",
          "name" : "appClipCodeTrackingEnabled",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration\/appClipCodeTrackingEnabled"
        },
        {
          "description" : "An anchor that tracks the position and orientation of an App Clip Code in the physical environment.",
          "name" : "ARAppClipCodeAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARAppClipCodeAnchor"
        }
      ],
      "title" : "Accessing App Clip Codes"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A configuration that tracks facial movement and expressions using the front camera.",
          "name" : "ARFaceTrackingConfiguration",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFaceTrackingConfiguration"
        }
      ],
      "title" : "Body and Face Tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "ARConfiguration"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "ARBodyTrackingConfiguration",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBodyTrackingConfiguration"
}