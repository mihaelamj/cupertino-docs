{
  "abstract" : "Analyze the video from the cameras and the accompanying data, and use ray-casting and depth-map information to determine the location of items.",
  "codeExamples" : [

  ],
  "contentHash" : "6eb537b3388db02bc8690b0ea4a8d9cfe0eb4ee7fdaabec24acc52357abaf069",
  "crawledAt" : "2025-12-03T15:29:00Z",
  "id" : "89D0EB78-CA6E-47A0-A3F5-554B2802D187",
  "kind" : "collection",
  "language" : "swift",
  "module" : "ARKit",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/environmental-analysis\ncrawled: 2025-12-03T15:29:00Z\n---\n\n# Environmental Analysis\n\n**API Collection**\n\nAnalyze the video from the cameras and the accompanying data, and use ray-casting and depth-map information to determine the location of items.\n\n## Video Frame Analysis\n\n- **Displaying a point cloud using scene depth**: Present a visualization of the physical environment by placing points based a scene’s depth data.\n- **Creating a fog effect using scene depth**: Apply virtual fog to the physical environment.\n- **ARFrame**: A video image captured as part of a session with position-tracking information.\n- **ARPointCloud**: A collection of points in the world coordinate space of the AR session.\n- **ARDepthData**: An object that describes the distance to regions of the real world from the plane of the camera.\n\n## Raycasting\n\n- **Placing objects and handling 3D interaction**: Place virtual content at tracked, real-world locations, and enable the user to interact with virtual content by using gestures.\n- **ARRaycastQuery**: A mathematical ray you use to find 3D positions on real-world surfaces.\n- **ARTrackedRaycast**: A raycast query that ARKit repeats in succession to give you refined results over time.\n- **ARRaycastResult**: Information about a real-world surface found by examining a point on the screen.\n\n## Hit-Testing\n\n- **ARHitTestResult**: Information about a real-world surface found by examining a point on the screen.\n\n## Virtual Content\n\n- **Content Anchors**: Identify items in the physical environment, including planar surfaces, images, physical objects, body positions, and faces.\n- **Camera, Lighting, and Effects**: Determine the camera position and lighting for the current session, and apply effects, such as occlusion, to elements of the environment.\n- **Data Management**: Obtain detailed information about skeletal and face geometry, and saved world data.\n- **Creating USD files for Apple devices**: Generate 3D assets that render as expected.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Present a visualization of the physical environment by placing points based a scene’s depth data.",
          "name" : "Displaying a point cloud using scene depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/displaying-a-point-cloud-using-scene-depth"
        },
        {
          "description" : "Apply virtual fog to the physical environment.",
          "name" : "Creating a fog effect using scene depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/creating-a-fog-effect-using-scene-depth"
        },
        {
          "description" : "A video image captured as part of a session with position-tracking information.",
          "name" : "ARFrame",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame"
        },
        {
          "description" : "A collection of points in the world coordinate space of the AR session.",
          "name" : "ARPointCloud",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARPointCloud"
        },
        {
          "description" : "An object that describes the distance to regions of the real world from the plane of the camera.",
          "name" : "ARDepthData",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARDepthData"
        }
      ],
      "title" : "Video Frame Analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Place virtual content at tracked, real-world locations, and enable the user to interact with virtual content by using gestures.",
          "name" : "Placing objects and handling 3D interaction",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/placing-objects-and-handling-3d-interaction"
        },
        {
          "description" : "A mathematical ray you use to find 3D positions on real-world surfaces.",
          "name" : "ARRaycastQuery",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARRaycastQuery"
        },
        {
          "description" : "A raycast query that ARKit repeats in succession to give you refined results over time.",
          "name" : "ARTrackedRaycast",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARTrackedRaycast"
        },
        {
          "description" : "Information about a real-world surface found by examining a point on the screen.",
          "name" : "ARRaycastResult",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARRaycastResult"
        }
      ],
      "title" : "Raycasting"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Information about a real-world surface found by examining a point on the screen.",
          "name" : "ARHitTestResult",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARHitTestResult"
        }
      ],
      "title" : "Hit-Testing"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Identify items in the physical environment, including planar surfaces, images, physical objects, body positions, and faces.",
          "name" : "Content Anchors",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/content-anchors"
        },
        {
          "description" : "Determine the camera position and lighting for the current session, and apply effects, such as occlusion, to elements of the environment.",
          "name" : "Camera, Lighting, and Effects",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/camera-lighting-and-effects"
        },
        {
          "description" : "Obtain detailed information about skeletal and face geometry, and saved world data.",
          "name" : "Data Management",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/data-management"
        },
        {
          "description" : "Generate 3D assets that render as expected.",
          "name" : "Creating USD files for Apple devices",
          "url" : "https:\/\/developer.apple.com\/documentation\/USD\/creating-usd-files-for-apple-devices"
        }
      ],
      "title" : "Virtual Content"
    }
  ],
  "source" : "appleJSON",
  "title" : "Environmental Analysis",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/environmental-analysis"
}