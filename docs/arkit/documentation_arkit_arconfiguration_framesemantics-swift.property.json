{
  "abstract" : "The set of active semantics on the frame.",
  "codeExamples" : [
    {
      "code" : "if let config = mySession.configuration as? ARBodyTrackingConfiguration {\n    config.frameSemantics.insert(.bodyDetection)\n    \/\/ Run the configuration to effect a frame semantics change.\n    mySession.run(config)\n}\n",
      "language" : "swift"
    },
    {
      "code" : "if let config = mySession.configuration as? ARWorldTrackingConfiguration {\n    config.frameSemantics.insert(.personSegmentationWithDepth)\n    \/\/ Run the configuration to effect a frame semantics change.\n    mySession.run(config)\n}\n",
      "language" : "swift"
    }
  ],
  "contentHash" : "173f01434e5c8babac6fc68b6191b196b27210417c651e87670b76c66bb15151",
  "crawledAt" : "2025-12-02T07:49:44Z",
  "declaration" : {
    "code" : "var frameSemantics: ARConfiguration.FrameSemantics { get set }",
    "language" : "swift"
  },
  "id" : "0E812769-525E-4473-9D96-B37FCBF69AE1",
  "kind" : "property",
  "module" : "ARKit",
  "overview" : "## Discussion\n\nYou can choose whether ARKit reports information about a particular per-frame metric, or *semantic*. Before enabling a frame sementic, call [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)] to ensure device support.\n\n### Enable 2D Body Detection\n\nTo get information about the 2D location of a person that ARKit recognizes in a frame, you enable the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/bodyDetection] frame semantic.\n\n### Enable People Occlusion\n\nPeople occlusion is a feature that enables people in the camera feed to cover your app’s virtual content.\n\n\n\nTo indicate that a person should overlap your app’s virtual content when the person is closer to the camera than the virtual content, add the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/personSegmentationWithDepth] option to your configuration’s frame semantics.\n\n\n\nTo indicate that a person should overlap your app’s virtual content regardless of the person’s depth in the scene, use the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/personSegmentation] frame semantic instead. This option is particularly appropriate for green-screen scenarios.\n\n\n\nStandard renderers ([doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView], and [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView]) implement people occlusion for you. See [doc:\/\/com.apple.arkit\/documentation\/ARKit\/occluding-virtual-content-with-people] for a sample app that demonstrates people occlusion in RealityKit.\n\nIf you implement your own renderer, use [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/segmentationBuffer] and [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/estimatedDepthData] to implement people occlusion yourself. [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARMatteGenerator] helps you by providing masks. For a sample app that demonstrates matte generator and people occlusion, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/effecting-people-occlusion-in-custom-renderers].\n\nIf you enable Scene Reconstruction, ARKit adjusts the mesh according to any people ARKit may detect in the camera feed. ARKit removes any part of the scene mesh that overlaps with people, as defined by the with- or without-depth frame semantics. For more information about scene reconstruction, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/visualizing-and-interacting-with-a-reconstructed-scene].",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property\ncrawled: 2025-12-02T07:49:44Z\n---\n\n# frameSemantics\n\n**Instance Property**\n\nThe set of active semantics on the frame.\n\n## Declaration\n\n```swift\nvar frameSemantics: ARConfiguration.FrameSemantics { get set }\n```\n\n## Discussion\n\nYou can choose whether ARKit reports information about a particular per-frame metric, or *semantic*. Before enabling a frame sementic, call [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)] to ensure device support.\n\n### Enable 2D Body Detection\n\nTo get information about the 2D location of a person that ARKit recognizes in a frame, you enable the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/bodyDetection] frame semantic.\n\n```swift\nif let config = mySession.configuration as? ARBodyTrackingConfiguration {\n    config.frameSemantics.insert(.bodyDetection)\n    \/\/ Run the configuration to effect a frame semantics change.\n    mySession.run(config)\n}\n\n```\n\n### Enable People Occlusion\n\nPeople occlusion is a feature that enables people in the camera feed to cover your app’s virtual content.\n\n\n\nTo indicate that a person should overlap your app’s virtual content when the person is closer to the camera than the virtual content, add the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/personSegmentationWithDepth] option to your configuration’s frame semantics.\n\n```swift\nif let config = mySession.configuration as? ARWorldTrackingConfiguration {\n    config.frameSemantics.insert(.personSegmentationWithDepth)\n    \/\/ Run the configuration to effect a frame semantics change.\n    mySession.run(config)\n}\n\n```\n\n\n\nTo indicate that a person should overlap your app’s virtual content regardless of the person’s depth in the scene, use the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/personSegmentation] frame semantic instead. This option is particularly appropriate for green-screen scenarios.\n\n\n\nStandard renderers ([doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView], and [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView]) implement people occlusion for you. See [doc:\/\/com.apple.arkit\/documentation\/ARKit\/occluding-virtual-content-with-people] for a sample app that demonstrates people occlusion in RealityKit.\n\nIf you implement your own renderer, use [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/segmentationBuffer] and [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/estimatedDepthData] to implement people occlusion yourself. [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARMatteGenerator] helps you by providing masks. For a sample app that demonstrates matte generator and people occlusion, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/effecting-people-occlusion-in-custom-renderers].\n\nIf you enable Scene Reconstruction, ARKit adjusts the mesh according to any people ARKit may detect in the camera feed. ARKit removes any part of the scene mesh that overlaps with people, as defined by the with- or without-depth frame semantics. For more information about scene reconstruction, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/visualizing-and-interacting-with-a-reconstructed-scene].\n\n## Enabling frame features\n\n- **ARConfiguration.FrameSemantics**: Types of optional frame features you can enable in your app.\n- **supportsFrameSemantics(_:)**: Checks whether a particular feature is supported.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Types of optional frame features you can enable in your app.",
          "name" : "ARConfiguration.FrameSemantics",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct"
        },
        {
          "description" : "Checks whether a particular feature is supported.",
          "name" : "supportsFrameSemantics(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)"
        }
      ],
      "title" : "Enabling frame features"
    }
  ],
  "source" : "appleJSON",
  "title" : "frameSemantics",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property"
}