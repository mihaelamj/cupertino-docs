{
  "abstract" : "Detect surfaces in the physical environment and visualize their shape and location in 3D space.",
  "codeExamples" : [
    {
      "code" : "let configuration = ARWorldTrackingConfiguration()\nconfiguration.planeDetection = [.horizontal, .vertical]\nsceneView.session.run(configuration)",
      "language" : "swift"
    },
    {
      "code" : "func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n    \/\/ Place content only for anchors found by plane detection.\n    guard let planeAnchor = anchor as? ARPlaneAnchor else { return }\n    \n    \/\/ Create a custom object to visualize the plane geometry and extent.\n    let plane = Plane(anchor: planeAnchor, in: sceneView)\n    \n    \/\/ Add the visualization to the ARKit-managed node so that it tracks\n    \/\/ changes in the plane anchor as plane estimation continues.\n    node.addChildNode(plane)\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create a mesh to visualize the estimated shape of the plane.\nguard let meshGeometry = ARSCNPlaneGeometry(device: sceneView.device!)\n    else { fatalError(\"Can't create plane geometry\") }\nmeshGeometry.update(from: anchor.geometry)\nmeshNode = SCNNode(geometry: meshGeometry)\n\n\/\/ Create a node to visualize the plane's bounding rectangle.\nlet extentPlane: SCNPlane = SCNPlane(width: CGFloat(anchor.extent.x), height: CGFloat(anchor.extent.z))\nextentNode = SCNNode(geometry: extentPlane)\nextentNode.simdPosition = anchor.center\n\n\/\/ `SCNPlane` is vertically oriented in its local coordinate space, so\n\/\/ rotate it to match the orientation of `ARPlaneAnchor`.\nextentNode.eulerAngles.x = -.pi \/ 2",
      "language" : "swift"
    },
    {
      "code" : "func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n    \/\/ Update only anchors and nodes set up by `renderer(_:didAdd:for:)`.\n    guard let planeAnchor = anchor as? ARPlaneAnchor,\n        let plane = node.childNodes.first as? Plane\n        else { return }\n    \n    \/\/ Update ARSCNPlaneGeometry to the anchor's new estimated shape.\n    if let planeGeometry = plane.meshNode.geometry as? ARSCNPlaneGeometry {\n        planeGeometry.update(from: planeAnchor.geometry)\n    }\n\n    \/\/ Update extent visualization to the anchor's new bounding rectangle.\n    if let extentGeometry = plane.extentNode.geometry as? SCNPlane {\n        extentGeometry.width = CGFloat(planeAnchor.extent.x)\n        extentGeometry.height = CGFloat(planeAnchor.extent.z)\n        plane.extentNode.simdPosition = planeAnchor.center\n    }\n    \n    \/\/ Update the plane's classification and the text position\n    if #available(iOS 12.0, *),\n        let classificationNode = plane.classificationNode,\n        let classificationGeometry = classificationNode.geometry as? SCNText {\n        let currentClassification = planeAnchor.classification.description\n        if let oldClassification = classificationGeometry.string as? String, oldClassification != currentClassification {\n            classificationGeometry.string = currentClassification\n            classificationNode.centerAlign()\n        }\n    }\n    \n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Display the plane's classification, if supported on the device\nif #available(iOS 12.0, *), ARPlaneAnchor.isClassificationSupported {\n    let classification = anchor.classification.description\n    let textNode = self.makeTextNode(classification)\n    classificationNode = textNode\n    \/\/ Change the pivot of the text node to its center\n    textNode.centerAlign()\n    \/\/ Add the classification node as a child node so that it displays the classification\n    extentNode.addChildNode(textNode)\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "040c901026432f3c43cd1401101e0e5bf15daa4fb7434f8490611365b3c92894",
  "crawledAt" : "2025-12-02T15:47:32Z",
  "id" : "437E4B46-DB1C-4A43-A49A-5040F5D0B6E9",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nThis sample app runs an [doc:\/\/com.apple.arkit\/documentation\/ARKit] world tracking session with content displayed in a SceneKit view. To demonstrate plane detection, the app visualizes both the estimated shape of and a bounding rectangle for each detected [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor] object. On supported devices, ARKit can recognize many types of real-world surfaces, so the app also labels each detected plane with identifying text.\n\n## Getting started\n\nARKit requires iOS 11 and a device with an A9 (or later) processor. ARKit is not available in iOS Simulator. Building the sample code requires Xcode 9 or later.\n\n## Configure and run the AR session\n\nThe [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] class is a SceneKit view that includes an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession] object that manages the motion tracking and image processing required to create an augmented reality (AR) experience. However, to run a session you must provide a session configuration.\n\n\n\nThe [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] class provides high-precision motion tracking and enables features to help you place virtual content in relation to real-world surfaces. To start an AR session, create a session configuration object with the options you want (such as plane detection), then call the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession\/run(_:options:)] method on the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView\/session] object of your [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] instance:\n\nRun your session only when the view that will display it is onscreen.\n\n## Place 3D content for detected planes\n\nAfter you’ve set up your AR session, you can use SceneKit to place virtual content in the view.\n\nWhen plane detection is enabled, ARKit adds and updates anchors for each detected plane. By default, the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] class adds an [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNNode] object to the SceneKit scene for each anchor. Your view’s delegate can implement the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didAdd:for:)] method to add content to the scene. When you add content as a child of the node corresponding to the anchor, the `ARSCNView` class automatically moves that content as ARKit refines its estimate of the plane’s position.\n\nARKit offers two ways to track the area of an estimated plane. A plane anchor’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor\/geometry] describes a convex polygon tightly enclosing all points that ARKit currently estimates to be part of the same plane (easily visualized using [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNPlaneGeometry]. ARKit also provides a simpler estimate in a plane anchor’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor\/extent] and [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor\/center]], which together describe a rectangular boundary (easily visualized using [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNPlane].\n\nARKit continually updates its estimates of each detected plane’s shape and extent. To show the current estimated shape for each plane, this sample app also implements the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didUpdate:for:)] method, updating the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNPlaneGeometry] and [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNPlane] objects to reflect the latest information from ARKit.\n\nOn some hardware, ARKit can also classify detected planes, reporting which kind of common real-world surface that plane represents (for example, a table, floor, or wall). In this example, the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didUpdate:for:)] method also displays and updates a text label to show that information when running on hardware that supports it.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-visualizing-planes\ncrawled: 2025-12-02T15:47:32Z\n---\n\n# Tracking and visualizing planes\n\n**Sample Code**\n\nDetect surfaces in the physical environment and visualize their shape and location in 3D space.\n\n## Overview\n\nThis sample app runs an [doc:\/\/com.apple.arkit\/documentation\/ARKit] world tracking session with content displayed in a SceneKit view. To demonstrate plane detection, the app visualizes both the estimated shape of and a bounding rectangle for each detected [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor] object. On supported devices, ARKit can recognize many types of real-world surfaces, so the app also labels each detected plane with identifying text.\n\n## Getting started\n\nARKit requires iOS 11 and a device with an A9 (or later) processor. ARKit is not available in iOS Simulator. Building the sample code requires Xcode 9 or later.\n\n## Configure and run the AR session\n\nThe [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] class is a SceneKit view that includes an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession] object that manages the motion tracking and image processing required to create an augmented reality (AR) experience. However, to run a session you must provide a session configuration.\n\n\n\nThe [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] class provides high-precision motion tracking and enables features to help you place virtual content in relation to real-world surfaces. To start an AR session, create a session configuration object with the options you want (such as plane detection), then call the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession\/run(_:options:)] method on the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView\/session] object of your [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] instance:\n\n```swift\nlet configuration = ARWorldTrackingConfiguration()\nconfiguration.planeDetection = [.horizontal, .vertical]\nsceneView.session.run(configuration)\n```\n\nRun your session only when the view that will display it is onscreen.\n\n\n\n## Place 3D content for detected planes\n\nAfter you’ve set up your AR session, you can use SceneKit to place virtual content in the view.\n\nWhen plane detection is enabled, ARKit adds and updates anchors for each detected plane. By default, the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] class adds an [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNNode] object to the SceneKit scene for each anchor. Your view’s delegate can implement the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didAdd:for:)] method to add content to the scene. When you add content as a child of the node corresponding to the anchor, the `ARSCNView` class automatically moves that content as ARKit refines its estimate of the plane’s position.\n\n```swift\nfunc renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n    \/\/ Place content only for anchors found by plane detection.\n    guard let planeAnchor = anchor as? ARPlaneAnchor else { return }\n    \n    \/\/ Create a custom object to visualize the plane geometry and extent.\n    let plane = Plane(anchor: planeAnchor, in: sceneView)\n    \n    \/\/ Add the visualization to the ARKit-managed node so that it tracks\n    \/\/ changes in the plane anchor as plane estimation continues.\n    node.addChildNode(plane)\n}\n```\n\nARKit offers two ways to track the area of an estimated plane. A plane anchor’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor\/geometry] describes a convex polygon tightly enclosing all points that ARKit currently estimates to be part of the same plane (easily visualized using [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNPlaneGeometry]. ARKit also provides a simpler estimate in a plane anchor’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor\/extent] and [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARPlaneAnchor\/center]], which together describe a rectangular boundary (easily visualized using [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNPlane].\n\n```swift\n\/\/ Create a mesh to visualize the estimated shape of the plane.\nguard let meshGeometry = ARSCNPlaneGeometry(device: sceneView.device!)\n    else { fatalError(\"Can't create plane geometry\") }\nmeshGeometry.update(from: anchor.geometry)\nmeshNode = SCNNode(geometry: meshGeometry)\n\n\/\/ Create a node to visualize the plane's bounding rectangle.\nlet extentPlane: SCNPlane = SCNPlane(width: CGFloat(anchor.extent.x), height: CGFloat(anchor.extent.z))\nextentNode = SCNNode(geometry: extentPlane)\nextentNode.simdPosition = anchor.center\n\n\/\/ `SCNPlane` is vertically oriented in its local coordinate space, so\n\/\/ rotate it to match the orientation of `ARPlaneAnchor`.\nextentNode.eulerAngles.x = -.pi \/ 2\n```\n\nARKit continually updates its estimates of each detected plane’s shape and extent. To show the current estimated shape for each plane, this sample app also implements the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didUpdate:for:)] method, updating the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNPlaneGeometry] and [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNPlane] objects to reflect the latest information from ARKit.\n\n```swift\nfunc renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n    \/\/ Update only anchors and nodes set up by `renderer(_:didAdd:for:)`.\n    guard let planeAnchor = anchor as? ARPlaneAnchor,\n        let plane = node.childNodes.first as? Plane\n        else { return }\n    \n    \/\/ Update ARSCNPlaneGeometry to the anchor's new estimated shape.\n    if let planeGeometry = plane.meshNode.geometry as? ARSCNPlaneGeometry {\n        planeGeometry.update(from: planeAnchor.geometry)\n    }\n\n    \/\/ Update extent visualization to the anchor's new bounding rectangle.\n    if let extentGeometry = plane.extentNode.geometry as? SCNPlane {\n        extentGeometry.width = CGFloat(planeAnchor.extent.x)\n        extentGeometry.height = CGFloat(planeAnchor.extent.z)\n        plane.extentNode.simdPosition = planeAnchor.center\n    }\n    \n    \/\/ Update the plane's classification and the text position\n    if #available(iOS 12.0, *),\n        let classificationNode = plane.classificationNode,\n        let classificationGeometry = classificationNode.geometry as? SCNText {\n        let currentClassification = planeAnchor.classification.description\n        if let oldClassification = classificationGeometry.string as? String, oldClassification != currentClassification {\n            classificationGeometry.string = currentClassification\n            classificationNode.centerAlign()\n        }\n    }\n    \n}\n```\n\nOn some hardware, ARKit can also classify detected planes, reporting which kind of common real-world surface that plane represents (for example, a table, floor, or wall). In this example, the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didUpdate:for:)] method also displays and updates a text label to show that information when running on hardware that supports it.\n\n```swift\n\/\/ Display the plane's classification, if supported on the device\nif #available(iOS 12.0, *), ARPlaneAnchor.isClassificationSupported {\n    let classification = anchor.classification.description\n    let textNode = self.makeTextNode(classification)\n    classificationNode = textNode\n    \/\/ Change the pivot of the text node to its center\n    textNode.centerAlign()\n    \/\/ Add the classification node as a child node so that it displays the classification\n    extentNode.addChildNode(textNode)\n}\n```\n\n## Surface Detection\n\n- **ARPlaneAnchor**: An anchor for a 2D planar surface that ARKit detects in the physical environment.\n- **ARMeshAnchor**: An anchor for a physical object that ARKit detects and recreates virtually using a polygonal mesh.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An anchor for a 2D planar surface that ARKit detects in the physical environment.",
          "name" : "ARPlaneAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARPlaneAnchor"
        },
        {
          "description" : "An anchor for a physical object that ARKit detects and recreates virtually using a polygonal mesh.",
          "name" : "ARMeshAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARMeshAnchor"
        }
      ],
      "title" : "Surface Detection"
    }
  ],
  "source" : "appleJSON",
  "title" : "Tracking and visualizing planes",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-visualizing-planes"
}