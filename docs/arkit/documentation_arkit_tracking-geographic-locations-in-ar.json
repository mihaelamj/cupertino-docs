{
  "abstract" : "Track specific geographic areas of interest and render them in an AR experience.",
  "codeExamples" : [
    {
      "code" : "if !ARGeoTrackingConfiguration.isSupported {\n    let storyboard = UIStoryboard(name: \"Main\", bundle: nil)\n    window?.rootViewController = storyboard.instantiateViewController(withIdentifier: \"unsupportedDeviceMessage\")\n}",
      "language" : "swift"
    },
    {
      "code" : "ARGeoTrackingConfiguration.checkAvailability { (available, error) in\n    if !available {\n        let errorDescription = error?.localizedDescription ?? \"\"\n        let recommendation = \"Please try again in an area where geotracking is supported.\"\n        let restartSession = UIAlertAction(title: \"Restart Session\", style: .default) { (_) in\n            self.restartSession()\n        }\n        self.alertUser(withTitle: \"Geotracking unavailable\",\n                       message: \"\\(errorDescription)\\n\\(recommendation)\",\n                       actions: [restartSession])\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "let geoTrackingConfig = ARGeoTrackingConfiguration()\ngeoTrackingConfig.planeDetection = [.horizontal]\narView.session.run(geoTrackingConfig, options: .removeExistingAnchors)",
      "language" : "swift"
    },
    {
      "code" : "func setupCoachingOverlay() {\n    coachingOverlay.delegate = self\n    arView.addSubview(coachingOverlay)\n    coachingOverlay.goal = .geoTracking",
      "language" : "swift"
    },
    {
      "code" : "self.trackingStateLabel.text = text",
      "language" : "swift"
    },
    {
      "code" : "case .notAvailableAtLocation: return \"Geotracking is unavailable here. Please return to your previous location to continue\"",
      "language" : "swift"
    },
    {
      "code" : "func coachingOverlayViewWillActivate(_ coachingOverlayView: ARCoachingOverlayView) {\n    mapView.isUserInteractionEnabled = false\n    undoButton.isEnabled = false\n    hideUIForCoaching(true)\n}",
      "language" : "swift"
    },
    {
      "code" : "func coachingOverlayViewDidDeactivate(_ coachingOverlayView: ARCoachingOverlayView) {\n    mapView.isUserInteractionEnabled = true\n    undoButton.isEnabled = true\n    hideUIForCoaching(false)\n}",
      "language" : "swift"
    },
    {
      "code" : "func handleTapOnMapView(_ sender: UITapGestureRecognizer) {\n    let point = sender.location(in: mapView)\n    let location = mapView.convert(point, toCoordinateFrom: mapView)",
      "language" : "swift"
    },
    {
      "code" : "geoAnchor = ARGeoAnchor(coordinate: location)",
      "language" : "swift"
    },
    {
      "code" : "arView.session.add(anchor: geoAnchor)",
      "language" : "swift"
    },
    {
      "code" : "func session(_ session: ARSession, didAdd anchors: [ARAnchor]) {\n    for geoAnchor in anchors.compactMap({ $0 as? ARGeoAnchor }) {\n        \/\/ Effect a spatial-based delay to avoid blocking the main thread.\n        DispatchQueue.main.asyncAfter(deadline: .now() + (distanceFromDevice(geoAnchor.coordinate) \/ 10)) {\n            \/\/ Add an AR placemark visualization for the geo anchor.\n            self.arView.scene.addAnchor(Entity.placemarkEntity(for: geoAnchor))",
      "language" : "swift"
    },
    {
      "code" : "let anchorIndicator = AnchorIndicator(center: geoAnchor.coordinate)\nself.mapView.addOverlay(anchorIndicator)",
      "language" : "swift"
    },
    {
      "code" : "if let result = arView.raycast(from: point, allowing: .estimatedPlane, alignment: .any).first {",
      "language" : "swift"
    },
    {
      "code" : "arView.session.getGeoLocation(forPoint: worldPosition) { (location, altitude, error) in",
      "language" : "swift"
    },
    {
      "code" : "if geoTrackingStatus.state == .localized {\n    text += \"Accuracy: \\(geoTrackingStatus.accuracy.description)\"",
      "language" : "swift"
    },
    {
      "code" : "func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {",
      "language" : "swift"
    },
    {
      "code" : "let camera = MKMapCamera(lookingAtCenter: location.coordinate,\n                         fromDistance: CLLocationDistance(250),\n                         pitch: 0,\n                         heading: mapView.camera.heading)\nmapView.setCamera(camera, animated: false)",
      "language" : "swift"
    }
  ],
  "contentHash" : "3869a41fe1de1e19245b91e3e1450e163baba9e358983e44f4b1257853c8bedb",
  "crawledAt" : "2025-12-02T15:29:26Z",
  "id" : "045B0F12-76E9-4317-9FAB-CF111726B0E9",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nIn this sample app, the user marks spots on a map or camera feed to create a collection of anchors they view in augmented reality (AR). By rendering those anchors as virtual content in an AR view, the user can see a nearby anchor through the camera feed, move to its physical location, and continue to move to any subsequent anchors in the collection. If a virtual anchor that the user is moving toward isn’t visible in the camera feed, the user can refer to its pin in the map view and advance until the virtual anchor becomes visible.\n\nGeotracking configuration ([doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingConfiguration]) combines GPS, the device’s compass, and world-tracking features in AR to track specific geographic locations. By giving ARKit a latitude and longitude (and optionally, altitude), the sample app declares interest in a specific location on the map.\n\nDuring a geotracking session, ARKit marks this location in the form of a *location anchor* ([doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoAnchor]) and continually refines its position in the camera feed as the user moves about. ARKit provides the location anchor’s coordinates with respect to the scene, which allows the app to render virtual content at its real-world location or trigger other interactions.\n\nFor example, when the user approaches a location anchor, an app may reveal a virtual signpost that explains a historic event that occurred there. Or, to form a street route, an app could render a virtual anchor in a series of location anchors that connect.\n\n\n\n## Configure the sample code project\n\nThe sample app demonstrates geotracking coaching, which requires iOS 15. The Xcode project defines a deployment target of iOS 15, accordingly.\n\nGeotracking requires a device with A12 Bionic chip or later, and cellular (GPS) capability. Set the project’s run destination to a device. ARKit doesn’t support iOS Simulator.\n\n## Ensure device support\n\nAt the application entry point (see the sample project’s `AppDelegate.swift`), the sample app prevents running an unsupported configuration by checking whether the device supports geotracking.\n\nIf the device doesn’t support geotracking, the sample project stops. Optionally, an app can present an error message and continue the session at a limited capacity without geotracking.\n\n## Display an AR view and map view\n\nAs an AR app, the sample project renders location anchors using an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView]. To reinforce the correspondence between geographic locations and positions in the session’s local space, the sample project also displays a map view [doc:\/\/com.apple.documentation\/documentation\/MapKit\/MKMapView] that marks the anchors from a top-down perspective. The app displays both views simultaneously by using a stack view ([doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIStackView]) with the camera feed on top. See the sample’s `View Controller Scene` within the project’s `Main.storyboard`.\n\n## Check availability and run a session\n\nTo place location anchors with precision, geotracking requires a better understanding of the user’s geographic location than is possible with GPS alone. Based on a particular GPS coordinate, ARKit downloads batches of imagery that depict the physical environment in that area and assist the session with determining the user’s precise geographic location.\n\nThis *localization imagery* captures the view mostly from public streets and routes accessible by car. As a result, geotracking doesn’t support areas within the city that are gated or accessible only to pedestrians, as ARKit lacks localization imagery there.\n\nBecause localization imagery depicts specific regions on the map, geotracking only supports areas where Apple has collected localization imagery in advance. Before starting a session, the sample project checks whether geotracking supports the user’s location by calling [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingConfiguration\/checkAvailability(completionHandler:)].\n\nARKit requires a network connection to download localization imagery. The [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingConfiguration\/checkAvailability(completionHandler:)] function will return `false` if a network connection is unavailable. If geotracking is available, the sample project runs a session.\n\n## Coach the User for Geotracking Status\n\nTo begin a geotracking session, the framework undergoes several geotracking states. At any point, the session can require action from the user to progress to the next state. To instruct the user on what to do, the sample project uses a [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARCoachingOverlayView] with the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARCoachingOverlayView\/Goal-swift.enum\/geoTracking] goal.\n\n## Instruct the user based on geotracking state\n\nAfter the app localizes and begins a geotracking session, the sample app monitors the geotracking state and instructs the user by presenting text with a label.\n\nAs the user moves along a street, the framework continues to download localization imagery as needed to maintain a precise understanding of the user’s position in the world. If the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/StateReason-swift.enum\/geoDataNotLoaded] state reason occurs after the session localized, it may indicate a network issue arose. If this state reason persists for some time, an app may ask the user to check the internet connection.\n\nWhile the session runs, the status reason [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/StateReason-swift.enum\/notAvailableAtLocation] occurs if the user crosses into an area where ARKit lacks geotracking support. To enable the session to continue, the sample project presents text to guide the user back to a supported area.\n\n## Coach the user as the session runs\n\nA geotracking session maps geographic coordinates to ARKit’s world-tracking local space, which requires basic world-tracking support. If environmental circumstances impair the device’s world-tracking condition, the geotracking coaching overlay alerts the user and displays instructions to resolve the problem.\n\nFor example, if the user travels too quickly, the device’s camera feed may not contain sufficient features that ARKit requires to model the environment. In this case:\n\nThe sample app reacts by disabling the user interface until the user complies with the coaching.\n\nARKit dismisses the coaching overlay when the tracking status improves. To resume the user’s ability to interact with the app, the sample project reenables the user interface.\n\n## Create an anchor when the user taps the map\n\nThe sample project acquires the user’s geographic coordinate (`CLLocationCoordinate2D`) from the map view at the screen location where the user tapped.\n\nWith the user’s latitude and longitude, the sample project creates a location anchor.\n\nBecause the map view returns a 2D coordinate with no altitude, the sample calls [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoAnchor\/init(coordinate:altitude:)], which defaults the location anchor’s altitude to ground level.\n\nTo begin tracking the anchor, the sample project adds it to the session.\n\nThe sample project listens for the location anchor in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)] and visualizes it in AR by adding a placemark entity to the scene.\n\nTo establish visual correspondence in the map view, the sample project adds an [doc:\/\/com.apple.documentation\/documentation\/MapKit\/MKOverlay] that represents the anchor on the map.\n\n## Create an anchor when the user taps the ar view\n\nWhen the user taps the camera feed, the sample project casts a ray at the screen-tap location to determine its intersection with a real-world surface.\n\nThe raycast result’s translation describes the intersection’s position in ARKit’s local coordinate space. To convert that point to a geographic location, the sample project calls the session-provided utility [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession\/getGeoLocation(forPoint:completionHandler:)].\n\nThen, the sample project creates a location anchor with the result. Because the result includes altitude, the sample project calls the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoAnchor\/init(coordinate:altitude:)]] anchor initializer.\n\n## Assess geotracking accuracy\n\nTo ensure the best possible user experience, an app must monitor and react to the geotracking [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/accuracy-swift.property]. When possible, the sample project displays the accuracy as part of its state messaging to the user. The session populates accuracy in its [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/geoTrackingStatus] in state [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/State-swift.enum\/localized].\n\nAn app renders location anchors using an asset that’s less exact if geotracking is off by a small distance, such as when accuracy is [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/Accuracy-swift.enum\/low]. For example, the sample app renders a location anchor as a large ball several meters in the air rather than an arrow that rests its point on a real-world surface.\n\n## Center the map as the user moves\n\nThe sample project uses updates from [doc:\/\/com.apple.documentation\/documentation\/CoreLocation] to center the user in the map view. When the user moves around, Core Location notifies the delegate of any updates in geographic position. The sample project monitors this event by implementing the relevant callback.\n\nWhen the user’s position changes, the sample project pans the map to center the user.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-geographic-locations-in-ar\ncrawled: 2025-12-02T15:29:26Z\n---\n\n# Tracking geographic locations in AR\n\n**Sample Code**\n\nTrack specific geographic areas of interest and render them in an AR experience.\n\n## Overview\n\nIn this sample app, the user marks spots on a map or camera feed to create a collection of anchors they view in augmented reality (AR). By rendering those anchors as virtual content in an AR view, the user can see a nearby anchor through the camera feed, move to its physical location, and continue to move to any subsequent anchors in the collection. If a virtual anchor that the user is moving toward isn’t visible in the camera feed, the user can refer to its pin in the map view and advance until the virtual anchor becomes visible.\n\nGeotracking configuration ([doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingConfiguration]) combines GPS, the device’s compass, and world-tracking features in AR to track specific geographic locations. By giving ARKit a latitude and longitude (and optionally, altitude), the sample app declares interest in a specific location on the map.\n\nDuring a geotracking session, ARKit marks this location in the form of a *location anchor* ([doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoAnchor]) and continually refines its position in the camera feed as the user moves about. ARKit provides the location anchor’s coordinates with respect to the scene, which allows the app to render virtual content at its real-world location or trigger other interactions.\n\nFor example, when the user approaches a location anchor, an app may reveal a virtual signpost that explains a historic event that occurred there. Or, to form a street route, an app could render a virtual anchor in a series of location anchors that connect.\n\n\n\n\n\n## Configure the sample code project\n\nThe sample app demonstrates geotracking coaching, which requires iOS 15. The Xcode project defines a deployment target of iOS 15, accordingly.\n\nGeotracking requires a device with A12 Bionic chip or later, and cellular (GPS) capability. Set the project’s run destination to a device. ARKit doesn’t support iOS Simulator.\n\n## Ensure device support\n\nAt the application entry point (see the sample project’s `AppDelegate.swift`), the sample app prevents running an unsupported configuration by checking whether the device supports geotracking.\n\n```swift\nif !ARGeoTrackingConfiguration.isSupported {\n    let storyboard = UIStoryboard(name: \"Main\", bundle: nil)\n    window?.rootViewController = storyboard.instantiateViewController(withIdentifier: \"unsupportedDeviceMessage\")\n}\n```\n\nIf the device doesn’t support geotracking, the sample project stops. Optionally, an app can present an error message and continue the session at a limited capacity without geotracking.\n\n## Display an AR view and map view\n\nAs an AR app, the sample project renders location anchors using an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ARView]. To reinforce the correspondence between geographic locations and positions in the session’s local space, the sample project also displays a map view [doc:\/\/com.apple.documentation\/documentation\/MapKit\/MKMapView] that marks the anchors from a top-down perspective. The app displays both views simultaneously by using a stack view ([doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIStackView]) with the camera feed on top. See the sample’s `View Controller Scene` within the project’s `Main.storyboard`.\n\n## Check availability and run a session\n\nTo place location anchors with precision, geotracking requires a better understanding of the user’s geographic location than is possible with GPS alone. Based on a particular GPS coordinate, ARKit downloads batches of imagery that depict the physical environment in that area and assist the session with determining the user’s precise geographic location.\n\nThis *localization imagery* captures the view mostly from public streets and routes accessible by car. As a result, geotracking doesn’t support areas within the city that are gated or accessible only to pedestrians, as ARKit lacks localization imagery there.\n\nBecause localization imagery depicts specific regions on the map, geotracking only supports areas where Apple has collected localization imagery in advance. Before starting a session, the sample project checks whether geotracking supports the user’s location by calling [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingConfiguration\/checkAvailability(completionHandler:)].\n\n```swift\nARGeoTrackingConfiguration.checkAvailability { (available, error) in\n    if !available {\n        let errorDescription = error?.localizedDescription ?? \"\"\n        let recommendation = \"Please try again in an area where geotracking is supported.\"\n        let restartSession = UIAlertAction(title: \"Restart Session\", style: .default) { (_) in\n            self.restartSession()\n        }\n        self.alertUser(withTitle: \"Geotracking unavailable\",\n                       message: \"\\(errorDescription)\\n\\(recommendation)\",\n                       actions: [restartSession])\n    }\n}\n```\n\nARKit requires a network connection to download localization imagery. The [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingConfiguration\/checkAvailability(completionHandler:)] function will return `false` if a network connection is unavailable. If geotracking is available, the sample project runs a session.\n\n```swift\nlet geoTrackingConfig = ARGeoTrackingConfiguration()\ngeoTrackingConfig.planeDetection = [.horizontal]\narView.session.run(geoTrackingConfig, options: .removeExistingAnchors)\n```\n\n\n\n## Coach the User for Geotracking Status\n\nTo begin a geotracking session, the framework undergoes several geotracking states. At any point, the session can require action from the user to progress to the next state. To instruct the user on what to do, the sample project uses a [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARCoachingOverlayView] with the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARCoachingOverlayView\/Goal-swift.enum\/geoTracking] goal.\n\n```swift\nfunc setupCoachingOverlay() {\n    coachingOverlay.delegate = self\n    arView.addSubview(coachingOverlay)\n    coachingOverlay.goal = .geoTracking\n```\n\n## Instruct the user based on geotracking state\n\nAfter the app localizes and begins a geotracking session, the sample app monitors the geotracking state and instructs the user by presenting text with a label.\n\n```swift\nself.trackingStateLabel.text = text\n```\n\nAs the user moves along a street, the framework continues to download localization imagery as needed to maintain a precise understanding of the user’s position in the world. If the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/StateReason-swift.enum\/geoDataNotLoaded] state reason occurs after the session localized, it may indicate a network issue arose. If this state reason persists for some time, an app may ask the user to check the internet connection.\n\nWhile the session runs, the status reason [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/StateReason-swift.enum\/notAvailableAtLocation] occurs if the user crosses into an area where ARKit lacks geotracking support. To enable the session to continue, the sample project presents text to guide the user back to a supported area.\n\n```swift\ncase .notAvailableAtLocation: return \"Geotracking is unavailable here. Please return to your previous location to continue\"\n```\n\n## Coach the user as the session runs\n\nA geotracking session maps geographic coordinates to ARKit’s world-tracking local space, which requires basic world-tracking support. If environmental circumstances impair the device’s world-tracking condition, the geotracking coaching overlay alerts the user and displays instructions to resolve the problem.\n\nFor example, if the user travels too quickly, the device’s camera feed may not contain sufficient features that ARKit requires to model the environment. In this case:\n\n- The framework sets world-tracking state to [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARCamera\/TrackingState-swift.enum\/limited(_:)].\n- The geotracking session observes the world-tracking status change and sets the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus] reason to [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/StateReason-swift.enum\/worldTrackingUnstable].\n- Coaching overlay activates and displays the text: “Slow down”.\n\nThe sample app reacts by disabling the user interface until the user complies with the coaching.\n\n```swift\nfunc coachingOverlayViewWillActivate(_ coachingOverlayView: ARCoachingOverlayView) {\n    mapView.isUserInteractionEnabled = false\n    undoButton.isEnabled = false\n    hideUIForCoaching(true)\n}\n```\n\nARKit dismisses the coaching overlay when the tracking status improves. To resume the user’s ability to interact with the app, the sample project reenables the user interface.\n\n```swift\nfunc coachingOverlayViewDidDeactivate(_ coachingOverlayView: ARCoachingOverlayView) {\n    mapView.isUserInteractionEnabled = true\n    undoButton.isEnabled = true\n    hideUIForCoaching(false)\n}\n```\n\n## Create an anchor when the user taps the map\n\nThe sample project acquires the user’s geographic coordinate (`CLLocationCoordinate2D`) from the map view at the screen location where the user tapped.\n\n```swift\nfunc handleTapOnMapView(_ sender: UITapGestureRecognizer) {\n    let point = sender.location(in: mapView)\n    let location = mapView.convert(point, toCoordinateFrom: mapView)\n```\n\nWith the user’s latitude and longitude, the sample project creates a location anchor.\n\n```swift\ngeoAnchor = ARGeoAnchor(coordinate: location)\n```\n\nBecause the map view returns a 2D coordinate with no altitude, the sample calls [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoAnchor\/init(coordinate:altitude:)], which defaults the location anchor’s altitude to ground level.\n\nTo begin tracking the anchor, the sample project adds it to the session.\n\n```swift\narView.session.add(anchor: geoAnchor)\n```\n\nThe sample project listens for the location anchor in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)] and visualizes it in AR by adding a placemark entity to the scene.\n\n```swift\nfunc session(_ session: ARSession, didAdd anchors: [ARAnchor]) {\n    for geoAnchor in anchors.compactMap({ $0 as? ARGeoAnchor }) {\n        \/\/ Effect a spatial-based delay to avoid blocking the main thread.\n        DispatchQueue.main.asyncAfter(deadline: .now() + (distanceFromDevice(geoAnchor.coordinate) \/ 10)) {\n            \/\/ Add an AR placemark visualization for the geo anchor.\n            self.arView.scene.addAnchor(Entity.placemarkEntity(for: geoAnchor))\n```\n\nTo establish visual correspondence in the map view, the sample project adds an [doc:\/\/com.apple.documentation\/documentation\/MapKit\/MKOverlay] that represents the anchor on the map.\n\n```swift\nlet anchorIndicator = AnchorIndicator(center: geoAnchor.coordinate)\nself.mapView.addOverlay(anchorIndicator)\n```\n\n## Create an anchor when the user taps the ar view\n\nWhen the user taps the camera feed, the sample project casts a ray at the screen-tap location to determine its intersection with a real-world surface.\n\n```swift\nif let result = arView.raycast(from: point, allowing: .estimatedPlane, alignment: .any).first {\n```\n\nThe raycast result’s translation describes the intersection’s position in ARKit’s local coordinate space. To convert that point to a geographic location, the sample project calls the session-provided utility [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession\/getGeoLocation(forPoint:completionHandler:)].\n\n```swift\narView.session.getGeoLocation(forPoint: worldPosition) { (location, altitude, error) in\n```\n\nThen, the sample project creates a location anchor with the result. Because the result includes altitude, the sample project calls the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoAnchor\/init(coordinate:altitude:)]] anchor initializer.\n\n\n\n## Assess geotracking accuracy\n\nTo ensure the best possible user experience, an app must monitor and react to the geotracking [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/accuracy-swift.property]. When possible, the sample project displays the accuracy as part of its state messaging to the user. The session populates accuracy in its [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/geoTrackingStatus] in state [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/State-swift.enum\/localized].\n\n```swift\nif geoTrackingStatus.state == .localized {\n    text += \"Accuracy: \\(geoTrackingStatus.accuracy.description)\"\n```\n\nAn app renders location anchors using an asset that’s less exact if geotracking is off by a small distance, such as when accuracy is [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARGeoTrackingStatus\/Accuracy-swift.enum\/low]. For example, the sample app renders a location anchor as a large ball several meters in the air rather than an arrow that rests its point on a real-world surface.\n\n## Center the map as the user moves\n\nThe sample project uses updates from [doc:\/\/com.apple.documentation\/documentation\/CoreLocation] to center the user in the map view. When the user moves around, Core Location notifies the delegate of any updates in geographic position. The sample project monitors this event by implementing the relevant callback.\n\n```swift\nfunc locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n```\n\nWhen the user’s position changes, the sample project pans the map to center the user.\n\n```swift\nlet camera = MKMapCamera(lookingAtCenter: location.coordinate,\n                         fromDistance: CLLocationDistance(250),\n                         pitch: 0,\n                         heading: mapView.camera.heading)\nmapView.setCamera(camera, animated: false)\n```\n\n## Geotracking\n\n- **ARGeoAnchor**: An anchor that identifies a geographic location using latitude, longitude, and altitude data.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An anchor that identifies a geographic location using latitude, longitude, and altitude data.",
          "name" : "ARGeoAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARGeoAnchor"
        }
      ],
      "title" : "Geotracking"
    }
  ],
  "source" : "appleJSON",
  "title" : "Tracking geographic locations in AR",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-geographic-locations-in-ar"
}