{
  "abstract" : "Enable nearby devices to share an AR experience by using a host-guest multiuser strategy.",
  "codeExamples" : [
    {
      "code" : "session = MCSession(peer: myPeerID, securityIdentity: nil, encryptionPreference: .required)\nsession.delegate = self\n\nserviceAdvertiser = MCNearbyServiceAdvertiser(peer: myPeerID, discoveryInfo: nil, serviceType: MultipeerSession.serviceType)\nserviceAdvertiser.delegate = self\nserviceAdvertiser.startAdvertisingPeer()\n\nserviceBrowser = MCNearbyServiceBrowser(peer: myPeerID, serviceType: MultipeerSession.serviceType)\nserviceBrowser.delegate = self\nserviceBrowser.startBrowsingForPeers()",
      "language" : "swift"
    },
    {
      "code" : "public func browser(_ browser: MCNearbyServiceBrowser, foundPeer peerID: MCPeerID, withDiscoveryInfo info: [String: String]?) {\n    \/\/ Invite the new peer to the session.\n    browser.invitePeer(peerID, to: session, withContext: nil, timeout: 10)\n}",
      "language" : "swift"
    },
    {
      "code" : "func advertiser(_ advertiser: MCNearbyServiceAdvertiser,\n                didReceiveInvitationFromPeer peerID: MCPeerID,\n                withContext context: Data?,\n                invitationHandler: @escaping (Bool, MCSession?) -> Void) {\n    \/\/ Call handler to accept invitation and join the session.\n    invitationHandler(true, self.session)\n}",
      "language" : "swift"
    },
    {
      "code" : "switch frame.worldMappingStatus {\ncase .notAvailable, .limited:\n    sendMapButton.isEnabled = false\ncase .extending:\n    sendMapButton.isEnabled = !multipeerSession.connectedPeers.isEmpty\ncase .mapped:\n    sendMapButton.isEnabled = !multipeerSession.connectedPeers.isEmpty\n@unknown default:\n    sendMapButton.isEnabled = false\n}\nmappingStatusLabel.text = frame.worldMappingStatus.description",
      "language" : "swift"
    },
    {
      "code" : "sceneView.session.getCurrentWorldMap { worldMap, error in\n    guard let map = worldMap\n        else { print(\"Error: \\(error!.localizedDescription)\"); return }\n    guard let data = try? NSKeyedArchiver.archivedData(withRootObject: map, requiringSecureCoding: true)\n        else { fatalError(\"can't encode map\") }\n    self.multipeerSession.sendToAllPeers(data)\n}",
      "language" : "swift"
    },
    {
      "code" : "if let worldMap = try NSKeyedUnarchiver.unarchivedObject(ofClass: ARWorldMap.self, from: data) {\n    \/\/ Run the session with the received world map.\n    let configuration = ARWorldTrackingConfiguration()\n    configuration.planeDetection = .horizontal\n    configuration.initialWorldMap = worldMap\n    sceneView.session.run(configuration, options: [.resetTracking, .removeExistingAnchors])\n    \n    \/\/ Remember who provided the map for showing UI feedback.\n    mapProvider = peer\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Place an anchor for a virtual character. The model appears in renderer(_:didAdd:for:).\nlet anchor = ARAnchor(name: \"panda\", transform: hitTestResult.worldTransform)\nsceneView.session.add(anchor: anchor)\n\n\/\/ Send the anchor info to peers, so they can place the same content.\nguard let data = try? NSKeyedArchiver.archivedData(withRootObject: anchor, requiringSecureCoding: true)\n    else { fatalError(\"can't encode anchor\") }\nself.multipeerSession.sendToAllPeers(data)",
      "language" : "swift"
    },
    {
      "code" : "if let anchor = try NSKeyedUnarchiver.unarchivedObject(ofClass: ARAnchor.self, from: data) {\n    \/\/ Add anchor to the session, ARSCNView delegate adds visible content.\n    sceneView.session.add(anchor: anchor)\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "32857baf8daaec4ed1f4fa1dcc67a63621ea2cc245dd1cf3c38e622e38529922",
  "crawledAt" : "2025-12-02T15:29:15Z",
  "id" : "62E953EF-9658-4367-ADB3-C5E9A44559DE",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\n\n\nThis sample app demonstrates a simple shared AR experience for two or more iOS 12 devices. Before exploring the code, try building and running the app to familiarize yourself with the user experience it demonstrates:\n\nFollow the steps below to see how this app uses the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldMap] class to save and restore ARKit’s spatial mapping state, and the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity] framework to send world maps between nearby devices.\n\n## Getting started\n\nRequires Xcode 10.0, iOS 12.0 and two or more iOS devices with A9 or later processors.\n\n## Run the AR Session and Place AR Content\n\nThis app extends the basic workflow for building an ARKit app. (For details, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/tracking-and-visualizing-planes].) It defines an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] with plane detection enabled, then runs that configuration in the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession] attached to the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] that displays the AR experience.\n\nWhen [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITapGestureRecognizer] detects a tap on the screen, the `handleSceneTap` method uses ARKit hit-testing to find a 3D point on a real-world surface, then places an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] marking that position. When ARKit calls the delegate method [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didAdd:for:)], the app loads a 3D model for [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] to display at the anchor’s position.\n\n## Connect to peer devices\n\nThe sample `MultipeerSession` class provides a simple abstraction around the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity] features this app uses. After the main view controller creates a `MultipeerSession` instance (at app launch), it starts running an [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceAdvertiser] to broadcast the device’s ability to join multipeer sessions and an [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowser] to find other devices:\n\nWhen the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowser] finds another device, it calls the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowserDelegate\/browser(_:foundPeer:withDiscoveryInfo:)] delegate method. To invite that other device to a shared session, call the browser’s [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowser\/invitePeer(_:to:withContext:timeout:)] method:\n\nWhen the other device receives that invitation, [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceAdvertiser] calls the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceAdvertiserDelegate\/advertiser(_:didReceiveInvitationFromPeer:withContext:invitationHandler:)] delegate method. To accept the invitation, call the provided `invitationHandler`:\n\nIn a multipeer session, all participants are by definition equal peers; there is no explicit separation of devices into host and guest roles. However, you may wish to define such roles for your own AR experience. For example, a multiplayer game design might require a host role to arbitrate gameplay. If you need to separate peers by role, you can choose a way to do so that fits the design of your app. For example:\n\n## Capture and send the ar world map\n\nAn [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldMap] object contains a snapshot of all the spatial mapping information that ARKit uses to locate the user’s device in real-world space. Reliably sharing a map to another device requires two key steps: finding a good time to capture a map, and capturing and sending it.\n\nARKit provides a [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/worldMappingStatus-swift.property] value that indicates whether it’s currently a good time to capture a world map (or if it’s better to wait until ARKit has mapped more of the local environment). This app uses that value to provide visual feedback on its Send World Map button:\n\nWhen the user taps the Send World Map button, the app calls [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession\/getCurrentWorldMap(completionHandler:)] to capture the map from the running ARSession, then serializes it to a [doc:\/\/com.apple.documentation\/documentation\/Foundation\/Data] object with [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSKeyedArchiver] and sends it to other devices in the multipeer session:\n\n## Receive and relocalize to the shared map\n\nWhen a device receives data sent by another participant in the multipeer session, the [doc:\/\/com.apple.documentation\/documentation\/multipeerconnectivity\/mcsessiondelegate\/1406934-session]delegate method provides that data. To make use of it, the app uses [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSKeyedArchiver] to deserialize an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldMap] object, then creates and runs a new [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] using that map as the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration\/initialWorldMap]:\n\nARKit then attempts to *relocalize* to the new world map—that is, to reconcile the received spatial-mapping information with what it senses of the local environment. For best results:\n\n## Share AR content and user actions\n\nSharing the world map also shares all existing anchors. In this app, this means that as soon as a receiving device relocalizes to the world map, it shows all the 3D characters that were placed by the sending device before it captured and sent a world map. However, recording and transmitting a world map and relocalizing to a world map are time-consuming, bandwidth-intensive operations, so you should take those steps only once, when a new device joins a session.\n\nTo create an ongoing shared AR experience, where each user’s actions affect the AR scene visible to other users, after each device relocalizes to the same world map you should share only the information needed to recreate each user action. For example, in this app the user can tap to place a virtual 3D character in the scene. That character is static, so all that is needed to place the character on another participating device is the character’s position and orientation in world space.\n\nThis app communicates virtual character positions by sharing [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] objects between peers. When one user taps in the scene, the app creates an anchor and adds it to the local [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession], then serializes that [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] using [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSKeyedArchiver] and sends it to other devices in the multipeer session:\n\nWhen other peers receive data from the multipeer session, they test for whether that data contains an archived [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor]; if so, they decode it and add it to their session:\n\nThis is just one strategy for adding dynamic features to a shared AR experience—many other strategies are possible. Choose one that fits the user interaction, rendering, and networking requirements of your app. For example, a game where users throw projectiles in the AR world space might define custom data types with attributes like initial position and velocity, then use Swift’s [doc:\/\/com.apple.documentation\/documentation\/Swift\/Codable] protocols to serialize that information to a binary representation for sending over the network.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/creating-a-multiuser-ar-experience\ncrawled: 2025-12-02T15:29:15Z\n---\n\n# Creating a multiuser AR experience\n\n**Sample Code**\n\nEnable nearby devices to share an AR experience by using a host-guest multiuser strategy.\n\n## Overview\n\n\n\nThis sample app demonstrates a simple shared AR experience for two or more iOS 12 devices. Before exploring the code, try building and running the app to familiarize yourself with the user experience it demonstrates:\n\n1. Run the app on one device. You can look around the local environment, and tap to place a virtual 3D character on real-world surfaces. (Tap again to place multiple copies of the character.)\n2. Run the app on a second device. On both device screens, a message indicates that they have automatically joined a shared session.\n3. Tap the Send World Map button on one device. Make sure the other device is in an area that the first device visited before sending the map, or has a similar view of the surrounding environment.\n4. The other device displays a message indicating that it has received the map and is attempting to use it. When that process succeeds, both devices show virtual content at the same real-world positions, and tapping on either device places virtual content visible to both.\n\nFollow the steps below to see how this app uses the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldMap] class to save and restore ARKit’s spatial mapping state, and the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity] framework to send world maps between nearby devices.\n\n## Getting started\n\nRequires Xcode 10.0, iOS 12.0 and two or more iOS devices with A9 or later processors.\n\n## Run the AR Session and Place AR Content\n\nThis app extends the basic workflow for building an ARKit app. (For details, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/tracking-and-visualizing-planes].) It defines an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] with plane detection enabled, then runs that configuration in the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession] attached to the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] that displays the AR experience.\n\nWhen [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UITapGestureRecognizer] detects a tap on the screen, the `handleSceneTap` method uses ARKit hit-testing to find a 3D point on a real-world surface, then places an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] marking that position. When ARKit calls the delegate method [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNViewDelegate\/renderer(_:didAdd:for:)], the app loads a 3D model for [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSCNView] to display at the anchor’s position.\n\n## Connect to peer devices\n\nThe sample `MultipeerSession` class provides a simple abstraction around the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity] features this app uses. After the main view controller creates a `MultipeerSession` instance (at app launch), it starts running an [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceAdvertiser] to broadcast the device’s ability to join multipeer sessions and an [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowser] to find other devices:\n\n```swift\nsession = MCSession(peer: myPeerID, securityIdentity: nil, encryptionPreference: .required)\nsession.delegate = self\n\nserviceAdvertiser = MCNearbyServiceAdvertiser(peer: myPeerID, discoveryInfo: nil, serviceType: MultipeerSession.serviceType)\nserviceAdvertiser.delegate = self\nserviceAdvertiser.startAdvertisingPeer()\n\nserviceBrowser = MCNearbyServiceBrowser(peer: myPeerID, serviceType: MultipeerSession.serviceType)\nserviceBrowser.delegate = self\nserviceBrowser.startBrowsingForPeers()\n```\n\nWhen the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowser] finds another device, it calls the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowserDelegate\/browser(_:foundPeer:withDiscoveryInfo:)] delegate method. To invite that other device to a shared session, call the browser’s [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowser\/invitePeer(_:to:withContext:timeout:)] method:\n\n```swift\npublic func browser(_ browser: MCNearbyServiceBrowser, foundPeer peerID: MCPeerID, withDiscoveryInfo info: [String: String]?) {\n    \/\/ Invite the new peer to the session.\n    browser.invitePeer(peerID, to: session, withContext: nil, timeout: 10)\n}\n```\n\nWhen the other device receives that invitation, [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceAdvertiser] calls the [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceAdvertiserDelegate\/advertiser(_:didReceiveInvitationFromPeer:withContext:invitationHandler:)] delegate method. To accept the invitation, call the provided `invitationHandler`:\n\n```swift\nfunc advertiser(_ advertiser: MCNearbyServiceAdvertiser,\n                didReceiveInvitationFromPeer peerID: MCPeerID,\n                withContext context: Data?,\n                invitationHandler: @escaping (Bool, MCSession?) -> Void) {\n    \/\/ Call handler to accept invitation and join the session.\n    invitationHandler(true, self.session)\n}\n```\n\n\n\nIn a multipeer session, all participants are by definition equal peers; there is no explicit separation of devices into host and guest roles. However, you may wish to define such roles for your own AR experience. For example, a multiplayer game design might require a host role to arbitrate gameplay. If you need to separate peers by role, you can choose a way to do so that fits the design of your app. For example:\n\n- Have the user choose whether to act as a host or guest before starting a session. The host uses [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceAdvertiser] to broadcast availability, and guests use [doc:\/\/com.apple.documentation\/documentation\/MultipeerConnectivity\/MCNearbyServiceBrowser] to find a host to join.\n- Join a session as peers, then negotiate between peers to nominate a host. (This approach can be helpful for designs that need a host role but also allow peers to join or leave at any time.)\n\n## Capture and send the ar world map\n\nAn [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldMap] object contains a snapshot of all the spatial mapping information that ARKit uses to locate the user’s device in real-world space. Reliably sharing a map to another device requires two key steps: finding a good time to capture a map, and capturing and sending it.\n\nARKit provides a [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/worldMappingStatus-swift.property] value that indicates whether it’s currently a good time to capture a world map (or if it’s better to wait until ARKit has mapped more of the local environment). This app uses that value to provide visual feedback on its Send World Map button:\n\n```swift\nswitch frame.worldMappingStatus {\ncase .notAvailable, .limited:\n    sendMapButton.isEnabled = false\ncase .extending:\n    sendMapButton.isEnabled = !multipeerSession.connectedPeers.isEmpty\ncase .mapped:\n    sendMapButton.isEnabled = !multipeerSession.connectedPeers.isEmpty\n@unknown default:\n    sendMapButton.isEnabled = false\n}\nmappingStatusLabel.text = frame.worldMappingStatus.description\n```\n\nWhen the user taps the Send World Map button, the app calls [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession\/getCurrentWorldMap(completionHandler:)] to capture the map from the running ARSession, then serializes it to a [doc:\/\/com.apple.documentation\/documentation\/Foundation\/Data] object with [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSKeyedArchiver] and sends it to other devices in the multipeer session:\n\n```swift\nsceneView.session.getCurrentWorldMap { worldMap, error in\n    guard let map = worldMap\n        else { print(\"Error: \\(error!.localizedDescription)\"); return }\n    guard let data = try? NSKeyedArchiver.archivedData(withRootObject: map, requiringSecureCoding: true)\n        else { fatalError(\"can't encode map\") }\n    self.multipeerSession.sendToAllPeers(data)\n}\n```\n\n## Receive and relocalize to the shared map\n\nWhen a device receives data sent by another participant in the multipeer session, the [doc:\/\/com.apple.documentation\/documentation\/multipeerconnectivity\/mcsessiondelegate\/1406934-session]delegate method provides that data. To make use of it, the app uses [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSKeyedArchiver] to deserialize an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldMap] object, then creates and runs a new [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration] using that map as the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARWorldTrackingConfiguration\/initialWorldMap]:\n\n```swift\nif let worldMap = try NSKeyedUnarchiver.unarchivedObject(ofClass: ARWorldMap.self, from: data) {\n    \/\/ Run the session with the received world map.\n    let configuration = ARWorldTrackingConfiguration()\n    configuration.planeDetection = .horizontal\n    configuration.initialWorldMap = worldMap\n    sceneView.session.run(configuration, options: [.resetTracking, .removeExistingAnchors])\n    \n    \/\/ Remember who provided the map for showing UI feedback.\n    mapProvider = peer\n}\n```\n\nARKit then attempts to *relocalize* to the new world map—that is, to reconcile the received spatial-mapping information with what it senses of the local environment. For best results:\n\n1. Thoroughly scan the local environment on the sending device before sharing a world map.\n2. Place the receiving device next to the sending device, so that both see the same view of the environment.\n\n## Share AR content and user actions\n\nSharing the world map also shares all existing anchors. In this app, this means that as soon as a receiving device relocalizes to the world map, it shows all the 3D characters that were placed by the sending device before it captured and sent a world map. However, recording and transmitting a world map and relocalizing to a world map are time-consuming, bandwidth-intensive operations, so you should take those steps only once, when a new device joins a session.\n\nTo create an ongoing shared AR experience, where each user’s actions affect the AR scene visible to other users, after each device relocalizes to the same world map you should share only the information needed to recreate each user action. For example, in this app the user can tap to place a virtual 3D character in the scene. That character is static, so all that is needed to place the character on another participating device is the character’s position and orientation in world space.\n\nThis app communicates virtual character positions by sharing [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] objects between peers. When one user taps in the scene, the app creates an anchor and adds it to the local [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARSession], then serializes that [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor] using [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSKeyedArchiver] and sends it to other devices in the multipeer session:\n\n```swift\n\/\/ Place an anchor for a virtual character. The model appears in renderer(_:didAdd:for:).\nlet anchor = ARAnchor(name: \"panda\", transform: hitTestResult.worldTransform)\nsceneView.session.add(anchor: anchor)\n\n\/\/ Send the anchor info to peers, so they can place the same content.\nguard let data = try? NSKeyedArchiver.archivedData(withRootObject: anchor, requiringSecureCoding: true)\n    else { fatalError(\"can't encode anchor\") }\nself.multipeerSession.sendToAllPeers(data)\n```\n\nWhen other peers receive data from the multipeer session, they test for whether that data contains an archived [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARAnchor]; if so, they decode it and add it to their session:\n\n```swift\nif let anchor = try NSKeyedUnarchiver.unarchivedObject(ofClass: ARAnchor.self, from: data) {\n    \/\/ Add anchor to the session, ARSCNView delegate adds visible content.\n    sceneView.session.add(anchor: anchor)\n}\n```\n\nThis is just one strategy for adding dynamic features to a shared AR experience—many other strategies are possible. Choose one that fits the user interaction, rendering, and networking requirements of your app. For example, a game where users throw projectiles in the AR world space might define custom data types with attributes like initial position and velocity, then use Swift’s [doc:\/\/com.apple.documentation\/documentation\/Swift\/Codable] protocols to serialize that information to a binary representation for sending over the network.\n\n## Shared Experiences\n\n- **Streaming an AR experience**: Control an AR experience remotely by transferring sensor and user input over the network.\n- **Creating a collaborative session**: Enable nearby devices to share an AR experience by using a peer-to-peer multiuser strategy.\n- **ARParticipantAnchor**: An anchor for another user in multiuser augmented reality experiences.\n- **ARSession.CollaborationData**: An object that holds information that a user has collected about the physical environment.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Control an AR experience remotely by transferring sensor and user input over the network.",
          "name" : "Streaming an AR experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/streaming-an-ar-experience"
        },
        {
          "description" : "Enable nearby devices to share an AR experience by using a peer-to-peer multiuser strategy.",
          "name" : "Creating a collaborative session",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/creating-a-collaborative-session"
        },
        {
          "description" : "An anchor for another user in multiuser augmented reality experiences.",
          "name" : "ARParticipantAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARParticipantAnchor"
        },
        {
          "description" : "An object that holds information that a user has collected about the physical environment.",
          "name" : "ARSession.CollaborationData",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSession\/CollaborationData"
        }
      ],
      "title" : "Shared Experiences"
    }
  ],
  "source" : "appleJSON",
  "title" : "Creating a multiuser AR experience",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/creating-a-multiuser-ar-experience"
}