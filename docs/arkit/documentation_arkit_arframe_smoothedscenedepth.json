{
  "abstract" : "An average of distance measurements between a device’s rear camera and real-world objects that creates smoother visuals in an AR experience.",
  "codeExamples" : [

  ],
  "contentHash" : "0534c76ac6f6ac5802e3ff88d8fcad070c39a5b767b1a6c0320f00db7d8130ef",
  "crawledAt" : "2025-12-02T18:52:56Z",
  "declaration" : {
    "code" : "var smoothedSceneDepth: ARDepthData? { get }",
    "language" : "swift"
  },
  "id" : "604AD2B2-7954-4EAA-9923-A60176E6BB61",
  "kind" : "property",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Discussion\n\nThis property describes the distance between a device’s camera and objects or areas in the real world, including ARKit’s confidence in the estimated distance. This is similar to [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/sceneDepth] except that the framework smoothes the depth data over time to lessen its frame-to-frame delta.\n\nThis property is `nil` by default. Add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/smoothedSceneDepth] frame semantic to your configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] to instruct the framework to populate this value with [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData] captured by the LiDAR scanner.\n\nCall [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)] on your app’s configuration to support smoothed scene depth on select devices and configurations.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/smoothedSceneDepth\ncrawled: 2025-12-02T18:52:56Z\n---\n\n# smoothedSceneDepth\n\n**Instance Property**\n\nAn average of distance measurements between a device’s rear camera and real-world objects that creates smoother visuals in an AR experience.\n\n## Declaration\n\n```swift\nvar smoothedSceneDepth: ARDepthData? { get }\n```\n\n## Discussion\n\nThis property describes the distance between a device’s camera and objects or areas in the real world, including ARKit’s confidence in the estimated distance. This is similar to [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/sceneDepth] except that the framework smoothes the depth data over time to lessen its frame-to-frame delta.\n\nThis property is `nil` by default. Add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/smoothedSceneDepth] frame semantic to your configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] to instruct the framework to populate this value with [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARDepthData] captured by the LiDAR scanner.\n\nCall [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/supportsFrameSemantics(_:)] on your app’s configuration to support smoothed scene depth on select devices and configurations.\n\n## Accessing scene data\n\n- **lightEstimate**: An estimate of lighting conditions based on the camera image.\n- **displayTransform(for:viewportSize:)**: Returns an affine transform for converting between normalized image coordinates and a coordinate space appropriate for rendering the camera image onscreen.\n- **rawFeaturePoints**: The current intermediate results of the scene analysis ARKit uses to perform world tracking.\n- **capturedDepthData**: Depth data captured in front-camera experiences.\n- **capturedDepthDataTimestamp**: The time at which depth data for the frame (if any) was captured.\n- **sceneDepth**: Data on the distance between a device’s rear camera and real-world objects in an AR experience.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An estimate of lighting conditions based on the camera image.",
          "name" : "lightEstimate",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/lightEstimate"
        },
        {
          "description" : "Returns an affine transform for converting between normalized image coordinates and a coordinate space appropriate for rendering the camera image onscreen.",
          "name" : "displayTransform(for:viewportSize:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/displayTransform(for:viewportSize:)"
        },
        {
          "description" : "The current intermediate results of the scene analysis ARKit uses to perform world tracking.",
          "name" : "rawFeaturePoints",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/rawFeaturePoints"
        },
        {
          "description" : "Depth data captured in front-camera experiences.",
          "name" : "capturedDepthData",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/capturedDepthData"
        },
        {
          "description" : "The time at which depth data for the frame (if any) was captured.",
          "name" : "capturedDepthDataTimestamp",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/capturedDepthDataTimestamp"
        },
        {
          "description" : "Data on the distance between a device’s rear camera and real-world objects in an AR experience.",
          "name" : "sceneDepth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/sceneDepth"
        }
      ],
      "title" : "Accessing scene data"
    }
  ],
  "source" : "appleJSON",
  "title" : "smoothedSceneDepth",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/smoothedSceneDepth"
}