{
  "abstract" : "The screen position information of a body that ARKit recognizes in the camera image.",
  "codeExamples" : [

  ],
  "contentHash" : "dd8983ad249ba6e27957263578a522c57bedeb64ccb7e850ec2e57433a7bb9c4",
  "crawledAt" : "2025-12-02T18:53:01Z",
  "declaration" : {
    "code" : "var detectedBody: ARBody2D? { get }",
    "language" : "swift"
  },
  "id" : "99D36045-5D92-4751-A9F2-83050D4FDF7B",
  "kind" : "property",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Discussion\n\nTo enable 2D body detection, you add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/bodyDetection] frame semantic to your configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] property, or run your session with an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARBodyTrackingConfiguration], in which body detection is enabled by default.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/detectedBody\ncrawled: 2025-12-02T18:53:01Z\n---\n\n# detectedBody\n\n**Instance Property**\n\nThe screen position information of a body that ARKit recognizes in the camera image.\n\n## Declaration\n\n```swift\nvar detectedBody: ARBody2D? { get }\n```\n\n## Discussion\n\nTo enable 2D body detection, you add the [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/FrameSemantics-swift.struct\/bodyDetection] frame semantic to your configuration’s [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARConfiguration\/frameSemantics-swift.property] property, or run your session with an [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARBodyTrackingConfiguration], in which body detection is enabled by default.\n\n## Checking for people\n\n- **ARBody2D**: The screen-space representation of a person ARKit recognizes in the camera feed.\n- **segmentationBuffer**: A buffer that contains pixel information identifying the shape of objects from the camera feed that you use to occlude virtual content.\n- **estimatedDepthData**: A buffer that represents the estimated depth values from the camera feed that you use to occlude virtual content.\n- **ARFrame.SegmentationClass**: A categorization of a pixel that defines a type of content you use to occlude your app’s virtual content.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The screen-space representation of a person ARKit recognizes in the camera feed.",
          "name" : "ARBody2D",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARBody2D"
        },
        {
          "description" : "A buffer that contains pixel information identifying the shape of objects from the camera feed that you use to occlude virtual content.",
          "name" : "segmentationBuffer",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/segmentationBuffer"
        },
        {
          "description" : "A buffer that represents the estimated depth values from the camera feed that you use to occlude virtual content.",
          "name" : "estimatedDepthData",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/estimatedDepthData"
        },
        {
          "description" : "A categorization of a pixel that defines a type of content you use to occlude your app’s virtual content.",
          "name" : "ARFrame.SegmentationClass",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/SegmentationClass"
        }
      ],
      "title" : "Checking for people"
    }
  ],
  "source" : "appleJSON",
  "title" : "detectedBody",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/detectedBody"
}