{
  "abstract" : "Depth data captured in front-camera experiences.",
  "codeExamples" : [

  ],
  "contentHash" : "5b09792ae80d701b06802d20ee8abd2f6dc9a4b3cd821efe10a6945d7c7eb46b",
  "crawledAt" : "2025-12-02T18:52:54Z",
  "declaration" : {
    "code" : "var capturedDepthData: AVDepthData? { get }",
    "language" : "swift"
  },
  "id" : "27ADFBBA-6E54-44A3-8E21-D366C4B43561",
  "kind" : "property",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Discussion\n\nFrames vended by the session contain a depth map captured by the depth sensor in addition to the color pixel buffer (see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/capturedImage]) captured by the color camera. The depth-sensing camera provides data at a different frame rate than the color camera, so this property’s value can be `nil` if no depth data was captured at the same time as the current color image.\n\nThis depth data is available only in face-based experiences (see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceTrackingConfiguration]) using the device’s front TrueDepth camera. This property’s value is `nil` when running other AR configurations.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/capturedDepthData\ncrawled: 2025-12-02T18:52:54Z\n---\n\n# capturedDepthData\n\n**Instance Property**\n\nDepth data captured in front-camera experiences.\n\n## Declaration\n\n```swift\nvar capturedDepthData: AVDepthData? { get }\n```\n\n## Discussion\n\nFrames vended by the session contain a depth map captured by the depth sensor in addition to the color pixel buffer (see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFrame\/capturedImage]) captured by the color camera. The depth-sensing camera provides data at a different frame rate than the color camera, so this property’s value can be `nil` if no depth data was captured at the same time as the current color image.\n\nThis depth data is available only in face-based experiences (see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/ARFaceTrackingConfiguration]) using the device’s front TrueDepth camera. This property’s value is `nil` when running other AR configurations.\n\n## Accessing scene data\n\n- **lightEstimate**: An estimate of lighting conditions based on the camera image.\n- **displayTransform(for:viewportSize:)**: Returns an affine transform for converting between normalized image coordinates and a coordinate space appropriate for rendering the camera image onscreen.\n- **rawFeaturePoints**: The current intermediate results of the scene analysis ARKit uses to perform world tracking.\n- **capturedDepthDataTimestamp**: The time at which depth data for the frame (if any) was captured.\n- **sceneDepth**: Data on the distance between a device’s rear camera and real-world objects in an AR experience.\n- **smoothedSceneDepth**: An average of distance measurements between a device’s rear camera and real-world objects that creates smoother visuals in an AR experience.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An estimate of lighting conditions based on the camera image.",
          "name" : "lightEstimate",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/lightEstimate"
        },
        {
          "description" : "Returns an affine transform for converting between normalized image coordinates and a coordinate space appropriate for rendering the camera image onscreen.",
          "name" : "displayTransform(for:viewportSize:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/displayTransform(for:viewportSize:)"
        },
        {
          "description" : "The current intermediate results of the scene analysis ARKit uses to perform world tracking.",
          "name" : "rawFeaturePoints",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/rawFeaturePoints"
        },
        {
          "description" : "The time at which depth data for the frame (if any) was captured.",
          "name" : "capturedDepthDataTimestamp",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/capturedDepthDataTimestamp"
        },
        {
          "description" : "Data on the distance between a device’s rear camera and real-world objects in an AR experience.",
          "name" : "sceneDepth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/sceneDepth"
        },
        {
          "description" : "An average of distance measurements between a device’s rear camera and real-world objects that creates smoother visuals in an AR experience.",
          "name" : "smoothedSceneDepth",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/smoothedSceneDepth"
        }
      ],
      "title" : "Accessing scene data"
    }
  ],
  "source" : "appleJSON",
  "title" : "capturedDepthData",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARFrame\/capturedDepthData"
}