{
  "abstract" : "Use sound effects and environmental sound layers to create an engaging AR experience.",
  "codeExamples" : [
    {
      "code" : "\/\/ As an environmental sound layer, audio should play indefinitely\naudioSource.loops = true\n\/\/ Decode the audio from disk ahead of time to prevent a delay in playback\naudioSource.load()",
      "language" : "swift"
    },
    {
      "code" : "\/\/ As an environmental sound layer, audio should play indefinitely\naudioSource.loops = true\n\/\/ Decode the audio from disk ahead of time to prevent a delay in playback\naudioSource.load()",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create a player from the source and add it to `objectNode`\nobjectNode.addAudioPlayer(SCNAudioPlayer(source: audioSource))",
      "language" : "swift"
    }
  ],
  "contentHash" : "e793871db7d880a0b117d1f6ca6e5554fb274040bc7eeca2904ee55a8ef32ccf",
  "crawledAt" : "2025-12-02T15:47:22Z",
  "id" : "2E97F9A6-F75A-4864-9FCF-8D22C99FF683",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "ARKit",
  "overview" : "## Overview\n\nThis sample app uses SceneKit’s node-based audio API to associate environmental sounds with a virtual object that’s placed in the real world. Because audio is 3D positional in SceneKit by default, volume is automatically mixed based on the user’s distance from a node.\n\n## Getting started\n\n## Run an AR session and place virtual content\n\nBefore you can use audio, you need to set up a session and place the object from which to play sound. For simplicity, this sample runs a world tracking configuration and places a virtual object on the first horizontal plane that it detects. For more detail about this kind of session setup, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/tracking-and-visualizing-planes]. The object placement approach in this sample is similar to the one demonstrated in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/placing-objects-and-handling-3d-interaction]\n\n## Add 3D audio to the scene\n\nTo play audio from a given position in 3D space, create an [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNAudioSource] from an audio file. This sample loads the file from the bundle in `viewDidLoad`:\n\nThen, the audio source is configured and prepared:\n\nWhen you’re ready to play the sound, create an [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNAudioPlayer], passing it the audio source:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ARKit\/creating-an-immersive-ar-experience-with-audio\ncrawled: 2025-12-02T15:47:22Z\n---\n\n# Creating an immersive ar experience with audio\n\n**Sample Code**\n\nUse sound effects and environmental sound layers to create an engaging AR experience.\n\n## Overview\n\nThis sample app uses SceneKit’s node-based audio API to associate environmental sounds with a virtual object that’s placed in the real world. Because audio is 3D positional in SceneKit by default, volume is automatically mixed based on the user’s distance from a node.\n\n## Getting started\n\n- This sample code supports `Relocalization` and therefore, it requires ARKit 1.5 (iOS 11.3) or greater\n- ARKit is not available in the iOS Simulator\n- Building the sample requires Xcode 9.3 or later\n\n## Run an AR session and place virtual content\n\nBefore you can use audio, you need to set up a session and place the object from which to play sound. For simplicity, this sample runs a world tracking configuration and places a virtual object on the first horizontal plane that it detects. For more detail about this kind of session setup, see [doc:\/\/com.apple.arkit\/documentation\/ARKit\/tracking-and-visualizing-planes]. The object placement approach in this sample is similar to the one demonstrated in [doc:\/\/com.apple.arkit\/documentation\/ARKit\/placing-objects-and-handling-3d-interaction]\n\n## Add 3D audio to the scene\n\nTo play audio from a given position in 3D space, create an [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNAudioSource] from an audio file. This sample loads the file from the bundle in `viewDidLoad`:\n\n```swift\n\/\/ As an environmental sound layer, audio should play indefinitely\naudioSource.loops = true\n\/\/ Decode the audio from disk ahead of time to prevent a delay in playback\naudioSource.load()\n```\n\nThen, the audio source is configured and prepared:\n\n```swift\n\/\/ As an environmental sound layer, audio should play indefinitely\naudioSource.loops = true\n\/\/ Decode the audio from disk ahead of time to prevent a delay in playback\naudioSource.load()\n```\n\nWhen you’re ready to play the sound, create an [doc:\/\/com.apple.documentation\/documentation\/SceneKit\/SCNAudioPlayer], passing it the audio source:\n\n```swift\n\/\/ Create a player from the source and add it to `objectNode`\nobjectNode.addAudioPlayer(SCNAudioPlayer(source: audioSource))\n```\n\n\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "Creating an immersive ar experience with audio",
  "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/creating-an-immersive-ar-experience-with-audio"
}