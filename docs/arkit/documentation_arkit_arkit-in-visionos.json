{
  "abstract" : "Create immersive augmented reality experiences.",
  "codeExamples" : [

  ],
  "contentHash" : "6558d73af8ffe584db7afc5f11534cb5f8be266a3ec2239c2e00b0e8f28b9465",
  "crawledAt" : "2025-12-01T15:00:30Z",
  "id" : "AC7EF5CA-7E73-454C-B04B-4EEAAFFA3752",
  "kind" : "collection",
  "module" : "ARKit",
  "overview" : "## Overview\n\nARKit in visionOS offers a new set of sensing capabilities that you adopt individually in your app, using data providers to deliver updates asynchronously. The available capabilities include:\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/arkit\/arkit-in-visionos\ncrawled: 2025-12-01T15:00:30Z\n---\n\n# ARKit in visionOS\n\n**API Collection**\n\nCreate immersive augmented reality experiences.\n\n## Overview\n\nARKit in visionOS offers a new set of sensing capabilities that you adopt individually in your app, using data providers to deliver updates asynchronously. The available capabilities include:\n\n- **Plane detection.** Detect surfaces in a person’s surroundings and use them to anchor content.\n- **World tracking.** Determine the position and orientation of Apple Vision Pro relative to its surroundings, and add world anchors to place content.\n- **Hand tracking.** Use a person’s hand and finger positions as input for custom gestures and interactivity.\n- **Scene reconstruction.** Build a mesh of a person’s physical surroundings and incorporate it into your immersive spaces to support interactions.\n- **Image tracking.** Look for known images in a person’s surroundings and use them as anchor points for custom content.\n- **Object tracking.** Use 3D reference objects to find and track real-world objects in a person’s environment.\n- **Barcode detection.** Detect and scan QR codes and barcodes in a variety of formats in a person’s surroundings.\n- **Room tracking**. Use room anchors to identify specific rooms and implement per-room experiences.\n- **Light estimation.** Understand the lighting characteristics of a room to help improve the appearance of shiny or semi-reflective materials in your virtual content.\n- **Camera frames.** Access camera frames from a device in several formats.\n- **Accessory tracking.** Work with the real-time position and orientation of accessories that a person is using.\n\n\n\n## Setup\n\n- **Setting up access to ARKit data**: Check whether your app can use ARKit and respect people’s privacy.\n- **ARKitSession**: The main entry point for receiving data from ARKit.\n- **DataProvider**: A source of live data from ARKit.\n- **DataProviderState**: The possible states of a data provider.\n- **Anchor**: The identity, location, and orientation of an object in world space.\n- **TrackableAnchor**: An anchor that can gain and lose its tracking state over the course of a session.\n- **ARKitCoordinateSpace**: An object which represents an ARKit coordinate space.\n\n## Barcode detection\n\n- **BarcodeDetectionProvider**: An object that provides the real-time position of barcodes the framework detects in a person’s environment.\n- **BarcodeAnchor**: A barcode’s position in a person’s surroundings.\n\n## Camera sampling\n\n- **CameraFrameProvider**: An object that provides camera streams.\n- **CameraFrame**: The representation of a camera frame.\n- **CameraVideoFormat**: A structure that represents a camera video format.\n\n## Rendering\n\n- **StereoPropertiesProvider**: The StereoPropertiesProvider serves the latest viewpoint properties on the device.\n- **ViewpointProperties**: The ViewpointProperties is a record of render camera transforms at some particular time.\n\n## Camera region\n\n- **CameraRegionProvider**: A camera region provider. An enterprise license is required to use the CameraRegionProvider. The provider will not deliver any data without it. The app must include the following entitlement: `com.apple.developer.arkit.camera-region.allow`\n- **CameraRegionAnchor**: Represents a region in space to capture a camera stream of.\n\n## Plane detection\n\n- **Placing content on detected planes**: Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.\n- **PlaneDetectionProvider**: A source of live data about planes in a person’s surroundings.\n- **PlaneAnchor**: An anchor that represents horizontal and vertical planes.\n\n## World tracking\n\n- **Tracking specific points in world space**: Retrieve the position and orientation of anchors your app stores in ARKit.\n- **WorldTrackingProvider**: A source of live data about the device pose and anchors in a person’s surroundings.\n- **WorldAnchor**: A fixed location in a person’s surroundings.\n- **DeviceAnchor**: The position and orientation of Apple Vision Pro.\n\n## Hand tracking\n\n- **Happy Beam**: Leverage a Full Space to create a fun game using ARKit.\n- **HandTrackingProvider**: A source of live data about the position of a person’s hands and hand joints.\n- **HandAnchor**: A hand’s position in a person’s surroundings.\n- **HandSkeleton**: A collection of joints in a hand.\n\n## Scene reconstruction\n\n- **Incorporating real-world surroundings in an immersive experience**: Create an immersive experience by making your app’s content respond to the local shape of the world.\n- **SceneReconstructionProvider**: A source of live data about the shape of a person’s surroundings.\n- **MeshAnchor**: A volume of space that contains a mesh of a person’s surroundings.\n\n## Image tracking\n\n- **Tracking and altering images**: Create images from rectangular shapes found in the user’s environment, and augment their appearance.\n- **Detecting Images in an AR Experience**: React to known 2D images in the user’s environment, and use their positions to place AR content.\n- **Tracking preregistered images in 3D space**: Place content based on the current position of a known image in a person’s surroundings.\n- **ImageTrackingProvider**: A source of live data about a 2D image’s position in a person’s surroundings.\n- **ImageAnchor**: A 2D image’s position in a person’s surroundings.\n- **ReferenceImage**: A 2D image the system uses as a reference to find the same image in a person’s surroundings.\n\n## Geometry\n\n- **GeometryElement**: A container for vertex indices of lines or triangles.\n- **GeometrySource**: A container for geometrical vector data.\n\n## Lighting estimation\n\n- **EnvironmentLightEstimationProvider**: A source of live data about lighting information in the environment.\n- **EnvironmentProbeAnchor**: An environment probe in the world.\n\n## Object tracking\n\n- **ObjectTrackingProvider**: A source of real-time position of reference objects in a person’s environment.\n- **ObjectAnchor**: A reference object ARKit is tracking.\n- **Exploring object tracking with ARKit**: Find and track real-world objects in visionOS using reference objects trained with Create ML.\n- **Implementing object tracking in your visionOS app**: Create engaging interactions by training models to recognize and track real-world objects in your app.\n\n## Accessory tracking\n\n- **AccessoryTrackingProvider**: Provides the real time position of accessories in the user’s environment.\n- **Accessory**: Represents an accessory to be tracked.\n- **AccessoryAnchor**: Represents a tracked accessory.\n- **Tracking accessories in volumetric windows**: Translate the position and velocity of tracked handheld accessories to throw virtual balls at a stack of cans.\n- **Tracking a handheld accessory as a virtual sculpting tool**: Use a tracked accessory with Apple Vision Pro to create a virtual sculpture.\n\n## Room tracking\n\n- **RoomTrackingProvider**: A source of real-time information about the room that a person is currently in.\n- **RoomAnchor**: The representation of a room ARKit is currently tracking.\n- **SurfaceClassification**: A value describing the classification of a surface.\n- **Building local experiences with room tracking**: Use room tracking in visionOS to provide custom interactions with physical spaces.\n\n## Shared coordinate spaces\n\n- **SharedCoordinateSpaceProvider**: Provides ability to establish a shared coordinate space among multiple participants.\n\n## visionOS\n\n- **Setting up access to ARKit data**: Check whether your app can use ARKit and respect people’s privacy.\n- **ARKitSession**: The main entry point for receiving data from ARKit.\n- **DataProvider**: A source of live data from ARKit.\n- **Anchor**: The identity, location, and orientation of an object in world space.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Check whether your app can use ARKit and respect people’s privacy.",
          "name" : "Setting up access to ARKit data",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/setting-up-access-to-arkit-data"
        },
        {
          "description" : "The main entry point for receiving data from ARKit.",
          "name" : "ARKitSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARKitSession"
        },
        {
          "description" : "A source of live data from ARKit.",
          "name" : "DataProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/DataProvider"
        },
        {
          "description" : "The possible states of a data provider.",
          "name" : "DataProviderState",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/DataProviderState"
        },
        {
          "description" : "The identity, location, and orientation of an object in world space.",
          "name" : "Anchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/Anchor"
        },
        {
          "description" : "An anchor that can gain and lose its tracking state over the course of a session.",
          "name" : "TrackableAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/TrackableAnchor"
        },
        {
          "description" : "An object which represents an ARKit coordinate space.",
          "name" : "ARKitCoordinateSpace",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARKitCoordinateSpace"
        }
      ],
      "title" : "Setup"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that provides the real-time position of barcodes the framework detects in a person’s environment.",
          "name" : "BarcodeDetectionProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/BarcodeDetectionProvider"
        },
        {
          "description" : "A barcode’s position in a person’s surroundings.",
          "name" : "BarcodeAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/BarcodeAnchor"
        }
      ],
      "title" : "Barcode detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that provides camera streams.",
          "name" : "CameraFrameProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/CameraFrameProvider"
        },
        {
          "description" : "The representation of a camera frame.",
          "name" : "CameraFrame",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/CameraFrame"
        },
        {
          "description" : "A structure that represents a camera video format.",
          "name" : "CameraVideoFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/CameraVideoFormat"
        }
      ],
      "title" : "Camera sampling"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The StereoPropertiesProvider serves the latest viewpoint properties on the device.",
          "name" : "StereoPropertiesProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/StereoPropertiesProvider"
        },
        {
          "description" : "The ViewpointProperties is a record of render camera transforms at some particular time.",
          "name" : "ViewpointProperties",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ViewpointProperties"
        }
      ],
      "title" : "Rendering"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A camera region provider. An enterprise license is required to use the CameraRegionProvider. The provider will not deliver any data without it. The app must include the following entitlement: `com.apple.developer.arkit.camera-region.allow`",
          "name" : "CameraRegionProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/CameraRegionProvider"
        },
        {
          "description" : "Represents a region in space to capture a camera stream of.",
          "name" : "CameraRegionAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/CameraRegionAnchor"
        }
      ],
      "title" : "Camera region"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.",
          "name" : "Placing content on detected planes",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/placing-content-on-detected-planes"
        },
        {
          "description" : "A source of live data about planes in a person’s surroundings.",
          "name" : "PlaneDetectionProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/PlaneDetectionProvider"
        },
        {
          "description" : "An anchor that represents horizontal and vertical planes.",
          "name" : "PlaneAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/PlaneAnchor"
        }
      ],
      "title" : "Plane detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Retrieve the position and orientation of anchors your app stores in ARKit.",
          "name" : "Tracking specific points in world space",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/tracking-points-in-world-space"
        },
        {
          "description" : "A source of live data about the device pose and anchors in a person’s surroundings.",
          "name" : "WorldTrackingProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/WorldTrackingProvider"
        },
        {
          "description" : "A fixed location in a person’s surroundings.",
          "name" : "WorldAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/WorldAnchor"
        },
        {
          "description" : "The position and orientation of Apple Vision Pro.",
          "name" : "DeviceAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/DeviceAnchor"
        }
      ],
      "title" : "World tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Leverage a Full Space to create a fun game using ARKit.",
          "name" : "Happy Beam",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/happybeam"
        },
        {
          "description" : "A source of live data about the position of a person’s hands and hand joints.",
          "name" : "HandTrackingProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/HandTrackingProvider"
        },
        {
          "description" : "A hand’s position in a person’s surroundings.",
          "name" : "HandAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/HandAnchor"
        },
        {
          "description" : "A collection of joints in a hand.",
          "name" : "HandSkeleton",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/HandSkeleton"
        }
      ],
      "title" : "Hand tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create an immersive experience by making your app’s content respond to the local shape of the world.",
          "name" : "Incorporating real-world surroundings in an immersive experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/incorporating-real-world-surroundings-in-an-immersive-experience"
        },
        {
          "description" : "A source of live data about the shape of a person’s surroundings.",
          "name" : "SceneReconstructionProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/SceneReconstructionProvider"
        },
        {
          "description" : "A volume of space that contains a mesh of a person’s surroundings.",
          "name" : "MeshAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/MeshAnchor"
        }
      ],
      "title" : "Scene reconstruction"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create images from rectangular shapes found in the user’s environment, and augment their appearance.",
          "name" : "Tracking and altering images",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-and-altering-images"
        },
        {
          "description" : "React to known 2D images in the user’s environment, and use their positions to place AR content.",
          "name" : "Detecting Images in an AR Experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/detecting-images-in-an-ar-experience"
        },
        {
          "description" : "Place content based on the current position of a known image in a person’s surroundings.",
          "name" : "Tracking preregistered images in 3D space",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/tracking-images-in-3d-space"
        },
        {
          "description" : "A source of live data about a 2D image’s position in a person’s surroundings.",
          "name" : "ImageTrackingProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ImageTrackingProvider"
        },
        {
          "description" : "A 2D image’s position in a person’s surroundings.",
          "name" : "ImageAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ImageAnchor"
        },
        {
          "description" : "A 2D image the system uses as a reference to find the same image in a person’s surroundings.",
          "name" : "ReferenceImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ReferenceImage"
        }
      ],
      "title" : "Image tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A container for vertex indices of lines or triangles.",
          "name" : "GeometryElement",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/GeometryElement"
        },
        {
          "description" : "A container for geometrical vector data.",
          "name" : "GeometrySource",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/GeometrySource"
        }
      ],
      "title" : "Geometry"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A source of live data about lighting information in the environment.",
          "name" : "EnvironmentLightEstimationProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/EnvironmentLightEstimationProvider"
        },
        {
          "description" : "An environment probe in the world.",
          "name" : "EnvironmentProbeAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/EnvironmentProbeAnchor"
        }
      ],
      "title" : "Lighting estimation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A source of real-time position of reference objects in a person’s environment.",
          "name" : "ObjectTrackingProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ObjectTrackingProvider"
        },
        {
          "description" : "A reference object ARKit is tracking.",
          "name" : "ObjectAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ObjectAnchor"
        },
        {
          "description" : "Find and track real-world objects in visionOS using reference objects trained with Create ML.",
          "name" : "Exploring object tracking with ARKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/exploring_object_tracking_with_arkit"
        },
        {
          "description" : "Create engaging interactions by training models to recognize and track real-world objects in your app.",
          "name" : "Implementing object tracking in your visionOS app",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/implementing-object-tracking-in-your-visionOS-app"
        }
      ],
      "title" : "Object tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Provides the real time position of accessories in the user’s environment.",
          "name" : "AccessoryTrackingProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/AccessoryTrackingProvider"
        },
        {
          "description" : "Represents an accessory to be tracked.",
          "name" : "Accessory",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/Accessory"
        },
        {
          "description" : "Represents a tracked accessory.",
          "name" : "AccessoryAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/AccessoryAnchor"
        },
        {
          "description" : "Translate the position and velocity of tracked handheld accessories to throw virtual balls at a stack of cans.",
          "name" : "Tracking accessories in volumetric windows",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-accessories-in-volumetric-windows"
        },
        {
          "description" : "Use a tracked accessory with Apple Vision Pro to create a virtual sculpture.",
          "name" : "Tracking a handheld accessory as a virtual sculpting tool",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/tracking-a-handheld-accessory-as-a-virtual-sculpting-tool"
        }
      ],
      "title" : "Accessory tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A source of real-time information about the room that a person is currently in.",
          "name" : "RoomTrackingProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/RoomTrackingProvider"
        },
        {
          "description" : "The representation of a room ARKit is currently tracking.",
          "name" : "RoomAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/RoomAnchor"
        },
        {
          "description" : "A value describing the classification of a surface.",
          "name" : "SurfaceClassification",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/SurfaceClassification"
        },
        {
          "description" : "Use room tracking in visionOS to provide custom interactions with physical spaces.",
          "name" : "Building local experiences with room tracking",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/building-local-experiences-with-room-tracking"
        }
      ],
      "title" : "Room tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Provides ability to establish a shared coordinate space among multiple participants.",
          "name" : "SharedCoordinateSpaceProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/SharedCoordinateSpaceProvider"
        }
      ],
      "title" : "Shared coordinate spaces"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Check whether your app can use ARKit and respect people’s privacy.",
          "name" : "Setting up access to ARKit data",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/setting-up-access-to-arkit-data"
        },
        {
          "description" : "The main entry point for receiving data from ARKit.",
          "name" : "ARKitSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARKitSession"
        },
        {
          "description" : "A source of live data from ARKit.",
          "name" : "DataProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/DataProvider"
        },
        {
          "description" : "The identity, location, and orientation of an object in world space.",
          "name" : "Anchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/Anchor"
        }
      ],
      "title" : "visionOS"
    }
  ],
  "source" : "appleJSON",
  "title" : "ARKit in visionOS",
  "url" : "https:\/\/developer.apple.com\/documentation\/arkit\/arkit-in-visionos"
}