{
  "abstract" : "An object that finds items in images that people can interact with, such as subjects, text, and QR codes.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "d3475e167ced74b61612216e8d7b83b8c872e6a8ac1ddae329047da23d8ca0c5",
  "crawledAt" : "2025-12-03T04:25:51Z",
  "declaration" : {
    "code" : "final class ImageAnalyzer",
    "language" : "swift"
  },
  "id" : "D8F78028-99A7-4F42-BA7E-21003309041C",
  "kind" : "class",
  "language" : "swift",
  "module" : "VisionKit",
  "overview" : "## Overview\n\nTo use an `ImageAnalyzer` object, first create an [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer\/Configuration] object, and specify the types of items you want to find in an image. Then pass the image you want to analyze and the configuration object to an `ImageAnalyzer` object using the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:configuration:)] or similar method. This method returns an [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysis] object that contains all the data VisionKit needs to implement the Live Text interface.\n\nNext, show the Live Text interface. For iOS apps, set the interaction object of the view that contains the image to an instance of [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction] and set its [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/analysis] property to the `ImageAnalysis` object. To enable interactions with the image, set the interaction object’s [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/preferredInteractionTypes] property. To customize the Live Text interface, set the `ImageAnalysisInteraction `object’s [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/delegate] property and implement the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate] protocol methods.\n\nFor macOS apps, add an `ImageAnalysisOverlayView` object above the view that contains the image, and set its `analysis` property. To enable interactions with the image, set the overlay view’s `preferredInteractionTypes` property. Set the `ImageAnalysisOverlayView `object’s `delegate` property and implement the `ImageAnalysisOverlayViewDelegate` protocol methods.\n\nBy default, the Live Text interface starts immediately when you show the view.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\ncrawled: 2025-12-03T04:25:51Z\n---\n\n# ImageAnalyzer\n\n**Class**\n\nAn object that finds items in images that people can interact with, such as subjects, text, and QR codes.\n\n## Declaration\n\n```swift\nfinal class ImageAnalyzer\n```\n\n## Overview\n\nTo use an `ImageAnalyzer` object, first create an [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer\/Configuration] object, and specify the types of items you want to find in an image. Then pass the image you want to analyze and the configuration object to an `ImageAnalyzer` object using the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:configuration:)] or similar method. This method returns an [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysis] object that contains all the data VisionKit needs to implement the Live Text interface.\n\nNext, show the Live Text interface. For iOS apps, set the interaction object of the view that contains the image to an instance of [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction] and set its [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/analysis] property to the `ImageAnalysis` object. To enable interactions with the image, set the interaction object’s [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/preferredInteractionTypes] property. To customize the Live Text interface, set the `ImageAnalysisInteraction `object’s [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/delegate] property and implement the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate] protocol methods.\n\nFor macOS apps, add an `ImageAnalysisOverlayView` object above the view that contains the image, and set its `analysis` property. To enable interactions with the image, set the overlay view’s `preferredInteractionTypes` property. Set the `ImageAnalysisOverlayView `object’s `delegate` property and implement the `ImageAnalysisOverlayViewDelegate` protocol methods.\n\nBy default, the Live Text interface starts immediately when you show the view.\n\n## Handling availability\n\n- **isSupported**: A Boolean value that indicates whether the device supports image analysis.\n- **supportedTextRecognitionLanguages**: The identifiers for the languages that the image analyzer recognizes.\n\n## Creating image analyzers\n\n- **init()**: Creates an image analyzer that identifies subjects, text, and machine-readable codes in images.\n\n## Configuring image analyzers\n\n- **ImageAnalyzer.Configuration**: A configuration that specifies the types of items and locales that the image analyzer recognizes.\n\n## Finding items in images\n\n- **analyze(_:configuration:)**: Returns the data for providing a Live Text interaction with an image.\n- **analyze(_:orientation:configuration:)**: Returns the data for providing a Live Text interaction with an image in the specified orientation.\n- **analyze(_:orientation:configuration:)**: Returns the data for providing a Live Text interaction with a Core Graphics image in the specified orientation.\n- **analyze(_:orientation:configuration:)**: Returns the data for providing a Live Text interaction with a pixel buffer image in the specified orientation.\n- **analyze(_:orientation:configuration:)**: Returns the data for providing a Live Text interaction with a bitmap image in the specified orientation.\n- **analyze(_:orientation:configuration:)**: Returns the data for providing a Live Text interaction with an image in the specified orientation.\n- **analyze(imageAt:orientation:configuration:)**: Returns the data for providing a Live Text interaction with an image at a URL and in the specified orientation.\n\n## Structures\n\n- **ImageAnalyzer.AnalysisTypes**: The types of items that an image analyzer looks for in an image.\n\n## Content recognition and interaction in images\n\n- **Enabling Live Text interactions with images**: Add a Live Text interface that enables users to perform actions with text and QR codes that appear in images.\n- **ImageAnalysis**: An object that represents the results of analyzing an image, and provides the input for the Live Text interface object.\n- **ImageAnalysisInteraction**: An interface that enables people to interact with recognized text, barcodes, and other objects in an image.\n- **ImageAnalysisInteractionDelegate**: A delegate that handles image-analysis and user-interaction callbacks for an interaction object.\n- **ImageAnalysisOverlayView**: A view that enables people to interact with recognized text, barcodes, and other objects in an image.\n- **ImageAnalysisOverlayViewDelegate**: A delegate that handles image-analysis and user-interaction callbacks for an overlay view.\n- **CameraRegionView**: This view displays a stabilized region of interest within a person’s view and provides passthrough camera feed for that selected region.\n\n## Conforms To\n\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the device supports image analysis.",
          "name" : "isSupported",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/isSupported"
        },
        {
          "description" : "The identifiers for the languages that the image analyzer recognizes.",
          "name" : "supportedTextRecognitionLanguages",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/supportedTextRecognitionLanguages"
        }
      ],
      "title" : "Handling availability"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an image analyzer that identifies subjects, text, and machine-readable codes in images.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/init()"
        }
      ],
      "title" : "Creating image analyzers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A configuration that specifies the types of items and locales that the image analyzer recognizes.",
          "name" : "ImageAnalyzer.Configuration",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/Configuration"
        }
      ],
      "title" : "Configuring image analyzers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Returns the data for providing a Live Text interaction with an image.",
          "name" : "analyze(_:configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:configuration:)"
        },
        {
          "description" : "Returns the data for providing a Live Text interaction with an image in the specified orientation.",
          "name" : "analyze(_:orientation:configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:orientation:configuration:)-5bs2w"
        },
        {
          "description" : "Returns the data for providing a Live Text interaction with a Core Graphics image in the specified orientation.",
          "name" : "analyze(_:orientation:configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:orientation:configuration:)-ufrs"
        },
        {
          "description" : "Returns the data for providing a Live Text interaction with a pixel buffer image in the specified orientation.",
          "name" : "analyze(_:orientation:configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:orientation:configuration:)-2ezqw"
        },
        {
          "description" : "Returns the data for providing a Live Text interaction with a bitmap image in the specified orientation.",
          "name" : "analyze(_:orientation:configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:orientation:configuration:)-4h43g"
        },
        {
          "description" : "Returns the data for providing a Live Text interaction with an image in the specified orientation.",
          "name" : "analyze(_:orientation:configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:orientation:configuration:)-fcjz"
        },
        {
          "description" : "Returns the data for providing a Live Text interaction with an image at a URL and in the specified orientation.",
          "name" : "analyze(imageAt:orientation:configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/analyze(imageAt:orientation:configuration:)"
        }
      ],
      "title" : "Finding items in images"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The types of items that an image analyzer looks for in an image.",
          "name" : "ImageAnalyzer.AnalysisTypes",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer\/AnalysisTypes"
        }
      ],
      "title" : "Structures"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Add a Live Text interface that enables users to perform actions with text and QR codes that appear in images.",
          "name" : "Enabling Live Text interactions with images",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/enabling-live-text-interactions-with-images"
        },
        {
          "description" : "An object that represents the results of analyzing an image, and provides the input for the Live Text interface object.",
          "name" : "ImageAnalysis",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysis"
        },
        {
          "description" : "An interface that enables people to interact with recognized text, barcodes, and other objects in an image.",
          "name" : "ImageAnalysisInteraction",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction"
        },
        {
          "description" : "A delegate that handles image-analysis and user-interaction callbacks for an interaction object.",
          "name" : "ImageAnalysisInteractionDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate"
        },
        {
          "description" : "A view that enables people to interact with recognized text, barcodes, and other objects in an image.",
          "name" : "ImageAnalysisOverlayView",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisOverlayView"
        },
        {
          "description" : "A delegate that handles image-analysis and user-interaction callbacks for an overlay view.",
          "name" : "ImageAnalysisOverlayViewDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisOverlayViewDelegate"
        },
        {
          "description" : "This view displays a stabilized region of interest within a person’s view and provides passthrough camera feed for that selected region.",
          "name" : "CameraRegionView",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/CameraRegionView"
        }
      ],
      "title" : "Content recognition and interaction in images"
    }
  ],
  "source" : "appleJSON",
  "title" : "ImageAnalyzer",
  "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer"
}