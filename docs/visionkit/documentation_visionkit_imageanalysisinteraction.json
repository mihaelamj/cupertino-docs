{
  "abstract" : "An interface that enables people to interact with recognized text, barcodes, and other objects in an image.",
  "codeExamples" : [
    {
      "code" : "interaction.preferredInteractionTypes = [.textSelection, .imageSubject]",
      "language" : "swift"
    }
  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol",
    "Sendable",
    "SendableMetatype",
    "UIInteraction"
  ],
  "contentHash" : "f1ca95c06eb73d2367eb82bdbe2813a692825ce9923e7e700b3a49aae97c6598",
  "crawledAt" : "2025-12-03T04:07:04Z",
  "declaration" : {
    "code" : "@MainActor @objc final class ImageAnalysisInteraction",
    "language" : "swift"
  },
  "id" : "CFEEBE4A-A7BD-4A06-98D0-D58ECB564A72",
  "kind" : "class",
  "language" : "swift",
  "module" : "VisionKit",
  "overview" : "## Overview\n\nThis class enables people to interact with specific content types ([doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes]) that the framework identifies in an image. For example:\n\n## Configure the interface and begin interaction\n\nThis class conforms to the [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIInteraction] protocol. To connect the interface with an image that your app displays, call [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIView\/addInteraction(_:)] on your app’s image view and pass in a new instance of this class.\n\nChoose the items that the framework recognizes in an image by configuring the  [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/preferredInteractionTypes] property. To recognize all types of content, specify the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes\/automatic] option, or choose a combination of types by assigning an array:\n\nTo begin interaction, call one of the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer] class’s `analyze` methods, such as [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:configuration:)] and set the result onto this class’s [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisOverlayView\/analysis] property.\n\nYou can take more control over the interaction or provide details about your app’s image view by implementing a delegate ([doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate]) and assigning it to the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/delegate] property. If your image view isn’t an instance of [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImageView], your app needs to define the interactive area within the image by implementing the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate\/contentsRect(for:)] method.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\ncrawled: 2025-12-03T04:07:04Z\n---\n\n# ImageAnalysisInteraction\n\n**Class**\n\nAn interface that enables people to interact with recognized text, barcodes, and other objects in an image.\n\n## Declaration\n\n```swift\n@MainActor @objc final class ImageAnalysisInteraction\n```\n\n## Overview\n\nThis class enables people to interact with specific content types ([doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes]) that the framework identifies in an image. For example:\n\n- The Live Text interface enables them to select any text present in the image ([doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes\/textSelection]), or invoke a URL ([doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes\/dataDetectors]). The text selection UI offers framework-standard buttons for copying selected text, or looking it up on the web for more information.\n- The *subject lift* feature identifies a wide variety of objects, or *subjects*, in images with the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes\/imageSubject] interaction type, and provides your app with an image of the objects with the background removed. The [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes\/visualLookUp] type supplements this feature by adding a button in the bottom corner of the view that people can click or tap for more information about the recognized subjects.\n\n## Configure the interface and begin interaction\n\nThis class conforms to the [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIInteraction] protocol. To connect the interface with an image that your app displays, call [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIView\/addInteraction(_:)] on your app’s image view and pass in a new instance of this class.\n\nChoose the items that the framework recognizes in an image by configuring the  [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/preferredInteractionTypes] property. To recognize all types of content, specify the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes\/automatic] option, or choose a combination of types by assigning an array:\n\n```swift\ninteraction.preferredInteractionTypes = [.textSelection, .imageSubject]\n```\n\nTo begin interaction, call one of the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer] class’s `analyze` methods, such as [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalyzer\/analyze(_:configuration:)] and set the result onto this class’s [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisOverlayView\/analysis] property.\n\nYou can take more control over the interaction or provide details about your app’s image view by implementing a delegate ([doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate]) and assigning it to the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteraction\/delegate] property. If your image view isn’t an instance of [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImageView], your app needs to define the interactive area within the image by implementing the [doc:\/\/com.apple.VisionKit\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate\/contentsRect(for:)] method.\n\n## Creating an image interaction\n\n- **init()**: Creates an interaction for Live Text actions with items in an image.\n- **init(_:)**: Creates an interaction for Live Text actions with the specified delegate.\n\n## Configuring an image interaction\n\n- **delegate**: The delegate that handles the interaction callbacks.\n- **analysis**: The results of analyzing an image for items that people can interact with.\n- **view**: The view that uses this interaction.\n- **preferredInteractionTypes**: The types of interactions that people can perform with the image.\n- **ImageAnalysisInteraction.InteractionTypes**: The types of interactions that people can perform with an image.\n- **activeInteractionTypes**: The types of interactions that a person actively performs.\n\n## Responding to view events\n\n- **willMove(to:)**: Performs an action before the view adds or removes the interaction from its interaction array.\n- **didMove(to:)**: Performs an action after the view adds or removes the interaction from its interaction array.\n\n## Accessing text information\n\n- **text**: The text contents of the current image analysis.\n- **selectedText**: The current selected text.\n- **selectedAttributedText**: The current selected attributed text.\n- **hasText(at:)**: Returns a Boolean value that indicates whether active text exists at the specified point.\n- **hasActiveTextSelection**: A Boolean value that indicates whether a person or the app has text selected within the image.\n- **analysisHasText(at:)**: Returns a Boolean value that indicates whether the analysis finds text at the specified point.\n- **hasDataDetector(at:)**: Returns a Boolean value that indicates whether the analysis detects data at the specified point.\n\n## Managing text selection\n\n- **selectedRanges**: Sets selected text ranges.\n- **resetTextSelection()**: Removes a person’s text selection from the interface.\n\n## Accessing image subjects\n\n- **subjects**: The set of all subjects the framework identifies in an image.\n- **ImageAnalysisInteraction.Subject**: An area of interest in an image that the framework identifies as a primary focal point.\n- **image(for:)**: Provides an image asynchronously that contains the given subjects with the background removed.\n- **subject(at:)**: Returns the subject at the given point within the interaction’s image, if one exists.\n\n## Managing image subjects\n\n- **highlightedSubjects**: All highlighted subjects in the interaction image.\n\n## Querying the interface state\n\n- **liveTextButtonVisible**: A Boolean value that indicates whether the Live Text button appears.\n- **isSupplementaryInterfaceHidden**: A Boolean value that indicates whether the view hides supplementary interface objects.\n- **hasInteractiveItem(at:)**: Returns a Boolean value that indicates whether active text, data detectors, or supplementary interface objects exist at the specified point.\n- **hasSupplementaryInterface(at:)**: Returns a Boolean value that indicates whether supplementary interface objects exist at the specified point.\n- **selectableItemsHighlighted**: A Boolean value that indicates whether the interaction highlights actionable text or data the analyzer detects in text.\n\n## Customizing the interface\n\n- **allowLongPressForDataDetectorsInTextMode**: A Boolean value that indicates whether people can press and hold text to activate data detectors.\n- **setSupplementaryInterfaceHidden(_:animated:)**: Hides or shows supplementary interface objects, such as the Live Action button and Quick Actions, depending on the item type.\n- **supplementaryInterfaceContentInsets**: The distances the edges of content are inset from the supplementary interface.\n- **supplementaryInterfaceFont**: The font to use for the supplementary interface.\n\n## Managing custom image views\n\n- **contentsRect**: A rectangle, in unit coordinate space, that describes the content area of the interaction.\n- **setContentsRectNeedsUpdate()**: Informs the view that contains the image when the layout changes and the view needs to reload its content.\n\n## Errors\n\n- **ImageAnalysisInteraction.SubjectUnavailable**: Error conditions that can occur during subject analysis.\n\n## Content recognition and interaction in images\n\n- **Enabling Live Text interactions with images**: Add a Live Text interface that enables users to perform actions with text and QR codes that appear in images.\n- **ImageAnalyzer**: An object that finds items in images that people can interact with, such as subjects, text, and QR codes.\n- **ImageAnalysis**: An object that represents the results of analyzing an image, and provides the input for the Live Text interface object.\n- **ImageAnalysisInteractionDelegate**: A delegate that handles image-analysis and user-interaction callbacks for an interaction object.\n- **ImageAnalysisOverlayView**: A view that enables people to interact with recognized text, barcodes, and other objects in an image.\n- **ImageAnalysisOverlayViewDelegate**: A delegate that handles image-analysis and user-interaction callbacks for an overlay view.\n- **CameraRegionView**: This view displays a stabilized region of interest within a person’s view and provides passthrough camera feed for that selected region.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n- Sendable\n- SendableMetatype\n- UIInteraction\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an interaction for Live Text actions with items in an image.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/init()"
        },
        {
          "description" : "Creates an interaction for Live Text actions with the specified delegate.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/init(_:)"
        }
      ],
      "title" : "Creating an image interaction"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The delegate that handles the interaction callbacks.",
          "name" : "delegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/delegate"
        },
        {
          "description" : "The results of analyzing an image for items that people can interact with.",
          "name" : "analysis",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/analysis"
        },
        {
          "description" : "The view that uses this interaction.",
          "name" : "view",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/view"
        },
        {
          "description" : "The types of interactions that people can perform with the image.",
          "name" : "preferredInteractionTypes",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/preferredInteractionTypes"
        },
        {
          "description" : "The types of interactions that people can perform with an image.",
          "name" : "ImageAnalysisInteraction.InteractionTypes",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/InteractionTypes"
        },
        {
          "description" : "The types of interactions that a person actively performs.",
          "name" : "activeInteractionTypes",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/activeInteractionTypes"
        }
      ],
      "title" : "Configuring an image interaction"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Performs an action before the view adds or removes the interaction from its interaction array.",
          "name" : "willMove(to:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/willMove(to:)"
        },
        {
          "description" : "Performs an action after the view adds or removes the interaction from its interaction array.",
          "name" : "didMove(to:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/didMove(to:)"
        }
      ],
      "title" : "Responding to view events"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The text contents of the current image analysis.",
          "name" : "text",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/text"
        },
        {
          "description" : "The current selected text.",
          "name" : "selectedText",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/selectedText"
        },
        {
          "description" : "The current selected attributed text.",
          "name" : "selectedAttributedText",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/selectedAttributedText"
        },
        {
          "description" : "Returns a Boolean value that indicates whether active text exists at the specified point.",
          "name" : "hasText(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/hasText(at:)"
        },
        {
          "description" : "A Boolean value that indicates whether a person or the app has text selected within the image.",
          "name" : "hasActiveTextSelection",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/hasActiveTextSelection"
        },
        {
          "description" : "Returns a Boolean value that indicates whether the analysis finds text at the specified point.",
          "name" : "analysisHasText(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/analysisHasText(at:)"
        },
        {
          "description" : "Returns a Boolean value that indicates whether the analysis detects data at the specified point.",
          "name" : "hasDataDetector(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/hasDataDetector(at:)"
        }
      ],
      "title" : "Accessing text information"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Sets selected text ranges.",
          "name" : "selectedRanges",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/selectedRanges"
        },
        {
          "description" : "Removes a person’s text selection from the interface.",
          "name" : "resetTextSelection()",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/resetTextSelection()"
        }
      ],
      "title" : "Managing text selection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The set of all subjects the framework identifies in an image.",
          "name" : "subjects",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/subjects"
        },
        {
          "description" : "An area of interest in an image that the framework identifies as a primary focal point.",
          "name" : "ImageAnalysisInteraction.Subject",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/Subject"
        },
        {
          "description" : "Provides an image asynchronously that contains the given subjects with the background removed.",
          "name" : "image(for:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/image(for:)"
        },
        {
          "description" : "Returns the subject at the given point within the interaction’s image, if one exists.",
          "name" : "subject(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/subject(at:)"
        }
      ],
      "title" : "Accessing image subjects"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "All highlighted subjects in the interaction image.",
          "name" : "highlightedSubjects",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/highlightedSubjects"
        }
      ],
      "title" : "Managing image subjects"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the Live Text button appears.",
          "name" : "liveTextButtonVisible",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/liveTextButtonVisible"
        },
        {
          "description" : "A Boolean value that indicates whether the view hides supplementary interface objects.",
          "name" : "isSupplementaryInterfaceHidden",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/isSupplementaryInterfaceHidden"
        },
        {
          "description" : "Returns a Boolean value that indicates whether active text, data detectors, or supplementary interface objects exist at the specified point.",
          "name" : "hasInteractiveItem(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/hasInteractiveItem(at:)"
        },
        {
          "description" : "Returns a Boolean value that indicates whether supplementary interface objects exist at the specified point.",
          "name" : "hasSupplementaryInterface(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/hasSupplementaryInterface(at:)"
        },
        {
          "description" : "A Boolean value that indicates whether the interaction highlights actionable text or data the analyzer detects in text.",
          "name" : "selectableItemsHighlighted",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/selectableItemsHighlighted"
        }
      ],
      "title" : "Querying the interface state"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether people can press and hold text to activate data detectors.",
          "name" : "allowLongPressForDataDetectorsInTextMode",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/allowLongPressForDataDetectorsInTextMode"
        },
        {
          "description" : "Hides or shows supplementary interface objects, such as the Live Action button and Quick Actions, depending on the item type.",
          "name" : "setSupplementaryInterfaceHidden(_:animated:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/setSupplementaryInterfaceHidden(_:animated:)"
        },
        {
          "description" : "The distances the edges of content are inset from the supplementary interface.",
          "name" : "supplementaryInterfaceContentInsets",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/supplementaryInterfaceContentInsets"
        },
        {
          "description" : "The font to use for the supplementary interface.",
          "name" : "supplementaryInterfaceFont",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/supplementaryInterfaceFont"
        }
      ],
      "title" : "Customizing the interface"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A rectangle, in unit coordinate space, that describes the content area of the interaction.",
          "name" : "contentsRect",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/contentsRect"
        },
        {
          "description" : "Informs the view that contains the image when the layout changes and the view needs to reload its content.",
          "name" : "setContentsRectNeedsUpdate()",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/setContentsRectNeedsUpdate()"
        }
      ],
      "title" : "Managing custom image views"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Error conditions that can occur during subject analysis.",
          "name" : "ImageAnalysisInteraction.SubjectUnavailable",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction\/SubjectUnavailable"
        }
      ],
      "title" : "Errors"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Add a Live Text interface that enables users to perform actions with text and QR codes that appear in images.",
          "name" : "Enabling Live Text interactions with images",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/enabling-live-text-interactions-with-images"
        },
        {
          "description" : "An object that finds items in images that people can interact with, such as subjects, text, and QR codes.",
          "name" : "ImageAnalyzer",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer"
        },
        {
          "description" : "An object that represents the results of analyzing an image, and provides the input for the Live Text interface object.",
          "name" : "ImageAnalysis",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysis"
        },
        {
          "description" : "A delegate that handles image-analysis and user-interaction callbacks for an interaction object.",
          "name" : "ImageAnalysisInteractionDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate"
        },
        {
          "description" : "A view that enables people to interact with recognized text, barcodes, and other objects in an image.",
          "name" : "ImageAnalysisOverlayView",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisOverlayView"
        },
        {
          "description" : "A delegate that handles image-analysis and user-interaction callbacks for an overlay view.",
          "name" : "ImageAnalysisOverlayViewDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisOverlayViewDelegate"
        },
        {
          "description" : "This view displays a stabilized region of interest within a person’s view and provides passthrough camera feed for that selected region.",
          "name" : "CameraRegionView",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/CameraRegionView"
        }
      ],
      "title" : "Content recognition and interaction in images"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "ImageAnalysisInteraction",
  "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction"
}