{
  "abstract" : "This view displays a stabilized region of interest within a person’s view and provides passthrough camera feed for that selected region.",
  "codeExamples" : [
    {
      "code" : "struct AppScene: Scene {\n    var body: some Scene {\n         \/\/ Enterprise use case which requires an enterprise license and\n         \/\/ entitlement.\n         WindowGroup(id: \"WithEnterpriseLicense\") {\n             CameraRegionView() { result in\n                 switch result {\n                     case .success(let context):\n                         let pixelBuffer = context.pixelBuffer\n\n                         \/\/ Add desired changes to pixel buffer.\n                        return pixelBuffer\n                    case .failure(let error):\n                       \/\/ Handle errors.\n                       return nil\n                }\n             }\n         }\n         .windowResizability(.contentSize)\n     }\n }",
      "language" : "swift"
    }
  ],
  "conformsTo" : [
    "Sendable",
    "SendableMetatype",
    "View"
  ],
  "contentHash" : "d7f0f6d1e94d87ba5ee2e61fc8c1def40d28a565b948efd1a3edfcad96032fc3",
  "crawledAt" : "2025-12-01T09:15:19Z",
  "declaration" : {
    "code" : "@MainActor @preconcurrency struct CameraRegionView",
    "language" : "swift"
  },
  "id" : "0E186036-0395-4051-AFE3-20C74CA66B2E",
  "kind" : "struct",
  "module" : "VisionKit",
  "overview" : "## Overview\n\n`CameraRegionView` needs enterprise API access in order to be used. To use this view, you need to apply for the [doc:\/\/com.apple.documentation\/documentation\/BundleResources\/Entitlements\/com.apple.developer.arkit.camera-region.allow] entitlement. For more information, including how to apply for this entitlement, see [doc:\/\/com.apple.documentation\/documentation\/visionOS\/building-spatial-experiences-for-business-apps-with-enterprise-apis].\n\nThis is a standalone view used in a `WindowGroup` that a person can freely move and place in order to position the desired region of interest. Examples of possible regions of interest are documents, user manuals, gauges, and displays.\n\nThe view also allows additional post-processing of passthrough camera frames. These stabilized camera frames of the selected region of interest are directly rendered into the view. The framework provides these frames to enterprise developers before rendering them on screen, so developers can apply any enhancements or modifications prior to the rendering within the view.",
  "platforms" : [
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/VisionKit\/CameraRegionView\ncrawled: 2025-12-01T09:15:19Z\n---\n\n# CameraRegionView\n\n**Structure**\n\nThis view displays a stabilized region of interest within a person’s view and provides passthrough camera feed for that selected region.\n\n## Declaration\n\n```swift\n@MainActor @preconcurrency struct CameraRegionView\n```\n\n## Overview\n\n`CameraRegionView` needs enterprise API access in order to be used. To use this view, you need to apply for the [doc:\/\/com.apple.documentation\/documentation\/BundleResources\/Entitlements\/com.apple.developer.arkit.camera-region.allow] entitlement. For more information, including how to apply for this entitlement, see [doc:\/\/com.apple.documentation\/documentation\/visionOS\/building-spatial-experiences-for-business-apps-with-enterprise-apis].\n\nThis is a standalone view used in a `WindowGroup` that a person can freely move and place in order to position the desired region of interest. Examples of possible regions of interest are documents, user manuals, gauges, and displays.\n\nThe view also allows additional post-processing of passthrough camera frames. These stabilized camera frames of the selected region of interest are directly rendered into the view. The framework provides these frames to enterprise developers before rendering them on screen, so developers can apply any enhancements or modifications prior to the rendering within the view.\n\n```swift\nstruct AppScene: Scene {\n    var body: some Scene {\n         \/\/ Enterprise use case which requires an enterprise license and\n         \/\/ entitlement.\n         WindowGroup(id: \"WithEnterpriseLicense\") {\n             CameraRegionView() { result in\n                 switch result {\n                     case .success(let context):\n                         let pixelBuffer = context.pixelBuffer\n\n                         \/\/ Add desired changes to pixel buffer.\n                        return pixelBuffer\n                    case .failure(let error):\n                       \/\/ Handle errors.\n                       return nil\n                }\n             }\n         }\n         .windowResizability(.contentSize)\n     }\n }\n```\n\n\n\n## Creating a view\n\n- **init(isContrastAndVibrancyEnhancementEnabled:pixelBufferProcessor:)**: Creates a view that renders a spatial camera region and optionally applies contrast enhancement.\n\n## Setting up frame processing in your view\n\n- **CameraRegionView.PixelBufferProcessingContext**: A context which provides the pixel buffer for a passthrough frame.\n\n## Content recognition and interaction in images\n\n- **Enabling Live Text interactions with images**: Add a Live Text interface that enables users to perform actions with text and QR codes that appear in images.\n- **ImageAnalyzer**: An object that finds items in images that people can interact with, such as subjects, text, and QR codes.\n- **ImageAnalysis**: An object that represents the results of analyzing an image, and provides the input for the Live Text interface object.\n- **ImageAnalysisInteraction**: An interface that enables people to interact with recognized text, barcodes, and other objects in an image.\n- **ImageAnalysisInteractionDelegate**: A delegate that handles image-analysis and user-interaction callbacks for an interaction object.\n- **ImageAnalysisOverlayView**: A view that enables people to interact with recognized text, barcodes, and other objects in an image.\n- **ImageAnalysisOverlayViewDelegate**: A delegate that handles image-analysis and user-interaction callbacks for an overlay view.\n\n## Conforms To\n\n- Sendable\n- SendableMetatype\n- View\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a view that renders a spatial camera region and optionally applies contrast enhancement.",
          "name" : "init(isContrastAndVibrancyEnhancementEnabled:pixelBufferProcessor:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/CameraRegionView\/init(isContrastAndVibrancyEnhancementEnabled:pixelBufferProcessor:)"
        }
      ],
      "title" : "Creating a view"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A context which provides the pixel buffer for a passthrough frame.",
          "name" : "CameraRegionView.PixelBufferProcessingContext",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/CameraRegionView\/PixelBufferProcessingContext"
        }
      ],
      "title" : "Setting up frame processing in your view"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Add a Live Text interface that enables users to perform actions with text and QR codes that appear in images.",
          "name" : "Enabling Live Text interactions with images",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/enabling-live-text-interactions-with-images"
        },
        {
          "description" : "An object that finds items in images that people can interact with, such as subjects, text, and QR codes.",
          "name" : "ImageAnalyzer",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalyzer"
        },
        {
          "description" : "An object that represents the results of analyzing an image, and provides the input for the Live Text interface object.",
          "name" : "ImageAnalysis",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysis"
        },
        {
          "description" : "An interface that enables people to interact with recognized text, barcodes, and other objects in an image.",
          "name" : "ImageAnalysisInteraction",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteraction"
        },
        {
          "description" : "A delegate that handles image-analysis and user-interaction callbacks for an interaction object.",
          "name" : "ImageAnalysisInteractionDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisInteractionDelegate"
        },
        {
          "description" : "A view that enables people to interact with recognized text, barcodes, and other objects in an image.",
          "name" : "ImageAnalysisOverlayView",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisOverlayView"
        },
        {
          "description" : "A delegate that handles image-analysis and user-interaction callbacks for an overlay view.",
          "name" : "ImageAnalysisOverlayViewDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/ImageAnalysisOverlayViewDelegate"
        }
      ],
      "title" : "Content recognition and interaction in images"
    }
  ],
  "source" : "appleJSON",
  "title" : "CameraRegionView",
  "url" : "https:\/\/developer.apple.com\/documentation\/VisionKit\/CameraRegionView"
}