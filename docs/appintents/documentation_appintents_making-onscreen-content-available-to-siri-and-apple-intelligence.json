{
  "abstract" : "Enable Siri and Apple Intelligence to respond to a person’s questions and action requests for your app’s onscreen content.",
  "codeExamples" : [
    {
      "code" : " MediaView(\n    image: image,\n    duration: asset.duration,\n    isFavorite: asset.isFavorite,\n    proxy: proxy\n)\n.userActivity(\n    \"com.example.apple-samplecode.AssistantSchemasExample.ViewingPhoto\",\n    element: asset.entity\n) { asset, activity in\n    activity.title = \"Viewing a photo\"\n    activity.appEntityIdentifier = EntityIdentifier(for: asset)\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "934a76d5f63e1aeb8fca65828dfe2b0746c373e53d94f9fc2e886e0a64402116",
  "crawledAt" : "2025-12-03T08:31:00Z",
  "id" : "11F3F248-EAAD-4EA7-880C-89A06679B94D",
  "kind" : "collection",
  "language" : "swift",
  "module" : "App Intents",
  "overview" : "## Overview\n\nWhen a person asks a question about onscreen content or wants to perform an action on it, Siri and Apple Intelligence will be able to retrieve the content to respond to the question and perform the action. If the user explicitly requests it, Siri and Apple Intelligence will be able to send content to supported third-party services. For example, someone could view a website and use Siri to provide a summary by saying or typing a phrase like “Hey Siri, what’s this document about?”\n\n### Create an app entity and associate it with the user activity object\n\nTo integrate your app’s onscreen content with current and upcoming personal intelligence features of Siri and Apple Intelligence, explicitly provide the onscreen content using the App Intents framework. Describe the content with an [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/AppEntity] — you might be able to reuse existing app entity code. Then, tell the system about the content when it becomes visible:\n\nTo remove the association between the user activity and your app entity, set the user activity’s `appEntityIdentifier` property to `nil`.\n\nThe following code snippet from the [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/making-your-app-s-functionality-available-to-siri] sample code project shows how a photo-viewing app might provide a photo to Siri and Apple Intelligence by creating an app entity identifier for the `asset` app entity that represents a photo, and associating it with the user activity:\n\n### Make the app entity transferable\n\nAssociating an [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/AppEntity] with the [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity] provides Siri and Apple Intelligence with your app’s onscreen content to offer personalized intelligence assistance. To go one step further and enable Siri and Apple Intelligence to further process the provided onscreen content and respond to a person’s explicit request to send the content as an attachment to other services, including third parties:\n\n### Provide additional context to the system with an assistant schema\n\nTo enable Siri and Apple Intelligence to further process the provided onscreen content and provide a better response in iOS 18, make sure that the app entity that you associate with an [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity] conforms to one of the assistant schemas in the list below.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/appintents\/making-onscreen-content-available-to-siri-and-apple-intelligence\ncrawled: 2025-12-03T08:31:00Z\n---\n\n# Making onscreen content available to Siri and Apple Intelligence\n\n**API Collection**\n\nEnable Siri and Apple Intelligence to respond to a person’s questions and action requests for your app’s onscreen content.\n\n## Overview\n\nWhen a person asks a question about onscreen content or wants to perform an action on it, Siri and Apple Intelligence will be able to retrieve the content to respond to the question and perform the action. If the user explicitly requests it, Siri and Apple Intelligence will be able to send content to supported third-party services. For example, someone could view a website and use Siri to provide a summary by saying or typing a phrase like “Hey Siri, what’s this document about?”\n\n\n\n### Create an app entity and associate it with the user activity object\n\nTo integrate your app’s onscreen content with current and upcoming personal intelligence features of Siri and Apple Intelligence, explicitly provide the onscreen content using the App Intents framework. Describe the content with an [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/AppEntity] — you might be able to reuse existing app entity code. Then, tell the system about the content when it becomes visible:\n\n1. Create an app entity identifier using [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/EntityIdentifier] .\n2. Associate the identifier with the current [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity] by setting the activity’s [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity\/appEntityIdentifier] property.\n\nTo remove the association between the user activity and your app entity, set the user activity’s `appEntityIdentifier` property to `nil`.\n\nThe following code snippet from the [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/making-your-app-s-functionality-available-to-siri] sample code project shows how a photo-viewing app might provide a photo to Siri and Apple Intelligence by creating an app entity identifier for the `asset` app entity that represents a photo, and associating it with the user activity:\n\n```swift\n MediaView(\n    image: image,\n    duration: asset.duration,\n    isFavorite: asset.isFavorite,\n    proxy: proxy\n)\n.userActivity(\n    \"com.example.apple-samplecode.AssistantSchemasExample.ViewingPhoto\",\n    element: asset.entity\n) { asset, activity in\n    activity.title = \"Viewing a photo\"\n    activity.appEntityIdentifier = EntityIdentifier(for: asset)\n}\n```\n\n### Make the app entity transferable\n\nAssociating an [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/AppEntity] with the [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity] provides Siri and Apple Intelligence with your app’s onscreen content to offer personalized intelligence assistance. To go one step further and enable Siri and Apple Intelligence to further process the provided onscreen content and respond to a person’s explicit request to send the content as an attachment to other services, including third parties:\n\n1. Update your app entity to conform to the [doc:\/\/com.apple.documentation\/documentation\/CoreTransferable\/Transferable] protocol.\n2. In your `Transferable` implementation, provide image, PDF, rich text, or plain text representations. To increase compatibility with third-party services, provide several representations that best fit your content. For example, an email client might represent an email as rich text, plain text, and a PDF. For more on adopting `Transferable`, refer to [http:\/\/developer.apple.com\/documentation\/coretransferable].\n\n### Provide additional context to the system with an assistant schema\n\nTo enable Siri and Apple Intelligence to further process the provided onscreen content and provide a better response in iOS 18, make sure that the app entity that you associate with an [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity] conforms to one of the assistant schemas in the list below.\n\n\n\n\n\n## System protocols\n\n- **AppEntityAnnotatable**: A protocol that framework types adopt to enable you to provide content to system experiences.\n\n## Siri and Apple Intelligence\n\n- **Integrating actions with Siri and Apple Intelligence**: Create app intents, entities, and enumerations that conform to assistant schemas to tap into the enhanced action capabilities of Siri and Apple Intelligence.\n- **App intent domains**: Make your app’s actions and content available to Siri and Apple Intelligence with assistant schemas.\n- **Making your app’s functionality available to Siri**: Add app intent schemas to your app so Siri can complete requests, and integrate your app with Apple Intelligence, Spotlight, and other system experiences.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A protocol that framework types adopt to enable you to provide content to system experiences.",
          "name" : "AppEntityAnnotatable",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/AppEntityAnnotatable"
        }
      ],
      "title" : "System protocols"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create app intents, entities, and enumerations that conform to assistant schemas to tap into the enhanced action capabilities of Siri and Apple Intelligence.",
          "name" : "Integrating actions with Siri and Apple Intelligence",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/Integrating-actions-with-siri-and-apple-intelligence"
        },
        {
          "description" : "Make your app’s actions and content available to Siri and Apple Intelligence with assistant schemas.",
          "name" : "App intent domains",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/app-intent-domains"
        },
        {
          "description" : "Add app intent schemas to your app so Siri can complete requests, and integrate your app with Apple Intelligence, Spotlight, and other system experiences.",
          "name" : "Making your app’s functionality available to Siri",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/making-your-app-s-functionality-available-to-siri"
        }
      ],
      "title" : "Siri and Apple Intelligence"
    }
  ],
  "source" : "appleJSON",
  "title" : "Making onscreen content available to Siri and Apple Intelligence",
  "url" : "https:\/\/developer.apple.com\/documentation\/appintents\/making-onscreen-content-available-to-siri-and-apple-intelligence"
}