{
  "abstract" : "Let people in Japan configure the side button of iPhone to launch your voice-based conversational app.",
  "codeExamples" : [
    {
      "code" : "@AppIntent(schema: .assistant.activate)\nstruct ActivateVoiceBasedConversationSceneIntent {\n    static let supportedModes: IntentModes = .foreground\n\n    func perform() async throws -> some IntentResult {\n\n        \/\/ Add code here to navigate to the scene in your app that provides\n        \/\/ voice-based conversational functionality.\n        \/\/ If applicable, pass information to your app that allows it to update\n        \/\/ its data or UI in response to the invocation from\n        \/\/ the side button and start voice-based conversational functionality.\n\n        return .result()\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "5ec4c06665235624a5a264ebbfe3ee7f55d53f608800a20e1de9a43b3d438644",
  "crawledAt" : "2025-12-02T18:23:13Z",
  "id" : "3DCD6BB4-A4C9-42C0-B457-5A53A354C982",
  "kind" : "article",
  "language" : "swift",
  "module" : "App Intents",
  "overview" : "## Overview\n\nBy adopting the App Intents framework and offering App Shortcuts, you let people instantly access app functionality and integrate it with system experiences like Spotlight or App Shortcuts. For example, a person might place an App Shortcut you provide on the Action button. In Japan, people might place an action on the side button of iPhone that instantly launches your voice-based conversational app. People expect the voice-based conversational functionality to be instantly available when they launch your app with the side button, so make sure to let them immediately use it by starting an audio session – for example, with [doc:\/\/com.apple.documentation\/documentation\/AVFoundation].\n\nTo allow people to press and hold the side button to launch your voice-based conversational app to its conversation experience:\n\nThe following example shows how an app that provides voice-based conversational functionality might implement an app intent that people in Japan can place on the side button of iPhone:\n\nIf you’re new to the AppIntents framework, refer to [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/Creating-your-first-app-intent] and [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/Making-actions-and-content-discoverable-and-widely-available] for additional information.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AppIntents\/Launching-your-voice-based-conversational-app-from-the-side-button-of-iPhone\ncrawled: 2025-12-02T18:23:13Z\n---\n\n# Launching your voice-based conversational app from the side button of iPhone\n\n**Article**\n\nLet people in Japan configure the side button of iPhone to launch your voice-based conversational app.\n\n## Overview\n\nBy adopting the App Intents framework and offering App Shortcuts, you let people instantly access app functionality and integrate it with system experiences like Spotlight or App Shortcuts. For example, a person might place an App Shortcut you provide on the Action button. In Japan, people might place an action on the side button of iPhone that instantly launches your voice-based conversational app. People expect the voice-based conversational functionality to be instantly available when they launch your app with the side button, so make sure to let them immediately use it by starting an audio session – for example, with [doc:\/\/com.apple.documentation\/documentation\/AVFoundation].\n\n\n\nTo allow people to press and hold the side button to launch your voice-based conversational app to its conversation experience:\n\n1. Add the `com.apple.developer.side-button-access.allow` entitlement to the `.entitlements` file in your app’s Xcode project. For details on adding this entitlement, see [doc:\/\/com.apple.documentation\/documentation\/BundleResources\/Entitlements\/com.apple.developer.side-button-access.allow].\n2. Create an app intent that conforms to the [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/AssistantSchemas\/AssistantIntent\/activate] app intent schema.\n3. In the app intent’s [doc:\/\/com.apple.documentation\/documentation\/AppIntents\/AppIntent\/perform()] implementation, navigate to the scene that provides voice-based conversational functionality and start an audio session.\n\nThe following example shows how an app that provides voice-based conversational functionality might implement an app intent that people in Japan can place on the side button of iPhone:\n\n```swift\n@AppIntent(schema: .assistant.activate)\nstruct ActivateVoiceBasedConversationSceneIntent {\n    static let supportedModes: IntentModes = .foreground\n\n    func perform() async throws -> some IntentResult {\n\n        \/\/ Add code here to navigate to the scene in your app that provides\n        \/\/ voice-based conversational functionality.\n        \/\/ If applicable, pass information to your app that allows it to update\n        \/\/ its data or UI in response to the invocation from\n        \/\/ the side button and start voice-based conversational functionality.\n\n        return .result()\n    }\n}\n```\n\nIf you’re new to the AppIntents framework, refer to [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/Creating-your-first-app-intent] and [doc:\/\/com.apple.AppIntents\/documentation\/AppIntents\/Making-actions-and-content-discoverable-and-widely-available] for additional information.\n\n## Other system experiences\n\n- **Making app entities available in Spotlight**: Allow people to find your app’s content in Spotlight by donating app entities to its semantic index.\n- **Focus**: Adjust your app’s behavior and filter incoming notifications when the current Focus changes.\n- **Action button on iPhone and Apple Watch**: Enable people to run your App Shortcuts with the Action button on iPhone or to start your app’s workout or dive sessions using the Action button on Apple Watch.\n- **Developing a WidgetKit strategy**: Explore features, tasks, related frameworks, and constraints as you make a plan to implement widgets, controls, watch complications, and Live Activities.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Allow people to find your app’s content in Spotlight by donating app entities to its semantic index.",
          "name" : "Making app entities available in Spotlight",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/making-app-entities-available-in-spotlight"
        },
        {
          "description" : "Adjust your app’s behavior and filter incoming notifications when the current Focus changes.",
          "name" : "Focus",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/focus"
        },
        {
          "description" : "Enable people to run your App Shortcuts with the Action button on iPhone or to start your app’s workout or dive sessions using the Action button on Apple Watch.",
          "name" : "Action button on iPhone and Apple Watch",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/ActionButton"
        },
        {
          "description" : "Explore features, tasks, related frameworks, and constraints as you make a plan to implement widgets, controls, watch complications, and Live Activities.",
          "name" : "Developing a WidgetKit strategy",
          "url" : "https:\/\/developer.apple.com\/documentation\/WidgetKit\/Developing-a-WidgetKit-strategy"
        }
      ],
      "title" : "Other system experiences"
    }
  ],
  "source" : "appleJSON",
  "title" : "Launching your voice-based conversational app from the side button of iPhone",
  "url" : "https:\/\/developer.apple.com\/documentation\/AppIntents\/Launching-your-voice-based-conversational-app-from-the-side-button-of-iPhone"
}