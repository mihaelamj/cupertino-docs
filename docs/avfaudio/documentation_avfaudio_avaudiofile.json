{
  "abstract" : "An object that represents an audio file that the system can open for reading or writing.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "99cac3eaca383f6074ed92a84cbbfe8c813d47af52955dd5557882631980c1e3",
  "crawledAt" : "2025-12-05T07:16:19Z",
  "declaration" : {
    "code" : "class AVAudioFile",
    "language" : "swift"
  },
  "id" : "15F6A967-04EF-40D0-8BC2-5BB48A52306D",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFAudio",
  "overview" : "## Overview\n\nRegardless of the file format, you read and write using [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPCMBuffer] objects. These objects contain samples as [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioCommonFormat] that the framework refers to as the file’s processing format. You convert to and from using the file’s actual format.\n\nReads and writes are always sequential. Random access is possible by setting the [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioFile\/framePosition] property.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\ncrawled: 2025-12-05T07:16:19Z\n---\n\n# AVAudioFile\n\n**Class**\n\nAn object that represents an audio file that the system can open for reading or writing.\n\n## Declaration\n\n```swift\nclass AVAudioFile\n```\n\n## Overview\n\nRegardless of the file format, you read and write using [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPCMBuffer] objects. These objects contain samples as [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioCommonFormat] that the framework refers to as the file’s processing format. You convert to and from using the file’s actual format.\n\nReads and writes are always sequential. Random access is possible by setting the [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioFile\/framePosition] property.\n\n## Creating an Audio File\n\n- **init(forReading:)**: Opens a file for reading using the standard, deinterleaved floating point format.\n- **init(forReading:commonFormat:interleaved:)**: Opens a file for reading using the specified processing format.\n- **init(forWriting:settings:)**: Opens a file for writing using the specified settings.\n- **init(forWriting:settings:commonFormat:interleaved:)**: Opens a file for writing using a specified processing format and settings.\n\n## Reading and Writing the Audio Buffer\n\n- **read(into:)**: Reads an entire audio buffer.\n- **read(into:frameCount:)**: Reads a portion of an audio buffer using the number of frames you specify.\n- **write(from:)**: Writes an audio buffer sequentially.\n- **close()**: Closes the audio file.\n\n## Getting Audio File Properties\n\n- **url**: The location of the audio file.\n- **fileFormat**: The on-disk format of the file.\n- **processingFormat**: The processing format of the file.\n- **length**: The number of sample frames in the file.\n- **AVAudioFramePosition**: A position in an audio file or stream.\n- **framePosition**: The position in the file where the next read or write operation occurs.\n- **AVAudioFrameCount**: A number of audio sample frames.\n- **AVAudioFileTypeKey**: A string that indicates the audio file type.\n- **isOpen**: A Boolean value that indicates whether the file is open.\n\n## Initializers\n\n- **init()**\n\n## Supporting data types\n\n- **AVAudioBuffer**: An object that represents a buffer of audio data with a format.\n- **AVAudioTime**: An object you use to represent a moment in time.\n- **Audio settings**: Configure audio processing settings using standard key and value constants.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Opens a file for reading using the standard, deinterleaved floating point format.",
          "name" : "init(forReading:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/init(forReading:)"
        },
        {
          "description" : "Opens a file for reading using the specified processing format.",
          "name" : "init(forReading:commonFormat:interleaved:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/init(forReading:commonFormat:interleaved:)"
        },
        {
          "description" : "Opens a file for writing using the specified settings.",
          "name" : "init(forWriting:settings:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/init(forWriting:settings:)"
        },
        {
          "description" : "Opens a file for writing using a specified processing format and settings.",
          "name" : "init(forWriting:settings:commonFormat:interleaved:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/init(forWriting:settings:commonFormat:interleaved:)"
        }
      ],
      "title" : "Creating an Audio File"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Reads an entire audio buffer.",
          "name" : "read(into:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/read(into:)"
        },
        {
          "description" : "Reads a portion of an audio buffer using the number of frames you specify.",
          "name" : "read(into:frameCount:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/read(into:frameCount:)"
        },
        {
          "description" : "Writes an audio buffer sequentially.",
          "name" : "write(from:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/write(from:)"
        },
        {
          "description" : "Closes the audio file.",
          "name" : "close()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/close()"
        }
      ],
      "title" : "Reading and Writing the Audio Buffer"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The location of the audio file.",
          "name" : "url",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/url"
        },
        {
          "description" : "The on-disk format of the file.",
          "name" : "fileFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/fileFormat"
        },
        {
          "description" : "The processing format of the file.",
          "name" : "processingFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/processingFormat"
        },
        {
          "description" : "The number of sample frames in the file.",
          "name" : "length",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/length"
        },
        {
          "description" : "A position in an audio file or stream.",
          "name" : "AVAudioFramePosition",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFramePosition"
        },
        {
          "description" : "The position in the file where the next read or write operation occurs.",
          "name" : "framePosition",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/framePosition"
        },
        {
          "description" : "A number of audio sample frames.",
          "name" : "AVAudioFrameCount",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFrameCount"
        },
        {
          "description" : "A string that indicates the audio file type.",
          "name" : "AVAudioFileTypeKey",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFileTypeKey"
        },
        {
          "description" : "A Boolean value that indicates whether the file is open.",
          "name" : "isOpen",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/isOpen"
        }
      ],
      "title" : "Getting Audio File Properties"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile\/init()"
        }
      ],
      "title" : "Initializers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that represents a buffer of audio data with a format.",
          "name" : "AVAudioBuffer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioBuffer"
        },
        {
          "description" : "An object you use to represent a moment in time.",
          "name" : "AVAudioTime",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioTime"
        },
        {
          "description" : "Configure audio processing settings using standard key and value constants.",
          "name" : "Audio settings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/audio-settings"
        }
      ],
      "title" : "Supporting data types"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAudioFile",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioFile"
}