{
  "abstract" : "An object for scheduling the playback of buffers or segments of audio files.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "AVAudio3DMixing",
    "AVAudioMixing",
    "AVAudioStereoMixing",
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "abc217a273b589e3f9904659feb9310f072a1ce115461a977c7b2800d1bc73a9",
  "crawledAt" : "2025-12-02T16:09:41Z",
  "declaration" : {
    "code" : "class AVAudioPlayerNode",
    "language" : "swift"
  },
  "id" : "8B754F4D-BFD1-4D6C-92C5-CA4AAE7503E1",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFAudio",
  "overview" : "## Overview\n\nThis audio node supports scheduling the playback of [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPCMBuffer] instances, or segments of audio files that you open through [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioFile]. You can schedule buffers and segments to play at specific points in time or to play immediately following preceding segments.\n\nGenerally, you want to configure the node’s output format with the same number of channels as in the files and buffers. Otherwise, the node drops or adds channels as necessary. It’s usually preferable to use an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioMixerNode] for this configuration.\n\nSimilarly, when playing file segments, the node makes sample rate conversions, if necessary. It’s preferable to configure the node’s output sample rate to match that of the files, and to use a mixer to perform the rate conversion.\n\nWhen playing buffers, there’s an implicit assumption that the buffers are at the same sample rate as the node’s output format.\n\nThe [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/stop()] method unschedules all previously scheduled buffers and file segments, and returns the player timeline to sample time `0`.\n\n### Player Timeline\n\nThe usual [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode] sample times, which [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/lastRenderTime] observes, have an arbitrary zero point. The `AVAudioPlayerNode` class superimposes a second player timeline on top of this to reflect when the player starts and intervals when it pauses. The methods [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/nodeTime(forPlayerTime:)] and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/playerTime(forNodeTime:)] convert between the two.\n\n### Scheduling Playback Time\n\nThe [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleBuffer(_:at:options:completionHandler:)], [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleFile(_:at:completionHandler:)], and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleSegment(_:startingFrame:frameCount:at:completionHandler:)] methods take an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioTime] `when` parameter, and you interpret it as follows:\n\nThe scheduling methods fail if:\n\n### Handling Buffer or File Completion\n\nThe buffer of file completion handlers are a means to schedule more data if available on the player node. For more information on the different completion callback types, see [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNodeCompletionCallbackType].\n\n### Rendering Offline\n\nWhen you use a player node with the engine operating in manual rendering mode, you use the buffer or file completion handlers — [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/lastRenderTime], [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/latency], and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/outputPresentationLatency] — to track how much data the player rendered and how much remains to render.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\ncrawled: 2025-12-02T16:09:41Z\n---\n\n# AVAudioPlayerNode\n\n**Class**\n\nAn object for scheduling the playback of buffers or segments of audio files.\n\n## Declaration\n\n```swift\nclass AVAudioPlayerNode\n```\n\n## Overview\n\nThis audio node supports scheduling the playback of [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPCMBuffer] instances, or segments of audio files that you open through [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioFile]. You can schedule buffers and segments to play at specific points in time or to play immediately following preceding segments.\n\nGenerally, you want to configure the node’s output format with the same number of channels as in the files and buffers. Otherwise, the node drops or adds channels as necessary. It’s usually preferable to use an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioMixerNode] for this configuration.\n\nSimilarly, when playing file segments, the node makes sample rate conversions, if necessary. It’s preferable to configure the node’s output sample rate to match that of the files, and to use a mixer to perform the rate conversion.\n\nWhen playing buffers, there’s an implicit assumption that the buffers are at the same sample rate as the node’s output format.\n\nThe [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/stop()] method unschedules all previously scheduled buffers and file segments, and returns the player timeline to sample time `0`.\n\n\n\n### Player Timeline\n\nThe usual [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode] sample times, which [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/lastRenderTime] observes, have an arbitrary zero point. The `AVAudioPlayerNode` class superimposes a second player timeline on top of this to reflect when the player starts and intervals when it pauses. The methods [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/nodeTime(forPlayerTime:)] and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/playerTime(forNodeTime:)] convert between the two.\n\n### Scheduling Playback Time\n\nThe [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleBuffer(_:at:options:completionHandler:)], [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleFile(_:at:completionHandler:)], and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleSegment(_:startingFrame:frameCount:at:completionHandler:)] methods take an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioTime] `when` parameter, and you interpret it as follows:\n\n- If the `when` parameter is `nil`:\n- If there are previous commands, the new one plays immediately following the last one.\n- Otherwise, if the node is in a playing state, the event plays in the very near future.\n- Otherwise, the command plays at sample time `0`.\n- If the `when` parameter is a sample time, the parameter interprets it as such.\n- If the `when` parameter is a host time, the system ignores it unless the sample time is invalid when the engine is rendering to an audio device.\n\nThe scheduling methods fail if:\n\n- A buffer’s channel count doesn’t match that of the node’s output format.\n- The system can’t access a file.\n- An [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioTime] doesn’t specify a valid sample time or a host time.\n- A segment’s start frame or frame count is a negative value.\n\n### Handling Buffer or File Completion\n\nThe buffer of file completion handlers are a means to schedule more data if available on the player node. For more information on the different completion callback types, see [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioPlayerNodeCompletionCallbackType].\n\n\n\n### Rendering Offline\n\nWhen you use a player node with the engine operating in manual rendering mode, you use the buffer or file completion handlers — [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/lastRenderTime], [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/latency], and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVAudioNode\/outputPresentationLatency] — to track how much data the player rendered and how much remains to render.\n\n## Creating a Player Node\n\n- **init()**: Creates an initialized audio player node.\n\n## Scheduling Playback\n\n- **scheduleFile(_:at:completionHandler:)**: Schedules the playing of an entire audio file.\n- **scheduleFile(_:at:completionCallbackType:completionHandler:)**: Schedules the playing of an entire audio file with a callback option you specify.\n- **scheduleSegment(_:startingFrame:frameCount:at:completionHandler:)**: Schedules the playing of an audio file segment.\n- **scheduleSegment(_:startingFrame:frameCount:at:completionCallbackType:completionHandler:)**: Schedules the playing of an audio file segment with a callback option you specify.\n- **scheduleBuffer(_:at:options:completionHandler:)**: Schedules the playing samples from an audio buffer at the time and playback options you specify.\n- **scheduleBuffer(_:completionHandler:)**: Schedules the playing samples from an audio buffer.\n- **scheduleBuffer(_:at:options:completionCallbackType:completionHandler:)**: Schedules the playing samples from an audio buffer with the playback options you specify.\n- **scheduleBuffer(_:completionCallbackType:completionHandler:)**: Schedules the playing samples from an audio buffer with the callback option you specify.\n- **AVAudioPlayerNodeBufferOptions**: The buffer options that control the playback scheduling.\n- **AVAudioPlayerNodeCompletionCallbackType**: Constants that specify when the framework must invoke the completion handler.\n- **AVAudioPlayerNodeCompletionHandler**: The callback handler for buffer or file completion.\n\n## Converting Node and Player Times\n\n- **nodeTime(forPlayerTime:)**: Converts from player time to node time.\n- **playerTime(forNodeTime:)**: Converts from node time to player time.\n\n## Controlling Playback\n\n- **prepare(withFrameCount:)**: Prepares the file regions or buffers you schedule for playback.\n- **play()**: Starts or resumes playback immediately.\n- **play(at:)**: Starts or resumes playback at a time you specify.\n- **isPlaying**: A Boolean value that indicates whether the player is playing.\n- **pause()**: Pauses the node’s playback.\n- **stop()**: Clears all of the node’s events you schedule and stops playback.\n\n## Playback\n\n- **Playing custom audio with your own player**: Construct an audio player to play your custom audio data, and optionally take advantage of the advanced features of AirPlay 2.\n- **Using voice processing**: Add voice-processing capabilities to your app by using audio engine.\n\n## Inherits From\n\n- AVAudioNode\n\n## Conforms To\n\n- AVAudio3DMixing\n- AVAudioMixing\n- AVAudioStereoMixing\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an initialized audio player node.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/init()"
        }
      ],
      "title" : "Creating a Player Node"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Schedules the playing of an entire audio file.",
          "name" : "scheduleFile(_:at:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleFile(_:at:completionHandler:)"
        },
        {
          "description" : "Schedules the playing of an entire audio file with a callback option you specify.",
          "name" : "scheduleFile(_:at:completionCallbackType:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleFile(_:at:completionCallbackType:completionHandler:)"
        },
        {
          "description" : "Schedules the playing of an audio file segment.",
          "name" : "scheduleSegment(_:startingFrame:frameCount:at:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleSegment(_:startingFrame:frameCount:at:completionHandler:)"
        },
        {
          "description" : "Schedules the playing of an audio file segment with a callback option you specify.",
          "name" : "scheduleSegment(_:startingFrame:frameCount:at:completionCallbackType:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleSegment(_:startingFrame:frameCount:at:completionCallbackType:completionHandler:)"
        },
        {
          "description" : "Schedules the playing samples from an audio buffer at the time and playback options you specify.",
          "name" : "scheduleBuffer(_:at:options:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleBuffer(_:at:options:completionHandler:)"
        },
        {
          "description" : "Schedules the playing samples from an audio buffer.",
          "name" : "scheduleBuffer(_:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleBuffer(_:completionHandler:)"
        },
        {
          "description" : "Schedules the playing samples from an audio buffer with the playback options you specify.",
          "name" : "scheduleBuffer(_:at:options:completionCallbackType:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleBuffer(_:at:options:completionCallbackType:completionHandler:)"
        },
        {
          "description" : "Schedules the playing samples from an audio buffer with the callback option you specify.",
          "name" : "scheduleBuffer(_:completionCallbackType:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/scheduleBuffer(_:completionCallbackType:completionHandler:)"
        },
        {
          "description" : "The buffer options that control the playback scheduling.",
          "name" : "AVAudioPlayerNodeBufferOptions",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNodeBufferOptions"
        },
        {
          "description" : "Constants that specify when the framework must invoke the completion handler.",
          "name" : "AVAudioPlayerNodeCompletionCallbackType",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNodeCompletionCallbackType"
        },
        {
          "description" : "The callback handler for buffer or file completion.",
          "name" : "AVAudioPlayerNodeCompletionHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNodeCompletionHandler"
        }
      ],
      "title" : "Scheduling Playback"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Converts from player time to node time.",
          "name" : "nodeTime(forPlayerTime:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/nodeTime(forPlayerTime:)"
        },
        {
          "description" : "Converts from node time to player time.",
          "name" : "playerTime(forNodeTime:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/playerTime(forNodeTime:)"
        }
      ],
      "title" : "Converting Node and Player Times"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Prepares the file regions or buffers you schedule for playback.",
          "name" : "prepare(withFrameCount:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/prepare(withFrameCount:)"
        },
        {
          "description" : "Starts or resumes playback immediately.",
          "name" : "play()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/play()"
        },
        {
          "description" : "Starts or resumes playback at a time you specify.",
          "name" : "play(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/play(at:)"
        },
        {
          "description" : "A Boolean value that indicates whether the player is playing.",
          "name" : "isPlaying",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/isPlaying"
        },
        {
          "description" : "Pauses the node’s playback.",
          "name" : "pause()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/pause()"
        },
        {
          "description" : "Clears all of the node’s events you schedule and stops playback.",
          "name" : "stop()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode\/stop()"
        }
      ],
      "title" : "Controlling Playback"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Construct an audio player to play your custom audio data, and optionally take advantage of the advanced features of AirPlay 2.",
          "name" : "Playing custom audio with your own player",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/playing-custom-audio-with-your-own-player"
        },
        {
          "description" : "Add voice-processing capabilities to your app by using audio engine.",
          "name" : "Using voice processing",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/using-voice-processing"
        }
      ],
      "title" : "Playback"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "AVAudioNode"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAudioPlayerNode",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioPlayerNode"
}