{
  "abstract" : "Generate audio signals using an audio source node and a custom render callback.",
  "codeExamples" : [
    {
      "code" : "void setSampleRate(float inSampleRate) {\n    \/\/ Store the sample rate.\n    sampleRate = inSampleRate;\n    \/\/ Update the maximum number of harmonics by taking the floor of the Nyquist frequency divided by the base frequency.\n    numHarmonics = int(0.5f * sampleRate \/ frequency);\n    \/\/ Set the phase increment ramp length to 100 milliseconds.\n    phaseIncrement.setRampLength(0.1f * sampleRate);\n    \/\/ Set the raw amplitude ramp length to 100 milliseconds.\n    rawAmplitude.setRampLength(0.1f * sampleRate);\n}",
      "language" : "obj-c"
    },
    {
      "code" : "inline float additiveSawtooth(float phase, int harmonics) {\n    float sample = 0;\n    \n    for (int i = 1; i <= harmonics; ++i)\n        sample += sin(i * phase) \/ i;\n    \n    return (2.0f \/ M_PI) * sample;\n}",
      "language" : "obj-c"
    },
    {
      "code" : "inline float additiveSquare(float phase, int harmonics) {\n    float sample = 0;\n    \n    for (int i = 1; i <= harmonics; i += 2)\n        sample += sin(i * phase) \/ i;\n    \n    return (4.0f \/ M_PI) * sample;\n}\n\ninline float additiveTriangle(float phase, int harmonics) {\n    float sample = 0;\n    \n    for (int i = 1; i <= harmonics; i += 2)\n        sample += powf(-1, (i - 1) \/ 2) * sin(i * phase) \/ (i * i);\n    \n    return (8.0f \/ (M_PI * M_PI)) * sample;\n}",
      "language" : "obj-c"
    },
    {
      "code" : "init() {\n    let srcNode = AVAudioSourceNode(renderBlock: signalGenerator.renderBlock)\n    let mainMixer = engine.mainMixerNode\n    ...\n    engine.attach(srcNode)\n    engine.connect(srcNode, to: mainMixer, format: inputFormat)\n    engine.connect(mainMixer, to: output, format: outputFormat)\n    mainMixer.outputVolume = 0.5\n}",
      "language" : "swift"
    },
    {
      "code" : "@interface SignalGenerator : NSObject\n\n\/\/ The block this class provides to implement rendering. Similar to `AUInternalRenderBlock`.\n@property (nonatomic, readonly) AVAudioSourceNodeRenderBlock renderBlock;\n\n...\n\n@end",
      "language" : "obj-c"
    },
    {
      "code" : "var waveform: Waveform = .sine {\n    willSet {\n        signalGenerator.setWaveform(newValue)\n    }\n}\n    \nvar frequency: Float = 440.0 {\n    willSet {\n        signalGenerator.setFrequency(newValue)\n    }\n}\n    \nvar amplitude: Float = -12.0 {\n    willSet {\n        signalGenerator.setAmplitude(newValue)\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "4858c737caad34acd061640728453de89e64cd9ae5e0e4747416b7bc5d17f22e",
  "crawledAt" : "2025-12-02T15:29:31Z",
  "id" : "4184915D-8898-4713-A8CB-3661AE1C4D57",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "AVFAudio",
  "overview" : "## Overview\n\nThis sample code project shows you how to use an audio source node and a custom render callback to generate classic waveforms.\n\nA class called `SignalGeneratorKernel`, written in C++ to ensure real-time safety, provides the digital signal processing (DSP) logic. The project also includes an Objective-C wrapper class called `SignalGenerator` to act as an intermediary.\n\nYou can change the waveform, frequency, and amplitude of the signal generator in real time. Because changing the amplitude and frequency of the signal generator can produce audible artifacts, the sample project uses the  included `ParameterRamp` class to ramp these parameters.\n\n## Synthesize classic waveforms\n\nThe classic waveforms the signal generator kernel produces are sine, sawtooth down, square, triangle, and white noise. Digital synthesis of classic waveforms that have discontinuities can produce aliasing. This is particularly the case for sawtooth and square waveforms, which have jump discontinuities.\n\nTo mitigate aliasing, the sample generates sawtooth, square, and triangle waveforms after their Fourier series. Although not efficient, this approach ensures the waveforms are band-limited, and produces the maximum number of harmonics with frequencies bound by the Nyquist frequency (half the sample rate).\n\nThe Fourier series for a sawtooth down waveform is a sum of harmonic partials that decays proportionally to the partial’s frequency.\n\nSquare and triangle waves are sums of odd partials. The square decays proportionally to the the partial’s frequency, and the triangle decays proportionally to the square of the partial’s frequency.\n\n## Define a custom render callback\n\nThe `AudioManager` class bridges an instance of `SignalGenerator` to an [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudioengine]. When initialized, `AudioManager` constructs an [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudiosourcenode] object using the `renderCallback` property of the signal generator class. After creating an audio source node, `AudioManager` attaches the node to the [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudioengine], and connects it to the main mixer node.\n\n`SignalGenerator` provides a render block in much the same way an instance of [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auaudiounit] provides an [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auaudiounit\/1439864-internalrenderblock]. The basic difference is that `SignalGenerator` provides a render block of type [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudiosourcenoderenderblock], and [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auaudiounit] provides a render block of type [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auinternalrenderblock].\n\n## Connect the user interface to the signal generator\n\nThe user interface is a [https:\/\/developer.apple.com\/documentation\/swiftui\/view] that observes a property of type `AudioManager`. The audio manager class, in turn, implements the [https:\/\/developer.apple.com\/documentation\/observation\/observable] protocol, and is responsible for maintaining the state of the user interface.\n\nThe audio manager exposes properties that control the waveform, frequency, and amplitude of the signal generator, and provides methods to start and stop the [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudioengine].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFAudio\/building-a-signal-generator\ncrawled: 2025-12-02T15:29:31Z\n---\n\n# Building a signal generator\n\n**Sample Code**\n\nGenerate audio signals using an audio source node and a custom render callback.\n\n## Overview\n\nThis sample code project shows you how to use an audio source node and a custom render callback to generate classic waveforms.\n\n\n\nA class called `SignalGeneratorKernel`, written in C++ to ensure real-time safety, provides the digital signal processing (DSP) logic. The project also includes an Objective-C wrapper class called `SignalGenerator` to act as an intermediary.\n\n\n\nYou can change the waveform, frequency, and amplitude of the signal generator in real time. Because changing the amplitude and frequency of the signal generator can produce audible artifacts, the sample project uses the  included `ParameterRamp` class to ramp these parameters.\n\n## Synthesize classic waveforms\n\nThe classic waveforms the signal generator kernel produces are sine, sawtooth down, square, triangle, and white noise. Digital synthesis of classic waveforms that have discontinuities can produce aliasing. This is particularly the case for sawtooth and square waveforms, which have jump discontinuities.\n\n\n\nTo mitigate aliasing, the sample generates sawtooth, square, and triangle waveforms after their Fourier series. Although not efficient, this approach ensures the waveforms are band-limited, and produces the maximum number of harmonics with frequencies bound by the Nyquist frequency (half the sample rate).\n\n```obj-c\nvoid setSampleRate(float inSampleRate) {\n    \/\/ Store the sample rate.\n    sampleRate = inSampleRate;\n    \/\/ Update the maximum number of harmonics by taking the floor of the Nyquist frequency divided by the base frequency.\n    numHarmonics = int(0.5f * sampleRate \/ frequency);\n    \/\/ Set the phase increment ramp length to 100 milliseconds.\n    phaseIncrement.setRampLength(0.1f * sampleRate);\n    \/\/ Set the raw amplitude ramp length to 100 milliseconds.\n    rawAmplitude.setRampLength(0.1f * sampleRate);\n}\n```\n\nThe Fourier series for a sawtooth down waveform is a sum of harmonic partials that decays proportionally to the partial’s frequency.\n\n```obj-c\ninline float additiveSawtooth(float phase, int harmonics) {\n    float sample = 0;\n    \n    for (int i = 1; i <= harmonics; ++i)\n        sample += sin(i * phase) \/ i;\n    \n    return (2.0f \/ M_PI) * sample;\n}\n```\n\nSquare and triangle waves are sums of odd partials. The square decays proportionally to the the partial’s frequency, and the triangle decays proportionally to the square of the partial’s frequency.\n\n```obj-c\ninline float additiveSquare(float phase, int harmonics) {\n    float sample = 0;\n    \n    for (int i = 1; i <= harmonics; i += 2)\n        sample += sin(i * phase) \/ i;\n    \n    return (4.0f \/ M_PI) * sample;\n}\n\ninline float additiveTriangle(float phase, int harmonics) {\n    float sample = 0;\n    \n    for (int i = 1; i <= harmonics; i += 2)\n        sample += powf(-1, (i - 1) \/ 2) * sin(i * phase) \/ (i * i);\n    \n    return (8.0f \/ (M_PI * M_PI)) * sample;\n}\n```\n\n## Define a custom render callback\n\nThe `AudioManager` class bridges an instance of `SignalGenerator` to an [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudioengine]. When initialized, `AudioManager` constructs an [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudiosourcenode] object using the `renderCallback` property of the signal generator class. After creating an audio source node, `AudioManager` attaches the node to the [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudioengine], and connects it to the main mixer node.\n\n```swift\ninit() {\n    let srcNode = AVAudioSourceNode(renderBlock: signalGenerator.renderBlock)\n    let mainMixer = engine.mainMixerNode\n    ...\n    engine.attach(srcNode)\n    engine.connect(srcNode, to: mainMixer, format: inputFormat)\n    engine.connect(mainMixer, to: output, format: outputFormat)\n    mainMixer.outputVolume = 0.5\n}\n```\n\n`SignalGenerator` provides a render block in much the same way an instance of [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auaudiounit] provides an [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auaudiounit\/1439864-internalrenderblock]. The basic difference is that `SignalGenerator` provides a render block of type [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudiosourcenoderenderblock], and [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auaudiounit] provides a render block of type [https:\/\/developer.apple.com\/documentation\/audiotoolbox\/auinternalrenderblock].\n\n```obj-c\n@interface SignalGenerator : NSObject\n\n\/\/ The block this class provides to implement rendering. Similar to `AUInternalRenderBlock`.\n@property (nonatomic, readonly) AVAudioSourceNodeRenderBlock renderBlock;\n\n...\n\n@end\n```\n\n## Connect the user interface to the signal generator\n\nThe user interface is a [https:\/\/developer.apple.com\/documentation\/swiftui\/view] that observes a property of type `AudioManager`. The audio manager class, in turn, implements the [https:\/\/developer.apple.com\/documentation\/observation\/observable] protocol, and is responsible for maintaining the state of the user interface.\n\nThe audio manager exposes properties that control the waveform, frequency, and amplitude of the signal generator, and provides methods to start and stop the [https:\/\/developer.apple.com\/documentation\/avfaudio\/avaudioengine].\n\n```swift\nvar waveform: Waveform = .sine {\n    willSet {\n        signalGenerator.setWaveform(newValue)\n    }\n}\n    \nvar frequency: Float = 440.0 {\n    willSet {\n        signalGenerator.setFrequency(newValue)\n    }\n}\n    \nvar amplitude: Float = -12.0 {\n    willSet {\n        signalGenerator.setAmplitude(newValue)\n    }\n}\n```\n\n## Rendering\n\n- **Performing offline audio processing**: Add offline audio processing features to your app by enabling offline manual rendering mode.\n- **AVAudioSourceNode**: An object that supplies audio data.\n- **AVAudioSinkNode**: An object that receives audio data.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Add offline audio processing features to your app by enabling offline manual rendering mode.",
          "name" : "Performing offline audio processing",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/performing-offline-audio-processing"
        },
        {
          "description" : "An object that supplies audio data.",
          "name" : "AVAudioSourceNode",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioSourceNode"
        },
        {
          "description" : "An object that receives audio data.",
          "name" : "AVAudioSinkNode",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVAudioSinkNode"
        }
      ],
      "title" : "Rendering"
    }
  ],
  "source" : "appleJSON",
  "title" : "Building a signal generator",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/building-a-signal-generator"
}