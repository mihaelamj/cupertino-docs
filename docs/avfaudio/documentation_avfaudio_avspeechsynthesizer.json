{
  "abstract" : "An object that produces synthesized speech from text utterances and enables monitoring or controlling of ongoing speech.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "18b5767e8ff766379cd98e927a1da36a36611657a7281b067654cb6d317d934d",
  "crawledAt" : "2025-12-05T08:20:39Z",
  "declaration" : {
    "code" : "class AVSpeechSynthesizer",
    "language" : "swift"
  },
  "id" : "018CD859-4078-4668-B4A1-99050F34A42C",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFAudio",
  "overview" : "## Overview\n\nTo speak some text, create an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechUtterance] instance that contains the text and pass it to [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/speak(_:)] on a speech synthesizer instance. You can optionally also retrieve an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesisVoice] and set it on the utterance’s [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechUtterance\/voice] property to have the speech synthesizer use that voice when speaking the utterance’s text.\n\nThe speech synthesizer maintains a queue of utterances that it speaks. If the synthesizer isn’t speaking, calling [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/speak(_:)] begins speaking that utterance either immediately or after pausing for its [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechUtterance\/preUtteranceDelay], if necessary. If the synthesizer is speaking, the synthesizer adds utterances to a queue and speaks them in the order it receives them.\n\nAfter speech begins, you can use the synthesizer object to pause or stop speech. After pausing, you can resume the speech from its paused point or stop the speech entirely and remove all remaining utterances in the queue.\n\nYou can monitor the speech synthesizer by examining its [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/isSpeaking] and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/isPaused] properties, or by setting a delegate that conforms to [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizerDelegate]. The delegate receives significant events as they occur during speech synthesis.\n\nAn `AVSpeechSynthesizer` also controls the route where the speech plays. For more information, see Directing speech output.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/avfaudio\/avspeechsynthesizer\ncrawled: 2025-12-05T08:20:39Z\n---\n\n# AVSpeechSynthesizer\n\n**Class**\n\nAn object that produces synthesized speech from text utterances and enables monitoring or controlling of ongoing speech.\n\n## Declaration\n\n```swift\nclass AVSpeechSynthesizer\n```\n\n## Overview\n\nTo speak some text, create an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechUtterance] instance that contains the text and pass it to [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/speak(_:)] on a speech synthesizer instance. You can optionally also retrieve an [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesisVoice] and set it on the utterance’s [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechUtterance\/voice] property to have the speech synthesizer use that voice when speaking the utterance’s text.\n\nThe speech synthesizer maintains a queue of utterances that it speaks. If the synthesizer isn’t speaking, calling [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/speak(_:)] begins speaking that utterance either immediately or after pausing for its [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechUtterance\/preUtteranceDelay], if necessary. If the synthesizer is speaking, the synthesizer adds utterances to a queue and speaks them in the order it receives them.\n\nAfter speech begins, you can use the synthesizer object to pause or stop speech. After pausing, you can resume the speech from its paused point or stop the speech entirely and remove all remaining utterances in the queue.\n\nYou can monitor the speech synthesizer by examining its [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/isSpeaking] and [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizer\/isPaused] properties, or by setting a delegate that conforms to [doc:\/\/com.apple.avfaudio\/documentation\/AVFAudio\/AVSpeechSynthesizerDelegate]. The delegate receives significant events as they occur during speech synthesis.\n\nAn `AVSpeechSynthesizer` also controls the route where the speech plays. For more information, see Directing speech output.\n\n\n\n## Controlling speech\n\n- **speak(_:)**: Adds the utterance you specify to the speech synthesizer’s queue.\n- **continueSpeaking()**: Resumes speech from its paused point.\n- **pauseSpeaking(at:)**: Pauses speech at the boundary you specify.\n- **stopSpeaking(at:)**: Stops speech at the boundary you specify.\n- **AVSpeechBoundary**: Specifies when to pause or stop speech.\n\n## Inspecting a speech synthesizer\n\n- **isSpeaking**: A Boolean value that indicates whether the speech synthesizer is speaking or is in a paused state and has utterances to speak.\n- **isPaused**: A Boolean value that indicates whether a speech synthesizer is in a paused state.\n\n## Managing the delegate\n\n- **delegate**: The delegate object for the speech synthesizer.\n- **AVSpeechSynthesizerDelegate**: A delegate protocol that contains optional methods you can implement to respond to events that occur during speech synthesis.\n\n## Directing speech output\n\n- **usesApplicationAudioSession**: A Boolean value that specifies whether the app manages the audio session.\n- **mixToTelephonyUplink**: A Boolean value that specifies whether to send synthesized speech to an active call.\n- **outputChannels**: An array of audio session channels to route generated speech.\n- **write(_:toBufferCallback:)**: Generates speech for the utterance and invokes the callback with the audio buffer.\n- **AVSpeechSynthesizer.BufferCallback**: A type that defines a callback that receives a buffer of generated speech.\n- **write(_:toBufferCallback:toMarkerCallback:)**: Generates audio buffers and associated metadata for storage or further speech synthesis processing.\n- **AVSpeechSynthesizer.MarkerCallback**: A type that defines a callback that receives speech markers.\n\n## Enabling personal voices\n\n- **personalVoiceAuthorizationStatus**: Your app’s authorization to use personal voices.\n- **availableVoicesDidChangeNotification**: A notification that indicates a change in available voices for speech synthesis.\n- **requestPersonalVoiceAuthorization(completionHandler:)**: Prompts the user to authorize your app to use personal voices.\n- **AVSpeechSynthesizer.PersonalVoiceAuthorizationStatus**: An enumeration that models the personal voices authorization status.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Adds the utterance you specify to the speech synthesizer’s queue.",
          "name" : "speak(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/speak(_:)"
        },
        {
          "description" : "Resumes speech from its paused point.",
          "name" : "continueSpeaking()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/continueSpeaking()"
        },
        {
          "description" : "Pauses speech at the boundary you specify.",
          "name" : "pauseSpeaking(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/pauseSpeaking(at:)"
        },
        {
          "description" : "Stops speech at the boundary you specify.",
          "name" : "stopSpeaking(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/stopSpeaking(at:)"
        },
        {
          "description" : "Specifies when to pause or stop speech.",
          "name" : "AVSpeechBoundary",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechBoundary"
        }
      ],
      "title" : "Controlling speech"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the speech synthesizer is speaking or is in a paused state and has utterances to speak.",
          "name" : "isSpeaking",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/isSpeaking"
        },
        {
          "description" : "A Boolean value that indicates whether a speech synthesizer is in a paused state.",
          "name" : "isPaused",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/isPaused"
        }
      ],
      "title" : "Inspecting a speech synthesizer"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The delegate object for the speech synthesizer.",
          "name" : "delegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/delegate"
        },
        {
          "description" : "A delegate protocol that contains optional methods you can implement to respond to events that occur during speech synthesis.",
          "name" : "AVSpeechSynthesizerDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizerDelegate"
        }
      ],
      "title" : "Managing the delegate"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that specifies whether the app manages the audio session.",
          "name" : "usesApplicationAudioSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/usesApplicationAudioSession"
        },
        {
          "description" : "A Boolean value that specifies whether to send synthesized speech to an active call.",
          "name" : "mixToTelephonyUplink",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/mixToTelephonyUplink"
        },
        {
          "description" : "An array of audio session channels to route generated speech.",
          "name" : "outputChannels",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/outputChannels"
        },
        {
          "description" : "Generates speech for the utterance and invokes the callback with the audio buffer.",
          "name" : "write(_:toBufferCallback:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/write(_:toBufferCallback:)"
        },
        {
          "description" : "A type that defines a callback that receives a buffer of generated speech.",
          "name" : "AVSpeechSynthesizer.BufferCallback",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/BufferCallback"
        },
        {
          "description" : "Generates audio buffers and associated metadata for storage or further speech synthesis processing.",
          "name" : "write(_:toBufferCallback:toMarkerCallback:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/write(_:toBufferCallback:toMarkerCallback:)"
        },
        {
          "description" : "A type that defines a callback that receives speech markers.",
          "name" : "AVSpeechSynthesizer.MarkerCallback",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/MarkerCallback"
        }
      ],
      "title" : "Directing speech output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Your app’s authorization to use personal voices.",
          "name" : "personalVoiceAuthorizationStatus",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/personalVoiceAuthorizationStatus-swift.type.property"
        },
        {
          "description" : "A notification that indicates a change in available voices for speech synthesis.",
          "name" : "availableVoicesDidChangeNotification",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/availableVoicesDidChangeNotification"
        },
        {
          "description" : "Prompts the user to authorize your app to use personal voices.",
          "name" : "requestPersonalVoiceAuthorization(completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/requestPersonalVoiceAuthorization(completionHandler:)"
        },
        {
          "description" : "An enumeration that models the personal voices authorization status.",
          "name" : "AVSpeechSynthesizer.PersonalVoiceAuthorizationStatus",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFAudio\/AVSpeechSynthesizer\/PersonalVoiceAuthorizationStatus-swift.enum"
        }
      ],
      "title" : "Enabling personal voices"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVSpeechSynthesizer",
  "url" : "https:\/\/developer.apple.com\/documentation\/avfaudio\/avspeechsynthesizer"
}