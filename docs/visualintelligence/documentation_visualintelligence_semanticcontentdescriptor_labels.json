{
  "abstract" : "A list of labels that visual intelligence uses to classify items onscreen or visual intelligence camera.",
  "codeExamples" : [

  ],
  "contentHash" : "59807d0e07f7657434bb1910b5c091e42a14e636155ae31a04d412bb24541490",
  "crawledAt" : "2025-12-02T16:55:19Z",
  "declaration" : {
    "code" : "let labels: [String]",
    "language" : "swift"
  },
  "id" : "E40E5E21-AFF9-428D-97B2-E96D3741B064",
  "kind" : "property",
  "language" : "swift",
  "module" : "Visual Intelligence",
  "overview" : "## Discussion\n\nVisual Intelligence defines the possible label values. Use them to search for content in your app and return matching content to visual search.",
  "platforms" : [
    "iOS",
    "iPadOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/VisualIntelligence\/SemanticContentDescriptor\/labels\ncrawled: 2025-12-02T16:55:19Z\n---\n\n# labels\n\n**Instance Property**\n\nA list of labels that visual intelligence uses to classify items onscreen or visual intelligence camera.\n\n## Declaration\n\n```swift\nlet labels: [String]\n```\n\n## Discussion\n\nVisual Intelligence defines the possible label values. Use them to search for content in your app and return matching content to visual search.\n\n\n\n## Accessing semantic content\n\n- **pixelBuffer**: The pixel buffer that visual intelligence captures.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The pixel buffer that visual intelligence captures.",
          "name" : "pixelBuffer",
          "url" : "https:\/\/developer.apple.com\/documentation\/VisualIntelligence\/SemanticContentDescriptor\/pixelBuffer"
        }
      ],
      "title" : "Accessing semantic content"
    }
  ],
  "source" : "appleJSON",
  "title" : "labels",
  "url" : "https:\/\/developer.apple.com\/documentation\/VisualIntelligence\/SemanticContentDescriptor\/labels"
}