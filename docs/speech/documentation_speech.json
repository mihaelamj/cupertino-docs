{
  "abstract" : "Perform speech recognition on live or prerecorded audio, and receive transcriptions, alternative interpretations, and confidence levels of the results.",
  "codeExamples" : [

  ],
  "contentHash" : "0dd2a79259f9181e8130266d60cf1d59a279e5605fe78b5ae0f6910793a1d975",
  "crawledAt" : "2025-12-03T07:15:12Z",
  "id" : "CF21396D-4B40-4918-8A0D-5973CAC40F5F",
  "kind" : "framework",
  "language" : "swift",
  "module" : "Speech",
  "overview" : "## Overview\n\nUse the Speech framework to recognize spoken words in recorded or live audio. The keyboard’s dictation support uses speech recognition to translate audio content into text. This framework provides a similar behavior, except that you can use it without the presence of the keyboard. For example, you might use speech recognition to recognize verbal commands or to handle text dictation in other parts of your app.\n\nThe [doc:\/\/com.apple.speech\/documentation\/Speech\/SpeechTranscriber] class and other module classes provide specific services. The [doc:\/\/com.apple.speech\/documentation\/Speech\/AssetInventory] class ensures that the system has the assets necessary to support those classes. The [doc:\/\/com.apple.speech\/documentation\/Speech\/SpeechAnalyzer] class manages an analysis session that uses those classes.\n\nFor a general understanding of how you use these classes together, see [doc:\/\/com.apple.speech\/documentation\/Speech\/SpeechAnalyzer].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/speech\ncrawled: 2025-12-03T07:15:12Z\n---\n\n# Speech\n\n**Framework**\n\nPerform speech recognition on live or prerecorded audio, and receive transcriptions, alternative interpretations, and confidence levels of the results.\n\n## Overview\n\nUse the Speech framework to recognize spoken words in recorded or live audio. The keyboard’s dictation support uses speech recognition to translate audio content into text. This framework provides a similar behavior, except that you can use it without the presence of the keyboard. For example, you might use speech recognition to recognize verbal commands or to handle text dictation in other parts of your app.\n\nThe [doc:\/\/com.apple.speech\/documentation\/Speech\/SpeechTranscriber] class and other module classes provide specific services. The [doc:\/\/com.apple.speech\/documentation\/Speech\/AssetInventory] class ensures that the system has the assets necessary to support those classes. The [doc:\/\/com.apple.speech\/documentation\/Speech\/SpeechAnalyzer] class manages an analysis session that uses those classes.\n\nFor a general understanding of how you use these classes together, see [doc:\/\/com.apple.speech\/documentation\/Speech\/SpeechAnalyzer].\n\n## Essentials\n\n- **Bringing advanced speech-to-text capabilities to your app**: Learn how to incorporate live speech-to-text transcription into your app with SpeechAnalyzer.\n- **SpeechAnalyzer**: Analyzes spoken audio content in various ways and manages the analysis session.\n- **AssetInventory**: Manages the assets that are necessary for transcription or other analyses.\n\n## Modules\n\n- **SpeechTranscriber**: A speech-to-text transcription module that’s appropriate for normal conversation and general purposes.\n- **DictationTranscriber**: A speech-to-text transcription module that’s similar to system dictation features and compatible with older devices.\n- **SpeechDetector**: A module that performs a voice activity detection (VAD) analysis.\n- **SpeechModule**: Protocol that all analyzer modules conform to.\n- **LocaleDependentSpeechModule**: A module that requires locale-specific assets.\n\n## Input and output\n\n- **AnalyzerInput**: Time-coded audio data.\n- **SpeechModuleResult**: Protocol that all module results conform to.\n\n## Custom vocabulary\n\n- **AnalysisContext**: Contextual information that may be shared among analyzers.\n- **SFSpeechLanguageModel**: A language model built from custom training data.\n- **SFSpeechLanguageModel.Configuration**: An object describing the location of a custom language model and specialized vocabulary.\n- **SFCustomLanguageModelData**: An object that generates and exports custom language model training data.\n\n## Asset and resource management\n\n- **AssetInstallationRequest**: An object that describes, downloads, and installs a selection of assets.\n- **SpeechModels**: Namespace for methods related to model management.\n\n## Legacy API\n\n- **Speech Recognition in Objective-C**: Use these classes to perform speech recognition in Objective-C code.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Learn how to incorporate live speech-to-text transcription into your app with SpeechAnalyzer.",
          "name" : "Bringing advanced speech-to-text capabilities to your app",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/bringing-advanced-speech-to-text-capabilities-to-your-app"
        },
        {
          "description" : "Analyzes spoken audio content in various ways and manages the analysis session.",
          "name" : "SpeechAnalyzer",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SpeechAnalyzer"
        },
        {
          "description" : "Manages the assets that are necessary for transcription or other analyses.",
          "name" : "AssetInventory",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/AssetInventory"
        }
      ],
      "title" : "Essentials"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A speech-to-text transcription module that’s appropriate for normal conversation and general purposes.",
          "name" : "SpeechTranscriber",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SpeechTranscriber"
        },
        {
          "description" : "A speech-to-text transcription module that’s similar to system dictation features and compatible with older devices.",
          "name" : "DictationTranscriber",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/DictationTranscriber"
        },
        {
          "description" : "A module that performs a voice activity detection (VAD) analysis.",
          "name" : "SpeechDetector",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SpeechDetector"
        },
        {
          "description" : "Protocol that all analyzer modules conform to.",
          "name" : "SpeechModule",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SpeechModule"
        },
        {
          "description" : "A module that requires locale-specific assets.",
          "name" : "LocaleDependentSpeechModule",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/LocaleDependentSpeechModule"
        }
      ],
      "title" : "Modules"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Time-coded audio data.",
          "name" : "AnalyzerInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/AnalyzerInput"
        },
        {
          "description" : "Protocol that all module results conform to.",
          "name" : "SpeechModuleResult",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SpeechModuleResult"
        }
      ],
      "title" : "Input and output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Contextual information that may be shared among analyzers.",
          "name" : "AnalysisContext",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/AnalysisContext"
        },
        {
          "description" : "A language model built from custom training data.",
          "name" : "SFSpeechLanguageModel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SFSpeechLanguageModel"
        },
        {
          "description" : "An object describing the location of a custom language model and specialized vocabulary.",
          "name" : "SFSpeechLanguageModel.Configuration",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SFSpeechLanguageModel\/Configuration"
        },
        {
          "description" : "An object that generates and exports custom language model training data.",
          "name" : "SFCustomLanguageModelData",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SFCustomLanguageModelData"
        }
      ],
      "title" : "Custom vocabulary"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that describes, downloads, and installs a selection of assets.",
          "name" : "AssetInstallationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/AssetInstallationRequest"
        },
        {
          "description" : "Namespace for methods related to model management.",
          "name" : "SpeechModels",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/SpeechModels"
        }
      ],
      "title" : "Asset and resource management"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use these classes to perform speech recognition in Objective-C code.",
          "name" : "Speech Recognition in Objective-C",
          "url" : "https:\/\/developer.apple.com\/documentation\/Speech\/speech-recognition-in-objc"
        }
      ],
      "title" : "Legacy API"
    }
  ],
  "source" : "appleJSON",
  "title" : "Speech",
  "url" : "https:\/\/developer.apple.com\/documentation\/speech"
}