{
  "abstract" : "Provides a result that indicates if the video file contains sensitive content.",
  "codeExamples" : [

  ],
  "contentHash" : "5513933dde65c6f84b99bfb45ae28c589b1472c107559e3d0cc15af8dfe9ce8c",
  "crawledAt" : "2025-12-05T12:46:09Z",
  "declaration" : {
    "code" : "final func hasSensitiveContent() async throws -> SCSensitivityAnalysis",
    "language" : "swift"
  },
  "id" : "B5C01467-1ADB-4F8C-93E2-13564554AD9F",
  "kind" : "method",
  "language" : "swift",
  "module" : "SensitiveContentAnalysis",
  "overview" : "## Return Value\n\nAn object that indicates if checked content contains nudity.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/VideoAnalysisHandler\/hasSensitiveContent()\ncrawled: 2025-12-05T12:46:09Z\n---\n\n# hasSensitiveContent()\n\n**Instance Method**\n\nProvides a result that indicates if the video file contains sensitive content.\n\n## Declaration\n\n```swift\nfinal func hasSensitiveContent() async throws -> SCSensitivityAnalysis\n```\n\n## Return Value\n\nAn object that indicates if checked content contains nudity.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "hasSensitiveContent()",
  "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/VideoAnalysisHandler\/hasSensitiveContent()"
}