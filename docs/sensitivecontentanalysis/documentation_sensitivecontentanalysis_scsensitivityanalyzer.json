{
  "abstract" : "An object that analyzes media for sensitive content.",
  "codeExamples" : [
    {
      "code" : "\/\/ Analyze an image file at a particular URL.\nlet response = try await analyzer.analyzeImage(at: url)",
      "language" : "swift"
    },
    {
      "code" : "let handler = analyzer.videoAnalysis(forFileAt: videoFileUrl)\nlet response = try await handler.hasSensitiveContent()",
      "language" : "swift"
    }
  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "e24fc1d9cbe3d795c4fbc2b958daac25e11088d07c9fbe20165063d246467c99",
  "crawledAt" : "2025-12-03T04:00:55Z",
  "declaration" : {
    "code" : "class SCSensitivityAnalyzer",
    "language" : "swift"
  },
  "id" : "E9E1BA2B-1D9F-4249-A08F-B154ECDDBC58",
  "kind" : "class",
  "language" : "swift",
  "module" : "SensitiveContentAnalysis",
  "overview" : "## Overview\n\nTo check an image for nudity, call one of this class’s `analyzeImage` methods and pass in a user-provided image, or a URL to the image.\n\nTo analyze a video file, pass a URL to a video on disk into [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/videoAnalysis(forFileAt:)] and wait for the [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/VideoAnalysisHandler\/hasSensitiveContent()] method to complete.\n\nThis class successfully detects nudity only when [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy] is a value other than [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalysisPolicy\/disabled].",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\ncrawled: 2025-12-03T04:00:55Z\n---\n\n# SCSensitivityAnalyzer\n\n**Class**\n\nAn object that analyzes media for sensitive content.\n\n## Declaration\n\n```swift\nclass SCSensitivityAnalyzer\n```\n\n## Overview\n\nTo check an image for nudity, call one of this class’s `analyzeImage` methods and pass in a user-provided image, or a URL to the image.\n\n```swift\n\/\/ Analyze an image file at a particular URL.\nlet response = try await analyzer.analyzeImage(at: url)\n```\n\nTo analyze a video file, pass a URL to a video on disk into [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/videoAnalysis(forFileAt:)] and wait for the [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/VideoAnalysisHandler\/hasSensitiveContent()] method to complete.\n\n```swift\nlet handler = analyzer.videoAnalysis(forFileAt: videoFileUrl)\nlet response = try await handler.hasSensitiveContent()\n```\n\nThis class successfully detects nudity only when [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy] is a value other than [doc:\/\/com.apple.SensitiveContentAnalysis\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalysisPolicy\/disabled].\n\n\n\n## Creating a sensitivity analyzer\n\n- **init()**: Creates a sensitivity analyzer.\n\n## Determining a nudity detection strategy\n\n- **analysisPolicy**: A property that determines if the app detects nudity and how the app responds.\n\n## Analyzing images\n\n- **analyzeImage(_:completionHandler:)**: Analyzes an image for sensitive content and runs code on completion.\n- **analyzeImage(at:completionHandler:)**: Analyzes an image file on disk at a URL and runs code on completion.\n\n## Analyzing video\n\n- **videoAnalysis(forFileAt:)**: Analyzes a video file on disk at a URL for sensitive content.\n- **SCSensitivityAnalyzer.VideoAnalysisHandler**: An object that checks if a video contains sensitive content and provides status updates.\n\n## Image and video file analysis\n\n- **SCSensitivityAnalysisPolicy**: Configurations that represent the way the framework checks for sensitive content and how the app responds.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a sensitivity analyzer.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/init()"
        }
      ],
      "title" : "Creating a sensitivity analyzer"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A property that determines if the app detects nudity and how the app responds.",
          "name" : "analysisPolicy",
          "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy"
        }
      ],
      "title" : "Determining a nudity detection strategy"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Analyzes an image for sensitive content and runs code on completion.",
          "name" : "analyzeImage(_:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analyzeImage(_:completionHandler:)"
        },
        {
          "description" : "Analyzes an image file on disk at a URL and runs code on completion.",
          "name" : "analyzeImage(at:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analyzeImage(at:completionHandler:)"
        }
      ],
      "title" : "Analyzing images"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Analyzes a video file on disk at a URL for sensitive content.",
          "name" : "videoAnalysis(forFileAt:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/videoAnalysis(forFileAt:)"
        },
        {
          "description" : "An object that checks if a video contains sensitive content and provides status updates.",
          "name" : "SCSensitivityAnalyzer.VideoAnalysisHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/VideoAnalysisHandler"
        }
      ],
      "title" : "Analyzing video"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Configurations that represent the way the framework checks for sensitive content and how the app responds.",
          "name" : "SCSensitivityAnalysisPolicy",
          "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalysisPolicy"
        }
      ],
      "title" : "Image and video file analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "SCSensitivityAnalyzer",
  "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer"
}