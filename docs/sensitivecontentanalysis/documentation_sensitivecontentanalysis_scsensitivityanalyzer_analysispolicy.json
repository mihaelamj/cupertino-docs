{
  "abstract" : "A property that determines if the app detects nudity and how the app responds.",
  "codeExamples" : [

  ],
  "contentHash" : "e05f2f036f4cb8506cce2ec3072b4b3d4d4b28d9dbe8da825ba98970841c8d5e",
  "crawledAt" : "2025-12-02T06:20:20Z",
  "declaration" : {
    "code" : "var analysisPolicy: SCSensitivityAnalysisPolicy { get }",
    "language" : "swift"
  },
  "id" : "1201DA34-D2E8-4148-91D9-9FEA2E2CFC37",
  "kind" : "unknown",
  "overview" : "SCSensitivityAnalyzer  analysisPolicy Instance PropertyanalysisPolicyA property that determines if the app detects nudity and how the app responds.iOS 17.0+iPadOS 17.0+Mac Catalyst 17.0+macOS 14.0+visionOS 2.0+var analysisPolicy: SCSensitivityAnalysisPolicy { get } Mentioned in  Detecting nudity in media and providing intervention options DiscussionBefore attempting to use the framework, first check the analysisPolicy:\n\nlet policy = analyzer.analysisPolicy\nif policy == .disabled { return }\nAn app can utilize the SensitiveContentAnalysis framework when the system sets the value of this property to either:\n\nSCSensitivityAnalysisPolicy.simpleInterventions, which indicates that a user activates the Communication Safety parental control in Screen Time.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy\ncrawled: 2025-12-02T06:20:20Z\n---\n\n# analysisPolicy | Apple Developer Documentation\n\n- [ SensitiveContentAnalysis ](\/documentation\/sensitivecontentanalysis)\n\n- [ SCSensitivityAnalyzer ](\/documentation\/sensitivecontentanalysis\/scsensitivityanalyzer)\n\n- [ analysisPolicy ](\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy)\n\n- [ SCSensitivityAnalyzer ](\/documentation\/sensitivecontentanalysis\/scsensitivityanalyzer)\n\n-  analysisPolicy \n\nInstance Property# analysisPolicy\n\nA property that determines if the app detects nudity and how the app responds.iOS 17.0+iPadOS 17.0+Mac Catalyst 17.0+macOS 14.0+visionOS 2.0+\n\n```\nvar analysisPolicy: SCSensitivityAnalysisPolicy { get }\n```\n\n## [ Mentioned in ](\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy#mentions)\n\n[ Detecting nudity in media and providing intervention options ](\/documentation\/sensitivecontentanalysis\/detecting-nudity-in-media-and-providing-intervention-options)## [Discussion](\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy#discussion)\n\nBefore attempting to use the framework, first check the [`analysisPolicy`](\/documentation\/sensitivecontentanalysis\/scsensitivityanalyzer\/analysispolicy):\n\n\n\n```\nlet policy = analyzer.analysisPolicy\nif policy == .disabled { return }\n\n```\n\nAn app can utilize the SensitiveContentAnalysis framework when the system sets the value of this property to either:\n\n- [`SCSensitivityAnalysisPolicy.simpleInterventions`](\/documentation\/sensitivecontentanalysis\/scsensitivityanalysispolicy\/simpleinterventions), which indicates that a user activates the Communication Safety parental control in Screen Time.\n\n- [`SCSensitivityAnalysisPolicy.descriptiveInterventions`](\/documentation\/sensitivecontentanalysis\/scsensitivityanalysispolicy\/descriptiveinterventions), which indicates that the user activates the Sensitive Content Warning user preference.\n\nThe framework wonâ€™t detect nudity if the system disables this property. For more information on why the system disables sensitive content analysis, see [`SCSensitivityAnalysisPolicy.disabled`](\/documentation\/sensitivecontentanalysis\/scsensitivityanalysispolicy\/disabled).",
  "sections" : [
    {
      "content" : "",
      "title" : "Mentioned in"
    },
    {
      "content" : "",
      "title" : "Discussion"
    }
  ],
  "source" : "appleWebKit",
  "title" : "analysisPolicy | Apple Developer Documentation",
  "url" : "https:\/\/developer.apple.com\/documentation\/SensitiveContentAnalysis\/SCSensitivityAnalyzer\/analysisPolicy"
}