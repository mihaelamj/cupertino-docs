{
  "abstract" : "Construct virtual objects to use in your AR experiences.",
  "codeExamples" : [
    {
      "code" : "guard PhotogrammetrySession.isSupported else {\n    \/\/ Inform user and don't proceed with reconstruction.\n}",
      "language" : "swift"
    },
    {
      "code" : "let inputFolderUrl = URL(fileURLWithPath: \"\/tmp\/MyInputImages\/\")\nlet url = URL(fileURLWithPath: \"MyObject.usdz\")\nvar request = PhotogrammetrySession.Request.modelFile(url: url, \n                                                      detail: .full)\nguard let session = try PhotogrammetrySession(input: inputFolderUrl) else {\n    return \n} ",
      "language" : "swift"
    },
    {
      "code" : "let waiter = async {\n    do {\n        for try await output in session.outputs {\n            switch output {\n                case .processingComplete:\n                    \/\/ RealityKit has processed all requests.\n                case .requestError(let request, let error):\n                    \/\/ Request encountered an error.\n                case .requestComplete(let request, let result):\n                    \/\/ RealityKit has finished processing a request.\n                case .requestProgress(let request, let fractionComplete):\n                    \/\/ Periodic progress update. Update UI here.\n                case .inputComplete: \n                    \/\/ Ingestion of images is complete and processing begins.\n                case .invalidSample(let id, let reason):\n                    \/\/ RealityKit deemed a sample invalid and didn't use it.\n                case .skippedSample(let id):\n                    \/\/ RealityKit was unable to use a provided sample.\n                case .automaticDownsampling:\n                    \/\/ RealityKit downsampled the input images because of\n                    \/\/ resource constraints.\n                case .processingCancelled\n                    \/\/ Processing was canceled.\n                @unknown default:\n                    \/\/ Unrecognized output.\n            }\n        }\n    } catch {\n        print(\"Output: ERROR = \\(String(describing: error))\")\n        \/\/ Handle error.\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "session.process(requests: [request])",
      "language" : "swift"
    },
    {
      "code" : "let config = Configuration()\n\n\/\/ Use slower, more sensitive landmark detection.\nconfig.featureSensitivity = .high\n\/\/ Adjacent images are next to each other.\nconfig.sampleOrdering = .sequential\n\/\/ Object masking is enabled.\nconfig.isObjectMaskingEnabled = true\n\nlet session = try PhotogrammetrySession(input: inputFolderUrl, \n                                        configuration:config)",
      "language" : "swift"
    }
  ],
  "contentHash" : "7a13668869108e7775f6087ed8148efc7a14c88a704f5ff73a8062e096f525a8",
  "crawledAt" : "2025-12-02T15:54:46Z",
  "id" : "56564DCD-D482-4A3A-970F-42D1C30AB0FB",
  "kind" : "article",
  "language" : "swift",
  "module" : "RealityKit",
  "overview" : "## Overview\n\nIn iOS 17 and later, and macOS 12 and later, to create a 3D object from a series of photographs, submit the images to RealityKit using a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession], register to receive status updates, and start the session. The completed process produces a 3D representation of the photographed object that you can use in your app or export to other software like *Reality Composer*.\n\nFor more information on capturing high-quality images for photogrammetry, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/capturing-photographs-for-realitykit-object-capture].\n\n### Check for availability\n\nRealityKit Object Capture is only available on Mac computers that meet the minimum requirements for performing object reconstruction, including a GPU with at least 4 GB of RAM and ray tracing support. It is also available on select iOS devices with LiDAR capabilities.\n\nBefore using any Object Capture APIs, check whether the device your code is running on meets those requirements, and only proceed if it does.\n\n### Create the photogrammetry session\n\nBegin by creating a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/Request] with a URL that points to the desired output location for the generated USDZ file and the desired level of detail for the model. Next, use that request, along with a URL pointing to the directory containing your images, to create the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession] object.\n\n### Listen for updates and begin creation\n\nRealityKit uses an [doc:\/\/com.apple.documentation\/documentation\/Swift\/AsyncSequence] of [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/Output] objects to deliver status updates about the object-creation process in the background. To update your app’s UI or to take other actions as a result of these status updates, create an `async` task and use a `for`-`try`-`await` loop on [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/outputs-swift.property].\n\nOnce you’ve created a session and registered to receive status updates, start the object-creation process by calling [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/process(requests:)]. RealityKit processes the photographs in the background and notifies your app when the process completes or fails.\n\n### Compensate for challenging images\n\nRealityKit’s default photogrammetry settings work for the vast majority of input images. If, however, you have image sets that are low contrast or lack many identifying landmarks, you can override the default values to compensate by creating a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/Configuration-swift.struct] object and passing it into the initializer when you create your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession].\n\nTo simplify the object-creation process, you can use a custom configuration to provide images to the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession] in sequence by listing adjacent images together, or to control support for object masking, which blocks out portions of an image around an object.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/RealityKit\/creating-3d-objects-from-photographs\ncrawled: 2025-12-02T15:54:46Z\n---\n\n# Creating 3D objects from photographs\n\n**Article**\n\nConstruct virtual objects to use in your AR experiences.\n\n## Overview\n\nIn iOS 17 and later, and macOS 12 and later, to create a 3D object from a series of photographs, submit the images to RealityKit using a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession], register to receive status updates, and start the session. The completed process produces a 3D representation of the photographed object that you can use in your app or export to other software like *Reality Composer*.\n\nFor more information on capturing high-quality images for photogrammetry, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/capturing-photographs-for-realitykit-object-capture].\n\n### Check for availability\n\nRealityKit Object Capture is only available on Mac computers that meet the minimum requirements for performing object reconstruction, including a GPU with at least 4 GB of RAM and ray tracing support. It is also available on select iOS devices with LiDAR capabilities.\n\nBefore using any Object Capture APIs, check whether the device your code is running on meets those requirements, and only proceed if it does.\n\n```swift\nguard PhotogrammetrySession.isSupported else {\n    \/\/ Inform user and don't proceed with reconstruction.\n}\n```\n\n### Create the photogrammetry session\n\nBegin by creating a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/Request] with a URL that points to the desired output location for the generated USDZ file and the desired level of detail for the model. Next, use that request, along with a URL pointing to the directory containing your images, to create the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession] object.\n\n```swift\nlet inputFolderUrl = URL(fileURLWithPath: \"\/tmp\/MyInputImages\/\")\nlet url = URL(fileURLWithPath: \"MyObject.usdz\")\nvar request = PhotogrammetrySession.Request.modelFile(url: url, \n                                                      detail: .full)\nguard let session = try PhotogrammetrySession(input: inputFolderUrl) else {\n    return \n} \n```\n\n### Listen for updates and begin creation\n\nRealityKit uses an [doc:\/\/com.apple.documentation\/documentation\/Swift\/AsyncSequence] of [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/Output] objects to deliver status updates about the object-creation process in the background. To update your app’s UI or to take other actions as a result of these status updates, create an `async` task and use a `for`-`try`-`await` loop on [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/outputs-swift.property].\n\n```swift\nlet waiter = async {\n    do {\n        for try await output in session.outputs {\n            switch output {\n                case .processingComplete:\n                    \/\/ RealityKit has processed all requests.\n                case .requestError(let request, let error):\n                    \/\/ Request encountered an error.\n                case .requestComplete(let request, let result):\n                    \/\/ RealityKit has finished processing a request.\n                case .requestProgress(let request, let fractionComplete):\n                    \/\/ Periodic progress update. Update UI here.\n                case .inputComplete: \n                    \/\/ Ingestion of images is complete and processing begins.\n                case .invalidSample(let id, let reason):\n                    \/\/ RealityKit deemed a sample invalid and didn't use it.\n                case .skippedSample(let id):\n                    \/\/ RealityKit was unable to use a provided sample.\n                case .automaticDownsampling:\n                    \/\/ RealityKit downsampled the input images because of\n                    \/\/ resource constraints.\n                case .processingCancelled\n                    \/\/ Processing was canceled.\n                @unknown default:\n                    \/\/ Unrecognized output.\n            }\n        }\n    } catch {\n        print(\"Output: ERROR = \\(String(describing: error))\")\n        \/\/ Handle error.\n    }\n}\n```\n\nOnce you’ve created a session and registered to receive status updates, start the object-creation process by calling [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/process(requests:)]. RealityKit processes the photographs in the background and notifies your app when the process completes or fails.\n\n```swift\nsession.process(requests: [request])\n```\n\n### Compensate for challenging images\n\nRealityKit’s default photogrammetry settings work for the vast majority of input images. If, however, you have image sets that are low contrast or lack many identifying landmarks, you can override the default values to compensate by creating a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession\/Configuration-swift.struct] object and passing it into the initializer when you create your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession].\n\nTo simplify the object-creation process, you can use a custom configuration to provide images to the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/PhotogrammetrySession] in sequence by listing adjacent images together, or to control support for object masking, which blocks out portions of an image around an object.\n\n```swift\nlet config = Configuration()\n\n\/\/ Use slower, more sensitive landmark detection.\nconfig.featureSensitivity = .high\n\/\/ Adjacent images are next to each other.\nconfig.sampleOrdering = .sequential\n\/\/ Object masking is enabled.\nconfig.isObjectMaskingEnabled = true\n\nlet session = try PhotogrammetrySession(input: inputFolderUrl, \n                                        configuration:config)\n```\n\n## Model creation\n\n- **Capturing photographs for RealityKit Object Capture**: Take high-quality images of objects to generate 3D models.\n- **Scanning objects using Object Capture**: Implement a full scanning workflow for capturing objects on iOS devices.\n- **Building an object reconstruction app**: Reconstruct objects from user-selected input images by using photogrammetry.\n- **Creating a photogrammetry command-line app**: Generate 3D objects from images using RealityKit Object Capture.\n- **Using object capture assets in RealityKit**: Create a chess game using RealityKit and assets created using Object Capture.\n- **PhotogrammetrySession**: Manages the creation of a 3D model from a set of images.\n- **PhotogrammetrySample**: An object that represents one image and its corresponding metadata.\n- **ObjectCaptureView**: A view that guides a user through capturing images for object capture.\n- **ObjectCaptureSession**: A session object that monitors and controls image capture for photogrammetry.\n- **ObjectCapturePointCloudView**: Renders the current state of the point cloud from an object capture session.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Take high-quality images of objects to generate 3D models.",
          "name" : "Capturing photographs for RealityKit Object Capture",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/capturing-photographs-for-realitykit-object-capture"
        },
        {
          "description" : "Implement a full scanning workflow for capturing objects on iOS devices.",
          "name" : "Scanning objects using Object Capture",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scanning-objects-using-object-capture"
        },
        {
          "description" : "Reconstruct objects from user-selected input images by using photogrammetry.",
          "name" : "Building an object reconstruction app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/building-an-object-reconstruction-app"
        },
        {
          "description" : "Generate 3D objects from images using RealityKit Object Capture.",
          "name" : "Creating a photogrammetry command-line app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/creating-a-photogrammetry-command-line-app"
        },
        {
          "description" : "Create a chess game using RealityKit and assets created using Object Capture.",
          "name" : "Using object capture assets in RealityKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/using-object-capture-assets-in-realitykit"
        },
        {
          "description" : "Manages the creation of a 3D model from a set of images.",
          "name" : "PhotogrammetrySession",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/PhotogrammetrySession"
        },
        {
          "description" : "An object that represents one image and its corresponding metadata.",
          "name" : "PhotogrammetrySample",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/PhotogrammetrySample"
        },
        {
          "description" : "A view that guides a user through capturing images for object capture.",
          "name" : "ObjectCaptureView",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ObjectCaptureView"
        },
        {
          "description" : "A session object that monitors and controls image capture for photogrammetry.",
          "name" : "ObjectCaptureSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ObjectCaptureSession"
        },
        {
          "description" : "Renders the current state of the point cloud from an object capture session.",
          "name" : "ObjectCapturePointCloudView",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ObjectCapturePointCloudView"
        }
      ],
      "title" : "Model creation"
    }
  ],
  "source" : "appleJSON",
  "title" : "Creating 3D objects from photographs",
  "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/creating-3d-objects-from-photographs"
}