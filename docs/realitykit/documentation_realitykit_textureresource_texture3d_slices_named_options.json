{
  "abstract" : "Asynchronously creates a 3D texture by generating it from images.",
  "codeExamples" : [
    {
      "code" : "\/\/ Create a 3D texture from image slices.\nlet texture3D = try await TextureResource.texture3D(\n    slices: [image0, image1, image2, image3],\n    options: TextureResource.CreateOptions(semantic: .color))\n\n\/\/ Assign the 3D texture to a compatible shader graph material parameter.\nvar material = try await ShaderGraphMaterial(\n    named: \"\/Root\/Alien\/MaterialWith3DTexture\", from: url)\n\ntry material.setParameter(\nname: \"input3DTexture\",\nvalue: .textureResource(texture3D))",
      "language" : "swift"
    }
  ],
  "contentHash" : "b959ef262d57e3fe0dd9161e6e974c16073353771e7852055d99e23368afd562",
  "crawledAt" : "2025-12-01T20:14:28Z",
  "declaration" : {
    "code" : "@MainActor @preconcurrency static func texture3D(slices: [CGImage], named resourceName: String? = nil, options: TextureResource.CreateOptions) async throws -> TextureResource",
    "language" : "swift"
  },
  "id" : "2B7785BF-615F-43D9-BA94-6BCE17BF342B",
  "kind" : "method",
  "module" : "RealityKit",
  "overview" : "## Discussion\n\nRealityKit creates a [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type3D] texture with `depth == slices.count` from an array of images.\n\nYou can assign the resulting texture to a material you create in Reality Composer Pro that requires a 3D texture.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/RealityKit\/TextureResource\/texture3D(slices:named:options:)\ncrawled: 2025-12-01T20:14:28Z\n---\n\n# texture3D(slices:named:options:)\n\n**Type Method**\n\nAsynchronously creates a 3D texture by generating it from images.\n\n## Declaration\n\n```swift\n@MainActor @preconcurrency static func texture3D(slices: [CGImage], named resourceName: String? = nil, options: TextureResource.CreateOptions) async throws -> TextureResource\n```\n\n## Parameters\n\n- **slices**: The source images, one per depth index. All images need to be square, and of equal size and format.\n- **resourceName**: A unique name for syncing the texture resource across the network. The name is empty if you donâ€™t include one.\n- **options**: A configuration for generating the texture.\n\n## Discussion\n\nRealityKit creates a [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type3D] texture with `depth == slices.count` from an array of images.\n\nYou can assign the resulting texture to a material you create in Reality Composer Pro that requires a 3D texture.\n\n```swift\n\/\/ Create a 3D texture from image slices.\nlet texture3D = try await TextureResource.texture3D(\n    slices: [image0, image1, image2, image3],\n    options: TextureResource.CreateOptions(semantic: .color))\n\n\/\/ Assign the 3D texture to a compatible shader graph material parameter.\nvar material = try await ShaderGraphMaterial(\n    named: \"\/Root\/Alien\/MaterialWith3DTexture\", from: url)\n\ntry material.setParameter(\nname: \"input3DTexture\",\nvalue: .textureResource(texture3D))\n```\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "texture3D(slices:named:options:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/TextureResource\/texture3D(slices:named:options:)"
}