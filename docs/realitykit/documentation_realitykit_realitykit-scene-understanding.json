{
  "abstract" : "Detect objects in an AR scene or create a detailed 3D reconstruction of the real-world environment.",
  "codeExamples" : [
    {
      "code" : "arView.environment.sceneUnderstanding.options.insert(.occlusion)\narView.environment.sceneUnderstanding.options.insert(.physics)\narView.environment.sceneUnderstanding.options.insert(.collision)\narView.environment.sceneUnderstanding.options.insert(.receivesLighting)",
      "language" : "swift"
    },
    {
      "code" : "let session = SpatialTrackingSession()\nlet config = SpatialTrackingSession.Configuration(\n    tracking:[],\n    sceneUnderstanding:[\n        .occlusion,\n        .physics,\n        .collision,\n        .shadow\n])\nawait session.run(config)",
      "language" : "swift"
    },
    {
      "code" : "var debugMaterial = UnlitMaterial(color: .green)\ndebugMaterial.triangleFillMode = .lines\n\nlet sceneUnderstandingQuery = EntityQuery(where: .has(SceneUnderstandingComponent.self) && .has(ModelComponent.self))\nlet queryResult = scene.performQuery(sceneUnderstandingQuery)\nqueryResult.forEach { entity in\n    entity.components[ModelComponent.self]?.materials = [debugMaterial]\n}",
      "language" : "swift"
    },
    {
      "code" : "let _ = content.subscribe(to: CollisionEvents.Began.self) { event in\n    if event.entityA.components.has(SceneUnderstandingComponent.self) {\n        \/\/ The entityA is a scene-understanding mesh.\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "let arSession = ARKitSession()\nlet sceneReconstruction = SceneReconstructionProvider(modes: [])\n\nTask {\n    do {\n        try await arSession.run([sceneReconstruction])\n    } catch {\n        \/\/ Handle the error.\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "b53a9e9955494641fa4b7573f8b42b5092616091d2b0e8d2d80bc1607ba0d64b",
  "crawledAt" : "2025-12-02T15:55:29Z",
  "id" : "0C24DE3B-C400-45DE-B168-155D865D6D54",
  "kind" : "article",
  "language" : "swift",
  "module" : "RealityKit",
  "overview" : "## Overview\n\nRealityKit can detect planes in the real-world environment on any device, allowing you to place virtual objects in the world and have them interact. On devices with a LiDAR sensor, RealityKit can create a detailed reconstruction of the surrounding environment, allowing more precise interactions between virtual content and the real world. With scene understanding enabled, RealityKit not only reconstructs the environment, but can also recognize what many real-world objects are.\n\n### Use scene understanding in iOS and macOS\n\nTo enable scene-understanding in an iOS or macOS RealityKit app, insert options into [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/sceneUnderstanding-swift.property] like this:\n\nOr, if you’re using [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView], you can configure the same options using [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/SpatialTrackingSession\/Configuration].\n\n### Use scene reconstruction in iOS and macOS\n\nAfter turning on scene-understanding options, RealityKit automatically generates entities representing real-world geometry with a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/SceneUnderstandingComponent].\n\nYou can get these entities by using an [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/EntityQuery]. Here’s an example of rendering a custom debug material with scene-understanding meshes:\n\nWith [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/SceneUnderstanding-swift.struct\/Options-swift.struct\/physics] or [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/SceneUnderstanding-swift.struct\/Options-swift.struct\/collision], scene-understanding meshes can participate in physics simulations and collision events.\n\nHere’s an example of identifying scene-understanding meshes in a collision event:\n\n### Use scene understanding in visionOS\n\nRealityKit doesn’t automatically provide scene-understanding meshes in visionOS. Instead, you can manually add [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/SceneUnderstandingComponent] to your custom entities to let it behave as a virtual scene-understanding mesh. A virtual scene-understanding mesh participates in system rendering features, such as shadows and depth mitigation, just like real-world geometry.\n\nCustom virtual scene-understanding meshes only work in [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/ImmersionStyle\/progressive] or [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/ImmersionStyle\/full] immersive space. They don’t work in [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/ImmersionStyle\/mixed] space, or in a window or volume in the Shared Space.\n\n### Use scene reconstruction in visionOS\n\nTo enable scene reconstruction for a visionOS app, use a [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/RealityKit\/realitykit-scene-understanding\ncrawled: 2025-12-02T15:55:29Z\n---\n\n# Implementing scene understanding and reconstruction in your RealityKit app\n\n**Article**\n\nDetect objects in an AR scene or create a detailed 3D reconstruction of the real-world environment.\n\n## Overview\n\nRealityKit can detect planes in the real-world environment on any device, allowing you to place virtual objects in the world and have them interact. On devices with a LiDAR sensor, RealityKit can create a detailed reconstruction of the surrounding environment, allowing more precise interactions between virtual content and the real world. With scene understanding enabled, RealityKit not only reconstructs the environment, but can also recognize what many real-world objects are.\n\n### Use scene understanding in iOS and macOS\n\nTo enable scene-understanding in an iOS or macOS RealityKit app, insert options into [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/sceneUnderstanding-swift.property] like this:\n\n```swift\narView.environment.sceneUnderstanding.options.insert(.occlusion)\narView.environment.sceneUnderstanding.options.insert(.physics)\narView.environment.sceneUnderstanding.options.insert(.collision)\narView.environment.sceneUnderstanding.options.insert(.receivesLighting)\n```\n\nOr, if you’re using [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView], you can configure the same options using [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/SpatialTrackingSession\/Configuration].\n\n```swift\nlet session = SpatialTrackingSession()\nlet config = SpatialTrackingSession.Configuration(\n    tracking:[],\n    sceneUnderstanding:[\n        .occlusion,\n        .physics,\n        .collision,\n        .shadow\n])\nawait session.run(config)\n```\n\n### Use scene reconstruction in iOS and macOS\n\nAfter turning on scene-understanding options, RealityKit automatically generates entities representing real-world geometry with a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/SceneUnderstandingComponent].\n\nYou can get these entities by using an [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/EntityQuery]. Here’s an example of rendering a custom debug material with scene-understanding meshes:\n\n```swift\nvar debugMaterial = UnlitMaterial(color: .green)\ndebugMaterial.triangleFillMode = .lines\n\nlet sceneUnderstandingQuery = EntityQuery(where: .has(SceneUnderstandingComponent.self) && .has(ModelComponent.self))\nlet queryResult = scene.performQuery(sceneUnderstandingQuery)\nqueryResult.forEach { entity in\n    entity.components[ModelComponent.self]?.materials = [debugMaterial]\n}\n```\n\nWith [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/SceneUnderstanding-swift.struct\/Options-swift.struct\/physics] or [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/SceneUnderstanding-swift.struct\/Options-swift.struct\/collision], scene-understanding meshes can participate in physics simulations and collision events.\n\nHere’s an example of identifying scene-understanding meshes in a collision event:\n\n```swift\nlet _ = content.subscribe(to: CollisionEvents.Began.self) { event in\n    if event.entityA.components.has(SceneUnderstandingComponent.self) {\n        \/\/ The entityA is a scene-understanding mesh.\n    }\n}\n```\n\n### Use scene understanding in visionOS\n\nRealityKit doesn’t automatically provide scene-understanding meshes in visionOS. Instead, you can manually add [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/SceneUnderstandingComponent] to your custom entities to let it behave as a virtual scene-understanding mesh. A virtual scene-understanding mesh participates in system rendering features, such as shadows and depth mitigation, just like real-world geometry.\n\nCustom virtual scene-understanding meshes only work in [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/ImmersionStyle\/progressive] or [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/ImmersionStyle\/full] immersive space. They don’t work in [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/ImmersionStyle\/mixed] space, or in a window or volume in the Shared Space.\n\n### Use scene reconstruction in visionOS\n\nTo enable scene reconstruction for a visionOS app, use a [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider].\n\n```swift\nlet arSession = ARKitSession()\nlet sceneReconstruction = SceneReconstructionProvider(modes: [])\n\nTask {\n    do {\n        try await arSession.run([sceneReconstruction])\n    } catch {\n        \/\/ Handle the error.\n    }\n}\n```\n\n## Scene reconstructions and analysis\n\n- **Creating a game with scene understanding**: Create AR games and experiences that interact with real-world objects on LiDAR-equipped iOS devices.\n- **Visualizing and interacting with a reconstructed scene**: Estimate the shape of the physical environment using a polygonal mesh.\n- **sceneReconstruction**: A flag that enables scene reconstruction.\n- **supportsSceneReconstruction(_:)**: Checks if the device supports scene reconstruction.\n- **SceneUnderstandingComponent**: A component that specifies an entity is participating in the system’s scene-understanding features.\n- **ARView.Environment.SceneUnderstanding**: An object that holds scene-understanding options for the view.\n- **ARView.Environment.SceneUnderstanding.Options**: Available scene-understanding options.\n- **HasSceneUnderstanding**: A specification that detects and reacts to features of the physical environment.\n- **SceneReconstructionProvider**: A source of live data about the shape of a person’s surroundings.\n- **ARSession**: The object that manages the major tasks associated with every AR experience, such as motion tracking, camera passthrough, and image analysis.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create AR games and experiences that interact with real-world objects on LiDAR-equipped iOS devices.",
          "name" : "Creating a game with scene understanding",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/creating-a-game-with-scene-understanding"
        },
        {
          "description" : "Estimate the shape of the physical environment using a polygonal mesh.",
          "name" : "Visualizing and interacting with a reconstructed scene",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/visualizing-and-interacting-with-a-reconstructed-scene"
        },
        {
          "description" : "A flag that enables scene reconstruction.",
          "name" : "sceneReconstruction",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARWorldTrackingConfiguration\/sceneReconstruction"
        },
        {
          "description" : "Checks if the device supports scene reconstruction.",
          "name" : "supportsSceneReconstruction(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARWorldTrackingConfiguration\/supportsSceneReconstruction(_:)"
        },
        {
          "description" : "A component that specifies an entity is participating in the system’s scene-understanding features.",
          "name" : "SceneUnderstandingComponent",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/SceneUnderstandingComponent"
        },
        {
          "description" : "An object that holds scene-understanding options for the view.",
          "name" : "ARView.Environment.SceneUnderstanding",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/SceneUnderstanding-swift.struct"
        },
        {
          "description" : "Available scene-understanding options.",
          "name" : "ARView.Environment.SceneUnderstanding.Options",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ARView\/Environment-swift.struct\/SceneUnderstanding-swift.struct\/Options-swift.struct"
        },
        {
          "description" : "A specification that detects and reacts to features of the physical environment.",
          "name" : "HasSceneUnderstanding",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/HasSceneUnderstanding"
        },
        {
          "description" : "A source of live data about the shape of a person’s surroundings.",
          "name" : "SceneReconstructionProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/SceneReconstructionProvider"
        },
        {
          "description" : "The object that manages the major tasks associated with every AR experience, such as motion tracking, camera passthrough, and image analysis.",
          "name" : "ARSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/ARKit\/ARSession"
        }
      ],
      "title" : "Scene reconstructions and analysis"
    }
  ],
  "source" : "appleJSON",
  "title" : "Implementing scene understanding and reconstruction in your RealityKit app",
  "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/realitykit-scene-understanding"
}