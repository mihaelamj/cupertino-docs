{
  "abstract" : "Create an object from a specified texture.",
  "codeExamples" : [
    {
      "code" : "    \/\/ Retrieve the entity's UV texture coordinates.\n    float2 uv = params.geometry().uv0();\n\n    \/\/ Models loaded from USDZ or Reality Composer use UVs that are flipped\n    \/\/ on the y-axis. This compensates for that.\n    uv.y = 1.0 - uv.y;\n\n    \/\/ Sample the normal map texture based on the resulting UV coordinates.\n    auto tex = params.textures();\n    float3 normal = (float3)tex.normal().sample(textureSampler, uv).rgb;\n\n    \/\/ Set the sampled value as this pixel's normal.\n    params.surface().set_normal(normal);",
      "language" : "swift"
    }
  ],
  "contentHash" : "f7d08a724b8654583cd9fc716f83e75cad60b5c70858c48b0485427e0245a8ea",
  "crawledAt" : "2025-12-03T15:12:37Z",
  "declaration" : {
    "code" : "init(texture: CustomMaterial.Texture? = nil)",
    "language" : "swift"
  },
  "id" : "0F543D3B-CA4A-40DB-92B7-7DF30CC01F39",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "RealityKit",
  "overview" : "## Discussion\n\nThis initializer creates an object from a normal map texture. *Normal mapping* is a real-time rendering technique that captures fine surface details for a model using a texture instead of increasing the number of polygons in the model. It works by storing *surface normals*, which are vectors perpendicular to the surface of the model, from a much higher-resolution version of the same 3D object. A normal map stores each vector in the image by storing the vectors’ `X`, `Y`, and `Z` values as the `R`, `G`, and `B` components of the corresponding pixel in the UV-mapped image.\n\nTo render an entity using a normal map, set [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CustomMaterial\/lightingModel-swift.property] to [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CustomMaterial\/LightingModel-swift.enum\/lit] or [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CustomMaterial\/LightingModel-swift.enum\/clearcoat], and call `params.surface().set_normal()` from its surface shader.\n\nThe following Metal code demonstrates how to sample and use a value from the normal map in your surface shader function:",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/RealityKit\/CustomMaterial\/Normal-swift.struct\/init(texture:)\ncrawled: 2025-12-03T15:12:37Z\n---\n\n# init(texture:)\n\n**Initializer**\n\nCreate an object from a specified texture.\n\n## Declaration\n\n```swift\ninit(texture: CustomMaterial.Texture? = nil)\n```\n\n## Parameters\n\n- **texture**: The image’s texture.\n\n## Discussion\n\nThis initializer creates an object from a normal map texture. *Normal mapping* is a real-time rendering technique that captures fine surface details for a model using a texture instead of increasing the number of polygons in the model. It works by storing *surface normals*, which are vectors perpendicular to the surface of the model, from a much higher-resolution version of the same 3D object. A normal map stores each vector in the image by storing the vectors’ `X`, `Y`, and `Z` values as the `R`, `G`, and `B` components of the corresponding pixel in the UV-mapped image.\n\nTo render an entity using a normal map, set [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CustomMaterial\/lightingModel-swift.property] to [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CustomMaterial\/LightingModel-swift.enum\/lit] or [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CustomMaterial\/LightingModel-swift.enum\/clearcoat], and call `params.surface().set_normal()` from its surface shader.\n\nThe following Metal code demonstrates how to sample and use a value from the normal map in your surface shader function:\n\n```swift\n    \/\/ Retrieve the entity's UV texture coordinates.\n    float2 uv = params.geometry().uv0();\n\n    \/\/ Models loaded from USDZ or Reality Composer use UVs that are flipped\n    \/\/ on the y-axis. This compensates for that.\n    uv.y = 1.0 - uv.y;\n\n    \/\/ Sample the normal map texture based on the resulting UV coordinates.\n    auto tex = params.textures();\n    float3 normal = (float3)tex.normal().sample(textureSampler, uv).rgb;\n\n    \/\/ Set the sampled value as this pixel's normal.\n    params.surface().set_normal(normal);\n```\n\n## Creating a normal object\n\n- **init(_:)**: Creates an object containing surface details for an entity from a custom material’s normal property.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an object containing surface details for an entity from a custom material’s normal property.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/CustomMaterial\/Normal-swift.struct\/init(_:)"
        }
      ],
      "title" : "Creating a normal object"
    }
  ],
  "source" : "appleJSON",
  "title" : "init(texture:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/CustomMaterial\/Normal-swift.struct\/init(texture:)"
}