{
  "abstract" : "Take high-quality images of objects to generate 3D models.",
  "codeExamples" : [

  ],
  "contentHash" : "adb346b1a4dd180b808f0a611095db058319ebdbf54d3c6848e2b79983cdcf47",
  "crawledAt" : "2025-12-02T15:54:45Z",
  "id" : "2353D444-9F38-44EF-B446-F100A7BBDEE4",
  "kind" : "article",
  "language" : "swift",
  "module" : "RealityKit",
  "overview" : "## Overview\n\nIn iOS 17 and later, and macOS 12 and later, you can create 3D objects from photographs using a process called *photogrammetry*. You provide RealityKit Object Capture with a series of well-lit photographs taken from many different angles. It analyzes the overlap area between different images to match up landmarks, and then produces a 3D model of the photographed object.\n\nTo generate the best 3D representation from the object-creation process, provide RealityKit with high-quality, high-resolution photographs that don’t contain hard shadows or strong highlights.\n\n\n\n### Select an object to photograph\n\nChoose objects that are static and won’t bend or deform while you’re taking photos. You can move the object between shots in order to photograph all sides, but a soft, articulated, or bendable object that changes shape when you move it can compromise RealityKit’s ability to match landmarks between different images, which may cause Object Capture to fail or produce low-quality results.\n\nAvoid objects that are very thin in one dimension, highly reflective, transparent, or translucent. Additionally, objects that are a single, solid color or have a very smooth surface may not provide enough data necessary for the object-creation algorithm to construct a 3D shape. You can draw or paint on the surface of an object to add color or texture, then match the original color or texture on the created 3D object with the material inspector in Xcode’s 3D model viewer or the property inspector in Reality Composer.\n\n### Choose an approach\n\nYou can approach taking photographs for object creation in two ways: Either move the camera around the object, taking photographs from different angles at different heights, or put the object on a turntable and rotate the object while taking pictures. When using a turntable, take pictures in front of a well-lit, solid color background to minimize extraneous image data that can interfere with the object-creation process and use a tripod if available. Standing the object on different sides while photographing it on a turntable captures the entire object with no gaps or holes.\n\nThe number of pictures that RealityKit needs in order to create an accurate 3D representation varies depending on the complexity and size of the object, but adjacent shots must have substantial overlap. Position sequential images so they have a 70% overlap or more. Anything less than 50% overlap between neighboring shots, and the object-creation process may fail or result in a low-quality recreation.\n\n\n\nRealityKit object creation accepts images captured by any digital camera, including the cameras on an iPhone or iPad, a DSLR or mirrorless camera, or even a camera-equipped drone. If your source images contain depth data, RealityKit uses it to calculate the real-world size of the scanned object. RealityKit can also create objects from images without depth data, but you may have to scale the object when placing it into your AR scene. For more information on capturing image depth data, see [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/capturing-photos-with-depth].\n\n### Compose your shots\n\nPosition the object so it fills as much of the camera’s frame as possible without excluding or cutting off any part. Use an aperture setting narrow enough to maintain a crisp focus. Shoot at the highest resolution your camera supports and use RAW format if possible.\n\nIn low-light situations, cameras with autofocus can have difficulty finding and maintaining focus. Focus manually if there isn’t enough ambient light to get a focus lock, and put your camera on a tripod to make sure you keep it steady. Use a remote trigger, such as the Apple Watch Camera Remote app, to make sure the camera doesn’t move or shake when you press the button to take a photo.\n\nUse diffused lighting if possible. Hard light, such as from an on-camera flash, direct sunlight, or a bare light bulb can cause problems during object creation. This type of lighting casts hard shadows that can confuse the photogrammetry algorithm. Instead, bounce the light off of a reflector, a wall, or the ceiling, or put a diffusing material like a lamp shade or thin white fabric between the light source and the object. You can also use light modifiers or a light tent designed for photographing objects.\n\nWhen photographing an object outdoors, keep the sun out of your images if possible. Shoot at midday so the sun is high enough in the sky that it won’t be visible in any of your images, or shoot on an overcast day.\n\n### Capture consistent images and perform post-processing\n\nIn order to ensure that RealityKit can match up landmarks between overlapping photographs, keep your camera settings as consistent as possible from shot to shot. If possible, don’t make changes to any camera settings while shooting, including the focal length (zoom), aperture, shutter speed, or ISO.\n\nIf your camera offers manual control of any settings, set those values to keep them consistent between shots. When shooting with the camera on an iPhone or iPad, you can lock the exposure and focus settings by long-pressing the image feed view until you see “AE\/AF Lock” appear at the top of the screen.\n\nIn addition, masking out objects in the background so the image only contains the object you’re capturing removes unnecessary data that can confuse the photogrammetry algorithm.\n\nThere may be times when you can’t capture images under ideal conditions, such as when photographing a large object in a crowded public space. Adjust for image shortcomings using an image editor. Modify a photograph’s contrast, brightness, sharpness, or exposure to compensate for problems in the original capture.\n\nFor information on using the RealityKit Object Capture APIs, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/creating-3d-objects-from-photographs].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/RealityKit\/capturing-photographs-for-realitykit-object-capture\ncrawled: 2025-12-02T15:54:45Z\n---\n\n# Capturing photographs for RealityKit Object Capture\n\n**Article**\n\nTake high-quality images of objects to generate 3D models.\n\n## Overview\n\nIn iOS 17 and later, and macOS 12 and later, you can create 3D objects from photographs using a process called *photogrammetry*. You provide RealityKit Object Capture with a series of well-lit photographs taken from many different angles. It analyzes the overlap area between different images to match up landmarks, and then produces a 3D model of the photographed object.\n\nTo generate the best 3D representation from the object-creation process, provide RealityKit with high-quality, high-resolution photographs that don’t contain hard shadows or strong highlights.\n\n\n\n### Select an object to photograph\n\nChoose objects that are static and won’t bend or deform while you’re taking photos. You can move the object between shots in order to photograph all sides, but a soft, articulated, or bendable object that changes shape when you move it can compromise RealityKit’s ability to match landmarks between different images, which may cause Object Capture to fail or produce low-quality results.\n\nAvoid objects that are very thin in one dimension, highly reflective, transparent, or translucent. Additionally, objects that are a single, solid color or have a very smooth surface may not provide enough data necessary for the object-creation algorithm to construct a 3D shape. You can draw or paint on the surface of an object to add color or texture, then match the original color or texture on the created 3D object with the material inspector in Xcode’s 3D model viewer or the property inspector in Reality Composer.\n\n### Choose an approach\n\nYou can approach taking photographs for object creation in two ways: Either move the camera around the object, taking photographs from different angles at different heights, or put the object on a turntable and rotate the object while taking pictures. When using a turntable, take pictures in front of a well-lit, solid color background to minimize extraneous image data that can interfere with the object-creation process and use a tripod if available. Standing the object on different sides while photographing it on a turntable captures the entire object with no gaps or holes.\n\nThe number of pictures that RealityKit needs in order to create an accurate 3D representation varies depending on the complexity and size of the object, but adjacent shots must have substantial overlap. Position sequential images so they have a 70% overlap or more. Anything less than 50% overlap between neighboring shots, and the object-creation process may fail or result in a low-quality recreation.\n\n\n\nRealityKit object creation accepts images captured by any digital camera, including the cameras on an iPhone or iPad, a DSLR or mirrorless camera, or even a camera-equipped drone. If your source images contain depth data, RealityKit uses it to calculate the real-world size of the scanned object. RealityKit can also create objects from images without depth data, but you may have to scale the object when placing it into your AR scene. For more information on capturing image depth data, see [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/capturing-photos-with-depth].\n\n\n\n### Compose your shots\n\nPosition the object so it fills as much of the camera’s frame as possible without excluding or cutting off any part. Use an aperture setting narrow enough to maintain a crisp focus. Shoot at the highest resolution your camera supports and use RAW format if possible.\n\n\n\nIn low-light situations, cameras with autofocus can have difficulty finding and maintaining focus. Focus manually if there isn’t enough ambient light to get a focus lock, and put your camera on a tripod to make sure you keep it steady. Use a remote trigger, such as the Apple Watch Camera Remote app, to make sure the camera doesn’t move or shake when you press the button to take a photo.\n\nUse diffused lighting if possible. Hard light, such as from an on-camera flash, direct sunlight, or a bare light bulb can cause problems during object creation. This type of lighting casts hard shadows that can confuse the photogrammetry algorithm. Instead, bounce the light off of a reflector, a wall, or the ceiling, or put a diffusing material like a lamp shade or thin white fabric between the light source and the object. You can also use light modifiers or a light tent designed for photographing objects.\n\nWhen photographing an object outdoors, keep the sun out of your images if possible. Shoot at midday so the sun is high enough in the sky that it won’t be visible in any of your images, or shoot on an overcast day.\n\n### Capture consistent images and perform post-processing\n\nIn order to ensure that RealityKit can match up landmarks between overlapping photographs, keep your camera settings as consistent as possible from shot to shot. If possible, don’t make changes to any camera settings while shooting, including the focal length (zoom), aperture, shutter speed, or ISO.\n\nIf your camera offers manual control of any settings, set those values to keep them consistent between shots. When shooting with the camera on an iPhone or iPad, you can lock the exposure and focus settings by long-pressing the image feed view until you see “AE\/AF Lock” appear at the top of the screen.\n\nIn addition, masking out objects in the background so the image only contains the object you’re capturing removes unnecessary data that can confuse the photogrammetry algorithm.\n\nThere may be times when you can’t capture images under ideal conditions, such as when photographing a large object in a crowded public space. Adjust for image shortcomings using an image editor. Modify a photograph’s contrast, brightness, sharpness, or exposure to compensate for problems in the original capture.\n\nFor information on using the RealityKit Object Capture APIs, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/creating-3d-objects-from-photographs].\n\n## Model creation\n\n- **Creating 3D objects from photographs**: Construct virtual objects to use in your AR experiences.\n- **Scanning objects using Object Capture**: Implement a full scanning workflow for capturing objects on iOS devices.\n- **Building an object reconstruction app**: Reconstruct objects from user-selected input images by using photogrammetry.\n- **Creating a photogrammetry command-line app**: Generate 3D objects from images using RealityKit Object Capture.\n- **Using object capture assets in RealityKit**: Create a chess game using RealityKit and assets created using Object Capture.\n- **PhotogrammetrySession**: Manages the creation of a 3D model from a set of images.\n- **PhotogrammetrySample**: An object that represents one image and its corresponding metadata.\n- **ObjectCaptureView**: A view that guides a user through capturing images for object capture.\n- **ObjectCaptureSession**: A session object that monitors and controls image capture for photogrammetry.\n- **ObjectCapturePointCloudView**: Renders the current state of the point cloud from an object capture session.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Construct virtual objects to use in your AR experiences.",
          "name" : "Creating 3D objects from photographs",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/creating-3d-objects-from-photographs"
        },
        {
          "description" : "Implement a full scanning workflow for capturing objects on iOS devices.",
          "name" : "Scanning objects using Object Capture",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scanning-objects-using-object-capture"
        },
        {
          "description" : "Reconstruct objects from user-selected input images by using photogrammetry.",
          "name" : "Building an object reconstruction app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/building-an-object-reconstruction-app"
        },
        {
          "description" : "Generate 3D objects from images using RealityKit Object Capture.",
          "name" : "Creating a photogrammetry command-line app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/creating-a-photogrammetry-command-line-app"
        },
        {
          "description" : "Create a chess game using RealityKit and assets created using Object Capture.",
          "name" : "Using object capture assets in RealityKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/using-object-capture-assets-in-realitykit"
        },
        {
          "description" : "Manages the creation of a 3D model from a set of images.",
          "name" : "PhotogrammetrySession",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/PhotogrammetrySession"
        },
        {
          "description" : "An object that represents one image and its corresponding metadata.",
          "name" : "PhotogrammetrySample",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/PhotogrammetrySample"
        },
        {
          "description" : "A view that guides a user through capturing images for object capture.",
          "name" : "ObjectCaptureView",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ObjectCaptureView"
        },
        {
          "description" : "A session object that monitors and controls image capture for photogrammetry.",
          "name" : "ObjectCaptureSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ObjectCaptureSession"
        },
        {
          "description" : "Renders the current state of the point cloud from an object capture session.",
          "name" : "ObjectCapturePointCloudView",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/ObjectCapturePointCloudView"
        }
      ],
      "title" : "Model creation"
    }
  ],
  "source" : "appleJSON",
  "title" : "Capturing photographs for RealityKit Object Capture",
  "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/capturing-photographs-for-realitykit-object-capture"
}