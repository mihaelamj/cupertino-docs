{
  "abstract" : "Create custom shaders to implement postprocess effects.",
  "codeExamples" : [
    {
      "code" : "[[kernel]]\nvoid postProcessInvert(uint2 gid [[thread_position_in_grid]],\n                       texture2d<half, access::read> inColor [[texture(0)]],\n                       texture2d<half, access::write> outColor [[texture(1)]])\n{\n    \/\/ Check to make sure that the specified thread_position_in_grid value is\n    \/\/ within the bounds of the framebuffer. This ensures that non-uniform size\n    \/\/ threadgroups don't trigger an error. For more information, see:\n    \/\/ https:\/\/developer.apple.com\/documentation\/metal\/calculating_threadgroup_and_grid_sizes\n    if (gid.x >= inColor.get_width() || gid.y >= inColor.get_height()) {    \n        return;\n    }\n\n    \/\/ Invert the pixel's color by subtracting it from 1.0.\n    outColor.write(1.0 - inColor.read(gid), gid);\n}",
      "language" : "other"
    },
    {
      "code" : "func loadPostprocessingShader(device: MTLDevice) {\n    guard let library = device.makeDefaultLibrary() else {\n        fatalError()\n    }\n\n    if let invertKernel = library.makeFunction(name: \"postProcessInvert\") {\n        \/\/ Create a pipeline state object and store it in a property.\n        invertPipeline = try? device.makeComputePipelineState(function: invertKernel)\n    }\n} ",
      "language" : "swift"
    },
    {
      "code" : "arView.renderCallbacks.postProcess = loadPostprocessingShader",
      "language" : "swift"
    },
    {
      "code" : "func postProcess(context: ARView.PostProcessContext) {\n    guard let encoder = context.commandBuffer.makeComputeCommandEncoder() else {\n        return\n    }\n\n    encoder.setComputePipelineState(pipeline)\n    encoder.setTexture(context.sourceColorTexture, index: 0)\n    encoder.setTexture(context.compatibleTargetTexture, index: 1)\n\n    let threadsPerGrid = MTLSize(width: context.sourceColorTexture.width,\n                                 height: context.sourceColorTexture.height,\n                                 depth: 1)\n\n    let w = pixelatePipeline.threadExecutionWidth\n    let h = pixelatePipeline.maxTotalThreadsPerThreadgroup \/ w\n    let threadsPerThreadgroup = MTLSizeMake(w, h, 1)\n\n    encoder.dispatchThreads(threadsPerGrid,\n                            threadsPerThreadgroup: threadsPerThreadgroup)\n    encoder.endEncoding()\n}",
      "language" : "swift"
    },
    {
      "code" : "arView.renderCallbacks.postProcess = postProcess",
      "language" : "swift"
    }
  ],
  "contentHash" : "b8fcc23ec46311ec7efbef863afb32e8abe04dae36edecc71c98c7ca256742d3",
  "crawledAt" : "2025-12-02T15:55:40Z",
  "id" : "6B4B6C3E-17A6-4961-94E5-1F615ECEAF2C",
  "kind" : "article",
  "language" : "swift",
  "module" : "RealityKit",
  "overview" : "## Overview\n\nIn iOS 15 and later, and macOS 12 and later, you can apply postprocess effects to a RealityKit scene after RealityKit renders it, but before RealityKit displays it. If you register a postprocess callback function, RealityKit passes that function the complete, rendered frame so you can modify it before the viewer sees it. You can use any image-processing or drawing APIs on the rendered frame but, as a practical matter, only APIs that execute on the GPU are fast enough to use every frame and maintain a good framerate.\n\nOne way to implement postprocess effects is to write custom Metal compute functions to process the rendered scene. Writing your own custom compute function gives you tremendous flexibility and allows you to create virtually any postprocessing effect. Because compute functions run on the GPU, they’re a good choice for implementing custom postprocessing effects.\n\nYou can also implement many common postprocessing effects without writing your own compute functions by using image filters from the [doc:\/\/com.apple.documentation\/documentation\/MetalPerformanceShaders] framework or [doc:\/\/com.apple.documentation\/documentation\/CoreImage], which also run on the GPU. For information on using the Metal Performance Shaders framework for postprocess effects, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/using-metal-performance-shaders-to-create-custom-postprocess-effects]. For information on using Core Image for postprocess effects, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/applying-core-image-filters-as-a-postprocess-effect].\n\n### Check the output texture pixel format\n\nSome device GPUs require that the output texture be in a specific pixel format. If the device your code is running on doesn’t support [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLGPUFamily\/apple2], convert the output texture to [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLPixelFormat\/bgra8Unorm] before using it. For more information, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/checking-the-pixel-format-of-a-postprocess-effect-s-output-texture].\n\n### Write a compute function\n\nAdd a new file to your Xcode project using the Metal File template. It doesn’t matter what filename you choose because Metal loads compute functions by the function name. As long as you include the file that contains the compute function in your build target, Metal is able to find and load it at runtime. A postprocess compute function executes once for each pixel in the rendered scene and is responsible for setting the final color of its pixel.\n\nHere’s a compute function that inverts every pixel of a passed framebuffer.\n\n### Load the compute function\n\nTo use the Metal compute function in your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/postProcess] render callback, retrieve the default [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLLibrary], then load your compute function and store the resulting [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLRenderPipelineState] object. Load the pipeline state object during startup and store it in a property because you’ll need it in your postprocess callback. A good place to create and store it is in a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/prepareWithDevice] render callback, which RealityKit calls once it has finished its setup but before it renders the next frame and passes it a reference to the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLDevice] where the scene displays. If you assign the callback during app startup, RealityKit calls your method before it renders the first frame.\n\nHere’s an example that loads the invert compute function from above and stores its pipeline state object in a property.\n\nTo make RealityKit call your function, assign it to the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/prepareWithDevice] property of the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/renderCallbacks-swift.property] property on your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView] during app startup.\n\n### Create a postprocess callback function\n\nTo apply the compute function to the rendered scene, create a callback function that takes a single [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext] argument and has no return value. In that function, use the command buffer passed in the context to create an [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder], and assign the pipeline state property you created to that encoder using [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLIndirectComputeCommand\/setComputePipelineState(_:)].\n\nThen use [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLArgumentEncoder\/setTexture(_:index:)] on the encoder to pass the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/sourceColorTexture] and the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/targetColorTexture] to your compute function. If your compute function needs access to additional textures, such as the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/sourceDepthTexture] or a custom texture, you can pass those the same way. Note that the index values used in [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLArgumentEncoder\/setTexture(_:index:)] must match the value your compute function uses to retrieve the texture.\n\nBecause the sample compute function above defines `inColor` as `[[texture(0)]]`, you need to use an index value of `0` when calling [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLArgumentEncoder\/setTexture(_:index:)] to pass [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/sourceColorTexture]. You can also use [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder\/setBytes(_:length:index:)] to pass non-texture data to your compute function. For more information on using that [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder\/setBytes(_:length:index:)] to pass non-texture data, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/passing-structured-data-to-a-metal-compute-function].\n\nOnce you’ve assigned the needed textures and data to the encoder, use [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder\/dispatchThreads(_:threadsPerThreadgroup:)] to start the compute function.\n\n### Register the callback function\n\nTo apply the effect, register the function as the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/postProcess] render callback for the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/RealityKit\/implementing-postprocess-effects-using-metal-compute-functions\ncrawled: 2025-12-02T15:55:40Z\n---\n\n# Implementing postprocess effects using Metal compute functions\n\n**Article**\n\nCreate custom shaders to implement postprocess effects.\n\n## Overview\n\nIn iOS 15 and later, and macOS 12 and later, you can apply postprocess effects to a RealityKit scene after RealityKit renders it, but before RealityKit displays it. If you register a postprocess callback function, RealityKit passes that function the complete, rendered frame so you can modify it before the viewer sees it. You can use any image-processing or drawing APIs on the rendered frame but, as a practical matter, only APIs that execute on the GPU are fast enough to use every frame and maintain a good framerate.\n\nOne way to implement postprocess effects is to write custom Metal compute functions to process the rendered scene. Writing your own custom compute function gives you tremendous flexibility and allows you to create virtually any postprocessing effect. Because compute functions run on the GPU, they’re a good choice for implementing custom postprocessing effects.\n\nYou can also implement many common postprocessing effects without writing your own compute functions by using image filters from the [doc:\/\/com.apple.documentation\/documentation\/MetalPerformanceShaders] framework or [doc:\/\/com.apple.documentation\/documentation\/CoreImage], which also run on the GPU. For information on using the Metal Performance Shaders framework for postprocess effects, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/using-metal-performance-shaders-to-create-custom-postprocess-effects]. For information on using Core Image for postprocess effects, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/applying-core-image-filters-as-a-postprocess-effect].\n\n### Check the output texture pixel format\n\nSome device GPUs require that the output texture be in a specific pixel format. If the device your code is running on doesn’t support [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLGPUFamily\/apple2], convert the output texture to [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLPixelFormat\/bgra8Unorm] before using it. For more information, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/checking-the-pixel-format-of-a-postprocess-effect-s-output-texture].\n\n### Write a compute function\n\nAdd a new file to your Xcode project using the Metal File template. It doesn’t matter what filename you choose because Metal loads compute functions by the function name. As long as you include the file that contains the compute function in your build target, Metal is able to find and load it at runtime. A postprocess compute function executes once for each pixel in the rendered scene and is responsible for setting the final color of its pixel.\n\nHere’s a compute function that inverts every pixel of a passed framebuffer.\n\n```other\n[[kernel]]\nvoid postProcessInvert(uint2 gid [[thread_position_in_grid]],\n                       texture2d<half, access::read> inColor [[texture(0)]],\n                       texture2d<half, access::write> outColor [[texture(1)]])\n{\n    \/\/ Check to make sure that the specified thread_position_in_grid value is\n    \/\/ within the bounds of the framebuffer. This ensures that non-uniform size\n    \/\/ threadgroups don't trigger an error. For more information, see:\n    \/\/ https:\/\/developer.apple.com\/documentation\/metal\/calculating_threadgroup_and_grid_sizes\n    if (gid.x >= inColor.get_width() || gid.y >= inColor.get_height()) {    \n        return;\n    }\n\n    \/\/ Invert the pixel's color by subtracting it from 1.0.\n    outColor.write(1.0 - inColor.read(gid), gid);\n}\n```\n\n\n\n### Load the compute function\n\nTo use the Metal compute function in your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/postProcess] render callback, retrieve the default [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLLibrary], then load your compute function and store the resulting [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLRenderPipelineState] object. Load the pipeline state object during startup and store it in a property because you’ll need it in your postprocess callback. A good place to create and store it is in a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/prepareWithDevice] render callback, which RealityKit calls once it has finished its setup but before it renders the next frame and passes it a reference to the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLDevice] where the scene displays. If you assign the callback during app startup, RealityKit calls your method before it renders the first frame.\n\nHere’s an example that loads the invert compute function from above and stores its pipeline state object in a property.\n\n```swift\nfunc loadPostprocessingShader(device: MTLDevice) {\n    guard let library = device.makeDefaultLibrary() else {\n        fatalError()\n    }\n\n    if let invertKernel = library.makeFunction(name: \"postProcessInvert\") {\n        \/\/ Create a pipeline state object and store it in a property.\n        invertPipeline = try? device.makeComputePipelineState(function: invertKernel)\n    }\n} \n```\n\nTo make RealityKit call your function, assign it to the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/prepareWithDevice] property of the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/renderCallbacks-swift.property] property on your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView] during app startup.\n\n```swift\narView.renderCallbacks.postProcess = loadPostprocessingShader\n```\n\n### Create a postprocess callback function\n\nTo apply the compute function to the rendered scene, create a callback function that takes a single [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext] argument and has no return value. In that function, use the command buffer passed in the context to create an [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder], and assign the pipeline state property you created to that encoder using [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLIndirectComputeCommand\/setComputePipelineState(_:)].\n\nThen use [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLArgumentEncoder\/setTexture(_:index:)] on the encoder to pass the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/sourceColorTexture] and the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/targetColorTexture] to your compute function. If your compute function needs access to additional textures, such as the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/sourceDepthTexture] or a custom texture, you can pass those the same way. Note that the index values used in [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLArgumentEncoder\/setTexture(_:index:)] must match the value your compute function uses to retrieve the texture.\n\nBecause the sample compute function above defines `inColor` as `[[texture(0)]]`, you need to use an index value of `0` when calling [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLArgumentEncoder\/setTexture(_:index:)] to pass [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/PostProcessContext\/sourceColorTexture]. You can also use [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder\/setBytes(_:length:index:)] to pass non-texture data to your compute function. For more information on using that [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder\/setBytes(_:length:index:)] to pass non-texture data, see [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/passing-structured-data-to-a-metal-compute-function].\n\nOnce you’ve assigned the needed textures and data to the encoder, use [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLComputeCommandEncoder\/dispatchThreads(_:threadsPerThreadgroup:)] to start the compute function.\n\n```swift\nfunc postProcess(context: ARView.PostProcessContext) {\n    guard let encoder = context.commandBuffer.makeComputeCommandEncoder() else {\n        return\n    }\n\n    encoder.setComputePipelineState(pipeline)\n    encoder.setTexture(context.sourceColorTexture, index: 0)\n    encoder.setTexture(context.compatibleTargetTexture, index: 1)\n\n    let threadsPerGrid = MTLSize(width: context.sourceColorTexture.width,\n                                 height: context.sourceColorTexture.height,\n                                 depth: 1)\n\n    let w = pixelatePipeline.threadExecutionWidth\n    let h = pixelatePipeline.maxTotalThreadsPerThreadgroup \/ w\n    let threadsPerThreadgroup = MTLSizeMake(w, h, 1)\n\n    encoder.dispatchThreads(threadsPerGrid,\n                            threadsPerThreadgroup: threadsPerThreadgroup)\n    encoder.endEncoding()\n}\n```\n\n\n\n### Register the callback function\n\nTo apply the effect, register the function as the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView\/RenderCallbacks-swift.struct\/postProcess] render callback for the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/ARView].\n\n```swift\narView.renderCallbacks.postProcess = postProcess\n```\n\n\n\n## Metal effects\n\n- **Using Metal performance shaders to create custom postprocess effects**: Leverage the Metal Performance Shaders framework to create special rendering effects for your RealityKit scenes.\n- **Implementing special rendering effects with RealityKit postprocessing**: Implement a variety of postprocessing techniques to alter RealityKit rendering.\n- **Checking the pixel format of a postprocess effect’s output texture**: Make sure your postprocess effect works on all devices.\n- **Passing Structured Data to a Metal Compute Function**: Send nontexture data from Swift to your Metal shaders using a shared header file.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Leverage the Metal Performance Shaders framework to create special rendering effects for your RealityKit scenes.",
          "name" : "Using Metal performance shaders to create custom postprocess effects",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/using-metal-performance-shaders-to-create-custom-postprocess-effects"
        },
        {
          "description" : "Implement a variety of postprocessing techniques to alter RealityKit rendering.",
          "name" : "Implementing special rendering effects with RealityKit postprocessing",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/implementing-special-rendering-effects-with-realitykit-postprocessing"
        },
        {
          "description" : "Make sure your postprocess effect works on all devices.",
          "name" : "Checking the pixel format of a postprocess effect’s output texture",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/checking-the-pixel-format-of-a-postprocess-effect-s-output-texture"
        },
        {
          "description" : "Send nontexture data from Swift to your Metal shaders using a shared header file.",
          "name" : "Passing Structured Data to a Metal Compute Function",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/passing-structured-data-to-a-metal-compute-function"
        }
      ],
      "title" : "Metal effects"
    }
  ],
  "source" : "appleJSON",
  "title" : "Implementing postprocess effects using Metal compute functions",
  "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/implementing-postprocess-effects-using-metal-compute-functions"
}