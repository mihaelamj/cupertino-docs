{
  "abstract" : "Build a RealityKit component to support standard visionOS gestures on any entity.",
  "codeExamples" : [
    {
      "code" : "\/\/\/ A component that handles gesture logic for an entity.\npublic struct GestureComponent: Component, Codable {\n    \n    \/\/\/ A Boolean value that indicates whether a gesture can drag the entity.\n    public var canDrag: Bool = true\n    \n    \/\/\/ ...\n    \n    \/\/\/ A Boolean value that indicates whether a gesture can scale the entity.\n    public var canScale: Bool = true\n    \n    \/\/\/ A Boolean value that indicates whether a gesture can rotate the entity.\n    public var canRotate: Bool = true\n\n    \/\/\/ ...",
      "language" : "swift"
    },
    {
      "code" : "    \/\/\/ A Boolean value that indicates whether the drag gesture can move the object in an arc, similar to dragging windows or moving the keyboard.\n    public var pivotOnDrag: Bool = true\n    \n    \/\/\/ A Boolean value that indicates whether a pivot drag keeps the orientation toward the\n    \/\/\/ viewer throughout the drag gesture.\n    \/\/\/\n    \/\/\/ The property only applies when `pivotOnDrag` is `true`.\n    public var preserveOrientationOnPivotDrag: Bool = true",
      "language" : "swift"
    },
    {
      "code" : "public class EntityGestureState {\n    \n    \/\/\/ The entity currently being dragged if a gesture is in progress.\n    var targetedEntity: Entity?\n    \n    \/\/ MARK: - Drag\n    \n    \/\/\/ The starting position.\n    var dragStartPosition: SIMD3<Float> = .zero\n    \n    \/\/\/ Marks whether the app is currently handling a drag gesture.\n    var isDragging = false\n    \n    \/\/\/ When `rotateOnDrag` is`true`, this entity acts as the pivot point for the drag.\n    var pivotEntity: Entity?\n    \n    var initialOrientation: simd_quatf?\n    \n    \/\/ MARK: - Magnify\n    \n    \/\/\/ The starting scale value.\n    var startScale: SIMD3<Float> = .one\n    \n    \/\/\/ Marks whether the app is currently handling a scale gesture.\n    var isScaling = false\n    \n    \/\/ MARK: - Rotation\n    \n    \/\/\/ The starting rotation value.\n    var startOrientation = Rotation3D.identity\n    \n    \/\/\/ Marks whether the app is currently handling a rotation gesture.\n    var isRotating = false\n    \n    \/\/ MARK: - Singleton Accessor\n    \n    \/\/\/ Retrieves the shared instance.\n    static let shared = EntityGestureState()\n}",
      "language" : "swift"
    },
    {
      "code" : "mutating func onChanged(value: EntityTargetValue<DragGesture.Value>) {\n    guard canDrag else { return }\n    let entity = value.entity\n    \n    var state: GestureStateComponent = entity.gestureStateComponent ?? GestureStateComponent()\n\n    \/\/ ...\n\n}",
      "language" : "swift"
    },
    {
      "code" : "if state.targetedEntity == nil {\n    state.targetedEntity = value.entity\n    state.initialOrientation = value.entity.orientation(relativeTo: nil)\n}",
      "language" : "swift"
    },
    {
      "code" : "let flippedRotation = Rotation3D(angle: rotation.angle, \n                                 axis: RotationAxis3D(x: -rotation.axis.x,\n                                                      y: rotation.axis.y,\n                                                      z: -rotation.axis.z))\nlet newOrientation = state.startOrientation.rotated(by: flippedRotation)\nentity.setOrientation(.init(newOrientation), relativeTo: nil)",
      "language" : "swift"
    },
    {
      "code" : "\/\/\/ Builds a drag gesture.\nvar dragGesture: some Gesture {\n    DragGesture()\n        .targetedToAnyEntity()\n        .useGestureComponent()\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/\/ Apply this to a `RealityView` to pass gestures on to the component code.\nfunc installGestures() -> some View {\n    simultaneousGesture(dragGesture)\n        .simultaneousGesture(magnifyGesture)\n        .simultaneousGesture(rotateGesture)\n}",
      "language" : "swift"
    },
    {
      "code" : "RealityView { content in\n    \/\/ Add the initial RealityKit content.\n    if let scene = try? await Entity(named: \"Scene\", in: realityKitContentBundle) {\n        content.add(scene)\n    }\n} update: { content in\n\n}\n.installGestures()",
      "language" : "swift"
    },
    {
      "code" : "var component = GestureComponent()\ncomponent.canDrag = true \ncomponent.canScale = false\ncomponent.canRotate = true\nmyEntity.components.set(component)",
      "language" : "swift"
    }
  ],
  "contentHash" : "e6d9d550ca8194c7ba5390f9ddf1473f2c960adc9bd024a092b6d9704d717e61",
  "crawledAt" : "2025-12-02T20:15:02Z",
  "id" : "1B23C985-0581-4512-AD12-D6399C2F9D8C",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "RealityKit",
  "overview" : "## Overview\n\nManipulating virtual objects using standard system drag, rotate, and scale gestures is a common task in visionOS apps. This sample project demonstrates how to apply SwiftUI gestures to a RealityKit [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/Entity] by implementing the gestures with a component and an extension on [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView]. The component marks entities as supporting transform gestures and the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] extension passes events from the SwiftUI gesture actions to the component, which also contains the logic to implement the gestures. You can add transformation gesture support to any entity in your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] just by adding the gesture component to the entity.\n\n### Create the main component\n\nTo implement the gesture functionality, the sample app first creates a `struct` that conforms to [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/Component]. This component marks entities that support transform gestures, and contains the logic to implement those gestures. In order to support Reality Composer Pro, the component also conforms to [doc:\/\/com.apple.documentation\/documentation\/Swift\/Codable]. To include the ability to turn different gestures on and off, the component contains three [doc:\/\/com.apple.documentation\/documentation\/Swift\/Bool] properties, one for each of the transforms the component supports. Reality Composer Pro exposes the transforms as checkboxes, which enable or disable specific gestures for an entity.\n\nThe component has two other properties for configuring the drag style, shown below:\n\nThe `pivotOnDrag` properties configure whether the object moves along the X-axis in a straight line, or pivots around a person, similar to the visionOS keyboard. When `pivotOnDrag` is `true`, the `preserveOrientationOnPivotDrag` determines if the object rotates to face the viewer as they drag it, such as for the visionOS keyboard, or keeps its original orientation throughout the drag gesture.\n\nPivoting on drag is more flexible because it allows a person to change their own orientation without the  entity they’re dragging from disappearing out of view. However, in some cases, dragging without the pivot may be a better option, such as when they need to precisely line up an entity with another.\n\n### Create a state object\n\nTo implement these transform gestures, the app needs to maintain some state. The [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] action passes a delta from the start transform, *not* the delta from the previous [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] call, so the app needs to keep track of the entity’s starting position, rotation, and scale. For example, each time SwiftUI calls the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] action for a drag gesture, the action provides the total distance dragged on each axis since the gesture started. The app also keeps track of whether a gesture is already in progress. Gestures don’t have an `.onStarted` action, so the app keeps track of whether the gesture has already started so it knows if it needs to store the starting position, rotation, or scale. Lastly, the sample app keeps a reference to the pivot entity. By parenting the dragged entity to the pivot entity, the system calculates the dragged entity’s rotation when the app rotates the pivot entity.\n\nThis component only supports dragging a single entity at a time, so there’s no need to store state on a per-entity level. As a result, the app uses a singleton object to store the state instead of a component:\n\n### Add transform logic to the main component\n\n`GestureComponent` needs to implement functions the app calls from the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] and [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onEnded(_:)] actions for each of the three supported types of gestures. The `onChange` functions first retrieve the gesture entity and its state component, creating a new state component if one doesn’t already exist, as shown below:\n\nThe first time the app calls the function for a particular gesture, the function stores the starting position, orientation, or scale. The drag function looks like this:\n\nFinally, the function calculates the entity’s new position, rotation, or scale by applying the information from the gesture to the starting value stored in the state component. Here’s the logic for the rotate gesture:\n\n### Create a RealityView extension\n\nTo connect the SwiftUI gestures to the component, this sample uses an extension on [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] that contains functions that send the gesture information to the component. For example, here’s the gesture property that forwards the drag gesture events to the component:\n\nThe extension also contains a function that installs all three of the gestures to a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] at once:\n\n### Install the gestures on the RealityView\n\nTo forward the gesture information to the entity components, the app calls the `installGestures()` function on the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] returned from the initializer.\n\n### Add the gesture component to entities\n\nOnce the app installs the gestures on the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView], people can manipulate any entity containing a `GestureComponent`. This sample uses a Reality Composer Pro scene to add a `GestureComponent` to each of its entities. It also adds an [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/InputTargetComponent] and a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CollisionComponent] to those entities, because all three components are necessary for the entity to support gestures. Each of the four entities in the sample’s Reality Composer scene support a different combination of gestures.\n\nInstead of adding the component in Reality Composer Pro, the app could add the components to entities in code, like this:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/realitykit\/transforming-realitykit-entities-with-gestures\ncrawled: 2025-12-02T20:15:02Z\n---\n\n# Transforming RealityKit entities using gestures\n\n**Sample Code**\n\nBuild a RealityKit component to support standard visionOS gestures on any entity.\n\n## Overview\n\nManipulating virtual objects using standard system drag, rotate, and scale gestures is a common task in visionOS apps. This sample project demonstrates how to apply SwiftUI gestures to a RealityKit [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/Entity] by implementing the gestures with a component and an extension on [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView]. The component marks entities as supporting transform gestures and the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] extension passes events from the SwiftUI gesture actions to the component, which also contains the logic to implement the gestures. You can add transformation gesture support to any entity in your [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] just by adding the gesture component to the entity.\n\n### Create the main component\n\nTo implement the gesture functionality, the sample app first creates a `struct` that conforms to [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/Component]. This component marks entities that support transform gestures, and contains the logic to implement those gestures. In order to support Reality Composer Pro, the component also conforms to [doc:\/\/com.apple.documentation\/documentation\/Swift\/Codable]. To include the ability to turn different gestures on and off, the component contains three [doc:\/\/com.apple.documentation\/documentation\/Swift\/Bool] properties, one for each of the transforms the component supports. Reality Composer Pro exposes the transforms as checkboxes, which enable or disable specific gestures for an entity.\n\n```swift\n\/\/\/ A component that handles gesture logic for an entity.\npublic struct GestureComponent: Component, Codable {\n    \n    \/\/\/ A Boolean value that indicates whether a gesture can drag the entity.\n    public var canDrag: Bool = true\n    \n    \/\/\/ ...\n    \n    \/\/\/ A Boolean value that indicates whether a gesture can scale the entity.\n    public var canScale: Bool = true\n    \n    \/\/\/ A Boolean value that indicates whether a gesture can rotate the entity.\n    public var canRotate: Bool = true\n\n    \/\/\/ ...\n```\n\nThe component has two other properties for configuring the drag style, shown below:\n\n```swift\n    \/\/\/ A Boolean value that indicates whether the drag gesture can move the object in an arc, similar to dragging windows or moving the keyboard.\n    public var pivotOnDrag: Bool = true\n    \n    \/\/\/ A Boolean value that indicates whether a pivot drag keeps the orientation toward the\n    \/\/\/ viewer throughout the drag gesture.\n    \/\/\/\n    \/\/\/ The property only applies when `pivotOnDrag` is `true`.\n    public var preserveOrientationOnPivotDrag: Bool = true\n```\n\nThe `pivotOnDrag` properties configure whether the object moves along the X-axis in a straight line, or pivots around a person, similar to the visionOS keyboard. When `pivotOnDrag` is `true`, the `preserveOrientationOnPivotDrag` determines if the object rotates to face the viewer as they drag it, such as for the visionOS keyboard, or keeps its original orientation throughout the drag gesture.\n\nPivoting on drag is more flexible because it allows a person to change their own orientation without the  entity they’re dragging from disappearing out of view. However, in some cases, dragging without the pivot may be a better option, such as when they need to precisely line up an entity with another.\n\n### Create a state object\n\nTo implement these transform gestures, the app needs to maintain some state. The [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] action passes a delta from the start transform, *not* the delta from the previous [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] call, so the app needs to keep track of the entity’s starting position, rotation, and scale. For example, each time SwiftUI calls the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] action for a drag gesture, the action provides the total distance dragged on each axis since the gesture started. The app also keeps track of whether a gesture is already in progress. Gestures don’t have an `.onStarted` action, so the app keeps track of whether the gesture has already started so it knows if it needs to store the starting position, rotation, or scale. Lastly, the sample app keeps a reference to the pivot entity. By parenting the dragged entity to the pivot entity, the system calculates the dragged entity’s rotation when the app rotates the pivot entity.\n\nThis component only supports dragging a single entity at a time, so there’s no need to store state on a per-entity level. As a result, the app uses a singleton object to store the state instead of a component:\n\n```swift\npublic class EntityGestureState {\n    \n    \/\/\/ The entity currently being dragged if a gesture is in progress.\n    var targetedEntity: Entity?\n    \n    \/\/ MARK: - Drag\n    \n    \/\/\/ The starting position.\n    var dragStartPosition: SIMD3<Float> = .zero\n    \n    \/\/\/ Marks whether the app is currently handling a drag gesture.\n    var isDragging = false\n    \n    \/\/\/ When `rotateOnDrag` is`true`, this entity acts as the pivot point for the drag.\n    var pivotEntity: Entity?\n    \n    var initialOrientation: simd_quatf?\n    \n    \/\/ MARK: - Magnify\n    \n    \/\/\/ The starting scale value.\n    var startScale: SIMD3<Float> = .one\n    \n    \/\/\/ Marks whether the app is currently handling a scale gesture.\n    var isScaling = false\n    \n    \/\/ MARK: - Rotation\n    \n    \/\/\/ The starting rotation value.\n    var startOrientation = Rotation3D.identity\n    \n    \/\/\/ Marks whether the app is currently handling a rotation gesture.\n    var isRotating = false\n    \n    \/\/ MARK: - Singleton Accessor\n    \n    \/\/\/ Retrieves the shared instance.\n    static let shared = EntityGestureState()\n}\n```\n\n### Add transform logic to the main component\n\n`GestureComponent` needs to implement functions the app calls from the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onChanged(_:)] and [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Gesture\/onEnded(_:)] actions for each of the three supported types of gestures. The `onChange` functions first retrieve the gesture entity and its state component, creating a new state component if one doesn’t already exist, as shown below:\n\n```swift\nmutating func onChanged(value: EntityTargetValue<DragGesture.Value>) {\n    guard canDrag else { return }\n    let entity = value.entity\n    \n    var state: GestureStateComponent = entity.gestureStateComponent ?? GestureStateComponent()\n\n    \/\/ ...\n\n}\n```\n\nThe first time the app calls the function for a particular gesture, the function stores the starting position, orientation, or scale. The drag function looks like this:\n\n```swift\nif state.targetedEntity == nil {\n    state.targetedEntity = value.entity\n    state.initialOrientation = value.entity.orientation(relativeTo: nil)\n}\n```\n\nFinally, the function calculates the entity’s new position, rotation, or scale by applying the information from the gesture to the starting value stored in the state component. Here’s the logic for the rotate gesture:\n\n```swift\nlet flippedRotation = Rotation3D(angle: rotation.angle, \n                                 axis: RotationAxis3D(x: -rotation.axis.x,\n                                                      y: rotation.axis.y,\n                                                      z: -rotation.axis.z))\nlet newOrientation = state.startOrientation.rotated(by: flippedRotation)\nentity.setOrientation(.init(newOrientation), relativeTo: nil)\n```\n\n### Create a RealityView extension\n\nTo connect the SwiftUI gestures to the component, this sample uses an extension on [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] that contains functions that send the gesture information to the component. For example, here’s the gesture property that forwards the drag gesture events to the component:\n\n```swift\n\/\/\/ Builds a drag gesture.\nvar dragGesture: some Gesture {\n    DragGesture()\n        .targetedToAnyEntity()\n        .useGestureComponent()\n}\n```\n\nThe extension also contains a function that installs all three of the gestures to a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] at once:\n\n```swift\n\/\/\/ Apply this to a `RealityView` to pass gestures on to the component code.\nfunc installGestures() -> some View {\n    simultaneousGesture(dragGesture)\n        .simultaneousGesture(magnifyGesture)\n        .simultaneousGesture(rotateGesture)\n}\n```\n\n### Install the gestures on the RealityView\n\nTo forward the gesture information to the entity components, the app calls the `installGestures()` function on the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView] returned from the initializer.\n\n```swift\nRealityView { content in\n    \/\/ Add the initial RealityKit content.\n    if let scene = try? await Entity(named: \"Scene\", in: realityKitContentBundle) {\n        content.add(scene)\n    }\n} update: { content in\n\n}\n.installGestures()\n```\n\n### Add the gesture component to entities\n\nOnce the app installs the gestures on the [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/RealityView], people can manipulate any entity containing a `GestureComponent`. This sample uses a Reality Composer Pro scene to add a `GestureComponent` to each of its entities. It also adds an [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/InputTargetComponent] and a [doc:\/\/com.apple.RealityKit\/documentation\/RealityKit\/CollisionComponent] to those entities, because all three components are necessary for the entity to support gestures. Each of the four entities in the sample’s Reality Composer scene support a different combination of gestures.\n\nInstead of adding the component in Reality Composer Pro, the app could add the components to entities in code, like this:\n\n```swift\nvar component = GestureComponent()\ncomponent.canDrag = true \ncomponent.canScale = false\ncomponent.canRotate = true\nmyEntity.components.set(component)\n```\n\n## Scene content\n\n- **Hello World**: Use windows, volumes, and immersive spaces to teach people about the Earth.\n- **Enabling video reflections in an immersive environment**: Create a more immersive experience by adding video reflections in a custom environment.\n- **Creating a spatial drawing app with RealityKit**: Use low-level mesh and texture APIs to achieve fast updates to a person’s brush strokes by integrating RealityKit with ARKit and SwiftUI.\n- **Generating interactive geometry with RealityKit**: Create an interactive mesh with low-level mesh and low-level texture.\n- **Combining 2D and 3D views in an immersive app**: Use attachments to place 2D content relative to 3D content in your visionOS app.\n- **Responding to gestures on an entity**: Respond to gestures performed on RealityKit entities using input target and collision components.\n- **Models and meshes**: Display virtual objects in your scene with mesh-based models.\n- **Materials, textures, and shaders**: Apply textures to the surface of your scene’s 3D objects to give each object a unique appearance.\n- **Anchors**: Lock virtual content to the real world.\n- **Lights and cameras**: Control the lighting and point of view for a scene.\n- **Content synchronization**: Synchronize the contents of entities locally or across the network.\n- **Audio**: Create personalized and realistic spatial audio experiences.\n- **Videos**: Present videos in your RealityKit experiences.\n- **Images**: Present images and spatial scenes in your RealityKit experiences.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use windows, volumes, and immersive spaces to teach people about the Earth.",
          "name" : "Hello World",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/World"
        },
        {
          "description" : "Create a more immersive experience by adding video reflections in a custom environment.",
          "name" : "Enabling video reflections in an immersive environment",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/enabling-video-reflections-in-an-immersive-environment"
        },
        {
          "description" : "Use low-level mesh and texture APIs to achieve fast updates to a person’s brush strokes by integrating RealityKit with ARKit and SwiftUI.",
          "name" : "Creating a spatial drawing app with RealityKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/creating-a-spatial-drawing-app-with-realitykit"
        },
        {
          "description" : "Create an interactive mesh with low-level mesh and low-level texture.",
          "name" : "Generating interactive geometry with RealityKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/generating-interactive-geometry-with-realitykit"
        },
        {
          "description" : "Use attachments to place 2D content relative to 3D content in your visionOS app.",
          "name" : "Combining 2D and 3D views in an immersive app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/combining-2d-and-3d-views-in-an-immersive-app"
        },
        {
          "description" : "Respond to gestures performed on RealityKit entities using input target and collision components.",
          "name" : "Responding to gestures on an entity",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/responding-to-gestures-on-an-entity"
        },
        {
          "description" : "Display virtual objects in your scene with mesh-based models.",
          "name" : "Models and meshes",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-models-and-meshes"
        },
        {
          "description" : "Apply textures to the surface of your scene’s 3D objects to give each object a unique appearance.",
          "name" : "Materials, textures, and shaders",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-materials-and-shaders"
        },
        {
          "description" : "Lock virtual content to the real world.",
          "name" : "Anchors",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-anchors"
        },
        {
          "description" : "Control the lighting and point of view for a scene.",
          "name" : "Lights and cameras",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-lights-and-cameras"
        },
        {
          "description" : "Synchronize the contents of entities locally or across the network.",
          "name" : "Content synchronization",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-content-synchronization"
        },
        {
          "description" : "Create personalized and realistic spatial audio experiences.",
          "name" : "Audio",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-audio"
        },
        {
          "description" : "Present videos in your RealityKit experiences.",
          "name" : "Videos",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-videos"
        },
        {
          "description" : "Present images and spatial scenes in your RealityKit experiences.",
          "name" : "Images",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/scene-content-images"
        }
      ],
      "title" : "Scene content"
    }
  ],
  "source" : "appleJSON",
  "title" : "Transforming RealityKit entities using gestures",
  "url" : "https:\/\/developer.apple.com\/documentation\/realitykit\/transforming-realitykit-entities-with-gestures"
}