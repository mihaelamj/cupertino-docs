{
  "abstract" : "Display content and provide services in an AR experience with App Clip Codes.",
  "codeExamples" : [
    {
      "code" : "AppClipCodeGenerator generate --url https:\/\/developer.apple.com\/sunfl --index 0 --output ~\/Downloads\/AppClipCode-sunflower.svg --logo badge",
      "language" : "shell"
    },
    {
      "code" : "guard ARWorldTrackingConfiguration.supportsAppClipCodeTracking else {\n    displayUnsupportedDevicePrompt()\n    return",
      "language" : "swift"
    },
    {
      "code" : "newConfiguration.appClipCodeTrackingEnabled = true\narView.session.run(newConfiguration)",
      "language" : "swift"
    },
    {
      "code" : "func scene(_ scene: UIScene, willConnectTo session: UISceneSession, options connectionOptions: UIScene.ConnectionOptions) {\n    for activity in connectionOptions.userActivities where activity.activityType == NSUserActivityTypeBrowsingWeb {\n        appClipCodeURL = activity.webpageURL",
      "language" : "swift"
    },
    {
      "code" : "process(productKey: getProductKey(from: appClipCodeLaunchURL), initializePreview: false)",
      "language" : "swift"
    },
    {
      "code" : "class AppClipCodeCoachingOverlayView: UILabel {\n    init(parentView: UIView) {\n        super.init(frame: .zero)\n        text = \"Scan code to start\"",
      "language" : "swift"
    },
    {
      "code" : "https:\/\/developer.apple.com\/sunfl",
      "language" : "other"
    },
    {
      "code" : "\"appclips\": {\n    \"apps\": [\n        \"A93A5CM278.com.example.apple-samplecode.AppClipCodesExampleApp1.Clip\",\n        \"A93A5CM278.com.example.apple-samplecode.AppClipCodesExampleApp1\"\n    ]\n}",
      "language" : "json"
    },
    {
      "code" : "<key>com.apple.developer.associated-domains<\/key>\n<array>\n    <string>appclips:developer.apple.com<\/string>\n<\/array>",
      "language" : "plist"
    },
    {
      "code" : "func session(_ session: ARSession, didAdd anchors: [ARAnchor]) {\n    for anchor in anchors {\n        if anchor is ARAppClipCodeAnchor {\n            \/\/ Hide the coaching overlay since ARKit recognized an App Clip Code.\n            appClipCodeCoachingOverlay.setCoachingViewHidden(true)",
      "language" : "swift"
    },
    {
      "code" : "func session(_ session: ARSession, didUpdate anchors: [ARAnchor]) {\n    for anchor in anchors {\n        if let appClipCodeAnchor = anchor as? ARAppClipCodeAnchor, appClipCodeAnchor.urlDecodingState != .decoding {\n            let decodedURL: URL\n            switch appClipCodeAnchor.urlDecodingState {\n            case .decoded:\n                    decodedURL = appClipCodeAnchor.url!\n                    if !decodedURLs.contains(decodedURL) {\n                        decodedURLs.append(decodedURL)\n                        process(productKey: getProductKey(from: decodedURL))",
      "language" : "swift"
    },
    {
      "code" : "var testAppClipCodeURL = URL(string: \"https:\/\/developer.apple.com\/sunfl\")!",
      "language" : "swift"
    },
    {
      "code" : "func getProductKey(from url: URL) -> String { return url.lastPathComponent }",
      "language" : "swift"
    },
    {
      "code" : "let modelURLFor: [String: URL] = [\n    \"sunfl\": URL(string: \"https:\/\/developer.apple.com\/sample-code\/ar\/sunflower.usdz\")!\n]",
      "language" : "swift"
    },
    {
      "code" : "extension ViewController {\n    func process(productKey: String, initializePreview: Bool = true) {\n        if let modelURL = modelURLFor[productKey] {\n            process(modelURL: modelURL, productKey: productKey)\n\nfunc process(modelURL: URL, productKey: String) {\n    let contentLoad = CachingWebLoader.shared.cachedWebLoad(url: modelURL)",
      "language" : "swift"
    },
    {
      "code" : "let imageURLFor: [String: URL] = [\n    \"sunfl\": URL(string: \"https:\/\/developer.apple.com\/sample-code\/ar\/sunflower.jpg\")!\n]",
      "language" : "swift"
    },
    {
      "code" : "func process(imageURL: URL, productKey: String, initializeImageAnchor: Bool) {\n    if initializeImageAnchor {\n        let imageLoader = CachingWebLoader.shared.cachedWebLoad(url: imageURL) { [weak self] url in\n            DispatchQueue.global(qos: .userInitiated).async {\n                if\n                    let dataProvider = CGDataProvider(url: url as CFURL),\n                    let image = CGImage(\n                        jpegDataProviderSource: dataProvider,\n                        decode: nil,\n                        shouldInterpolate: false,\n                        intent: .absoluteColorimetric\n                    )\n                {\n                    let modelAnchorImage = ARReferenceImage(\n                        image,\n                        orientation: .up,\n                        \/\/ Note: the width of the sample seed packet is about 8cm.\n                        physicalWidth: 0.08\n                    )",
      "language" : "swift"
    },
    {
      "code" : "if let imageAnchorForModel = self?.imageAnchorFor[productKey], let self = self {\n    self.modelFor[productKey]!.present(on: imageAnchorForModel)",
      "language" : "swift"
    }
  ],
  "contentHash" : "8a835b849c32b44574442e46b3fb0dfb3d214f7d9e2a8d2d11df7b32a4b5b8ce",
  "crawledAt" : "2025-12-02T15:28:20Z",
  "id" : "AD39211C-0282-46E7-AB03-AF0B6E56F15E",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "App Clips",
  "overview" : "## Overview\n\nThe sample app Seed Shop provides gardeners with previews of fully grown plants. At the nursery, Seed Shop identifies the plant from an App Clip Code on a seed packet, and displays the adult plant in 3D. With the help of AR, the buyer can see, for example, the real height of a typical Mammoth sunflower by inspecting the virtual plant at scale, relative to real objects in the camera feed.\n\n\n\nWhen a user with a device running iOS & iPad OS 14.3 or later scans the seed packet’s App Clip Code with their camera or Code Scanner, the sample project’s App Clip provides a virtual image of the plant.\n\nIf the user indicates they may buy a particular plant in the App Clip experience, Seed Shop suggests the user download the full version of the app to preview the plant in their own garden. This sample project builds the App Clip Code provided on the seed packet at the garden store, allowing the user to view an AR version of the plant before purchase.\n\n### Configure the Sample Code Project\n\nTo configure Seed Shop for code signing, first set a development team on each target. Define a unique bundle ID for the targets, and set the App Clip’s parent application identifiers entitlement.\n\nNext, set the hostname for the App Clip experience URL in the Associated Domains entitlement. The process of setting the hostname requires an explicit App ID, provided by a development team member with Admin permission. For more information on setting a development team, bundle ID, and entitlements, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/creating-an-app-clip-with-xcode].\n\nRun the following command to generate an App Clip Code from the [https:\/\/developer.apple.com\/app-clips\/resources\/]:\n\nTo add the sample’s App Clip Codes to the environment, you can display them on another device or print them out. For more on creating App Clip Codes, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/creating-app-clip-codes].\n\nThe App Clip Codes in Seed Shop display on a package of seeds. Add this [https:\/\/developer.apple.com\/sample-code\/ar\/sunflower.jpg] to your physical environment by displaying it on another device or printing it out.\n\n### Ensure Device Support and Run a Session\n\nIn [x-source-tag:\/\/ViewDidLoad], the sample app calls [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARWorldTrackingConfiguration\/supportsAppClipCodeTracking] to check if the device contains the Apple Neural Engine (ANE), which App Clip Code tracking requires.\n\nTo search the environment for physical codes, the sample sets [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARWorldTrackingConfiguration\/appClipCodeTrackingEnabled] to `true` before running the session.\n\n### Identify the App Clip Code that Launched the Experience\n\nWhen the user points the device at an App Clip Code using the camera or Code Scanner, the system launches its associated App Clip, or if present, the full app.\n\nIn the AR experience, the sample code checks the [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity] invocation URL to identify the App Clip Code that invoked the app or App Clip.\n\nThe source of the URL depends on how the App Clip launched:\n\nThere may be multiple App Clip Codes visible in the camera feed that share the same [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/url]; for more information, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor].\n\nIf an app interacts with a single App Clip Code, the app can limit its interaction with App Clip Codes that encode the invocation URL. For simplicity, the sample allows the user to scan any associated App Clip Code. However, because the sample app downloads custom assets over the web per App Clip Code, the sample app begins downloading assets for the invocation URL immediately, in anticipation that ARKit will recognize the invoking App Clip Code in the camera feed.\n\n### Guide the User with Messaging\n\nThe device may pan away from the App Clip Code that launched the experience in the time it takes for the system to transition from the camera or Code Scanner to the app or App Clip. In the event ARKit doesn’t immediately find the App Clip Code in the camera feed, the sample app displays text instructing the user what to do.\n\n### Launch the App Clip in Code Scanner\n\nDuring development, the sample project can launch the App Clip target in Xcode to test the AR experience. After the target launches once, the device scans the test App Clip Code with Code Scanner to invoke the App Clip.\n\nTo associate an App Clip Code to the App Clip during development, Seed Shop sets up an App Clip local experience. The sample app requires a local experience URL prefix of `https:\/\/developer.apple.com`, and a bundle ID of `com.example.apple-samplecode.AppClipCodesExampleApp1.Clip`.\n\nFor more on local experiences, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/testing-the-launch-experience-of-your-app-clip#Test-invocations-with-a-local-experience].\n\n### Set Up an App Clip Experience in App Store Connect\n\nAt runtime, the system checks the App Clip registry in App Store Connect to ensure an App Clip associates to an App Clip Code before allowing the app access to the App Clip Code URL. For more information, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/url].\n\nTo decode App Clip Code URLs, Seed Shop sets up an App Clip experience in App Store Connect, and defines the App Clip experience URL of `https:\/\/developer.apple.com`. The value of the App Clip experience URL maps to a server that’s unique and depends on the development team. For more information, see [https:\/\/help.apple.com\/app-store-connect\/#\/dev5b665db74].\n\nThe app generates App Clip Codes that associate to the App Clip experience in App Store Connect by uploading a CSV file containing the App Clip Code URLs. The fully qualified domain name of each URL matches the App Clip experience URL. The URL suffix identifies the context-specific items or locations with which the App Clip interacts. The sample app identifies a seed packet for a sunflower. To create an App Clip Code for the sunflower, the sample requires a CSV file containing the URL:\n\nWhen testers view App Clip Codes to launch the App Clip or decode [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] URLs in an AR experience, the framework refers to the device’s local experience. Otherwise, the system displays the App Clip card in the device camera, and allows [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] URL decoding, only for App Clip experience URLs of app-review approved App Clips. For more information, see [https:\/\/help.apple.com\/app-store-connect\/#\/devbc57e2ec6].\n\n### Configure the Server and Targets for App Site Association\n\nApp Store Connect allows an app to define a particular App Clip experience URL if the server hosting the URL’s domain approves of it via Apple App Site Association. In addition, the framework performs an equivalent runtime check before allowing the App Clip or parent app to decode [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] URLs that are within the App Clip experience’s domain. This check occurs for local and App Store Connect experiences. To express approval, the server provides the App Clip’s and parent app’s fully qualified application identifiers in an Apple App Site Association (AASA) file’s `appclips` node.\n\nSeed Shop requires the AASA file that the Apple Developer website hosts at [https:\/\/developer.apple.com\/.well-known\/apple-app-site-association]. Navigate the URL in Safari and inspect its `appclips` node to see the sample app’s AASA configuration.\n\nThe sample project enables the Associated Domains capability on both targets. The key’s value is the fully qualified domain of the sample project’s App Clip experience URL.\n\nFor more on configuring AASA for App Clips, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/associating-your-app-clip-with-your-website].\n\n### Recognize an App Clip Code and Decode the URL\n\nWhen ARKit recognizes an App Clip Code in the camera feed, it instantiates an [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] and passes it to the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)] callback. Since the user succeeded in scanning a code, the sample app hides the instructional text.\n\nAccess the anchor’s URL for context-specific information about the recognized App Clip Code. The URL is `nil` until the anchor’s [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/urlDecodingState-swift.property] is [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/URLDecodingState-swift.enum\/decoded]. To check for decoding state changes, the sample app monitors the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARSessionDelegate\/session(_:didUpdate:)-3qtt8] callback.\n\nIf Seed Shop fails to decode the URL, the sample project uses a test URL.\n\nFor more on URL decoding failure, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/URLDecodingState-swift.enum\/failed].\n\n### Retrieve a Product’s 3D Model\n\nWhen ARKit decodes an App Clip Code’s URL, the sample app parses the URL suffix to get the product name.\n\nThe app implements a custom URL mapping system using the project’s `modelURLFor` dictionary. Each dictionary key is an App Clip Code’s URL suffix, and the value represents the seed packet’s corresponding grown plant 3D asset.\n\nThe sample app downloads the asset and prepares the 3D model using the mapped `contentURL`.\n\n### Search for Product Packaging\n\nThe sample project’s URL mapping system includes an image of the product’s packaging material on which to place the product’s 3D model in the environment.\n\nARKit estimates the 3D position and orientation of each [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor], but [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARImageAnchor] serves as a better platform on which to place virtual content for several reasons:\n\nTo search the environment for the product’s packaging image, the sample downloads the image that the mapping URL references and then creates an [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARReferenceImage].\n\nFor more information about image tracking, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/tracking-and-altering-images].\n\n### Display the 3D Asset\n\nWhen the user pans the device from the scanned App Clip Code to its downloaded packaging image, ARKit identifies the seed packet’s real-world location and displays the full-grown plant on top.\n\n\n\nWhen ARKit recognizes the packaging image, the session creates an image anchor and passes it into the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)] callback. The app displays the virtual product on top of the image by calling its `present(_:on)` function.\n\nAs the user views the virtual plant, the App Clip waits for the user to scan another seed packet. During this time, the App Clip can provide information about the features of the full app. For example, the Seed Shop App Clip might offer the user the ability to download the full app to preview the full-grown plant in their garden. For recommendations about showcasing an app in an App Clip, see [https:\/\/developer.apple.com\/design\/human-interface-guidelines\/app-clips\/overview\/].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AppClip\/interacting-with-app-clip-codes-in-ar\ncrawled: 2025-12-02T15:28:20Z\n---\n\n# Interacting with App Clip Codes in AR\n\n**Sample Code**\n\nDisplay content and provide services in an AR experience with App Clip Codes.\n\n## Overview\n\nThe sample app Seed Shop provides gardeners with previews of fully grown plants. At the nursery, Seed Shop identifies the plant from an App Clip Code on a seed packet, and displays the adult plant in 3D. With the help of AR, the buyer can see, for example, the real height of a typical Mammoth sunflower by inspecting the virtual plant at scale, relative to real objects in the camera feed.\n\n\n\nWhen a user with a device running iOS & iPad OS 14.3 or later scans the seed packet’s App Clip Code with their camera or Code Scanner, the sample project’s App Clip provides a virtual image of the plant.\n\nIf the user indicates they may buy a particular plant in the App Clip experience, Seed Shop suggests the user download the full version of the app to preview the plant in their own garden. This sample project builds the App Clip Code provided on the seed packet at the garden store, allowing the user to view an AR version of the plant before purchase.\n\n### Configure the Sample Code Project\n\nTo configure Seed Shop for code signing, first set a development team on each target. Define a unique bundle ID for the targets, and set the App Clip’s parent application identifiers entitlement.\n\nNext, set the hostname for the App Clip experience URL in the Associated Domains entitlement. The process of setting the hostname requires an explicit App ID, provided by a development team member with Admin permission. For more information on setting a development team, bundle ID, and entitlements, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/creating-an-app-clip-with-xcode].\n\nRun the following command to generate an App Clip Code from the [https:\/\/developer.apple.com\/app-clips\/resources\/]:\n\n```shell\nAppClipCodeGenerator generate --url https:\/\/developer.apple.com\/sunfl --index 0 --output ~\/Downloads\/AppClipCode-sunflower.svg --logo badge\n```\n\nTo add the sample’s App Clip Codes to the environment, you can display them on another device or print them out. For more on creating App Clip Codes, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/creating-app-clip-codes].\n\nThe App Clip Codes in Seed Shop display on a package of seeds. Add this [https:\/\/developer.apple.com\/sample-code\/ar\/sunflower.jpg] to your physical environment by displaying it on another device or printing it out.\n\n\n\n### Ensure Device Support and Run a Session\n\nIn [x-source-tag:\/\/ViewDidLoad], the sample app calls [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARWorldTrackingConfiguration\/supportsAppClipCodeTracking] to check if the device contains the Apple Neural Engine (ANE), which App Clip Code tracking requires.\n\n```swift\nguard ARWorldTrackingConfiguration.supportsAppClipCodeTracking else {\n    displayUnsupportedDevicePrompt()\n    return\n```\n\nTo search the environment for physical codes, the sample sets [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARWorldTrackingConfiguration\/appClipCodeTrackingEnabled] to `true` before running the session.\n\n```swift\nnewConfiguration.appClipCodeTrackingEnabled = true\narView.session.run(newConfiguration)\n```\n\n### Identify the App Clip Code that Launched the Experience\n\nWhen the user points the device at an App Clip Code using the camera or Code Scanner, the system launches its associated App Clip, or if present, the full app.\n\nIn the AR experience, the sample code checks the [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSUserActivity] invocation URL to identify the App Clip Code that invoked the app or App Clip.\n\n```swift\nfunc scene(_ scene: UIScene, willConnectTo session: UISceneSession, options connectionOptions: UIScene.ConnectionOptions) {\n    for activity in connectionOptions.userActivities where activity.activityType == NSUserActivityTypeBrowsingWeb {\n        appClipCodeURL = activity.webpageURL\n```\n\nThe source of the URL depends on how the App Clip launched:\n\n- The invocation URL is the `_XCAppClipURL` scheme environment variable when Xcode launches the app or App Clip. For more information, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/testing-the-launch-experience-of-your-app-clip#Debug-your-App-Clip].\n- The invocation URL is the invoking App Clip Code’s URL when the system launches the app or App Clip in the device’s camera feed or through the Code Scanner.\n\nThere may be multiple App Clip Codes visible in the camera feed that share the same [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/url]; for more information, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor].\n\nIf an app interacts with a single App Clip Code, the app can limit its interaction with App Clip Codes that encode the invocation URL. For simplicity, the sample allows the user to scan any associated App Clip Code. However, because the sample app downloads custom assets over the web per App Clip Code, the sample app begins downloading assets for the invocation URL immediately, in anticipation that ARKit will recognize the invoking App Clip Code in the camera feed.\n\n```swift\nprocess(productKey: getProductKey(from: appClipCodeLaunchURL), initializePreview: false)\n```\n\n### Guide the User with Messaging\n\nThe device may pan away from the App Clip Code that launched the experience in the time it takes for the system to transition from the camera or Code Scanner to the app or App Clip. In the event ARKit doesn’t immediately find the App Clip Code in the camera feed, the sample app displays text instructing the user what to do.\n\n```swift\nclass AppClipCodeCoachingOverlayView: UILabel {\n    init(parentView: UIView) {\n        super.init(frame: .zero)\n        text = \"Scan code to start\"\n```\n\n### Launch the App Clip in Code Scanner\n\nDuring development, the sample project can launch the App Clip target in Xcode to test the AR experience. After the target launches once, the device scans the test App Clip Code with Code Scanner to invoke the App Clip.\n\n\n\nTo associate an App Clip Code to the App Clip during development, Seed Shop sets up an App Clip local experience. The sample app requires a local experience URL prefix of `https:\/\/developer.apple.com`, and a bundle ID of `com.example.apple-samplecode.AppClipCodesExampleApp1.Clip`.\n\nFor more on local experiences, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/testing-the-launch-experience-of-your-app-clip#Test-invocations-with-a-local-experience].\n\n### Set Up an App Clip Experience in App Store Connect\n\nAt runtime, the system checks the App Clip registry in App Store Connect to ensure an App Clip associates to an App Clip Code before allowing the app access to the App Clip Code URL. For more information, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/url].\n\nTo decode App Clip Code URLs, Seed Shop sets up an App Clip experience in App Store Connect, and defines the App Clip experience URL of `https:\/\/developer.apple.com`. The value of the App Clip experience URL maps to a server that’s unique and depends on the development team. For more information, see [https:\/\/help.apple.com\/app-store-connect\/#\/dev5b665db74].\n\nThe app generates App Clip Codes that associate to the App Clip experience in App Store Connect by uploading a CSV file containing the App Clip Code URLs. The fully qualified domain name of each URL matches the App Clip experience URL. The URL suffix identifies the context-specific items or locations with which the App Clip interacts. The sample app identifies a seed packet for a sunflower. To create an App Clip Code for the sunflower, the sample requires a CSV file containing the URL:\n\n```other\nhttps:\/\/developer.apple.com\/sunfl\n```\n\nWhen testers view App Clip Codes to launch the App Clip or decode [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] URLs in an AR experience, the framework refers to the device’s local experience. Otherwise, the system displays the App Clip card in the device camera, and allows [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] URL decoding, only for App Clip experience URLs of app-review approved App Clips. For more information, see [https:\/\/help.apple.com\/app-store-connect\/#\/devbc57e2ec6].\n\n\n\n### Configure the Server and Targets for App Site Association\n\nApp Store Connect allows an app to define a particular App Clip experience URL if the server hosting the URL’s domain approves of it via Apple App Site Association. In addition, the framework performs an equivalent runtime check before allowing the App Clip or parent app to decode [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] URLs that are within the App Clip experience’s domain. This check occurs for local and App Store Connect experiences. To express approval, the server provides the App Clip’s and parent app’s fully qualified application identifiers in an Apple App Site Association (AASA) file’s `appclips` node.\n\n```json\n\"appclips\": {\n    \"apps\": [\n        \"A93A5CM278.com.example.apple-samplecode.AppClipCodesExampleApp1.Clip\",\n        \"A93A5CM278.com.example.apple-samplecode.AppClipCodesExampleApp1\"\n    ]\n}\n```\n\nSeed Shop requires the AASA file that the Apple Developer website hosts at [https:\/\/developer.apple.com\/.well-known\/apple-app-site-association]. Navigate the URL in Safari and inspect its `appclips` node to see the sample app’s AASA configuration.\n\nThe sample project enables the Associated Domains capability on both targets. The key’s value is the fully qualified domain of the sample project’s App Clip experience URL.\n\n```plist\n<key>com.apple.developer.associated-domains<\/key>\n<array>\n    <string>appclips:developer.apple.com<\/string>\n<\/array>\n```\n\nFor more on configuring AASA for App Clips, see [doc:\/\/com.apple.documentation\/documentation\/AppClip\/associating-your-app-clip-with-your-website].\n\n### Recognize an App Clip Code and Decode the URL\n\nWhen ARKit recognizes an App Clip Code in the camera feed, it instantiates an [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor] and passes it to the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)] callback. Since the user succeeded in scanning a code, the sample app hides the instructional text.\n\n```swift\nfunc session(_ session: ARSession, didAdd anchors: [ARAnchor]) {\n    for anchor in anchors {\n        if anchor is ARAppClipCodeAnchor {\n            \/\/ Hide the coaching overlay since ARKit recognized an App Clip Code.\n            appClipCodeCoachingOverlay.setCoachingViewHidden(true)\n```\n\nAccess the anchor’s URL for context-specific information about the recognized App Clip Code. The URL is `nil` until the anchor’s [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/urlDecodingState-swift.property] is [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/URLDecodingState-swift.enum\/decoded]. To check for decoding state changes, the sample app monitors the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARSessionDelegate\/session(_:didUpdate:)-3qtt8] callback.\n\n```swift\nfunc session(_ session: ARSession, didUpdate anchors: [ARAnchor]) {\n    for anchor in anchors {\n        if let appClipCodeAnchor = anchor as? ARAppClipCodeAnchor, appClipCodeAnchor.urlDecodingState != .decoding {\n            let decodedURL: URL\n            switch appClipCodeAnchor.urlDecodingState {\n            case .decoded:\n                    decodedURL = appClipCodeAnchor.url!\n                    if !decodedURLs.contains(decodedURL) {\n                        decodedURLs.append(decodedURL)\n                        process(productKey: getProductKey(from: decodedURL))\n```\n\nIf Seed Shop fails to decode the URL, the sample project uses a test URL.\n\n```swift\nvar testAppClipCodeURL = URL(string: \"https:\/\/developer.apple.com\/sunfl\")!\n```\n\nFor more on URL decoding failure, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor\/URLDecodingState-swift.enum\/failed].\n\n\n\n### Retrieve a Product’s 3D Model\n\nWhen ARKit decodes an App Clip Code’s URL, the sample app parses the URL suffix to get the product name.\n\n```swift\nfunc getProductKey(from url: URL) -> String { return url.lastPathComponent }\n```\n\nThe app implements a custom URL mapping system using the project’s `modelURLFor` dictionary. Each dictionary key is an App Clip Code’s URL suffix, and the value represents the seed packet’s corresponding grown plant 3D asset.\n\n```swift\nlet modelURLFor: [String: URL] = [\n    \"sunfl\": URL(string: \"https:\/\/developer.apple.com\/sample-code\/ar\/sunflower.usdz\")!\n]\n```\n\nThe sample app downloads the asset and prepares the 3D model using the mapped `contentURL`.\n\n```swift\nextension ViewController {\n    func process(productKey: String, initializePreview: Bool = true) {\n        if let modelURL = modelURLFor[productKey] {\n            process(modelURL: modelURL, productKey: productKey)\n\nfunc process(modelURL: URL, productKey: String) {\n    let contentLoad = CachingWebLoader.shared.cachedWebLoad(url: modelURL)\n```\n\n### Search for Product Packaging\n\nThe sample project’s URL mapping system includes an image of the product’s packaging material on which to place the product’s 3D model in the environment.\n\n```swift\nlet imageURLFor: [String: URL] = [\n    \"sunfl\": URL(string: \"https:\/\/developer.apple.com\/sample-code\/ar\/sunflower.jpg\")!\n]\n```\n\nARKit estimates the 3D position and orientation of each [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARAppClipCodeAnchor], but [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARImageAnchor] serves as a better platform on which to place virtual content for several reasons:\n\n- Small physical size impacts ARKit’s tracking accuracy, and App Clip Codes typically run small on product packaging or in an advertisement.\n- ARKit manages the removal of App Clip Code anchors from the session whereas the app controls whether to remove an image anchor. As a result, the image anchor is less likely to go away.\n\n\n\nTo search the environment for the product’s packaging image, the sample downloads the image that the mapping URL references and then creates an [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARReferenceImage].\n\n```swift\nfunc process(imageURL: URL, productKey: String, initializeImageAnchor: Bool) {\n    if initializeImageAnchor {\n        let imageLoader = CachingWebLoader.shared.cachedWebLoad(url: imageURL) { [weak self] url in\n            DispatchQueue.global(qos: .userInitiated).async {\n                if\n                    let dataProvider = CGDataProvider(url: url as CFURL),\n                    let image = CGImage(\n                        jpegDataProviderSource: dataProvider,\n                        decode: nil,\n                        shouldInterpolate: false,\n                        intent: .absoluteColorimetric\n                    )\n                {\n                    let modelAnchorImage = ARReferenceImage(\n                        image,\n                        orientation: .up,\n                        \/\/ Note: the width of the sample seed packet is about 8cm.\n                        physicalWidth: 0.08\n                    )\n```\n\nFor more information about image tracking, see [doc:\/\/com.apple.documentation\/documentation\/ARKit\/tracking-and-altering-images].\n\n### Display the 3D Asset\n\nWhen the user pans the device from the scanned App Clip Code to its downloaded packaging image, ARKit identifies the seed packet’s real-world location and displays the full-grown plant on top.\n\n\n\nWhen ARKit recognizes the packaging image, the session creates an image anchor and passes it into the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARSessionDelegate\/session(_:didAdd:)] callback. The app displays the virtual product on top of the image by calling its `present(_:on)` function.\n\n```swift\nif let imageAnchorForModel = self?.imageAnchorFor[productKey], let self = self {\n    self.modelFor[productKey]!.present(on: imageAnchorForModel)\n```\n\nAs the user views the virtual plant, the App Clip waits for the user to scan another seed packet. During this time, the App Clip can provide information about the features of the full app. For example, the Seed Shop App Clip might offer the user the ability to download the full app to preview the full-grown plant in their garden. For recommendations about showcasing an app in an App Clip, see [https:\/\/developer.apple.com\/design\/human-interface-guidelines\/app-clips\/overview\/].\n\n## App Clip Codes\n\n- **Creating App Clip Codes**: Help users discover your App Clip by using an NFC-integrated or scan-only App Clip Code.\n- **Encoding a URL in an App Clip Code**: Choose an invocation URL for your App Clip Code that you can encode efficiently.\n- **Preparing multiple App Clip Codes for production**: Prepare your App Clip Codes to send to a professional printing service.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Help users discover your App Clip by using an NFC-integrated or scan-only App Clip Code.",
          "name" : "Creating App Clip Codes",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppClip\/creating-app-clip-codes"
        },
        {
          "description" : "Choose an invocation URL for your App Clip Code that you can encode efficiently.",
          "name" : "Encoding a URL in an App Clip Code",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppClip\/encoding-a-url-in-an-app-clip-code"
        },
        {
          "description" : "Prepare your App Clip Codes to send to a professional printing service.",
          "name" : "Preparing multiple App Clip Codes for production",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppClip\/preparing-multiple-app-clip-codes-for-production"
        }
      ],
      "title" : "App Clip Codes"
    }
  ],
  "source" : "appleJSON",
  "title" : "Interacting with App Clip Codes in AR",
  "url" : "https:\/\/developer.apple.com\/documentation\/AppClip\/interacting-with-app-clip-codes-in-ar"
}