{
  "abstract" : "An object that continues to track an object that you’ve started tracking, and adds a new detection to the detection track you’re building.",
  "codeExamples" : [

  ],
  "contentHash" : "9e22a935cdb3882189bd7de7f6fc1da9050bd3259819e97cf8eac59fbd713354",
  "crawledAt" : "2025-12-04T02:47:38Z",
  "declaration" : {
    "code" : "func continueTracking(at time: CMTime, sourceImage: CVPixelBuffer, sourceDisparity: CVPixelBuffer) -> CNBoundsPrediction?",
    "language" : "swift"
  },
  "id" : "5536DE6C-E1E1-48A4-AFFF-977C3F769C17",
  "kind" : "method",
  "language" : "swift",
  "module" : "Cinematic",
  "overview" : "## Return Value\n\nAn object representing a prediction of where the object is in the source image.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Cinematic\/CNObjectTracker-1n598\/continueTracking(at:sourceImage:sourceDisparity:)\ncrawled: 2025-12-04T02:47:38Z\n---\n\n# continueTracking(at:sourceImage:sourceDisparity:)\n\n**Instance Method**\n\nAn object that continues to track an object that you’ve started tracking, and adds a new detection to the detection track you’re building.\n\n## Declaration\n\n```swift\nfunc continueTracking(at time: CMTime, sourceImage: CVPixelBuffer, sourceDisparity: CVPixelBuffer) -> CNBoundsPrediction?\n```\n\n## Parameters\n\n- **time**: The presentation time of the first frame in the detection track.\n- **sourceImage**: The image buffer containing the image.\n- **sourceDisparity**: The disparity buffer containing depth information.\n\n## Return Value\n\nAn object representing a prediction of where the object is in the source image.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "continueTracking(at:sourceImage:sourceDisparity:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/Cinematic\/CNObjectTracker-1n598\/continueTracking(at:sourceImage:sourceDisparity:)"
}