{
  "abstract" : "Add Spatial Audio editing capabilities with the Audio Mix API in the Cinematic framework.",
  "codeExamples" : [
    {
      "code" : "let myAsset = AVURLAsset(url: URL(filePath: \"myMediaURL\"))\nlet myPlayerItem = AVPlayerItem(asset: myAsset)",
      "language" : "swift"
    },
    {
      "code" : "do {\n    \/\/ This command throws if the input file does not have proper Spatial Audio.\n    let audioInfo = try await CNAssetSpatialAudioInfo(asset: myAsset)\n} catch {\n    print(\"A problem occured reading the spatial audio asset: \\(error)\")\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Sets the mix parameters.\nlet intensity = 0.5 \/\/ Float values between 0.0 and 1.0.\nlet style = CNSpatialAudioRenderingStyle.cinematic\n\n\/\/ Creates an `AVAudioMix` with effect intensity and rendering style.   \nlet newAudioMix = audioInfo.audioMix(effectIntensity: intensity, renderingStyle: style)\nmyPlayerItem.audioMix = newAudioMix\n\n\/\/ AVPlayer plays the asset with the new audio mix parameters.\nlet player = AVPlayer(playerItem: myPlayerItem)",
      "language" : "swift"
    }
  ],
  "contentHash" : "5cdd50420dc00b709508a9cf1fc6213693635437f418b72e8de2fcd287c4891b",
  "crawledAt" : "2025-12-03T07:31:39Z",
  "id" : "B66176FE-64A5-43BC-B7C6-80666EC2B0B7",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Cinematic",
  "overview" : "## Overview\n\nBeginning with iPhone 16, you can use Spatial Audio capture to record video with 3D audio, and edit the audio mix in the Photos app. With Audio Mix, you have creative control of the background and foreground sounds in a recording. It isolates speech as foreground and ambience as background, and you can select between multiple creative rendering styles to adjust the mix.\n\nThe `SpatialAudioCLI` sample project is a command-line tool that demonstrates three different methods for applying an audio mix: using [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer], using [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVAssetWriter], and using [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/kAudioUnitSubType_AUAudioMix].\n\n### Configure the sample code project\n\nFor best results, use `SpatialAudioCLI` with media that contains a Spatial Audio track. On all iPhone 16 models, Spatial Audio recording is available when capturing video with the Camera app. See the [https:\/\/support.apple.com\/en-kw\/guide\/iphone\/iph31c1ca6c7\/ios] for how to change sound recording options.\n\nYou can record Spatial Audio in your app by setting the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDeviceInput\/multichannelAudioMode] property of the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDeviceInput] to a value of `firstOrderAmbisonics`.\n\n### Adjust the audio mix in AVPlayer\n\nThe simplest way to adjust the audio mix is to play Spatial Audio assets with [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer].\n\nFirst, the sample loads the specified input file into an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayerItem]:\n\nThen the sample uses the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVAsset] to initialize an instance of `CNAssetSpatialAudioInfo`:\n\nThe two primary mix parameters are `effectIntensity` and `renderingStyle`. The sample creates an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVAudioMix] with the specified mix parameters and sets it on the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayerItem]:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/cinematic\/editing-spatial-audio-with-an-audio-mix\ncrawled: 2025-12-03T07:31:39Z\n---\n\n# Editing Spatial Audio with an audio mix\n\n**Sample Code**\n\nAdd Spatial Audio editing capabilities with the Audio Mix API in the Cinematic framework.\n\n## Overview\n\nBeginning with iPhone 16, you can use Spatial Audio capture to record video with 3D audio, and edit the audio mix in the Photos app. With Audio Mix, you have creative control of the background and foreground sounds in a recording. It isolates speech as foreground and ambience as background, and you can select between multiple creative rendering styles to adjust the mix.\n\nThe `SpatialAudioCLI` sample project is a command-line tool that demonstrates three different methods for applying an audio mix: using [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer], using [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVAssetWriter], and using [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/kAudioUnitSubType_AUAudioMix].\n\n\n\n### Configure the sample code project\n\nFor best results, use `SpatialAudioCLI` with media that contains a Spatial Audio track. On all iPhone 16 models, Spatial Audio recording is available when capturing video with the Camera app. See the [https:\/\/support.apple.com\/en-kw\/guide\/iphone\/iph31c1ca6c7\/ios] for how to change sound recording options.\n\nYou can record Spatial Audio in your app by setting the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDeviceInput\/multichannelAudioMode] property of the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDeviceInput] to a value of `firstOrderAmbisonics`.\n\n### Adjust the audio mix in AVPlayer\n\nThe simplest way to adjust the audio mix is to play Spatial Audio assets with [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer].\n\nFirst, the sample loads the specified input file into an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayerItem]:\n\n```swift\nlet myAsset = AVURLAsset(url: URL(filePath: \"myMediaURL\"))\nlet myPlayerItem = AVPlayerItem(asset: myAsset)\n```\n\nThen the sample uses the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVAsset] to initialize an instance of `CNAssetSpatialAudioInfo`:\n\n```swift\ndo {\n    \/\/ This command throws if the input file does not have proper Spatial Audio.\n    let audioInfo = try await CNAssetSpatialAudioInfo(asset: myAsset)\n} catch {\n    print(\"A problem occured reading the spatial audio asset: \\(error)\")\n}\n```\n\nThe two primary mix parameters are `effectIntensity` and `renderingStyle`. The sample creates an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVAudioMix] with the specified mix parameters and sets it on the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayerItem]:\n\n```swift\n\/\/ Sets the mix parameters.\nlet intensity = 0.5 \/\/ Float values between 0.0 and 1.0.\nlet style = CNSpatialAudioRenderingStyle.cinematic\n\n\/\/ Creates an `AVAudioMix` with effect intensity and rendering style.   \nlet newAudioMix = audioInfo.audioMix(effectIntensity: intensity, renderingStyle: style)\nmyPlayerItem.audioMix = newAudioMix\n\n\/\/ AVPlayer plays the asset with the new audio mix parameters.\nlet player = AVPlayer(playerItem: myPlayerItem)\n```\n\n## Editing\n\n- **CNDetection**: A structure that represents a detected subject, face, torso or pet at a particular time.\n- **CNDecision**: An object that represents a decision to focus on a particular detection, or group of detections, at a particular time.\n- **CNDetectionTrack**: An object representing a series of detections of the same subject over time.\n- **CNFixedDetectionTrack**: An object representing the fixed detection track.\n- **CNCustomDetectionTrack**: An object representing a discrete detection track composed of individual detections.\n- **CNDetectionType**: The type of object detected, such as face, torso, cat, dog and so on.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A structure that represents a detected subject, face, torso or pet at a particular time.",
          "name" : "CNDetection",
          "url" : "https:\/\/developer.apple.com\/documentation\/Cinematic\/CNDetection-swift.struct"
        },
        {
          "description" : "An object that represents a decision to focus on a particular detection, or group of detections, at a particular time.",
          "name" : "CNDecision",
          "url" : "https:\/\/developer.apple.com\/documentation\/Cinematic\/CNDecision-swift.struct"
        },
        {
          "description" : "An object representing a series of detections of the same subject over time.",
          "name" : "CNDetectionTrack",
          "url" : "https:\/\/developer.apple.com\/documentation\/Cinematic\/CNDetectionTrack-2bxtd"
        },
        {
          "description" : "An object representing the fixed detection track.",
          "name" : "CNFixedDetectionTrack",
          "url" : "https:\/\/developer.apple.com\/documentation\/Cinematic\/CNFixedDetectionTrack-93rrw"
        },
        {
          "description" : "An object representing a discrete detection track composed of individual detections.",
          "name" : "CNCustomDetectionTrack",
          "url" : "https:\/\/developer.apple.com\/documentation\/Cinematic\/CNCustomDetectionTrack-9a2zo"
        },
        {
          "description" : "The type of object detected, such as face, torso, cat, dog and so on.",
          "name" : "CNDetectionType",
          "url" : "https:\/\/developer.apple.com\/documentation\/Cinematic\/CNDetectionType"
        }
      ],
      "title" : "Editing"
    }
  ],
  "source" : "appleJSON",
  "title" : "Editing Spatial Audio with an audio mix",
  "url" : "https:\/\/developer.apple.com\/documentation\/cinematic\/editing-spatial-audio-with-an-audio-mix"
}