{
  "abstract" : "Integrate machine learning models into your app.",
  "codeExamples" : [

  ],
  "contentHash" : "01b29b8750eb8d847a0dd5a23d9212591a464f705a463f07c65e0331451aca8c",
  "crawledAt" : "2025-12-03T12:01:52Z",
  "id" : "BB72694D-D1BE-4447-8D54-D850319A0258",
  "kind" : "framework",
  "language" : "swift",
  "module" : "Core ML",
  "overview" : "## Overview\n\nUse [doc:\/\/com.apple.coreml\/documentation\/CoreML] to integrate machine learning models into your app. [doc:\/\/com.apple.coreml\/documentation\/CoreML] provides a unified representation for all models. Your app uses [doc:\/\/com.apple.coreml\/documentation\/CoreML] APIs and user data to make predictions, and to train or fine-tune models, all on a person’s device.\n\n\n\nA model is the result of applying a machine learning algorithm to a set of training data. You use a model to make predictions based on new input data. Models can accomplish a wide variety of tasks that would be difficult or impractical to write in code. For example, you can train a model to categorize photos, or detect specific objects within a photo directly from its pixels.\n\nYou build and train a model with the [https:\/\/developer.apple.com\/machine-learning\/create-ml\/] bundled with Xcode. Models trained using [doc:\/\/com.apple.documentation\/documentation\/CreateML] are in the [doc:\/\/com.apple.coreml\/documentation\/CoreML] model format and are ready to use in your app. Alternatively, you can use a wide variety of other machine learning libraries and then use [https:\/\/coremltools.readme.io] to convert the model into the [doc:\/\/com.apple.coreml\/documentation\/CoreML] format. Once a model is on a person’s device, you can use [doc:\/\/com.apple.coreml\/documentation\/CoreML] to retrain or fine-tune it on-device, with that person’s data.\n\n[doc:\/\/com.apple.coreml\/documentation\/CoreML] optimizes on-device performance by leveraging the CPU, GPU, and Neural Engine while minimizing its memory footprint and power consumption. Running a model strictly on a person’s device removes any need for a network connection, which helps keep a person’s data private and your app responsive.\n\nThe framework is the foundation for domain-specific frameworks and functionality. It supports [doc:\/\/com.apple.documentation\/documentation\/Vision] for analyzing images, [doc:\/\/com.apple.documentation\/documentation\/NaturalLanguage] for processing text, [doc:\/\/com.apple.documentation\/documentation\/Speech] for converting audio to text, and [doc:\/\/com.apple.documentation\/documentation\/SoundAnalysis] for identifying sounds in audio. [doc:\/\/com.apple.coreml\/documentation\/CoreML] itself builds on top of low-level primitives like [doc:\/\/com.apple.documentation\/documentation\/Accelerate] and [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/BNNS], as well as [doc:\/\/com.apple.documentation\/documentation\/MetalPerformanceShaders].\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/coreml\ncrawled: 2025-12-03T12:01:52Z\n---\n\n# Core ML\n\n**Framework**\n\nIntegrate machine learning models into your app.\n\n## Overview\n\nUse [doc:\/\/com.apple.coreml\/documentation\/CoreML] to integrate machine learning models into your app. [doc:\/\/com.apple.coreml\/documentation\/CoreML] provides a unified representation for all models. Your app uses [doc:\/\/com.apple.coreml\/documentation\/CoreML] APIs and user data to make predictions, and to train or fine-tune models, all on a person’s device.\n\n\n\nA model is the result of applying a machine learning algorithm to a set of training data. You use a model to make predictions based on new input data. Models can accomplish a wide variety of tasks that would be difficult or impractical to write in code. For example, you can train a model to categorize photos, or detect specific objects within a photo directly from its pixels.\n\nYou build and train a model with the [https:\/\/developer.apple.com\/machine-learning\/create-ml\/] bundled with Xcode. Models trained using [doc:\/\/com.apple.documentation\/documentation\/CreateML] are in the [doc:\/\/com.apple.coreml\/documentation\/CoreML] model format and are ready to use in your app. Alternatively, you can use a wide variety of other machine learning libraries and then use [https:\/\/coremltools.readme.io] to convert the model into the [doc:\/\/com.apple.coreml\/documentation\/CoreML] format. Once a model is on a person’s device, you can use [doc:\/\/com.apple.coreml\/documentation\/CoreML] to retrain or fine-tune it on-device, with that person’s data.\n\n[doc:\/\/com.apple.coreml\/documentation\/CoreML] optimizes on-device performance by leveraging the CPU, GPU, and Neural Engine while minimizing its memory footprint and power consumption. Running a model strictly on a person’s device removes any need for a network connection, which helps keep a person’s data private and your app responsive.\n\nThe framework is the foundation for domain-specific frameworks and functionality. It supports [doc:\/\/com.apple.documentation\/documentation\/Vision] for analyzing images, [doc:\/\/com.apple.documentation\/documentation\/NaturalLanguage] for processing text, [doc:\/\/com.apple.documentation\/documentation\/Speech] for converting audio to text, and [doc:\/\/com.apple.documentation\/documentation\/SoundAnalysis] for identifying sounds in audio. [doc:\/\/com.apple.coreml\/documentation\/CoreML] itself builds on top of low-level primitives like [doc:\/\/com.apple.documentation\/documentation\/Accelerate] and [doc:\/\/com.apple.documentation\/documentation\/Accelerate\/BNNS], as well as [doc:\/\/com.apple.documentation\/documentation\/MetalPerformanceShaders].\n\n\n\n## Core ML models\n\n- **Getting a Core ML Model**: Obtain a Core ML model to use in your app.\n- **Updating a Model File to a Model Package**: Convert a Core ML model file into a model package in Xcode.\n- **Integrating a Core ML Model into Your App**: Add a simple model to an app, pass input data to the model, and process the model’s predictions.\n- **MLModel**: An encapsulation of all the details of your machine learning model.\n- **Model Customization**: Expand and modify your model with new layers.\n- **Model Personalization**: Update your model to adapt to new data.\n\n## Model inputs and outputs\n\n- **Making Predictions with a Sequence of Inputs**: Integrate a recurrent neural network model to process sequences of inputs.\n- **MLFeatureValue**: A generic wrapper around an underlying value and the value’s type.\n- **MLSendableFeatureValue**: A sendable feature value.\n- **MLFeatureProvider**: An interface that represents a collection of values for either a model’s input or its output.\n- **MLDictionaryFeatureProvider**: A convenience wrapper for the given dictionary of data.\n- **MLBatchProvider**: An interface that represents a collection of feature providers.\n- **MLArrayBatchProvider**: A convenience wrapper for batches of feature providers.\n- **MLModelAsset**: An abstraction of a compiled Core ML model asset.\n\n## App integration\n\n- **Downloading and Compiling a Model on the User’s Device**: Install Core ML models on the user’s device dynamically at runtime.\n- **Model Integration Samples**: Integrate tabular, image, and text classifcation models into your app.\n\n## Model encryption\n\n- **Generating a Model Encryption Key**: Create a model encryption key to encrypt a compiled model or model archive.\n- **Encrypting a Model in Your App**: Encrypt your app’s built-in model at compile time by adding a compiler flag.\n\n## Compute devices\n\n- **MLComputeDevice**: Compute devices for framework operations.\n- **MLCPUComputeDevice**: An object that represents a CPU compute device.\n- **MLGPUComputeDevice**: An object that represents a GPU compute device.\n- **MLNeuralEngineComputeDevice**: An object that represents a Neural Engine compute device.\n- **MLComputeDeviceProtocol**: An interface that represents a compute device type.\n\n## Compute plan\n\n- **MLComputePlan**: A class representing the compute plan of a model.\n- **MLModelStructure**: An enum representing the structure of a model.\n- **MLComputePolicy**: The compute policy determining what compute device, or compute devices, to execute ML workloads on.\n- **withMLTensorComputePolicy(_:_:)**: Calls the given closure within a task-local context using the specified compute policy to influence what compute device tensor operations are executed on.\n- **withMLTensorComputePolicy(_:_:)**: Calls the given closure within a task-local context using the specified compute policy to influence what compute device tensor operations are executed on.\n\n## Model state\n\n- **MLState**: Handle to the state buffers.\n- **MLStateConstraint**: Constraint of a state feature value.\n\n## Model tensor\n\n- **MLTensor**: A multi-dimensional array of numerical or Boolean scalars tailored to ML use cases, containing methods to perform transformations and mathematical operations efficiently using a ML compute device.\n- **MLTensorScalar**: A type that represents the tensor scalar types supported by the framework. Don’t use this type directly.\n- **MLTensorRangeExpression**: A type that can be used to slice a dimension of a tensor. Don’t use this type directly.\n- **pointwiseMin(_:_:)**: Computes the element-wise minimum of two tensors.\n- **pointwiseMax(_:_:)**: Computes the element-wise minimum between two tensors.\n- **withMLTensorComputePolicy(_:_:)**: Calls the given closure within a task-local context using the specified compute policy to influence what compute device tensor operations are executed on.\n\n## Model structure\n\n- **MLModelStructure**: An enum representing the structure of a model.\n\n## Model errors\n\n- **MLModelError**: Information about a Core ML model error.\n- **MLModelError.Code**: Information about a Core ML model error.\n- **MLModelErrorDomain**: The domain for Core ML errors.\n\n## Model deployments\n\n- **MLModelCollection**: A set of Core ML models from a model deployment.\n\n## Reference\n\n- **CoreML Enumerations**\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Obtain a Core ML model to use in your app.",
          "name" : "Getting a Core ML Model",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/getting-a-core-ml-model"
        },
        {
          "description" : "Convert a Core ML model file into a model package in Xcode.",
          "name" : "Updating a Model File to a Model Package",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/updating-a-model-file-to-a-model-package"
        },
        {
          "description" : "Add a simple model to an app, pass input data to the model, and process the model’s predictions.",
          "name" : "Integrating a Core ML Model into Your App",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/integrating-a-core-ml-model-into-your-app"
        },
        {
          "description" : "An encapsulation of all the details of your machine learning model.",
          "name" : "MLModel",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModel"
        },
        {
          "description" : "Expand and modify your model with new layers.",
          "name" : "Model Customization",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/model-customization"
        },
        {
          "description" : "Update your model to adapt to new data.",
          "name" : "Model Personalization",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/model-personalization"
        }
      ],
      "title" : "Core ML models"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Integrate a recurrent neural network model to process sequences of inputs.",
          "name" : "Making Predictions with a Sequence of Inputs",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/making-predictions-with-a-sequence-of-inputs"
        },
        {
          "description" : "A generic wrapper around an underlying value and the value’s type.",
          "name" : "MLFeatureValue",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLFeatureValue"
        },
        {
          "description" : "A sendable feature value.",
          "name" : "MLSendableFeatureValue",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLSendableFeatureValue"
        },
        {
          "description" : "An interface that represents a collection of values for either a model’s input or its output.",
          "name" : "MLFeatureProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLFeatureProvider"
        },
        {
          "description" : "A convenience wrapper for the given dictionary of data.",
          "name" : "MLDictionaryFeatureProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLDictionaryFeatureProvider"
        },
        {
          "description" : "An interface that represents a collection of feature providers.",
          "name" : "MLBatchProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLBatchProvider"
        },
        {
          "description" : "A convenience wrapper for batches of feature providers.",
          "name" : "MLArrayBatchProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLArrayBatchProvider"
        },
        {
          "description" : "An abstraction of a compiled Core ML model asset.",
          "name" : "MLModelAsset",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModelAsset"
        }
      ],
      "title" : "Model inputs and outputs"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Install Core ML models on the user’s device dynamically at runtime.",
          "name" : "Downloading and Compiling a Model on the User’s Device",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/downloading-and-compiling-a-model-on-the-user-s-device"
        },
        {
          "description" : "Integrate tabular, image, and text classifcation models into your app.",
          "name" : "Model Integration Samples",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/model-integration-samples"
        }
      ],
      "title" : "App integration"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create a model encryption key to encrypt a compiled model or model archive.",
          "name" : "Generating a Model Encryption Key",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/generating-a-model-encryption-key"
        },
        {
          "description" : "Encrypt your app’s built-in model at compile time by adding a compiler flag.",
          "name" : "Encrypting a Model in Your App",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/encrypting-a-model-in-your-app"
        }
      ],
      "title" : "Model encryption"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Compute devices for framework operations.",
          "name" : "MLComputeDevice",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLComputeDevice"
        },
        {
          "description" : "An object that represents a CPU compute device.",
          "name" : "MLCPUComputeDevice",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLCPUComputeDevice"
        },
        {
          "description" : "An object that represents a GPU compute device.",
          "name" : "MLGPUComputeDevice",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLGPUComputeDevice"
        },
        {
          "description" : "An object that represents a Neural Engine compute device.",
          "name" : "MLNeuralEngineComputeDevice",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLNeuralEngineComputeDevice"
        },
        {
          "description" : "An interface that represents a compute device type.",
          "name" : "MLComputeDeviceProtocol",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLComputeDeviceProtocol"
        }
      ],
      "title" : "Compute devices"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A class representing the compute plan of a model.",
          "name" : "MLComputePlan",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLComputePlan-1w21n"
        },
        {
          "description" : "An enum representing the structure of a model.",
          "name" : "MLModelStructure",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModelStructure-swift.enum"
        },
        {
          "description" : "The compute policy determining what compute device, or compute devices, to execute ML workloads on.",
          "name" : "MLComputePolicy",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLComputePolicy"
        },
        {
          "description" : "Calls the given closure within a task-local context using the specified compute policy to influence what compute device tensor operations are executed on.",
          "name" : "withMLTensorComputePolicy(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/withMLTensorComputePolicy(_:_:)-8stx9"
        },
        {
          "description" : "Calls the given closure within a task-local context using the specified compute policy to influence what compute device tensor operations are executed on.",
          "name" : "withMLTensorComputePolicy(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/withMLTensorComputePolicy(_:_:)-6z33x"
        }
      ],
      "title" : "Compute plan"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Handle to the state buffers.",
          "name" : "MLState",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLState"
        },
        {
          "description" : "Constraint of a state feature value.",
          "name" : "MLStateConstraint",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLStateConstraint"
        }
      ],
      "title" : "Model state"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A multi-dimensional array of numerical or Boolean scalars tailored to ML use cases, containing methods to perform transformations and mathematical operations efficiently using a ML compute device.",
          "name" : "MLTensor",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLTensor"
        },
        {
          "description" : "A type that represents the tensor scalar types supported by the framework. Don’t use this type directly.",
          "name" : "MLTensorScalar",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLTensorScalar"
        },
        {
          "description" : "A type that can be used to slice a dimension of a tensor. Don’t use this type directly.",
          "name" : "MLTensorRangeExpression",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLTensorRangeExpression"
        },
        {
          "description" : "Computes the element-wise minimum of two tensors.",
          "name" : "pointwiseMin(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/pointwiseMin(_:_:)"
        },
        {
          "description" : "Computes the element-wise minimum between two tensors.",
          "name" : "pointwiseMax(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/pointwiseMax(_:_:)"
        },
        {
          "description" : "Calls the given closure within a task-local context using the specified compute policy to influence what compute device tensor operations are executed on.",
          "name" : "withMLTensorComputePolicy(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/withMLTensorComputePolicy(_:_:)"
        }
      ],
      "title" : "Model tensor"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An enum representing the structure of a model.",
          "name" : "MLModelStructure",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModelStructure-swift.enum"
        }
      ],
      "title" : "Model structure"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Information about a Core ML model error.",
          "name" : "MLModelError",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModelError-swift.struct"
        },
        {
          "description" : "Information about a Core ML model error.",
          "name" : "MLModelError.Code",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModelError-swift.struct\/Code"
        },
        {
          "description" : "The domain for Core ML errors.",
          "name" : "MLModelErrorDomain",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModelErrorDomain"
        }
      ],
      "title" : "Model errors"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A set of Core ML models from a model deployment.",
          "name" : "MLModelCollection",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/MLModelCollection"
        }
      ],
      "title" : "Model deployments"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "CoreML Enumerations",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/coreml-enumerations"
        }
      ],
      "title" : "Reference"
    }
  ],
  "source" : "appleJSON",
  "title" : "Core ML",
  "url" : "https:\/\/developer.apple.com\/documentation\/coreml"
}