{
  "abstract" : "A group of inputs with tracks that are mutually exclusive to each other for playback or processing.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol"
  ],
  "contentHash" : "aa6a9a9b8c04f533979915354c018530b72acbb3863f35b6ce62d53a5182c611",
  "crawledAt" : "2025-12-02T15:46:00Z",
  "declaration" : {
    "code" : "class AVAssetWriterInputGroup",
    "language" : "swift"
  },
  "id" : "0477B408-6833-4F16-BFFA-ACFA5A6E84BB",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nAssets may contain multiple tracks of media that are mutually exclusive to each other when you play or process them. For example, an asset may contain multiple audio tracks for different spoken languages, but only one of them should play at a time. You use an input group to mark a collection of tracks as mutually exclusive to each other in the file the asset writer outputs.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup\ncrawled: 2025-12-02T15:46:00Z\n---\n\n# AVAssetWriterInputGroup\n\n**Class**\n\nA group of inputs with tracks that are mutually exclusive to each other for playback or processing.\n\n## Declaration\n\n```swift\nclass AVAssetWriterInputGroup\n```\n\n## Overview\n\nAssets may contain multiple tracks of media that are mutually exclusive to each other when you play or process them. For example, an asset may contain multiple audio tracks for different spoken languages, but only one of them should play at a time. You use an input group to mark a collection of tracks as mutually exclusive to each other in the file the asset writer outputs.\n\n\n\n## Creating an input group\n\n- **init(inputs:defaultInput:)**: Creates a group for the asset writer inputs.\n\n## Accessing the inputs\n\n- **inputs**: The inputs with tracks that are mutually exclusive to each other for playback or processing.\n- **defaultInput**: The default input for the group.\n\n## Media writing\n\n- **Converting projected video to Apple Projected Media Profile**: Convert content with equirectangular or half-equirectangular projection to APMP.\n- **Converting side-by-side 3D video to multiview HEVC and spatial video**: Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.\n- **Writing fragmented MPEG-4 files for HTTP Live Streaming**: Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.\n- **Creating spatial photos and videos with spatial metadata**: Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.\n- **Tagging media with video color information**: Inspect and set video color space information when writing and transcoding media.\n- **Evaluating an app’s video color**: Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.\n- **AVOutputSettingsAssistant**: An object that builds audio and video output settings dictionaries.\n- **AVAssetWriter**: An object that writes media data to a container file.\n- **AVAssetWriterInput**: An object that appends media samples to a track in an asset writer’s output file.\n- **AVAssetWriterInputPixelBufferAdaptor**: An object that appends video samples to an asset writer input.\n- **AVAssetWriterInputTaggedPixelBufferGroupAdaptor**: An object that appends tagged buffer groups to an asset writer input.\n- **AVAssetWriterInputMetadataAdaptor**: An object that appends timed metadata groups to an asset writer input.\n\n## Inherits From\n\n- AVMediaSelectionGroup\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a group for the asset writer inputs.",
          "name" : "init(inputs:defaultInput:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup\/init(inputs:defaultInput:)"
        }
      ],
      "title" : "Creating an input group"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The inputs with tracks that are mutually exclusive to each other for playback or processing.",
          "name" : "inputs",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup\/inputs"
        },
        {
          "description" : "The default input for the group.",
          "name" : "defaultInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup\/defaultInput"
        }
      ],
      "title" : "Accessing the inputs"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert content with equirectangular or half-equirectangular projection to APMP.",
          "name" : "Converting projected video to Apple Projected Media Profile",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-projected-video-to-apple-projected-media-profile"
        },
        {
          "description" : "Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.",
          "name" : "Converting side-by-side 3D video to multiview HEVC and spatial video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video"
        },
        {
          "description" : "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.",
          "name" : "Writing fragmented MPEG-4 files for HTTP Live Streaming",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/writing-fragmented-mpeg-4-files-for-http-live-streaming"
        },
        {
          "description" : "Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.",
          "name" : "Creating spatial photos and videos with spatial metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/ImageIO\/Creating-spatial-photos-and-videos-with-spatial-metadata"
        },
        {
          "description" : "Inspect and set video color space information when writing and transcoding media.",
          "name" : "Tagging media with video color information",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information"
        },
        {
          "description" : "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.",
          "name" : "Evaluating an app’s video color",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color"
        },
        {
          "description" : "An object that builds audio and video output settings dictionaries.",
          "name" : "AVOutputSettingsAssistant",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant"
        },
        {
          "description" : "An object that writes media data to a container file.",
          "name" : "AVAssetWriter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriter"
        },
        {
          "description" : "An object that appends media samples to a track in an asset writer’s output file.",
          "name" : "AVAssetWriterInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput"
        },
        {
          "description" : "An object that appends video samples to an asset writer input.",
          "name" : "AVAssetWriterInputPixelBufferAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPixelBufferAdaptor"
        },
        {
          "description" : "An object that appends tagged buffer groups to an asset writer input.",
          "name" : "AVAssetWriterInputTaggedPixelBufferGroupAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputTaggedPixelBufferGroupAdaptor"
        },
        {
          "description" : "An object that appends timed metadata groups to an asset writer input.",
          "name" : "AVAssetWriterInputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor"
        }
      ],
      "title" : "Media writing"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "AVMediaSelectionGroup"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAssetWriterInputGroup",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup"
}