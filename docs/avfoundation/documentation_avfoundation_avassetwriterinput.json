{
  "abstract" : "An object that appends media samples to a track in an asset writer’s output file.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "3c13061719ae770a55027850cc6c63422273ffa8d5e848ad6b3c1fbcb887cde6",
  "crawledAt" : "2025-12-02T15:45:57Z",
  "declaration" : {
    "code" : "class AVAssetWriterInput",
    "language" : "swift"
  },
  "id" : "F814A327-64A8-43C5-81F9-539417318986",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nCreate an asset writer input to write a single track of media, and optional track-level metadata, to the output file. To write multiple concurrent tracks with ideal interleaving of media data, observe the value of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput\/isReadyForMoreMediaData] property of each input.\n\nYou can use an asset writer input to create tracks in a QuickTime movie file that aren’t self-contained, and instead reference sample data that exists in another file.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\ncrawled: 2025-12-02T15:45:57Z\n---\n\n# AVAssetWriterInput\n\n**Class**\n\nAn object that appends media samples to a track in an asset writer’s output file.\n\n## Declaration\n\n```swift\nclass AVAssetWriterInput\n```\n\n## Overview\n\nCreate an asset writer input to write a single track of media, and optional track-level metadata, to the output file. To write multiple concurrent tracks with ideal interleaving of media data, observe the value of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput\/isReadyForMoreMediaData] property of each input.\n\nYou can use an asset writer input to create tracks in a QuickTime movie file that aren’t self-contained, and instead reference sample data that exists in another file.\n\n## Creating an input\n\n- **init(mediaType:outputSettings:)**: Creates an input to append sample buffers of the specified type to the output file.\n- **init(mediaType:outputSettings:sourceFormatHint:)**: Creates an input that appends sample buffers of the specified type and format hint to the output file.\n\n## Configuring presentation\n\n- **naturalSize**: The natural display dimensions of the output’s visual media.\n- **transform**: The transform to use for display of the output’s visual media.\n- **preferredVolume**: The volume to prefer for playback of the output’s audio data.\n- **mediaTimeScale**: The time scale of the track in the output file.\n- **marksOutputTrackAsEnabled**: A Boolean value that indicates whether to enable a track in the output for playback and processing.\n\n## Configuring language support\n\n- **languageCode**: The language code of the input’s track.\n- **extendedLanguageTag**: The extended language for the input’s track.\n\n## Configuring metadata\n\n- **metadata**: The track-level metadata to write to the output.\n\n## Configuring media data layout\n\n- **preferredMediaChunkAlignment**: The boundary, in bytes, for aligning media chunks.\n- **preferredMediaChunkDuration**: The duration to use for each chunk of sample data in the output file.\n- **sampleReferenceBaseURL**: The base URL sample references are relative to.\n- **mediaDataLocation**: Specifies how the input lays out and interleaves media data.\n- **AVAssetWriterInput.MediaDataLocation**: A structure that indicates how to lay out and interleave media data.\n\n## Configuring track associations\n\n- **canAddTrackAssociation(withTrackOf:type:)**: Determines whether it’s valid to associate another input’s track with this input’s track.\n- **addTrackAssociation(withTrackOf:type:)**: Adds an association between input tracks.\n\n## Appending media samples\n\n- **expectsMediaDataInRealTime**: A Boolean value that indicates whether the input tailors its processing for real-time sources.\n- **isReadyForMoreMediaData**: A Boolean value that indicates whether the input is ready to accept media data.\n- **requestMediaDataWhenReady(on:using:)**: Tells the input to request media data, at its convenience, to write to the output file.\n- **append(_:)**: Appends a sample buffer to an input to write to the output file.\n- **markAsFinished()**: Marks the input as finished to indicate that you’re done appending samples to it.\n- **AVAssetWriterInput.SampleBufferReceiver**: Provides an interface for writing sample buffers to an input.\n- **AVAssetWriterInput.PixelBufferReceiver**: Provides an interface for writing pixel buffers to an input.\n- **AVAssetWriterInput.TaggedPixelBufferGroupReceiver**: Provides an interface for writing tagged pixel buffers to an input.\n- **AVAssetWriterInput.MetadataReceiver**: Provides an interface for writing timed metadata groups to an input.\n- **AVAssetWriterInput.CaptionReceiver**: Provides an interface for writing caption data to an input.\n\n## Performing multiple-pass encoding\n\n- **canPerformMultiplePasses**: A Boolean value that indicates whether the input may perform multiple passes over appended media data.\n- **currentPassDescription**: An object that describes the requirements for the current pass.\n- **AVAssetWriterInputPassDescription**: An object that defines the interface to query for the requirements of the current pass.\n- **markCurrentPassAsFinished()**: Tells the input to analyze the appended media to determine whether it can improve the results by reencoding certain segments.\n- **performsMultiPassEncodingIfSupported**: A Boolean value that indicates whether the input attempts to encode the source media data using multiple passes.\n- **respondToEachPassDescription(on:using:)**: Tells the input to invoke a callback whenever it begins a new pass.\n- **AVAssetWriterInput.MultiPassController**: Provides an interface to receive an async sequence of pass descriptions for the writer input receiver, if multi-pass is supported.\n\n## Inspecting an input\n\n- **mediaType**: The media type of the samples that the input accepts.\n- **outputSettings**: The settings to use for encoding media data you append to the output.\n- **sourceFormatHint**: A hint about the format of the sample buffers to append to the input.\n\n## Media writing\n\n- **Converting projected video to Apple Projected Media Profile**: Convert content with equirectangular or half-equirectangular projection to APMP.\n- **Converting side-by-side 3D video to multiview HEVC and spatial video**: Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.\n- **Writing fragmented MPEG-4 files for HTTP Live Streaming**: Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.\n- **Creating spatial photos and videos with spatial metadata**: Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.\n- **Tagging media with video color information**: Inspect and set video color space information when writing and transcoding media.\n- **Evaluating an app’s video color**: Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.\n- **AVOutputSettingsAssistant**: An object that builds audio and video output settings dictionaries.\n- **AVAssetWriter**: An object that writes media data to a container file.\n- **AVAssetWriterInputPixelBufferAdaptor**: An object that appends video samples to an asset writer input.\n- **AVAssetWriterInputTaggedPixelBufferGroupAdaptor**: An object that appends tagged buffer groups to an asset writer input.\n- **AVAssetWriterInputMetadataAdaptor**: An object that appends timed metadata groups to an asset writer input.\n- **AVAssetWriterInputGroup**: A group of inputs with tracks that are mutually exclusive to each other for playback or processing.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an input to append sample buffers of the specified type to the output file.",
          "name" : "init(mediaType:outputSettings:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/init(mediaType:outputSettings:)"
        },
        {
          "description" : "Creates an input that appends sample buffers of the specified type and format hint to the output file.",
          "name" : "init(mediaType:outputSettings:sourceFormatHint:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/init(mediaType:outputSettings:sourceFormatHint:)"
        }
      ],
      "title" : "Creating an input"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The natural display dimensions of the output’s visual media.",
          "name" : "naturalSize",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/naturalSize"
        },
        {
          "description" : "The transform to use for display of the output’s visual media.",
          "name" : "transform",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/transform"
        },
        {
          "description" : "The volume to prefer for playback of the output’s audio data.",
          "name" : "preferredVolume",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/preferredVolume"
        },
        {
          "description" : "The time scale of the track in the output file.",
          "name" : "mediaTimeScale",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/mediaTimeScale"
        },
        {
          "description" : "A Boolean value that indicates whether to enable a track in the output for playback and processing.",
          "name" : "marksOutputTrackAsEnabled",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/marksOutputTrackAsEnabled"
        }
      ],
      "title" : "Configuring presentation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The language code of the input’s track.",
          "name" : "languageCode",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/languageCode"
        },
        {
          "description" : "The extended language for the input’s track.",
          "name" : "extendedLanguageTag",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/extendedLanguageTag"
        }
      ],
      "title" : "Configuring language support"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The track-level metadata to write to the output.",
          "name" : "metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/metadata"
        }
      ],
      "title" : "Configuring metadata"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The boundary, in bytes, for aligning media chunks.",
          "name" : "preferredMediaChunkAlignment",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/preferredMediaChunkAlignment"
        },
        {
          "description" : "The duration to use for each chunk of sample data in the output file.",
          "name" : "preferredMediaChunkDuration",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/preferredMediaChunkDuration"
        },
        {
          "description" : "The base URL sample references are relative to.",
          "name" : "sampleReferenceBaseURL",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/sampleReferenceBaseURL"
        },
        {
          "description" : "Specifies how the input lays out and interleaves media data.",
          "name" : "mediaDataLocation",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/mediaDataLocation-swift.property"
        },
        {
          "description" : "A structure that indicates how to lay out and interleave media data.",
          "name" : "AVAssetWriterInput.MediaDataLocation",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/MediaDataLocation-swift.struct"
        }
      ],
      "title" : "Configuring media data layout"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Determines whether it’s valid to associate another input’s track with this input’s track.",
          "name" : "canAddTrackAssociation(withTrackOf:type:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/canAddTrackAssociation(withTrackOf:type:)"
        },
        {
          "description" : "Adds an association between input tracks.",
          "name" : "addTrackAssociation(withTrackOf:type:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/addTrackAssociation(withTrackOf:type:)"
        }
      ],
      "title" : "Configuring track associations"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the input tailors its processing for real-time sources.",
          "name" : "expectsMediaDataInRealTime",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/expectsMediaDataInRealTime"
        },
        {
          "description" : "A Boolean value that indicates whether the input is ready to accept media data.",
          "name" : "isReadyForMoreMediaData",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/isReadyForMoreMediaData"
        },
        {
          "description" : "Tells the input to request media data, at its convenience, to write to the output file.",
          "name" : "requestMediaDataWhenReady(on:using:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/requestMediaDataWhenReady(on:using:)"
        },
        {
          "description" : "Appends a sample buffer to an input to write to the output file.",
          "name" : "append(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/append(_:)"
        },
        {
          "description" : "Marks the input as finished to indicate that you’re done appending samples to it.",
          "name" : "markAsFinished()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/markAsFinished()"
        },
        {
          "description" : "Provides an interface for writing sample buffers to an input.",
          "name" : "AVAssetWriterInput.SampleBufferReceiver",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/SampleBufferReceiver"
        },
        {
          "description" : "Provides an interface for writing pixel buffers to an input.",
          "name" : "AVAssetWriterInput.PixelBufferReceiver",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/PixelBufferReceiver"
        },
        {
          "description" : "Provides an interface for writing tagged pixel buffers to an input.",
          "name" : "AVAssetWriterInput.TaggedPixelBufferGroupReceiver",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/TaggedPixelBufferGroupReceiver"
        },
        {
          "description" : "Provides an interface for writing timed metadata groups to an input.",
          "name" : "AVAssetWriterInput.MetadataReceiver",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/MetadataReceiver"
        },
        {
          "description" : "Provides an interface for writing caption data to an input.",
          "name" : "AVAssetWriterInput.CaptionReceiver",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/CaptionReceiver"
        }
      ],
      "title" : "Appending media samples"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the input may perform multiple passes over appended media data.",
          "name" : "canPerformMultiplePasses",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/canPerformMultiplePasses"
        },
        {
          "description" : "An object that describes the requirements for the current pass.",
          "name" : "currentPassDescription",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/currentPassDescription"
        },
        {
          "description" : "An object that defines the interface to query for the requirements of the current pass.",
          "name" : "AVAssetWriterInputPassDescription",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPassDescription"
        },
        {
          "description" : "Tells the input to analyze the appended media to determine whether it can improve the results by reencoding certain segments.",
          "name" : "markCurrentPassAsFinished()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/markCurrentPassAsFinished()"
        },
        {
          "description" : "A Boolean value that indicates whether the input attempts to encode the source media data using multiple passes.",
          "name" : "performsMultiPassEncodingIfSupported",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/performsMultiPassEncodingIfSupported"
        },
        {
          "description" : "Tells the input to invoke a callback whenever it begins a new pass.",
          "name" : "respondToEachPassDescription(on:using:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/respondToEachPassDescription(on:using:)"
        },
        {
          "description" : "Provides an interface to receive an async sequence of pass descriptions for the writer input receiver, if multi-pass is supported.",
          "name" : "AVAssetWriterInput.MultiPassController",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/MultiPassController"
        }
      ],
      "title" : "Performing multiple-pass encoding"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The media type of the samples that the input accepts.",
          "name" : "mediaType",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/mediaType"
        },
        {
          "description" : "The settings to use for encoding media data you append to the output.",
          "name" : "outputSettings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/outputSettings"
        },
        {
          "description" : "A hint about the format of the sample buffers to append to the input.",
          "name" : "sourceFormatHint",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput\/sourceFormatHint"
        }
      ],
      "title" : "Inspecting an input"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert content with equirectangular or half-equirectangular projection to APMP.",
          "name" : "Converting projected video to Apple Projected Media Profile",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-projected-video-to-apple-projected-media-profile"
        },
        {
          "description" : "Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.",
          "name" : "Converting side-by-side 3D video to multiview HEVC and spatial video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video"
        },
        {
          "description" : "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.",
          "name" : "Writing fragmented MPEG-4 files for HTTP Live Streaming",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/writing-fragmented-mpeg-4-files-for-http-live-streaming"
        },
        {
          "description" : "Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.",
          "name" : "Creating spatial photos and videos with spatial metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/ImageIO\/Creating-spatial-photos-and-videos-with-spatial-metadata"
        },
        {
          "description" : "Inspect and set video color space information when writing and transcoding media.",
          "name" : "Tagging media with video color information",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information"
        },
        {
          "description" : "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.",
          "name" : "Evaluating an app’s video color",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color"
        },
        {
          "description" : "An object that builds audio and video output settings dictionaries.",
          "name" : "AVOutputSettingsAssistant",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant"
        },
        {
          "description" : "An object that writes media data to a container file.",
          "name" : "AVAssetWriter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriter"
        },
        {
          "description" : "An object that appends video samples to an asset writer input.",
          "name" : "AVAssetWriterInputPixelBufferAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPixelBufferAdaptor"
        },
        {
          "description" : "An object that appends tagged buffer groups to an asset writer input.",
          "name" : "AVAssetWriterInputTaggedPixelBufferGroupAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputTaggedPixelBufferGroupAdaptor"
        },
        {
          "description" : "An object that appends timed metadata groups to an asset writer input.",
          "name" : "AVAssetWriterInputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor"
        },
        {
          "description" : "A group of inputs with tracks that are mutually exclusive to each other for playback or processing.",
          "name" : "AVAssetWriterInputGroup",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup"
        }
      ],
      "title" : "Media writing"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAssetWriterInput",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput"
}