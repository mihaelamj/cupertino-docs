{
  "abstract" : "An object that reads media data from a single track of an asset.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "843487d3e8df73fbb341221008873a1c21d7a8fff9de13ec4c30c2884239ed6e",
  "crawledAt" : "2025-12-02T16:10:10Z",
  "declaration" : {
    "code" : "class AVAssetReaderTrackOutput",
    "language" : "swift"
  },
  "id" : "7CC2E38B-AB8C-4BD6-B074-899A3D3315F1",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nRead the media data of an asset track by adding a track output to an asset reader. You can read the media samples in their stored format, or you can convert them to an alternative format.\n\nA track output produces uncompressed output. For audio output settings, this means that [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVFormatIDKey] must be [doc:\/\/com.apple.documentation\/documentation\/CoreAudioTypes\/kAudioFormatLinearPCM]. For video output settings, this means that the dictionary must contain values for uncompressed video output, as defined in `Video Settings`. A track output doesn’t support the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVSampleRateConverterAudioQualityKey] audio setting key or the following video settings keys: [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCleanApertureKey], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoPixelAspectRatioKey], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoScalingModeKey].\n\nWhen constructing video output settings, the choice of pixel format affects the performance and quality of the decompression. For optimal performance when decompressing video, the requested pixel format should be one that the decoder supports natively to avoid unnecessary conversions. Below are some recommendations:",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput\ncrawled: 2025-12-02T16:10:10Z\n---\n\n# AVAssetReaderTrackOutput\n\n**Class**\n\nAn object that reads media data from a single track of an asset.\n\n## Declaration\n\n```swift\nclass AVAssetReaderTrackOutput\n```\n\n## Overview\n\nRead the media data of an asset track by adding a track output to an asset reader. You can read the media samples in their stored format, or you can convert them to an alternative format.\n\nA track output produces uncompressed output. For audio output settings, this means that [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVFormatIDKey] must be [doc:\/\/com.apple.documentation\/documentation\/CoreAudioTypes\/kAudioFormatLinearPCM]. For video output settings, this means that the dictionary must contain values for uncompressed video output, as defined in `Video Settings`. A track output doesn’t support the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVSampleRateConverterAudioQualityKey] audio setting key or the following video settings keys: [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCleanApertureKey], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoPixelAspectRatioKey], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoScalingModeKey].\n\nWhen constructing video output settings, the choice of pixel format affects the performance and quality of the decompression. For optimal performance when decompressing video, the requested pixel format should be one that the decoder supports natively to avoid unnecessary conversions. Below are some recommendations:\n\n- For H.264, use [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange] or [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_420YpCbCr8BiPlanarFullRange] when you know the video is full range.\n- In iOS, use [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_420YpCbCr8BiPlanarFullRange] for JPEG output.\n- In macOS, [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_422YpCbCr8] is the preferred pixel format for video and generally provides the best performance when decoding. If you need to work in the RGB domain, use [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_32BGRA] in iOS, and [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_32ARGB] in macOS.\n- ProRes-encoded media can contain up to 12 bits per channel. For ProRes-encoded sources that you wish to preserve more than 8 bits per channel during decompression, use one of the following pixel formats: [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_4444AYpCbCr16], [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_422YpCbCr16], [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_422YpCbCr10], or [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_64ARGB]. [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetReader] doesn’t support scaling with any of these high-bit-depth pixel formats. If you use the above pixel formats, don’t specify [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelBufferWidthKey] or [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelBufferHeightKey] in the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetReaderTrackOutput\/outputSettings] dictionary. Only ProRes encoders support these pixel formats.\n- ProRes 4444-encoded media can contain a mathematically lossless alpha channel. To preserve the alpha channel during decompression, use a pixel format with an alpha component such as [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_4444AYpCbCr16] or [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_64ARGB]. To test whether your source contains an alpha channel, check that the track’s format description has a [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/kCMFormatDescriptionExtension_Depth] key with a value of `32`.\n\n## Creating a track output\n\n- **init(track:outputSettings:)**: Creates an object that reads media data from an asset track.\n- **Video settings**: Configure video processing settings using standard key and value constants.\n\n## Configuring audio settings\n\n- **audioTimePitchAlgorithm**: The processing algorithm to use for scaled audio edits.\n\n## Inspecting an output\n\n- **outputSettings**: The output settings for this track output.\n- **track**: The track from which the output reads sample buffers.\n\n## Media reading\n\n- **Reading multiview 3D video files**: Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.\n- **AVAssetReader**: An object that reads media data from an asset.\n- **AVAssetReaderOutput**: An abstract class that defines the interface to read media samples from an asset reader.\n- **AVAssetReaderAudioMixOutput**: An object that reads audio samples that result from mixing audio from one or more tracks.\n- **AVAssetReaderVideoCompositionOutput**: An object that reads composited video frames from one or more tracks of an asset.\n- **AVAssetReaderSampleReferenceOutput**: An object that reads sample references from an asset track.\n- **AVAssetReaderOutputMetadataAdaptor**: An object that creates timed metadata group objects for an asset track.\n\n## Inherits From\n\n- AVAssetReaderOutput\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an object that reads media data from an asset track.",
          "name" : "init(track:outputSettings:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput\/init(track:outputSettings:)"
        },
        {
          "description" : "Configure video processing settings using standard key and value constants.",
          "name" : "Video settings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/video-settings"
        }
      ],
      "title" : "Creating a track output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The processing algorithm to use for scaled audio edits.",
          "name" : "audioTimePitchAlgorithm",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput\/audioTimePitchAlgorithm"
        }
      ],
      "title" : "Configuring audio settings"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The output settings for this track output.",
          "name" : "outputSettings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput\/outputSettings"
        },
        {
          "description" : "The track from which the output reads sample buffers.",
          "name" : "track",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput\/track"
        }
      ],
      "title" : "Inspecting an output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.",
          "name" : "Reading multiview 3D video files",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/reading-multiview-3d-video-files"
        },
        {
          "description" : "An object that reads media data from an asset.",
          "name" : "AVAssetReader",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReader"
        },
        {
          "description" : "An abstract class that defines the interface to read media samples from an asset reader.",
          "name" : "AVAssetReaderOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutput"
        },
        {
          "description" : "An object that reads audio samples that result from mixing audio from one or more tracks.",
          "name" : "AVAssetReaderAudioMixOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput"
        },
        {
          "description" : "An object that reads composited video frames from one or more tracks of an asset.",
          "name" : "AVAssetReaderVideoCompositionOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderVideoCompositionOutput"
        },
        {
          "description" : "An object that reads sample references from an asset track.",
          "name" : "AVAssetReaderSampleReferenceOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderSampleReferenceOutput"
        },
        {
          "description" : "An object that creates timed metadata group objects for an asset track.",
          "name" : "AVAssetReaderOutputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutputMetadataAdaptor"
        }
      ],
      "title" : "Media reading"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "AVAssetReaderOutput"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAssetReaderTrackOutput",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput"
}