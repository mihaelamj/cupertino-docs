{
  "abstract" : "An object that builds audio and video output settings dictionaries.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "80bbba97bdb27348cef5530a66ec8c89022acbd6b645b316ab231d21f496f8e5",
  "crawledAt" : "2025-12-02T15:45:55Z",
  "declaration" : {
    "code" : "class AVOutputSettingsAssistant",
    "language" : "swift"
  },
  "id" : "D263B213-6C5F-449F-A601-A378AC2158F4",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nUse an output settings assistant to create the audio and video settings that you use to configure instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriter] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput]. You create an assistant with a specific preset configuration, such as [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVOutputSettingsPreset\/hevc3840x2160WithAlpha] or [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVOutputSettingsPreset\/preset1920x1080]. You can accept the settings dictionaries as is to generate a file that conforms to the criteria that the preset implies. You may also use the dictionaries it generates as a base configuration that you can customize as you require.\n\nProviding the assistant additional details about your source media helps it generate more complete results. For example, setting a value for its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/sourceVideoFormat] property ensures that the assistant generates settings that don’t scale up video frames from a smaller size.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\ncrawled: 2025-12-02T15:45:55Z\n---\n\n# AVOutputSettingsAssistant\n\n**Class**\n\nAn object that builds audio and video output settings dictionaries.\n\n## Declaration\n\n```swift\nclass AVOutputSettingsAssistant\n```\n\n## Overview\n\nUse an output settings assistant to create the audio and video settings that you use to configure instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriter] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput]. You create an assistant with a specific preset configuration, such as [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVOutputSettingsPreset\/hevc3840x2160WithAlpha] or [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVOutputSettingsPreset\/preset1920x1080]. You can accept the settings dictionaries as is to generate a file that conforms to the criteria that the preset implies. You may also use the dictionaries it generates as a base configuration that you can customize as you require.\n\nProviding the assistant additional details about your source media helps it generate more complete results. For example, setting a value for its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/sourceVideoFormat] property ensures that the assistant generates settings that don’t scale up video frames from a smaller size.\n\n## Creating an assistant\n\n- **init(preset:)**: Creates an output setting assistant with a preset configuration.\n- **AVOutputSettingsPreset**: A structure that defines preset configurations for an output settings assistant.\n- **availableOutputSettingsPresets()**: Returns an array of preset values to use to initialize an output settings assistant.\n\n## Configuring output settings\n\n- **outputFileType**: A uniform type identifier (UTI) that indicates the type of file to write.\n- **audioSettings**: An audio settings dictionary.\n- **sourceAudioFormat**: The format of the source audio data.\n- **videoSettings**: A video settings dictionary.\n- **sourceVideoFormat**: The format of the source video data.\n- **sourceVideoMinFrameDuration**: A time value that describes the minimum frame duration of the video data.\n- **sourceVideoAverageFrameDuration**: A time value that describes the average frame duration of the video data.\n\n## Media writing\n\n- **Converting projected video to Apple Projected Media Profile**: Convert content with equirectangular or half-equirectangular projection to APMP.\n- **Converting side-by-side 3D video to multiview HEVC and spatial video**: Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.\n- **Writing fragmented MPEG-4 files for HTTP Live Streaming**: Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.\n- **Creating spatial photos and videos with spatial metadata**: Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.\n- **Tagging media with video color information**: Inspect and set video color space information when writing and transcoding media.\n- **Evaluating an app’s video color**: Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.\n- **AVAssetWriter**: An object that writes media data to a container file.\n- **AVAssetWriterInput**: An object that appends media samples to a track in an asset writer’s output file.\n- **AVAssetWriterInputPixelBufferAdaptor**: An object that appends video samples to an asset writer input.\n- **AVAssetWriterInputTaggedPixelBufferGroupAdaptor**: An object that appends tagged buffer groups to an asset writer input.\n- **AVAssetWriterInputMetadataAdaptor**: An object that appends timed metadata groups to an asset writer input.\n- **AVAssetWriterInputGroup**: A group of inputs with tracks that are mutually exclusive to each other for playback or processing.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an output setting assistant with a preset configuration.",
          "name" : "init(preset:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/init(preset:)"
        },
        {
          "description" : "A structure that defines preset configurations for an output settings assistant.",
          "name" : "AVOutputSettingsPreset",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsPreset"
        },
        {
          "description" : "Returns an array of preset values to use to initialize an output settings assistant.",
          "name" : "availableOutputSettingsPresets()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/availableOutputSettingsPresets()"
        }
      ],
      "title" : "Creating an assistant"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A uniform type identifier (UTI) that indicates the type of file to write.",
          "name" : "outputFileType",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/outputFileType"
        },
        {
          "description" : "An audio settings dictionary.",
          "name" : "audioSettings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/audioSettings"
        },
        {
          "description" : "The format of the source audio data.",
          "name" : "sourceAudioFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/sourceAudioFormat"
        },
        {
          "description" : "A video settings dictionary.",
          "name" : "videoSettings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/videoSettings"
        },
        {
          "description" : "The format of the source video data.",
          "name" : "sourceVideoFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/sourceVideoFormat"
        },
        {
          "description" : "A time value that describes the minimum frame duration of the video data.",
          "name" : "sourceVideoMinFrameDuration",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/sourceVideoMinFrameDuration"
        },
        {
          "description" : "A time value that describes the average frame duration of the video data.",
          "name" : "sourceVideoAverageFrameDuration",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant\/sourceVideoAverageFrameDuration"
        }
      ],
      "title" : "Configuring output settings"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert content with equirectangular or half-equirectangular projection to APMP.",
          "name" : "Converting projected video to Apple Projected Media Profile",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-projected-video-to-apple-projected-media-profile"
        },
        {
          "description" : "Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.",
          "name" : "Converting side-by-side 3D video to multiview HEVC and spatial video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video"
        },
        {
          "description" : "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.",
          "name" : "Writing fragmented MPEG-4 files for HTTP Live Streaming",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/writing-fragmented-mpeg-4-files-for-http-live-streaming"
        },
        {
          "description" : "Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.",
          "name" : "Creating spatial photos and videos with spatial metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/ImageIO\/Creating-spatial-photos-and-videos-with-spatial-metadata"
        },
        {
          "description" : "Inspect and set video color space information when writing and transcoding media.",
          "name" : "Tagging media with video color information",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information"
        },
        {
          "description" : "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.",
          "name" : "Evaluating an app’s video color",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color"
        },
        {
          "description" : "An object that writes media data to a container file.",
          "name" : "AVAssetWriter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriter"
        },
        {
          "description" : "An object that appends media samples to a track in an asset writer’s output file.",
          "name" : "AVAssetWriterInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput"
        },
        {
          "description" : "An object that appends video samples to an asset writer input.",
          "name" : "AVAssetWriterInputPixelBufferAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPixelBufferAdaptor"
        },
        {
          "description" : "An object that appends tagged buffer groups to an asset writer input.",
          "name" : "AVAssetWriterInputTaggedPixelBufferGroupAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputTaggedPixelBufferGroupAdaptor"
        },
        {
          "description" : "An object that appends timed metadata groups to an asset writer input.",
          "name" : "AVAssetWriterInputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor"
        },
        {
          "description" : "A group of inputs with tracks that are mutually exclusive to each other for playback or processing.",
          "name" : "AVAssetWriterInputGroup",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup"
        }
      ],
      "title" : "Media writing"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVOutputSettingsAssistant",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant"
}