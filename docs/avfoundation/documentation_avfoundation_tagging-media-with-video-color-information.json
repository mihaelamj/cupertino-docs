{
  "abstract" : "Inspect and set video color space information when writing and transcoding media.",
  "codeExamples" : [
    {
      "code" : "\/\/ Use the asset writer object you create.\nlet writer = AVAssetWriter(contentType: .movie)\n        \nlet colorPropertySettings = [\n    AVVideoColorPrimariesKey: AVVideoColorPrimaries_ITU_R_709_2,\n    AVVideoYCbCrMatrixKey: AVVideoTransferFunction_ITU_R_709_2,\n    AVVideoTransferFunctionKey: AVVideoYCbCrMatrix_ITU_R_709_2\n]\n        \nlet compressionSettings: [String: Any] = [\n    AVVideoCodecKey: AVVideoCodecType.h264,\n    AVVideoWidthKey: 1920,\n    AVVideoHeightKey: 1080,\n    AVVideoColorPropertiesKey: colorPropertySettings\n]\n\nlet input = AVAssetWriterInput(mediaType: .video,\n                               outputSettings: compressionSettings)\nwriter.add(input)",
      "language" : "swift"
    },
    {
      "code" : "let videoComposition = AVMutableVideoComposition()\nvideoComposition.colorPrimaries = AVVideoColorPrimaries_P3_D65\nvideoComposition.colorTransferFunction = AVVideoTransferFunction_ITU_R_709_2\nvideoComposition.colorYCbCrMatrix = AVVideoYCbCrMatrix_ITU_R_709_2",
      "language" : "swift"
    },
    {
      "code" : "CVBufferSetAttachment(pixelBuffer, kCVImageBufferColorPrimariesKey, kCVImageBufferColorPrimaries_P3_D65, .shouldPropagate)\nCVBufferSetAttachment(pixelBuffer, kCVImageBufferTransferFunctionKey, kCVImageBufferTransferFunction_ITU_R_709_2, .shouldPropagate)\nCVBufferSetAttachment(pixelBuffer, kCVImageBufferYCbCrMatrixKey, kCVImageBufferYCbCrMatrix_ITU_R_709_2, .shouldPropagate)\ninputPixelBufferAdaptor.append(pixelBuffer, withPresentationTime: presentationTime)",
      "language" : "swift"
    },
    {
      "code" : "let assetTracks = try await asset.loadTracks(withMediaType: .video)\n        \nfor assetTrack in assetTracks {\n    let formatDescriptions = try await assetTrack.load(.formatDescriptions)\n    for formatDescription in formatDescriptions {\n        guard let colorPrimaries = CMFormatDescriptionGetExtension(formatDescription, extensionKey: kCMFormatDescriptionExtension_ColorPrimaries) else {\n            return\n        }\n\n        if CFGetTypeID(colorPrimaries) == CFStringGetTypeID() {\n            let result = CFStringCompareWithOptions((colorPrimaries as! CFString),\n                                                    kCMFormatDescriptionColorPrimaries_ITU_R_709_2,\n                                                    CFRangeMake(0, CFStringGetLength((colorPrimaries as! CFString))),\n                                                    CFStringCompareFlags.compareCaseInsensitive)\n\n            if result == CFComparisonResult.compareEqualTo {\n                \/\/ The color space is Rec. 709.\n            }\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "let asset = <# Your AVAsset #>\nlet wideGamutTracks = asset.tracks(withMediaCharacteristic: .usesWideGamutColorSpace)\nif wideGamutTracks.count > 0 {\n    \/\/ Use wide color aware processing.\n} else {\n    \/\/ Use Rec 709 processing.\n}",
      "language" : "swift"
    },
    {
      "code" : "let allowWideColorSettings = [AVVideoAllowWideColorKey: true]\nlet readerOutput = AVAssetReaderOutput(outputSettings: allowWideColorSettings) ",
      "language" : "swift"
    },
    {
      "code" : "class MyCustomVideoCompositor : AVVideoCompositing { \n   \/\/ ...\n   var supportsWideColorSourceFrames: Boolean  { return true }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "0af4ce55b7d0ca3ba71cf64c249f2128eac903b5e3c0c5852c4e6d78b8996f72",
  "crawledAt" : "2025-12-02T16:04:24Z",
  "id" : "2116969E-53FF-4FC9-86C0-79D781636752",
  "kind" : "article",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nMedia files may contain video color space information tags that describe the video media. The system’s color management uses these video color tags to ensure a consistent color appearance across all environments. You can retrieve and inspect the color information tags from your media, and specify new tags when writing and transcoding media. You can also detect wide color media to prevent clamping of the media to a smaller gamut color space.\n\n### Video tags describe key video parameters\n\nFor historical reasons, color scientists defined many permutations of broadcast video color spaces. As a result, you should *tag* your media files with color information that describes the video media. If you don’t, the untagged media content might not match your intentions across all the different configurations and environments your customers encounter.\n\nThis color information tagging mechanism supports three key video parameters:\n\nColorSync uses these video parameters to generate one of the following video color spaces:\n\n[https:\/\/www.iso.org\/standard\/69661.html], *Coding-Independent Code Points* defines these standard tag numbers.\n\n### Tag your video using asset writer\n\nWhen you initialize an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput] object, you can optionally specify a dictionary that contains the settings for encoding the media that you append to the output. The [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoColorPropertiesKey] is a dictionary that contains properties specifying video color (see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/setting-color-properties-for-a-specific-resolution] for the details). Set this key in the `AVAssetWriterInput` output settings dictionary to override the tagging of color properties in the video.\n\nIf the video color properties key is present in the output settings, the writer tags the output as follows:\n\nIf you don’t intend to override the color property tags in your video, don’t set a value for the video color properties key. If the video color properties key isn’t present in the output settings, the framework tags the output as follows:\n\nThe following example code specifies the Rec. 709 output color space for the video color properties key in the output settings:\n\n### Specify color space information for your video composition\n\nYou configure video compositions with color space information using analogous properties.\n\nYou designate a working color space for the entire video composition using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition\/colorPrimaries] property. Set the transfer function using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition\/colorTransferFunction] key, and the Y’CbCr matrix using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition\/colorYCbCrMatrix] key. Specify values suitable for the `AVVideoColorPrimariesKey`, [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoTransferFunctionKey], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoYCbCrMatrixKey] keys, respectively.\n\nHere’s a code example:\n\n### Tag your core video buffers with color space information\n\nIf you generate Core Video source buffers for rendering (for example, using a pixel buffer pool in Metal), you should tag them with color information.\n\nYou explicitly set the color space tags in the dictionary of attachments of the buffer as shown in the example below:\n\n### Get your media’s color space information\n\nYou access the low-level details about an asset’s video track media using [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/CMFormatDescription]. A `CMFormatDescriptionRef` object describes the media of a particular type (audio, video, and so on). You get the format descriptions for the asset track’s media sample references using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack] [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack\/formatDescriptions] property. Look in the format description for the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVImageBufferColorPrimariesKey] extension key that defines the color properties of the media. The `CMFormatDescription.h` header defines the color primary key values.\n\nHere’s an example that checks for the [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/kCMFormatDescriptionColorPrimaries_ITU_R_709_2-swift.var] color primary key value in the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVImageBufferColorPrimariesKey] extension:\n\n### View your media’s color information\n\nYou can use the Show Movie Inspector command in the macOS QuickTime Player app to view the color space information for the video media in a file. Open the file in the app and choose Window > Show Movie Inspector. The Inspector window displays the color information and other details about the video media.\n\n\n\nThe Finder Get Info command also shows the color information for the video media in a file. Select a file in the Finder and choose File > Get Info. The More Info section contains the color profile information.\n\n\n\n### Detect wide color tags in your media\n\nThe [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMediaCharacteristic\/usesWideGamutColorSpace] media characteristic indicates that the video track contains color primaries wider than Rec. 709 that the system can’t accurately represent. A wide color space, such as P3 D65, contains additional dynamic range that may benefit from special treatment when compositing in your workflow. You should exercise care to avoid clamping the colors back to the Rec. 709 space. If you don’t, it’s generally best to stay within the Rec. 709 space for your processing.\n\nHere’s an example:\n\n### Preserve wide color in your media\n\nSet the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetReaderOutput] [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoAllowWideColorKey] property to `true` to receive buffers in their original color space. The default value (`false`) permits implicit color conversions to a nonwide gamut color space.\n\n### Support wide color in custom video compositors\n\nYou implement the optional [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositing\/supportsWideColorSourceFrames] property and return `true` to indicate your custom video compositor handles frames that contain wide color properties. In this case, the compositor examines and honors color space tags on every single source frame buffer.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information\ncrawled: 2025-12-02T16:04:24Z\n---\n\n# Tagging media with video color information\n\n**Article**\n\nInspect and set video color space information when writing and transcoding media.\n\n## Overview\n\nMedia files may contain video color space information tags that describe the video media. The system’s color management uses these video color tags to ensure a consistent color appearance across all environments. You can retrieve and inspect the color information tags from your media, and specify new tags when writing and transcoding media. You can also detect wide color media to prevent clamping of the media to a smaller gamut color space.\n\n### Video tags describe key video parameters\n\nFor historical reasons, color scientists defined many permutations of broadcast video color spaces. As a result, you should *tag* your media files with color information that describes the video media. If you don’t, the untagged media content might not match your intentions across all the different configurations and environments your customers encounter.\n\n\n\nThis color information tagging mechanism supports three key video parameters:\n\n\n\n\n\nColorSync uses these video parameters to generate one of the following video color spaces:\n\n- SD (SMPTE-C)\n- HD (Rec. 709)\n- P3 (D65)\n- UHD (Rec. 2020)\n\n[https:\/\/www.iso.org\/standard\/69661.html], *Coding-Independent Code Points* defines these standard tag numbers.\n\n### Tag your video using asset writer\n\nWhen you initialize an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput] object, you can optionally specify a dictionary that contains the settings for encoding the media that you append to the output. The [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoColorPropertiesKey] is a dictionary that contains properties specifying video color (see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/setting-color-properties-for-a-specific-resolution] for the details). Set this key in the `AVAssetWriterInput` output settings dictionary to override the tagging of color properties in the video.\n\nIf the video color properties key is present in the output settings, the writer tags the output as follows:\n\n- If the source buffers don’t have color property tags, the asset writer tags the output according to the video color properties.\n- If the source buffers also have color property tags, the writer (if necessary) color-converts the source buffers to match the video color properties. The writer also tags the output according to the video color properties.\n\nIf you don’t intend to override the color property tags in your video, don’t set a value for the video color properties key. If the video color properties key isn’t present in the output settings, the framework tags the output as follows:\n\n- If the source buffers have color property tags, the writer tags the output according to the source buffer color properties.\n- If the source buffers don’t have color property tags, the writer doesn’t tag the output with any color properties.\n\nThe following example code specifies the Rec. 709 output color space for the video color properties key in the output settings:\n\n```swift\n\/\/ Use the asset writer object you create.\nlet writer = AVAssetWriter(contentType: .movie)\n        \nlet colorPropertySettings = [\n    AVVideoColorPrimariesKey: AVVideoColorPrimaries_ITU_R_709_2,\n    AVVideoYCbCrMatrixKey: AVVideoTransferFunction_ITU_R_709_2,\n    AVVideoTransferFunctionKey: AVVideoYCbCrMatrix_ITU_R_709_2\n]\n        \nlet compressionSettings: [String: Any] = [\n    AVVideoCodecKey: AVVideoCodecType.h264,\n    AVVideoWidthKey: 1920,\n    AVVideoHeightKey: 1080,\n    AVVideoColorPropertiesKey: colorPropertySettings\n]\n\nlet input = AVAssetWriterInput(mediaType: .video,\n                               outputSettings: compressionSettings)\nwriter.add(input)\n```\n\n### Specify color space information for your video composition\n\nYou configure video compositions with color space information using analogous properties.\n\nYou designate a working color space for the entire video composition using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition\/colorPrimaries] property. Set the transfer function using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition\/colorTransferFunction] key, and the Y’CbCr matrix using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition\/colorYCbCrMatrix] key. Specify values suitable for the `AVVideoColorPrimariesKey`, [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoTransferFunctionKey], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoYCbCrMatrixKey] keys, respectively.\n\nHere’s a code example:\n\n```swift\nlet videoComposition = AVMutableVideoComposition()\nvideoComposition.colorPrimaries = AVVideoColorPrimaries_P3_D65\nvideoComposition.colorTransferFunction = AVVideoTransferFunction_ITU_R_709_2\nvideoComposition.colorYCbCrMatrix = AVVideoYCbCrMatrix_ITU_R_709_2\n```\n\n\n\n### Tag your core video buffers with color space information\n\nIf you generate Core Video source buffers for rendering (for example, using a pixel buffer pool in Metal), you should tag them with color information.\n\nYou explicitly set the color space tags in the dictionary of attachments of the buffer as shown in the example below:\n\n```swift\nCVBufferSetAttachment(pixelBuffer, kCVImageBufferColorPrimariesKey, kCVImageBufferColorPrimaries_P3_D65, .shouldPropagate)\nCVBufferSetAttachment(pixelBuffer, kCVImageBufferTransferFunctionKey, kCVImageBufferTransferFunction_ITU_R_709_2, .shouldPropagate)\nCVBufferSetAttachment(pixelBuffer, kCVImageBufferYCbCrMatrixKey, kCVImageBufferYCbCrMatrix_ITU_R_709_2, .shouldPropagate)\ninputPixelBufferAdaptor.append(pixelBuffer, withPresentationTime: presentationTime)\n```\n\n### Get your media’s color space information\n\nYou access the low-level details about an asset’s video track media using [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/CMFormatDescription]. A `CMFormatDescriptionRef` object describes the media of a particular type (audio, video, and so on). You get the format descriptions for the asset track’s media sample references using the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack] [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack\/formatDescriptions] property. Look in the format description for the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVImageBufferColorPrimariesKey] extension key that defines the color properties of the media. The `CMFormatDescription.h` header defines the color primary key values.\n\nHere’s an example that checks for the [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/kCMFormatDescriptionColorPrimaries_ITU_R_709_2-swift.var] color primary key value in the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVImageBufferColorPrimariesKey] extension:\n\n```swift\nlet assetTracks = try await asset.loadTracks(withMediaType: .video)\n        \nfor assetTrack in assetTracks {\n    let formatDescriptions = try await assetTrack.load(.formatDescriptions)\n    for formatDescription in formatDescriptions {\n        guard let colorPrimaries = CMFormatDescriptionGetExtension(formatDescription, extensionKey: kCMFormatDescriptionExtension_ColorPrimaries) else {\n            return\n        }\n\n        if CFGetTypeID(colorPrimaries) == CFStringGetTypeID() {\n            let result = CFStringCompareWithOptions((colorPrimaries as! CFString),\n                                                    kCMFormatDescriptionColorPrimaries_ITU_R_709_2,\n                                                    CFRangeMake(0, CFStringGetLength((colorPrimaries as! CFString))),\n                                                    CFStringCompareFlags.compareCaseInsensitive)\n\n            if result == CFComparisonResult.compareEqualTo {\n                \/\/ The color space is Rec. 709.\n            }\n        }\n    }\n}\n```\n\n### View your media’s color information\n\nYou can use the Show Movie Inspector command in the macOS QuickTime Player app to view the color space information for the video media in a file. Open the file in the app and choose Window > Show Movie Inspector. The Inspector window displays the color information and other details about the video media.\n\n\n\nThe Finder Get Info command also shows the color information for the video media in a file. Select a file in the Finder and choose File > Get Info. The More Info section contains the color profile information.\n\n\n\n### Detect wide color tags in your media\n\nThe [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMediaCharacteristic\/usesWideGamutColorSpace] media characteristic indicates that the video track contains color primaries wider than Rec. 709 that the system can’t accurately represent. A wide color space, such as P3 D65, contains additional dynamic range that may benefit from special treatment when compositing in your workflow. You should exercise care to avoid clamping the colors back to the Rec. 709 space. If you don’t, it’s generally best to stay within the Rec. 709 space for your processing.\n\nHere’s an example:\n\n```swift\nlet asset = <# Your AVAsset #>\nlet wideGamutTracks = asset.tracks(withMediaCharacteristic: .usesWideGamutColorSpace)\nif wideGamutTracks.count > 0 {\n    \/\/ Use wide color aware processing.\n} else {\n    \/\/ Use Rec 709 processing.\n}\n```\n\n### Preserve wide color in your media\n\nSet the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetReaderOutput] [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoAllowWideColorKey] property to `true` to receive buffers in their original color space. The default value (`false`) permits implicit color conversions to a nonwide gamut color space.\n\n```swift\nlet allowWideColorSettings = [AVVideoAllowWideColorKey: true]\nlet readerOutput = AVAssetReaderOutput(outputSettings: allowWideColorSettings) \n```\n\n### Support wide color in custom video compositors\n\nYou implement the optional [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositing\/supportsWideColorSourceFrames] property and return `true` to indicate your custom video compositor handles frames that contain wide color properties. In this case, the compositor examines and honors color space tags on every single source frame buffer.\n\n```swift\nclass MyCustomVideoCompositor : AVVideoCompositing { \n   \/\/ ...\n   var supportsWideColorSourceFrames: Boolean  { return true }\n}\n```\n\n## Media writing\n\n- **Converting projected video to Apple Projected Media Profile**: Convert content with equirectangular or half-equirectangular projection to APMP.\n- **Converting side-by-side 3D video to multiview HEVC and spatial video**: Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.\n- **Writing fragmented MPEG-4 files for HTTP Live Streaming**: Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.\n- **Creating spatial photos and videos with spatial metadata**: Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.\n- **Evaluating an app’s video color**: Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.\n- **AVOutputSettingsAssistant**: An object that builds audio and video output settings dictionaries.\n- **AVAssetWriter**: An object that writes media data to a container file.\n- **AVAssetWriterInput**: An object that appends media samples to a track in an asset writer’s output file.\n- **AVAssetWriterInputPixelBufferAdaptor**: An object that appends video samples to an asset writer input.\n- **AVAssetWriterInputTaggedPixelBufferGroupAdaptor**: An object that appends tagged buffer groups to an asset writer input.\n- **AVAssetWriterInputMetadataAdaptor**: An object that appends timed metadata groups to an asset writer input.\n- **AVAssetWriterInputGroup**: A group of inputs with tracks that are mutually exclusive to each other for playback or processing.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert content with equirectangular or half-equirectangular projection to APMP.",
          "name" : "Converting projected video to Apple Projected Media Profile",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-projected-video-to-apple-projected-media-profile"
        },
        {
          "description" : "Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.",
          "name" : "Converting side-by-side 3D video to multiview HEVC and spatial video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video"
        },
        {
          "description" : "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.",
          "name" : "Writing fragmented MPEG-4 files for HTTP Live Streaming",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/writing-fragmented-mpeg-4-files-for-http-live-streaming"
        },
        {
          "description" : "Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.",
          "name" : "Creating spatial photos and videos with spatial metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/ImageIO\/Creating-spatial-photos-and-videos-with-spatial-metadata"
        },
        {
          "description" : "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.",
          "name" : "Evaluating an app’s video color",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color"
        },
        {
          "description" : "An object that builds audio and video output settings dictionaries.",
          "name" : "AVOutputSettingsAssistant",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant"
        },
        {
          "description" : "An object that writes media data to a container file.",
          "name" : "AVAssetWriter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriter"
        },
        {
          "description" : "An object that appends media samples to a track in an asset writer’s output file.",
          "name" : "AVAssetWriterInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput"
        },
        {
          "description" : "An object that appends video samples to an asset writer input.",
          "name" : "AVAssetWriterInputPixelBufferAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPixelBufferAdaptor"
        },
        {
          "description" : "An object that appends tagged buffer groups to an asset writer input.",
          "name" : "AVAssetWriterInputTaggedPixelBufferGroupAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputTaggedPixelBufferGroupAdaptor"
        },
        {
          "description" : "An object that appends timed metadata groups to an asset writer input.",
          "name" : "AVAssetWriterInputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor"
        },
        {
          "description" : "A group of inputs with tracks that are mutually exclusive to each other for playback or processing.",
          "name" : "AVAssetWriterInputGroup",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup"
        }
      ],
      "title" : "Media writing"
    }
  ],
  "source" : "appleJSON",
  "title" : "Tagging media with video color information",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information"
}