{
  "abstract" : "Information about the camera characteristics used to capture images and depth data.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "d3752f82cfe14c77c2aa0ec473731910194af74808df9ece9cafd21b862c5b45",
  "crawledAt" : "2025-12-02T16:09:51Z",
  "declaration" : {
    "code" : "class AVCameraCalibrationData",
    "language" : "swift"
  },
  "id" : "56FB50C2-5C2C-42B1-8564-CD6F1113CD9C",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nInformation about the calibration of a camera—such as its pixel focal length, principal point, and lens distortion characteristics—helps to determine the geometric relationships between the camera device and the images it captures. You can use this information to accurately render visual effects into images produced by a camera or perform computer vision tasks such as correcting images for geometric distortions.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\ncrawled: 2025-12-02T16:09:51Z\n---\n\n# AVCameraCalibrationData\n\n**Class**\n\nInformation about the camera characteristics used to capture images and depth data.\n\n## Declaration\n\n```swift\nclass AVCameraCalibrationData\n```\n\n## Overview\n\nInformation about the calibration of a camera—such as its pixel focal length, principal point, and lens distortion characteristics—helps to determine the geometric relationships between the camera device and the images it captures. You can use this information to accurately render visual effects into images produced by a camera or perform computer vision tasks such as correcting images for geometric distortions.\n\n## Mapping pixels to scene geometry\n\n- **intrinsicMatrix**: A matrix that relates a camera’s internal properties to an ideal pinhole-camera model.\n- **intrinsicMatrixReferenceDimensions**: The image dimensions to which the camera’s intrinsic matrix values are relative.\n- **extrinsicMatrix**: A matrix relating a camera’s position and orientation to a world or scene coordinate system.\n- **pixelSize**: The size, in millimeters, of one image pixel.\n\n## Correcting for lens distortion\n\n- **lensDistortionLookupTable**: A map of floating-point values describing radial distortions imparted by the camera lens, for use in rectifying camera images.\n- **inverseLensDistortionLookupTable**: A map of floating-point values describing radial distortions for use in reapplying camera geometry to a rectified image.\n- **lensDistortionCenter**: The offset of the distortion center of the camera lens from the top-left corner of the image.\n\n## Depth data capture\n\n- **Capturing photos with depth**: Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).\n- **Creating auxiliary depth data manually**: Generate a depth image and attach it to your own image.\n- **Capturing depth using the LiDAR camera**: Access the LiDAR camera on supporting devices to capture precise depth data.\n- **AVCamFilter: Applying filters to a capture stream**: Render a capture stream with rose-colored filtering and depth effects.\n- **Streaming depth data from the TrueDepth camera**: Visualize depth data in 2D and 3D from the TrueDepth camera.\n- **Enhancing live video by leveraging TrueDepth camera data**: Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.\n- **AVCaptureDepthDataOutput**: A capture output that records scene depth information on compatible camera devices.\n- **AVDepthData**: A container for per-pixel distance or disparity information captured by compatible camera devices.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A matrix that relates a camera’s internal properties to an ideal pinhole-camera model.",
          "name" : "intrinsicMatrix",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\/intrinsicMatrix"
        },
        {
          "description" : "The image dimensions to which the camera’s intrinsic matrix values are relative.",
          "name" : "intrinsicMatrixReferenceDimensions",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\/intrinsicMatrixReferenceDimensions"
        },
        {
          "description" : "A matrix relating a camera’s position and orientation to a world or scene coordinate system.",
          "name" : "extrinsicMatrix",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\/extrinsicMatrix"
        },
        {
          "description" : "The size, in millimeters, of one image pixel.",
          "name" : "pixelSize",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\/pixelSize"
        }
      ],
      "title" : "Mapping pixels to scene geometry"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A map of floating-point values describing radial distortions imparted by the camera lens, for use in rectifying camera images.",
          "name" : "lensDistortionLookupTable",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\/lensDistortionLookupTable"
        },
        {
          "description" : "A map of floating-point values describing radial distortions for use in reapplying camera geometry to a rectified image.",
          "name" : "inverseLensDistortionLookupTable",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\/inverseLensDistortionLookupTable"
        },
        {
          "description" : "The offset of the distortion center of the camera lens from the top-left corner of the image.",
          "name" : "lensDistortionCenter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData\/lensDistortionCenter"
        }
      ],
      "title" : "Correcting for lens distortion"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).",
          "name" : "Capturing photos with depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-with-depth"
        },
        {
          "description" : "Generate a depth image and attach it to your own image.",
          "name" : "Creating auxiliary depth data manually",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/creating-auxiliary-depth-data-manually"
        },
        {
          "description" : "Access the LiDAR camera on supporting devices to capture precise depth data.",
          "name" : "Capturing depth using the LiDAR camera",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-depth-using-the-lidar-camera"
        },
        {
          "description" : "Render a capture stream with rose-colored filtering and depth effects.",
          "name" : "AVCamFilter: Applying filters to a capture stream",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/avcamfilter-applying-filters-to-a-capture-stream"
        },
        {
          "description" : "Visualize depth data in 2D and 3D from the TrueDepth camera.",
          "name" : "Streaming depth data from the TrueDepth camera",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/streaming-depth-data-from-the-truedepth-camera"
        },
        {
          "description" : "Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.",
          "name" : "Enhancing live video by leveraging TrueDepth camera data",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/enhancing-live-video-by-leveraging-truedepth-camera-data"
        },
        {
          "description" : "A capture output that records scene depth information on compatible camera devices.",
          "name" : "AVCaptureDepthDataOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureDepthDataOutput"
        },
        {
          "description" : "A container for per-pixel distance or disparity information captured by compatible camera devices.",
          "name" : "AVDepthData",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData"
        }
      ],
      "title" : "Depth data capture"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVCameraCalibrationData",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData"
}