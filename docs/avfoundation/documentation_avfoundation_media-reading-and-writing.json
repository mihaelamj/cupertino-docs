{
  "abstract" : "Read images from video, export to alternative formats, and perform sample-level reading and writing of media data.",
  "codeExamples" : [

  ],
  "contentHash" : "b82a45cad56d082315db8579ad8efa5daab3a9155f7c7f8224937616d37ff893",
  "crawledAt" : "2025-12-02T21:50:44Z",
  "id" : "76012C76-6F93-4D92-9137-260915CA21C6",
  "kind" : "collection",
  "language" : "swift",
  "module" : "AVFoundation",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/media-reading-and-writing\ncrawled: 2025-12-02T21:50:44Z\n---\n\n# Media reading and writing\n\n**API Collection**\n\nRead images from video, export to alternative formats, and perform sample-level reading and writing of media data.\n\n## Media export\n\n- **Exporting video to alternative formats**: Convert an existing movie file to a different format.\n- **AVAssetExportSession**: An object that exports assets in a format that you specify using an export preset.\n\n## Image generation\n\n- **Creating images from a video asset**: Display images for specific times within the media timeline by generating images from a video’s frames.\n- **AVAssetImageGenerator**: An object that generates images from a video asset.\n\n## Media reading\n\n- **Reading multiview 3D video files**: Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.\n- **AVAssetReader**: An object that reads media data from an asset.\n- **AVAssetReaderOutput**: An abstract class that defines the interface to read media samples from an asset reader.\n- **AVAssetReaderTrackOutput**: An object that reads media data from a single track of an asset.\n- **AVAssetReaderAudioMixOutput**: An object that reads audio samples that result from mixing audio from one or more tracks.\n- **AVAssetReaderVideoCompositionOutput**: An object that reads composited video frames from one or more tracks of an asset.\n- **AVAssetReaderSampleReferenceOutput**: An object that reads sample references from an asset track.\n- **AVAssetReaderOutputMetadataAdaptor**: An object that creates timed metadata group objects for an asset track.\n\n## Media writing\n\n- **Converting projected video to Apple Projected Media Profile**: Convert content with equirectangular or half-equirectangular projection to APMP.\n- **Converting side-by-side 3D video to multiview HEVC and spatial video**: Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.\n- **Writing fragmented MPEG-4 files for HTTP Live Streaming**: Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.\n- **Creating spatial photos and videos with spatial metadata**: Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.\n- **Tagging media with video color information**: Inspect and set video color space information when writing and transcoding media.\n- **Evaluating an app’s video color**: Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.\n- **AVOutputSettingsAssistant**: An object that builds audio and video output settings dictionaries.\n- **AVAssetWriter**: An object that writes media data to a container file.\n- **AVAssetWriterInput**: An object that appends media samples to a track in an asset writer’s output file.\n- **AVAssetWriterInputPixelBufferAdaptor**: An object that appends video samples to an asset writer input.\n- **AVAssetWriterInputTaggedPixelBufferGroupAdaptor**: An object that appends tagged buffer groups to an asset writer input.\n- **AVAssetWriterInputMetadataAdaptor**: An object that appends timed metadata groups to an asset writer input.\n- **AVAssetWriterInputGroup**: A group of inputs with tracks that are mutually exclusive to each other for playback or processing.\n\n## Captions\n\n- **Caption authoring**: Create captions and subtitles in industry-standard formats.\n\n## Common\n\n- **Media assets**: Load media assets from files and streams to inspect their attributes, tracks, and embedded metadata.\n- **Media types and utilities**: Identify the types of content and file formats that AVFoundation supports.\n- **Video settings**: Configure video processing settings using standard key and value constants.\n- **Audio settings**: Configure audio processing settings using standard key and value constants.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert an existing movie file to a different format.",
          "name" : "Exporting video to alternative formats",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/exporting-video-to-alternative-formats"
        },
        {
          "description" : "An object that exports assets in a format that you specify using an export preset.",
          "name" : "AVAssetExportSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetExportSession"
        }
      ],
      "title" : "Media export"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Display images for specific times within the media timeline by generating images from a video’s frames.",
          "name" : "Creating images from a video asset",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/creating-images-from-a-video-asset"
        },
        {
          "description" : "An object that generates images from a video asset.",
          "name" : "AVAssetImageGenerator",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetImageGenerator"
        }
      ],
      "title" : "Image generation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.",
          "name" : "Reading multiview 3D video files",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/reading-multiview-3d-video-files"
        },
        {
          "description" : "An object that reads media data from an asset.",
          "name" : "AVAssetReader",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReader"
        },
        {
          "description" : "An abstract class that defines the interface to read media samples from an asset reader.",
          "name" : "AVAssetReaderOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutput"
        },
        {
          "description" : "An object that reads media data from a single track of an asset.",
          "name" : "AVAssetReaderTrackOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput"
        },
        {
          "description" : "An object that reads audio samples that result from mixing audio from one or more tracks.",
          "name" : "AVAssetReaderAudioMixOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput"
        },
        {
          "description" : "An object that reads composited video frames from one or more tracks of an asset.",
          "name" : "AVAssetReaderVideoCompositionOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderVideoCompositionOutput"
        },
        {
          "description" : "An object that reads sample references from an asset track.",
          "name" : "AVAssetReaderSampleReferenceOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderSampleReferenceOutput"
        },
        {
          "description" : "An object that creates timed metadata group objects for an asset track.",
          "name" : "AVAssetReaderOutputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutputMetadataAdaptor"
        }
      ],
      "title" : "Media reading"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert content with equirectangular or half-equirectangular projection to APMP.",
          "name" : "Converting projected video to Apple Projected Media Profile",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-projected-video-to-apple-projected-media-profile"
        },
        {
          "description" : "Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.",
          "name" : "Converting side-by-side 3D video to multiview HEVC and spatial video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video"
        },
        {
          "description" : "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.",
          "name" : "Writing fragmented MPEG-4 files for HTTP Live Streaming",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/writing-fragmented-mpeg-4-files-for-http-live-streaming"
        },
        {
          "description" : "Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.",
          "name" : "Creating spatial photos and videos with spatial metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/ImageIO\/Creating-spatial-photos-and-videos-with-spatial-metadata"
        },
        {
          "description" : "Inspect and set video color space information when writing and transcoding media.",
          "name" : "Tagging media with video color information",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information"
        },
        {
          "description" : "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.",
          "name" : "Evaluating an app’s video color",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color"
        },
        {
          "description" : "An object that builds audio and video output settings dictionaries.",
          "name" : "AVOutputSettingsAssistant",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant"
        },
        {
          "description" : "An object that writes media data to a container file.",
          "name" : "AVAssetWriter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriter"
        },
        {
          "description" : "An object that appends media samples to a track in an asset writer’s output file.",
          "name" : "AVAssetWriterInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput"
        },
        {
          "description" : "An object that appends video samples to an asset writer input.",
          "name" : "AVAssetWriterInputPixelBufferAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPixelBufferAdaptor"
        },
        {
          "description" : "An object that appends tagged buffer groups to an asset writer input.",
          "name" : "AVAssetWriterInputTaggedPixelBufferGroupAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputTaggedPixelBufferGroupAdaptor"
        },
        {
          "description" : "An object that appends timed metadata groups to an asset writer input.",
          "name" : "AVAssetWriterInputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor"
        },
        {
          "description" : "A group of inputs with tracks that are mutually exclusive to each other for playback or processing.",
          "name" : "AVAssetWriterInputGroup",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup"
        }
      ],
      "title" : "Media writing"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create captions and subtitles in industry-standard formats.",
          "name" : "Caption authoring",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/caption-authoring"
        }
      ],
      "title" : "Captions"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Load media assets from files and streams to inspect their attributes, tracks, and embedded metadata.",
          "name" : "Media assets",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/media-assets"
        },
        {
          "description" : "Identify the types of content and file formats that AVFoundation supports.",
          "name" : "Media types and utilities",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/media-types-and-utilities"
        },
        {
          "description" : "Configure video processing settings using standard key and value constants.",
          "name" : "Video settings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/video-settings"
        },
        {
          "description" : "Configure audio processing settings using standard key and value constants.",
          "name" : "Audio settings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/audio-settings"
        }
      ],
      "title" : "Common"
    }
  ],
  "source" : "appleJSON",
  "title" : "Media reading and writing",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/media-reading-and-writing"
}