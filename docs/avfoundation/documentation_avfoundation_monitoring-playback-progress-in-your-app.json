{
  "abstract" : "Observe the playback of a media asset to update your app’s user-interface state.",
  "codeExamples" : [
    {
      "code" : "@Published private(set) var duration: TimeInterval = 0.0\n@Published private(set) var currentTime: TimeInterval = 0.0\n\nprivate let player = AVPlayer()\nprivate var timeObserver: Any?\n\n\/\/\/ Adds an observer of the player timing.\nprivate func addPeriodicTimeObserver() {\n    \/\/ Create a 0.5 second interval time.\n    let interval = CMTime(value: 1, timescale: 2)\n    timeObserver = player.addPeriodicTimeObserver(forInterval: interval,\n                                                  queue: .main) { [weak self] time in\n        guard let self else { return }\n        \/\/ Update the published currentTime and duration values.\n        currentTime = time.seconds\n        duration = player.currentItem?.duration.seconds ?? 0.0\n    }\n}\n\n\/\/\/ Removes the time observer from the player.\nprivate func removePeriodicTimeObserver() {\n    guard let timeObserver else { return }\n    player.removeTimeObserver(timeObserver)\n    self.timeObserver = nil\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/\/ Adds an observer of the player traversing specific times during standard playback.\nprivate func addBoundaryTimeObserver() async throws {\n    \n    \/\/ Asynchronously load the duration of the asset.\n    let duration = try await asset.load(.duration)\n    \n    \/\/ Divide the asset's duration into quarters.\n    let quarterDuration = CMTimeMultiplyByRatio(duration,\n                                                multiplier: 1,\n                                                divisor: 4)\n    \n    var currentTime = CMTime.zero\n    var times = [NSValue]()\n    \n    \/\/ Calculate boundary times.\n    while currentTime < duration {\n        currentTime = currentTime + quarterDuration\n        times.append(NSValue(time:currentTime))\n    }\n    \n    timeObserver = player.addBoundaryTimeObserver(forTimes: times,\n                                                  queue: .main) { [weak self] in\n        \/\/ Update the percentage complete in the user interface.\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "7d16e3ab8c8a7153e8e5cd0a29ec67aee2b99be7126d825a333f07ec965c5f99",
  "crawledAt" : "2025-12-02T16:05:21Z",
  "id" : "921C51AC-75BC-4176-B815-47B8F9A542E3",
  "kind" : "article",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nMedia playback apps commonly need to monitor playback progress to drive the state of player UI or perform other actions. Monitoring this state requires a higher level of time precision than key-value observing can deliver, so [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer] provides specific API to observe playback time. This article describes how you can observe this state at regular intervals or as playback crosses specific time boundaries.\n\n### Observe the current playback time at regular intervals\n\nThe most common way to observe a player’s current time is at regular intervals. Observing it this way is useful when driving the state of a time display in a player’s user interface.\n\nTo observe the player’s current time at regular intervals, call its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/addPeriodicTimeObserver(forInterval:queue:using:)] method. This method takes a [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/CMTime] value that represents the interval at which to observe the time, a serial dispatch queue, and a callback that the player invokes at the specified time interval. The following example adds an observer that the player calls every half-second during normal playback:\n\nAlways pair a call to the player’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/addPeriodicTimeObserver(forInterval:queue:using:)] method with a call to [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/removeTimeObserver(_:)] when you’re finished monitoring the state. Failing to observe this rule results in undefined behavior.\n\n### Observe the playback of specific times within a media presentation\n\nAnother way to observe the player is when it crosses specific times boundaries during playback. You can respond to the passage of these times by updating your player UI or performing other actions.\n\nTo have the player notify your app as it cross specific points in the media timeline, call the player’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/addBoundaryTimeObserver(forTimes:queue:using:)] method. This method takes an array of [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSValue] objects that wrap [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/CMTime] values that define your boundary times, a serial dispatch queue, and a callback closure. The following example shows how to define boundary times for each quarter of playback:\n\nIf you add either a periodic or boundary time observer, you need to remove observation by calling [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/removeTimeObserver(_:)] when complete.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/monitoring-playback-progress-in-your-app\ncrawled: 2025-12-02T16:05:21Z\n---\n\n# Monitoring playback progress in your app\n\n**Article**\n\nObserve the playback of a media asset to update your app’s user-interface state.\n\n## Overview\n\nMedia playback apps commonly need to monitor playback progress to drive the state of player UI or perform other actions. Monitoring this state requires a higher level of time precision than key-value observing can deliver, so [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer] provides specific API to observe playback time. This article describes how you can observe this state at regular intervals or as playback crosses specific time boundaries.\n\n### Observe the current playback time at regular intervals\n\nThe most common way to observe a player’s current time is at regular intervals. Observing it this way is useful when driving the state of a time display in a player’s user interface.\n\nTo observe the player’s current time at regular intervals, call its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/addPeriodicTimeObserver(forInterval:queue:using:)] method. This method takes a [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/CMTime] value that represents the interval at which to observe the time, a serial dispatch queue, and a callback that the player invokes at the specified time interval. The following example adds an observer that the player calls every half-second during normal playback:\n\n```swift\n@Published private(set) var duration: TimeInterval = 0.0\n@Published private(set) var currentTime: TimeInterval = 0.0\n\nprivate let player = AVPlayer()\nprivate var timeObserver: Any?\n\n\/\/\/ Adds an observer of the player timing.\nprivate func addPeriodicTimeObserver() {\n    \/\/ Create a 0.5 second interval time.\n    let interval = CMTime(value: 1, timescale: 2)\n    timeObserver = player.addPeriodicTimeObserver(forInterval: interval,\n                                                  queue: .main) { [weak self] time in\n        guard let self else { return }\n        \/\/ Update the published currentTime and duration values.\n        currentTime = time.seconds\n        duration = player.currentItem?.duration.seconds ?? 0.0\n    }\n}\n\n\/\/\/ Removes the time observer from the player.\nprivate func removePeriodicTimeObserver() {\n    guard let timeObserver else { return }\n    player.removeTimeObserver(timeObserver)\n    self.timeObserver = nil\n}\n```\n\nAlways pair a call to the player’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/addPeriodicTimeObserver(forInterval:queue:using:)] method with a call to [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/removeTimeObserver(_:)] when you’re finished monitoring the state. Failing to observe this rule results in undefined behavior.\n\n### Observe the playback of specific times within a media presentation\n\nAnother way to observe the player is when it crosses specific times boundaries during playback. You can respond to the passage of these times by updating your player UI or performing other actions.\n\nTo have the player notify your app as it cross specific points in the media timeline, call the player’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/addBoundaryTimeObserver(forTimes:queue:using:)] method. This method takes an array of [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NSValue] objects that wrap [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/CMTime] values that define your boundary times, a serial dispatch queue, and a callback closure. The following example shows how to define boundary times for each quarter of playback:\n\n```swift\n\/\/\/ Adds an observer of the player traversing specific times during standard playback.\nprivate func addBoundaryTimeObserver() async throws {\n    \n    \/\/ Asynchronously load the duration of the asset.\n    let duration = try await asset.load(.duration)\n    \n    \/\/ Divide the asset's duration into quarters.\n    let quarterDuration = CMTimeMultiplyByRatio(duration,\n                                                multiplier: 1,\n                                                divisor: 4)\n    \n    var currentTime = CMTime.zero\n    var times = [NSValue]()\n    \n    \/\/ Calculate boundary times.\n    while currentTime < duration {\n        currentTime = currentTime + quarterDuration\n        times.append(NSValue(time:currentTime))\n    }\n    \n    timeObserver = player.addBoundaryTimeObserver(forTimes: times,\n                                                  queue: .main) { [weak self] in\n        \/\/ Update the percentage complete in the user interface.\n    }\n}\n```\n\nIf you add either a periodic or boundary time observer, you need to remove observation by calling [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPlayer\/removeTimeObserver(_:)] when complete.\n\n## Presentation\n\n- **Using HEVC video with alpha**: Play, write, and export HEVC video with an alpha channel to add overlay effects to your video processing.\n- **AVPlayerLayer**: An object that presents the visual contents of a player object.\n- **AVSynchronizedLayer**: A Core Animation layer that derives its timing from a player item so that you can synchronize layer animations with media playback.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Play, write, and export HEVC video with an alpha channel to add overlay effects to your video processing.",
          "name" : "Using HEVC video with alpha",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/using-hevc-video-with-alpha"
        },
        {
          "description" : "An object that presents the visual contents of a player object.",
          "name" : "AVPlayerLayer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVPlayerLayer"
        },
        {
          "description" : "A Core Animation layer that derives its timing from a player item so that you can synchronize layer animations with media playback.",
          "name" : "AVSynchronizedLayer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSynchronizedLayer"
        }
      ],
      "title" : "Presentation"
    }
  ],
  "source" : "appleJSON",
  "title" : "Monitoring playback progress in your app",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/monitoring-playback-progress-in-your-app"
}