{
  "abstract" : "Build responsive apps by using language-level concurrency features to efficiently load media data.",
  "codeExamples" : [
    {
      "code" : "public func load<T>(_ property: AVAsyncProperty<Self, T>) async throws -> T",
      "language" : "swift"
    },
    {
      "code" : "\/\/ A CMTime value.\nlet duration = try await asset.load(.duration)\n\/\/ An array of AVMetadataItem for the asset.\nlet metadata = try await asset.load(.metadata)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ A CMTime value and an array of AVMetadataItem.\nlet (duration, metadata) = try await asset.load(.duration, .metadata)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Determine the loaded status of the metadata property.\nswitch asset.status(of: .metadata) {\ncase .notYetLoaded:\n    \/\/ The initial state of a property.\ncase .loading:\n    \/\/ The asset is actively loading the property value.\ncase .loaded(let metadata):\n    \/\/ The property is ready to use.\ncase .failed(let error):\n    \/\/ The property value fails to load.\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Verify the metadata property is in a loaded state.\nif case .loaded(let metadata) = asset.status(of: .metadata) {\n    \/\/ Process the loaded value.\n    processMetadata(metadata)\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Load the asset's audio tracks asynchronously.\nlet audioTracks = try await asset.loadTracks(withMediaType: .audio)\nvar allDescriptions = [CMFormatDescription]()\nfor track in audioTracks {\n    \/\/ Load each audio track's format descriptions asynchronously.\n    allDescriptions.append(contentsOf: try await track.load(.formatDescriptions))\n}\n\/\/ Collect the unique sample rates, and sort them from highest to lowest.\nlet sampleRates = Set(allDescriptions).map {\n    Float($0.audioStreamBasicDescription?.mSampleRate ?? 0)\n}.sorted(by: { $0 > $1 })",
      "language" : "swift"
    }
  ],
  "contentHash" : "d261fd5babe7ea073424b850c60d037d8ad462e8670d0139daa8b2bd6db37000",
  "crawledAt" : "2025-12-02T16:45:18Z",
  "id" : "CCAF0266-07C1-42D6-90C1-2652ED87DBB8",
  "kind" : "article",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nAVFoundation uses the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset] class to model timed audiovisual media. Creating an asset is a lightweight operation because it defers loading its media until it requires the data. How long it takes an asset to load its data depends on factors, including the media’s size, local device capabilities, and remote network conditions. To avoid blocking the calling thread, you must load media data asynchronously.\n\n### Load properties asynchronously\n\nThe framework builds its asynchronous property-loading capabilities around two key types: [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsyncProperty] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading]. The framework uses the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsyncProperty] class to define type-safe identifiers for properties with values that require asynchronous loading, and uses the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading] protocol to define the interface for objects to load properties asynchronously. [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMetadataItem] adopt this protocol, which provides them an asynchronous [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading\/load(_:isolation:)] method with the following signature:\n\nCall this method from an asynchronous context, and specify the `await` keyword to indicate that execution can suspend until it finishes loading the data. The method returns a type-safe value if it successfully loads the property, or throws an error if it fails.\n\nIf you know in advance that you require loading several asset properties, you can use a variation of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading\/load(_:isolation:)] method that takes multiple identifiers and returns its result in a tuple. Like loading a single property value, loading several properties at the same time is also a type-safe operation.\n\n### Determine a property status\n\n[doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading] also provides a [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading\/status(of:)] method that returns the status of a property identifier. It returns an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsyncProperty\/Status] value that indicates the state of the property’s value using the cases shown in the example below:\n\nThe `.loaded` and `.failed` cases provide an associated value. The `.loaded` case contains the previously loaded property value, and the `.failed` case contains an error that indicates the reason for the failure. Having access to an associated value enables you to perform operations like checking a property’s status and accessing its value in a single step.\n\n### Filter property collections\n\nSome properties provide arrays of values, such as an asset’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPartialAsyncProperty\/tracks-44ptx] or its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPartialAsyncProperty\/metadata-16qej]. In many cases, you’re interested in only a subset of those values. [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack] also provide methods to filter their collections to only the values that you require. For example, the code listing below determines the audio sample rates that an asset contains. It calls the asset’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset\/loadTracks(withMediaType:completionHandler:)] to retrieve only its audio tracks. It iterates over each track and asynchronously loads the track’s format descriptions. Finally, it retrieves the sample rates from the stream description and sorts the results.\n\nUsing Swift concurrency and the AVFoundation asynchronous APIs makes performing even advanced inspection, as shown above, a simple, straight-line operation.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/loading-media-data-asynchronously\ncrawled: 2025-12-02T16:45:18Z\n---\n\n# Loading media data asynchronously\n\n**Article**\n\nBuild responsive apps by using language-level concurrency features to efficiently load media data.\n\n## Overview\n\nAVFoundation uses the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset] class to model timed audiovisual media. Creating an asset is a lightweight operation because it defers loading its media until it requires the data. How long it takes an asset to load its data depends on factors, including the media’s size, local device capabilities, and remote network conditions. To avoid blocking the calling thread, you must load media data asynchronously.\n\n\n\n### Load properties asynchronously\n\nThe framework builds its asynchronous property-loading capabilities around two key types: [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsyncProperty] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading]. The framework uses the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsyncProperty] class to define type-safe identifiers for properties with values that require asynchronous loading, and uses the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading] protocol to define the interface for objects to load properties asynchronously. [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMetadataItem] adopt this protocol, which provides them an asynchronous [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading\/load(_:isolation:)] method with the following signature:\n\n```swift\npublic func load<T>(_ property: AVAsyncProperty<Self, T>) async throws -> T\n```\n\nCall this method from an asynchronous context, and specify the `await` keyword to indicate that execution can suspend until it finishes loading the data. The method returns a type-safe value if it successfully loads the property, or throws an error if it fails.\n\n```swift\n\/\/ A CMTime value.\nlet duration = try await asset.load(.duration)\n\/\/ An array of AVMetadataItem for the asset.\nlet metadata = try await asset.load(.metadata)\n```\n\nIf you know in advance that you require loading several asset properties, you can use a variation of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading\/load(_:isolation:)] method that takes multiple identifiers and returns its result in a tuple. Like loading a single property value, loading several properties at the same time is also a type-safe operation.\n\n```swift\n\/\/ A CMTime value and an array of AVMetadataItem.\nlet (duration, metadata) = try await asset.load(.duration, .metadata)\n```\n\n\n\n### Determine a property status\n\n[doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading] also provides a [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousKeyValueLoading\/status(of:)] method that returns the status of a property identifier. It returns an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsyncProperty\/Status] value that indicates the state of the property’s value using the cases shown in the example below:\n\n```swift\n\/\/ Determine the loaded status of the metadata property.\nswitch asset.status(of: .metadata) {\ncase .notYetLoaded:\n    \/\/ The initial state of a property.\ncase .loading:\n    \/\/ The asset is actively loading the property value.\ncase .loaded(let metadata):\n    \/\/ The property is ready to use.\ncase .failed(let error):\n    \/\/ The property value fails to load.\n}\n```\n\nThe `.loaded` and `.failed` cases provide an associated value. The `.loaded` case contains the previously loaded property value, and the `.failed` case contains an error that indicates the reason for the failure. Having access to an associated value enables you to perform operations like checking a property’s status and accessing its value in a single step.\n\n```swift\n\/\/ Verify the metadata property is in a loaded state.\nif case .loaded(let metadata) = asset.status(of: .metadata) {\n    \/\/ Process the loaded value.\n    processMetadata(metadata)\n}\n```\n\n### Filter property collections\n\nSome properties provide arrays of values, such as an asset’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPartialAsyncProperty\/tracks-44ptx] or its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVPartialAsyncProperty\/metadata-16qej]. In many cases, you’re interested in only a subset of those values. [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetTrack] also provide methods to filter their collections to only the values that you require. For example, the code listing below determines the audio sample rates that an asset contains. It calls the asset’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsset\/loadTracks(withMediaType:completionHandler:)] to retrieve only its audio tracks. It iterates over each track and asynchronously loads the track’s format descriptions. Finally, it retrieves the sample rates from the stream description and sorts the results.\n\n```swift\n\/\/ Load the asset's audio tracks asynchronously.\nlet audioTracks = try await asset.loadTracks(withMediaType: .audio)\nvar allDescriptions = [CMFormatDescription]()\nfor track in audioTracks {\n    \/\/ Load each audio track's format descriptions asynchronously.\n    allDescriptions.append(contentsOf: try await track.load(.formatDescriptions))\n}\n\/\/ Collect the unique sample rates, and sort them from highest to lowest.\nlet sampleRates = Set(allDescriptions).map {\n    Float($0.audioStreamBasicDescription?.mSampleRate ?? 0)\n}.sorted(by: { $0 > $1 })\n```\n\nUsing Swift concurrency and the AVFoundation asynchronous APIs makes performing even advanced inspection, as shown above, a simple, straight-line operation.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "Loading media data asynchronously",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/loading-media-data-asynchronously"
}