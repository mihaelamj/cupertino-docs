{
  "abstract" : "Configure your app for flexible enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.",
  "codeExamples" : [
    {
      "code" : "let serializationQueue = DispatchQueue(label: \"sample.buffer.player.serialization.queue\")\nlet audioRenderer = AVSampleBufferAudioRenderer()\nlet renderSynchronizer = AVSampleBufferRenderSynchronizer()",
      "language" : "swift"
    },
    {
      "code" : "automaticFlushObserver = NotificationCenter.default.addObserver(forName: .AVSampleBufferAudioRendererWasFlushedAutomatically,\n                                                                object: audioRenderer,\n                                                                queue: nil) { [weak self] notification in\n    self?.serializationQueue.async { [weak self] in\n        guard let self = self else { return } \n        \/\/ Restart from the point where the flush interrupts the audio.\n        let restartTime = (notification.userInfo?[AVSampleBufferAudioRendererFlushTimeKey] as? NSValue)?.timeValue\n        self.autoflushPlayback(restartingAt: restartTime)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "renderSynchronizer.addRenderer(audioRenderer)",
      "language" : "swift"
    },
    {
      "code" : "serializationQueue.async { [weak self] in\n    guard let self = self else { return }\n    \/\/ Start processing audio data and stop when there's no more data.\n    self.audioRenderer.requestMediaDataWhenReady(on: serializationQueue) { [weak self] in\n        guard let self = self else { return }\n        while self.audioRenderer.isReadyForMoreMediaData {\n            let sampleBuffer = self.nextSampleBuffer() \/\/ Returns nil at end of data.\n            if let sampleBuffer = sampleBuffer {\n                self.audioRenderer.enqueue(sampleBuffer)\n            } else {\n                \/\/ Tell the renderer to stop requesting audio data.\n                audioRenderer.stopRequestingMediaData()\n            }\n        }\n    }\n\n    \/\/ Start playback at the natural rate of the media.\n    self.renderSynchronizer.rate = 1.0\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "681abb85c6cceb4754a0cd8bdd5a2a14840686da6ff38e1f8c104705037a2d3e",
  "crawledAt" : "2025-12-02T15:51:14Z",
  "id" : "456C5F77-121B-420D-9506-9D18CE9594C4",
  "kind" : "article",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nIf you’re working with content that requires flexibility with buffering, use the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer] classes.\n\nTo implement flexible enhanced buffering, complete the following steps.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/implementing-flexible-enhanced-buffering-for-your-content\ncrawled: 2025-12-02T15:51:14Z\n---\n\n# Implementing flexible enhanced buffering for your content\n\n**Article**\n\nConfigure your app for flexible enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.\n\n## Overview\n\nIf you’re working with content that requires flexibility with buffering, use the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer] classes.\n\nTo implement flexible enhanced buffering, complete the following steps.\n\n1. Create a serialization queue to perform all playback operations on, and create the audio renderer and the render synchronizer to establish the media timeline.\n\n```swift\nlet serializationQueue = DispatchQueue(label: \"sample.buffer.player.serialization.queue\")\nlet audioRenderer = AVSampleBufferAudioRenderer()\nlet renderSynchronizer = AVSampleBufferRenderSynchronizer()\n```\n\n1. Observe when the renderer has flushed enqueued audio, such as when the rate of playback increases or decreases, and re-enqueue audio data starting from the time the flush occurred.\n\n```swift\nautomaticFlushObserver = NotificationCenter.default.addObserver(forName: .AVSampleBufferAudioRendererWasFlushedAutomatically,\n                                                                object: audioRenderer,\n                                                                queue: nil) { [weak self] notification in\n    self?.serializationQueue.async { [weak self] in\n        guard let self = self else { return } \n        \/\/ Restart from the point where the flush interrupts the audio.\n        let restartTime = (notification.userInfo?[AVSampleBufferAudioRendererFlushTimeKey] as? NSValue)?.timeValue\n        self.autoflushPlayback(restartingAt: restartTime)\n    }\n}\n```\n\n1. Add the audio renderer to the render synchronizer, to tell the audio renderer to follow the media timeline.\n\n```swift\nrenderSynchronizer.addRenderer(audioRenderer)\n```\n\n1. Tell the audio renderer to start processing audio data, and set the render synchronizer’s rate to `1` to start playback.\n\n```swift\nserializationQueue.async { [weak self] in\n    guard let self = self else { return }\n    \/\/ Start processing audio data and stop when there's no more data.\n    self.audioRenderer.requestMediaDataWhenReady(on: serializationQueue) { [weak self] in\n        guard let self = self else { return }\n        while self.audioRenderer.isReadyForMoreMediaData {\n            let sampleBuffer = self.nextSampleBuffer() \/\/ Returns nil at end of data.\n            if let sampleBuffer = sampleBuffer {\n                self.audioRenderer.enqueue(sampleBuffer)\n            } else {\n                \/\/ Tell the renderer to stop requesting audio data.\n                audioRenderer.stopRequestingMediaData()\n            }\n        }\n    }\n\n    \/\/ Start playback at the natural rate of the media.\n    self.renderSynchronizer.rate = 1.0\n}\n```\n\n## Buffered playback\n\n- **Implementing simple enhanced buffering for your content**: Configure your app for simple enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.\n- **Integrating AirPlay for long-form video apps**: Integrate AirPlay features and implement a dedicated external playback experience by preparing the routing system for long-form video playback.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Configure your app for simple enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.",
          "name" : "Implementing simple enhanced buffering for your content",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/implementing-simple-enhanced-buffering-for-your-content"
        },
        {
          "description" : "Integrate AirPlay features and implement a dedicated external playback experience by preparing the routing system for long-form video playback.",
          "name" : "Integrating AirPlay for long-form video apps",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/integrating-airplay-for-long-form-video-apps"
        }
      ],
      "title" : "Buffered playback"
    }
  ],
  "source" : "appleJSON",
  "title" : "Implementing flexible enhanced buffering for your content",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/implementing-flexible-enhanced-buffering-for-your-content"
}