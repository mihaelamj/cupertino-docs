{
  "abstract" : "Support professional photography workflows by enabling minimally processed image capture in your camera app.",
  "codeExamples" : [
    {
      "code" : "private let captureSession = AVCaptureSession()\nprivate let photoOutput = AVCapturePhotoOutput()\n\nprivate func setupSession() throws {\n    \n    \/\/ Start the capture session configuration.\n    captureSession.beginConfiguration()\n    \n    \/\/ Configure the session for photo capture.\n    captureSession.sessionPreset = .photo\n    \n    \/\/ Connect the default video device.\n    let videoInput = try AVCaptureDeviceInput(device: defaultVideoDevice)\n    if captureSession.canAddInput(videoInput) {\n        captureSession.addInput(videoInput)\n        currentVideoInput = videoInput\n    } else {\n        throw CameraError.setupFailed\n    }\n    \n    \/\/ Connect and configure the capture output.\n    if captureSession.canAddOutput(photoOutput) {\n        captureSession.addOutput(photoOutput)\n        \n        \/\/ Use the Apple ProRAW format when the environment supports it.\n        photoOutput.isAppleProRAWEnabled = photoOutput.isAppleProRAWSupported\n    } else {\n        throw CameraError.setupFailed\n    }\n    \n    \/\/ Session configuration is complete. Commit the configuration.\n    captureSession.commitConfiguration()\n}\n",
      "language" : "swift"
    },
    {
      "code" : "let query = photoOutput.isAppleProRAWEnabled ?\n    { AVCapturePhotoOutput.isAppleProRAWPixelFormat($0) } :\n    { AVCapturePhotoOutput.isBayerRAWPixelFormat($0) }\n\n\/\/ Retrieve the RAW format, favoring the Apple ProRAW format when it's in an enabled state.\nguard let rawFormat =\n        photoOutput.availableRawPhotoPixelFormatTypes.first(where: query) else {\n    fatalError(\"No RAW format found.\")\n}\n\n\/\/ Capture a RAW format photo, along with a processed format photo.\nlet processedFormat = [AVVideoCodecKey: AVVideoCodecType.hevc]\nlet photoSettings = AVCapturePhotoSettings(rawPixelFormatType: rawFormat,\n                                           processedFormat: processedFormat)\n\n\/\/ Create a delegate to monitor the capture process.\nlet delegate = RAWCaptureDelegate()\ncaptureDelegates[photoSettings.uniqueID] = delegate\n\n\/\/ Remove the delegate reference when it finishes its processing.\ndelegate.didFinish = {\n    self.captureDelegates[photoSettings.uniqueID] = nil\n}\n\n\/\/ Tell the output to capture the photo.\nphotoOutput.capturePhoto(with: photoSettings, delegate: delegate)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Select the first available codec type, which is JPEG.\nguard let thumbnailPhotoCodecType =\n    photoSettings.availableRawEmbeddedThumbnailPhotoCodecTypes.first else {\n    \/\/ Handle the failure to find an available thumbnail photo codec type.\n}\n\n\/\/ Select the maximum photo dimensions as thumbnail dimensions if a full-size thumbnail is desired.\n\/\/ The system clamps these dimensions to the photo dimensions if the capture produces a photo with smaller than maximum dimensions.\nlet dimensions = photoSettings.maxPhotoDimensions\n\nphotoSettings.rawEmbeddedThumbnailPhotoFormat = [\n    AVVideoCodecKey: thumbnailPhotoCodecType,\n    AVVideoWidthKey: dimensions.width,\n    AVVideoHeightKey: dimensions.height\n]",
      "language" : "swift"
    },
    {
      "code" : "class RAWCaptureDelegate: NSObject, AVCapturePhotoCaptureDelegate {\n    \n    private var rawFileURL: URL?\n    private var compressedData: Data?\n    \n    var didFinish: (() -> Void)?\n    \n    \/\/ Store the RAW file and compressed photo data until the capture finishes.\n    func photoOutput(_ output: AVCapturePhotoOutput,\n                     didFinishProcessingPhoto photo: AVCapturePhoto,\n                     error: Error?) {\n        \n        guard error == nil else {\n            print(\"Error capturing photo: \\(error!)\")\n            return\n        }\n        \n        \/\/ Access the file data representation of this photo.\n        guard let photoData = photo.fileDataRepresentation() else {\n            print(\"No photo data to write.\")\n            return\n        }\n        \n        if photo.isRawPhoto {\n            \/\/ Generate a unique URL to write the RAW file.\n            rawFileURL = makeUniqueDNGFileURL()\n            do {\n                \/\/ Write the RAW (DNG) file data to a URL.\n                try photoData.write(to: rawFileURL!)\n            } catch {\n                fatalError(\"Couldn't write DNG file to the URL.\")\n            }\n        } else {\n            \/\/ Store compressed bitmap data.\n            compressedData = photoData\n        }\n    }\n    \n    private func makeUniqueDNGFileURL() -> URL {\n        let tempDir = FileManager.default.temporaryDirectory\n        let fileName = ProcessInfo.processInfo.globallyUniqueString\n        return tempDir.appendingPathComponent(fileName).appendingPathExtension(\"dng\")\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "class AppleProRAWCustomizer: NSObject, AVCapturePhotoFileDataRepresentationCustomizer {\n    \n    \/\/ Customize the compression settings.\n    func replacementAppleProRAWCompressionSettings(for photo: AVCapturePhoto, \n                                                   defaultSettings: [String : Any], \n                                                   maximumBitDepth: Int) -> [String : Any] {\n        \n        \/\/ Reduce the bit depth and quality of the final file.\n        return [AVVideoAppleProRAWBitDepthKey: maximumBitDepth - 2, \n                AVVideoQualityKey: 0.95]\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Get a minimally compressed representation of the file data.\nlet customizer = AppleProRAWCustomizer()\nlet photoData = photo.fileDataRepresentation(with: customizer)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ After both RAW and compressed versions are complete, add them to the Photos library.\nfunc photoOutput(_ output: AVCapturePhotoOutput,\n                 didFinishCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings,\n                 error: Error?) {\n    \n    \/\/ Call the \"finished\" closure, if you set it.\n    defer { didFinish?() }\n    \n    guard error == nil else {\n        print(\"Error capturing photo: \\(error!)\")\n        return\n    }\n    \n    \/\/ Ensure the RAW and processed photo data exists.\n    guard let rawFileURL = rawFileURL,\n          let compressedData = compressedData else {\n        print(\"The expected photo data isn't available.\")\n        return\n    }\n    \n    \/\/ Request add-only access to the user's Photos library (if the user hasn't already granted that access).\n    PHPhotoLibrary.requestAuthorization(for: .addOnly) { status in\n        \n        \/\/ Don't continue unless the user granted access.\n        guard status == .authorized else { return }\n        \n        PHPhotoLibrary.shared().performChanges {\n            \n            let creationRequest = PHAssetCreationRequest.forAsset()\n            \n            \/\/ Save the RAW (DNG) file as the main resource for the Photos asset.\n            let options = PHAssetResourceCreationOptions()\n            options.shouldMoveFile = true\n            creationRequest.addResource(with: .photo,\n                                        fileURL: rawFileURL,\n                                        options: options)\n            \n            \n            \/\/ Add the compressed (HEIF) data as an alternative resource.\n            creationRequest.addResource(with: .alternatePhoto,\n                                        data: compressedData,\n                                        options: nil)\n            \n        } completionHandler: { success, error in\n            \/\/ Process the Photos library error.\n        }\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "126e952fec97f245849d53685c5db90145ee372b1343825ea573c26aceb4d582",
  "crawledAt" : "2025-12-02T16:09:53Z",
  "id" : "96C7A266-0950-4952-BFEA-9A9857A3377C",
  "kind" : "article",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nBy default, the image-capture pipeline uses advanced computational photography techniques to achieve the highest quality images, and delivers the processed result to your app in a compressed format for efficient storage and display. Processed formats are a great choice in many cases, but RAW formats contain minimally processed image data from the camera sensor, which gives your app users more creative control.\n\nCapturing images in RAW formats results in much larger files than compressed formats, but greatly expands editing capabilities in post-production. One drawback to shooting in standard RAW formats is that it bypasses the advanced processing that the image-capture pipeline provides.\n\nBeginning in iOS 14.3, and available on iPhone 12 Pro and Pro Max, you can use the Apple ProRAW format. The Apple ProRAW format provides the benefits of RAW capture, and applies many of the multi-image fusion techniques previously unavailable to RAW workflows.\n\n### Enable Apple ProRAW support\n\nTo determine whether your app’s photo output supports the Apple ProRAW format in the current environment, add the output to a capture session that has a connected video source, and query its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isAppleProRAWSupported] property. If the current environment supports the Apple ProRAW format, you can enable the photo output to use it by setting its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isAppleProRAWEnabled] property to [doc:\/\/com.apple.documentation\/documentation\/Swift\/true] as the example below shows:\n\nEnabling use of the Apple ProRAW format adds an entry to the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/availableRawPhotoPixelFormatTypes-5fatm] array. You can determine whether a particular format in the array is an Apple ProRAW or a Bayer RAW format by querying the output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isAppleProRAWPixelFormat(_:)] or [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isBayerRAWPixelFormat(_:)] methods.\n\n### Capture RAW and Apple ProRAW photos\n\nCapturing photos in RAW and Apple ProRAW formats requires only minor changes to the basic photography workflow in [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/capturing-still-and-live-photos]. Begin by creating an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings] object that specifies the RAW format to capture, and optionally, a processed format to capture if your app supports creating RAW+JPEG files. The capture pipeline only supports the RAW formats in the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/availableRawPhotoPixelFormatTypes-5fatm] array.\n\nThe example below finds the appropriate RAW format, choosing the Apple ProRAW format when it’s in an enabled state, and the Bayer RAW format when it’s not. It creates a photo settings object that specifies the RAW and processed formats, and a delegate object to monitor the capture progress. Finally, it calls the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/capturePhoto(with:delegate:)] method, passing it the photo settings and delegate objects.\n\nThe Apple ProRAW format supports capturing up to a full-resolution JPEG image to use as a thumbnail photo. Set [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings\/rawEmbeddedThumbnailPhotoFormat] on your photo settings object as the following example shows:\n\n### Handle the captured photos\n\nThe photo output calls its delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method at least once for each format you request, and possibly additional times, depending on your capture settings. Using the capture settings in the previous section results in the photo output calling this delegate method twice: once for the RAW or Apple ProRAW image, and again for the processed image. In each invocation, get the photo’s file data by calling its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation()] method and store it as necessary. If you call this method on a RAW or Apple ProRAW photo, it returns the data in the industry-standard DNG file format. If you call it on processed images, it returns the compressed bitmap image data.\n\nThe following code shows an example implementation of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method. It writes the RAW file to disk and stores a reference to the processed photo’s compressed bitmap data for later use.\n\n### Customize the Apple ProRAW output\n\nBy default, when you ask for the file data representation of an Apple ProRAW photo, you get the data in full lossless quality. If you’re willing to accept some lossy compression to achieve smaller file sizes, you can customize the compression settings by calling [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation(with:)] and passing it a custom object that conforms to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoFileDataRepresentationCustomizer] protocol. The following code shows an example implementation of this protocol that applies minimal compression to the output image:\n\nTo use this customizer when retrieving the file data representation of a ProRAW photo, create a new instance of your customizer and pass it to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation(with:)] method as the example below shows:\n\n### Save the photos to the photos library\n\nThe photo output indicates when it finishes the capture request by calling the delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishCaptureFor:error:)] method. This callback provides an opportunity to save the captured photos to the user’s Photos library. For more information about configuring your app to access the user’s Photos library, see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/saving-captured-photos].\n\nTo save the captured photos to the user’s Photos library, create a single Photos asset that associates the RAW or Apple ProRAW data with the processed data. Create an instance of [doc:\/\/com.apple.documentation\/documentation\/Photos\/PHAssetCreationRequest], then specify the DNG version as the asset’s main [doc:\/\/com.apple.documentation\/documentation\/Photos\/PHAssetResourceType\/photo] resource, and the processed image as an [doc:\/\/com.apple.documentation\/documentation\/Photos\/PHAssetResourceType\/alternatePhoto] resource. Perform the request inside a change block as the example below shows:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-in-raw-and-apple-proraw-formats\ncrawled: 2025-12-02T16:09:53Z\n---\n\n# Capturing photos in RAW and Apple ProRAW formats\n\n**Article**\n\nSupport professional photography workflows by enabling minimally processed image capture in your camera app.\n\n## Overview\n\nBy default, the image-capture pipeline uses advanced computational photography techniques to achieve the highest quality images, and delivers the processed result to your app in a compressed format for efficient storage and display. Processed formats are a great choice in many cases, but RAW formats contain minimally processed image data from the camera sensor, which gives your app users more creative control.\n\nCapturing images in RAW formats results in much larger files than compressed formats, but greatly expands editing capabilities in post-production. One drawback to shooting in standard RAW formats is that it bypasses the advanced processing that the image-capture pipeline provides.\n\nBeginning in iOS 14.3, and available on iPhone 12 Pro and Pro Max, you can use the Apple ProRAW format. The Apple ProRAW format provides the benefits of RAW capture, and applies many of the multi-image fusion techniques previously unavailable to RAW workflows.\n\n\n\n### Enable Apple ProRAW support\n\nTo determine whether your app’s photo output supports the Apple ProRAW format in the current environment, add the output to a capture session that has a connected video source, and query its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isAppleProRAWSupported] property. If the current environment supports the Apple ProRAW format, you can enable the photo output to use it by setting its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isAppleProRAWEnabled] property to [doc:\/\/com.apple.documentation\/documentation\/Swift\/true] as the example below shows:\n\n```swift\nprivate let captureSession = AVCaptureSession()\nprivate let photoOutput = AVCapturePhotoOutput()\n\nprivate func setupSession() throws {\n    \n    \/\/ Start the capture session configuration.\n    captureSession.beginConfiguration()\n    \n    \/\/ Configure the session for photo capture.\n    captureSession.sessionPreset = .photo\n    \n    \/\/ Connect the default video device.\n    let videoInput = try AVCaptureDeviceInput(device: defaultVideoDevice)\n    if captureSession.canAddInput(videoInput) {\n        captureSession.addInput(videoInput)\n        currentVideoInput = videoInput\n    } else {\n        throw CameraError.setupFailed\n    }\n    \n    \/\/ Connect and configure the capture output.\n    if captureSession.canAddOutput(photoOutput) {\n        captureSession.addOutput(photoOutput)\n        \n        \/\/ Use the Apple ProRAW format when the environment supports it.\n        photoOutput.isAppleProRAWEnabled = photoOutput.isAppleProRAWSupported\n    } else {\n        throw CameraError.setupFailed\n    }\n    \n    \/\/ Session configuration is complete. Commit the configuration.\n    captureSession.commitConfiguration()\n}\n\n```\n\nEnabling use of the Apple ProRAW format adds an entry to the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/availableRawPhotoPixelFormatTypes-5fatm] array. You can determine whether a particular format in the array is an Apple ProRAW or a Bayer RAW format by querying the output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isAppleProRAWPixelFormat(_:)] or [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/isBayerRAWPixelFormat(_:)] methods.\n\n\n\n### Capture RAW and Apple ProRAW photos\n\nCapturing photos in RAW and Apple ProRAW formats requires only minor changes to the basic photography workflow in [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/capturing-still-and-live-photos]. Begin by creating an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings] object that specifies the RAW format to capture, and optionally, a processed format to capture if your app supports creating RAW+JPEG files. The capture pipeline only supports the RAW formats in the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/availableRawPhotoPixelFormatTypes-5fatm] array.\n\nThe example below finds the appropriate RAW format, choosing the Apple ProRAW format when it’s in an enabled state, and the Bayer RAW format when it’s not. It creates a photo settings object that specifies the RAW and processed formats, and a delegate object to monitor the capture progress. Finally, it calls the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/capturePhoto(with:delegate:)] method, passing it the photo settings and delegate objects.\n\n```swift\nlet query = photoOutput.isAppleProRAWEnabled ?\n    { AVCapturePhotoOutput.isAppleProRAWPixelFormat($0) } :\n    { AVCapturePhotoOutput.isBayerRAWPixelFormat($0) }\n\n\/\/ Retrieve the RAW format, favoring the Apple ProRAW format when it's in an enabled state.\nguard let rawFormat =\n        photoOutput.availableRawPhotoPixelFormatTypes.first(where: query) else {\n    fatalError(\"No RAW format found.\")\n}\n\n\/\/ Capture a RAW format photo, along with a processed format photo.\nlet processedFormat = [AVVideoCodecKey: AVVideoCodecType.hevc]\nlet photoSettings = AVCapturePhotoSettings(rawPixelFormatType: rawFormat,\n                                           processedFormat: processedFormat)\n\n\/\/ Create a delegate to monitor the capture process.\nlet delegate = RAWCaptureDelegate()\ncaptureDelegates[photoSettings.uniqueID] = delegate\n\n\/\/ Remove the delegate reference when it finishes its processing.\ndelegate.didFinish = {\n    self.captureDelegates[photoSettings.uniqueID] = nil\n}\n\n\/\/ Tell the output to capture the photo.\nphotoOutput.capturePhoto(with: photoSettings, delegate: delegate)\n```\n\nThe Apple ProRAW format supports capturing up to a full-resolution JPEG image to use as a thumbnail photo. Set [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings\/rawEmbeddedThumbnailPhotoFormat] on your photo settings object as the following example shows:\n\n```swift\n\/\/ Select the first available codec type, which is JPEG.\nguard let thumbnailPhotoCodecType =\n    photoSettings.availableRawEmbeddedThumbnailPhotoCodecTypes.first else {\n    \/\/ Handle the failure to find an available thumbnail photo codec type.\n}\n\n\/\/ Select the maximum photo dimensions as thumbnail dimensions if a full-size thumbnail is desired.\n\/\/ The system clamps these dimensions to the photo dimensions if the capture produces a photo with smaller than maximum dimensions.\nlet dimensions = photoSettings.maxPhotoDimensions\n\nphotoSettings.rawEmbeddedThumbnailPhotoFormat = [\n    AVVideoCodecKey: thumbnailPhotoCodecType,\n    AVVideoWidthKey: dimensions.width,\n    AVVideoHeightKey: dimensions.height\n]\n```\n\n### Handle the captured photos\n\nThe photo output calls its delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method at least once for each format you request, and possibly additional times, depending on your capture settings. Using the capture settings in the previous section results in the photo output calling this delegate method twice: once for the RAW or Apple ProRAW image, and again for the processed image. In each invocation, get the photo’s file data by calling its [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation()] method and store it as necessary. If you call this method on a RAW or Apple ProRAW photo, it returns the data in the industry-standard DNG file format. If you call it on processed images, it returns the compressed bitmap image data.\n\nThe following code shows an example implementation of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method. It writes the RAW file to disk and stores a reference to the processed photo’s compressed bitmap data for later use.\n\n```swift\nclass RAWCaptureDelegate: NSObject, AVCapturePhotoCaptureDelegate {\n    \n    private var rawFileURL: URL?\n    private var compressedData: Data?\n    \n    var didFinish: (() -> Void)?\n    \n    \/\/ Store the RAW file and compressed photo data until the capture finishes.\n    func photoOutput(_ output: AVCapturePhotoOutput,\n                     didFinishProcessingPhoto photo: AVCapturePhoto,\n                     error: Error?) {\n        \n        guard error == nil else {\n            print(\"Error capturing photo: \\(error!)\")\n            return\n        }\n        \n        \/\/ Access the file data representation of this photo.\n        guard let photoData = photo.fileDataRepresentation() else {\n            print(\"No photo data to write.\")\n            return\n        }\n        \n        if photo.isRawPhoto {\n            \/\/ Generate a unique URL to write the RAW file.\n            rawFileURL = makeUniqueDNGFileURL()\n            do {\n                \/\/ Write the RAW (DNG) file data to a URL.\n                try photoData.write(to: rawFileURL!)\n            } catch {\n                fatalError(\"Couldn't write DNG file to the URL.\")\n            }\n        } else {\n            \/\/ Store compressed bitmap data.\n            compressedData = photoData\n        }\n    }\n    \n    private func makeUniqueDNGFileURL() -> URL {\n        let tempDir = FileManager.default.temporaryDirectory\n        let fileName = ProcessInfo.processInfo.globallyUniqueString\n        return tempDir.appendingPathComponent(fileName).appendingPathExtension(\"dng\")\n    }\n}\n```\n\n### Customize the Apple ProRAW output\n\nBy default, when you ask for the file data representation of an Apple ProRAW photo, you get the data in full lossless quality. If you’re willing to accept some lossy compression to achieve smaller file sizes, you can customize the compression settings by calling [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation(with:)] and passing it a custom object that conforms to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoFileDataRepresentationCustomizer] protocol. The following code shows an example implementation of this protocol that applies minimal compression to the output image:\n\n```swift\nclass AppleProRAWCustomizer: NSObject, AVCapturePhotoFileDataRepresentationCustomizer {\n    \n    \/\/ Customize the compression settings.\n    func replacementAppleProRAWCompressionSettings(for photo: AVCapturePhoto, \n                                                   defaultSettings: [String : Any], \n                                                   maximumBitDepth: Int) -> [String : Any] {\n        \n        \/\/ Reduce the bit depth and quality of the final file.\n        return [AVVideoAppleProRAWBitDepthKey: maximumBitDepth - 2, \n                AVVideoQualityKey: 0.95]\n    }\n}\n```\n\nTo use this customizer when retrieving the file data representation of a ProRAW photo, create a new instance of your customizer and pass it to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation(with:)] method as the example below shows:\n\n```swift\n\/\/ Get a minimally compressed representation of the file data.\nlet customizer = AppleProRAWCustomizer()\nlet photoData = photo.fileDataRepresentation(with: customizer)\n```\n\n### Save the photos to the photos library\n\nThe photo output indicates when it finishes the capture request by calling the delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishCaptureFor:error:)] method. This callback provides an opportunity to save the captured photos to the user’s Photos library. For more information about configuring your app to access the user’s Photos library, see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/saving-captured-photos].\n\nTo save the captured photos to the user’s Photos library, create a single Photos asset that associates the RAW or Apple ProRAW data with the processed data. Create an instance of [doc:\/\/com.apple.documentation\/documentation\/Photos\/PHAssetCreationRequest], then specify the DNG version as the asset’s main [doc:\/\/com.apple.documentation\/documentation\/Photos\/PHAssetResourceType\/photo] resource, and the processed image as an [doc:\/\/com.apple.documentation\/documentation\/Photos\/PHAssetResourceType\/alternatePhoto] resource. Perform the request inside a change block as the example below shows:\n\n```swift\n\/\/ After both RAW and compressed versions are complete, add them to the Photos library.\nfunc photoOutput(_ output: AVCapturePhotoOutput,\n                 didFinishCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings,\n                 error: Error?) {\n    \n    \/\/ Call the \"finished\" closure, if you set it.\n    defer { didFinish?() }\n    \n    guard error == nil else {\n        print(\"Error capturing photo: \\(error!)\")\n        return\n    }\n    \n    \/\/ Ensure the RAW and processed photo data exists.\n    guard let rawFileURL = rawFileURL,\n          let compressedData = compressedData else {\n        print(\"The expected photo data isn't available.\")\n        return\n    }\n    \n    \/\/ Request add-only access to the user's Photos library (if the user hasn't already granted that access).\n    PHPhotoLibrary.requestAuthorization(for: .addOnly) { status in\n        \n        \/\/ Don't continue unless the user granted access.\n        guard status == .authorized else { return }\n        \n        PHPhotoLibrary.shared().performChanges {\n            \n            let creationRequest = PHAssetCreationRequest.forAsset()\n            \n            \/\/ Save the RAW (DNG) file as the main resource for the Photos asset.\n            let options = PHAssetResourceCreationOptions()\n            options.shouldMoveFile = true\n            creationRequest.addResource(with: .photo,\n                                        fileURL: rawFileURL,\n                                        options: options)\n            \n            \n            \/\/ Add the compressed (HEIF) data as an alternative resource.\n            creationRequest.addResource(with: .alternatePhoto,\n                                        data: compressedData,\n                                        options: nil)\n            \n        } completionHandler: { success, error in\n            \/\/ Process the Photos library error.\n        }\n    }\n}\n```\n\n## Photo capture\n\n- **Capturing consistent color images**: Add the power of a photography studio and lighting rig to your app with the new Constant Color API.\n- **Capturing still and Live Photos**: Configure and capture single or multiple still images, Live Photos, and other forms of photography.\n- **Supporting Continuity Camera in Your Mac App**: Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.\n- **AVCapturePhoto**: A container for image data from a photo capture output.\n- **AVCaptureDeferredPhotoProxy**: A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.\n- **AVCapturePhotoOutput**: A capture output for still image, Live Photos, and other photography workflows.\n- **AVCapturePhotoCaptureDelegate**: Methods for monitoring progress and receiving results from a photo capture output.\n- **AVCapturePhotoOutputReadinessCoordinator**: An object that monitors changes to a photo output’s capture readiness.\n- **AVCapturePhotoOutputReadinessCoordinatorDelegate**: A delegate protocol to receive updates about a photo output’s capture readiness.\n- **AVCaptureStillImageOutput**: A capture output for capturing still photos.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Add the power of a photography studio and lighting rig to your app with the new Constant Color API.",
          "name" : "Capturing consistent color images",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-consistent-color-images"
        },
        {
          "description" : "Configure and capture single or multiple still images, Live Photos, and other forms of photography.",
          "name" : "Capturing still and Live Photos",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-still-and-live-photos"
        },
        {
          "description" : "Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.",
          "name" : "Supporting Continuity Camera in Your Mac App",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppKit\/supporting-continuity-camera-in-your-mac-app"
        },
        {
          "description" : "A container for image data from a photo capture output.",
          "name" : "AVCapturePhoto",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhoto"
        },
        {
          "description" : "A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.",
          "name" : "AVCaptureDeferredPhotoProxy",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureDeferredPhotoProxy"
        },
        {
          "description" : "A capture output for still image, Live Photos, and other photography workflows.",
          "name" : "AVCapturePhotoOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoOutput"
        },
        {
          "description" : "Methods for monitoring progress and receiving results from a photo capture output.",
          "name" : "AVCapturePhotoCaptureDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate"
        },
        {
          "description" : "An object that monitors changes to a photo output’s capture readiness.",
          "name" : "AVCapturePhotoOutputReadinessCoordinator",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoOutputReadinessCoordinator"
        },
        {
          "description" : "A delegate protocol to receive updates about a photo output’s capture readiness.",
          "name" : "AVCapturePhotoOutputReadinessCoordinatorDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoOutputReadinessCoordinatorDelegate"
        },
        {
          "description" : "A capture output for capturing still photos.",
          "name" : "AVCaptureStillImageOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureStillImageOutput"
        }
      ],
      "title" : "Photo capture"
    }
  ],
  "source" : "appleJSON",
  "title" : "Capturing photos in RAW and Apple ProRAW formats",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-in-raw-and-apple-proraw-formats"
}