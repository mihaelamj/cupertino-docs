{
  "abstract" : "A container for per-pixel distance or disparity information captured by compatible camera devices.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "3829ae0648e180f4b9bd84481f6795ef610d7425f1ca9acf0c76812d926bf44d",
  "crawledAt" : "2025-12-04T21:51:59Z",
  "declaration" : {
    "code" : "class AVDepthData",
    "language" : "swift"
  },
  "id" : "A9368224-F7B8-4EB3-8823-417244C10BA2",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\n*Depth data* is a generic term for a map of per-pixel data containing depth-related information. A depth data object wraps a disparity or depth map and provides conversion methods, focus information, and camera calibration data to aid in using the map for rendering or computer vision tasks.\n\nA depth map describes at each pixel the distance to an object, in meters.\n\nA disparity map describes normalized shift values for use in comparing two images. The value for each pixel in the map is in units of 1\/meters: (`pixelShift \/ (pixelFocalLength * baselineInMeters)`).\n\nThe capture pipeline generates disparity or depth maps from camera images containing nonrectilinear data. Camera lenses have small imperfections that cause small distortions in their resultant images compared to an ideal pinhole camera model, so [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] maps contain nonrectilinear (nondistortion-corrected) data as well. The maps’ values are warped to match the lens distortion characteristics present in the YUV image pixel buffers captured at the same time.\n\nBecause a depth data map is nonrectilinear, you can use an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] map as a proxy for depth when rendering effects to its accompanying image, but not to correlate points in 3D space. To use depth data for computer vision tasks, use the data in the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData\/cameraCalibrationData] property to rectify the depth data.\n\nThere are two ways to capture depth data:\n\nYou can also create [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] objects using information obtained from image files with the [doc:\/\/com.apple.documentation\/documentation\/ImageIO] framework.\n\nWhen editing images containing depth information, use the methods listed in Transforming and Processing to generate derivative [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] objects reflecting the edits that have been performed.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/avfoundation\/avdepthdata\ncrawled: 2025-12-04T21:51:59Z\n---\n\n# AVDepthData\n\n**Class**\n\nA container for per-pixel distance or disparity information captured by compatible camera devices.\n\n## Declaration\n\n```swift\nclass AVDepthData\n```\n\n## Overview\n\n*Depth data* is a generic term for a map of per-pixel data containing depth-related information. A depth data object wraps a disparity or depth map and provides conversion methods, focus information, and camera calibration data to aid in using the map for rendering or computer vision tasks.\n\nA depth map describes at each pixel the distance to an object, in meters.\n\nA disparity map describes normalized shift values for use in comparing two images. The value for each pixel in the map is in units of 1\/meters: (`pixelShift \/ (pixelFocalLength * baselineInMeters)`).\n\nThe capture pipeline generates disparity or depth maps from camera images containing nonrectilinear data. Camera lenses have small imperfections that cause small distortions in their resultant images compared to an ideal pinhole camera model, so [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] maps contain nonrectilinear (nondistortion-corrected) data as well. The maps’ values are warped to match the lens distortion characteristics present in the YUV image pixel buffers captured at the same time.\n\nBecause a depth data map is nonrectilinear, you can use an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] map as a proxy for depth when rendering effects to its accompanying image, but not to correlate points in 3D space. To use depth data for computer vision tasks, use the data in the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData\/cameraCalibrationData] property to rectify the depth data.\n\nThere are two ways to capture depth data:\n\n- The [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDepthDataOutput] class captures and delivers depth data in a stream (similar to how the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureVideoDataOutput] delivers video data).\n- The [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput] class delivers depth data as a property of an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto] object containing the captured image.\n\nYou can also create [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] objects using information obtained from image files with the [doc:\/\/com.apple.documentation\/documentation\/ImageIO] framework.\n\nWhen editing images containing depth information, use the methods listed in Transforming and Processing to generate derivative [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] objects reflecting the edits that have been performed.\n\n## Creating depth data\n\n- **init(fromDictionaryRepresentation:)**: Creates a depth data object from depth information such as that found in an image file.\n- **dictionaryRepresentation(forAuxiliaryDataType:)**: Returns a dictionary representation of the depth data suitable for writing into an image file.\n\n## Reading pixel depth information\n\n- **depthDataMap**: A pixel buffer containing the depth data’s per-pixel depth or disparity data map.\n- **depthDataType**: The pixel format of the depth data map.\n\n## Evaluating depth data\n\n- **isDepthDataFiltered**: A Boolean value indicating whether the depth map contains temporally smoothed data.\n- **depthDataAccuracy**: The general accuracy of depth data map values.\n- **AVDepthData.Accuracy**: Values indicating the general accuracy of a depth data map.\n- **depthDataQuality**: The overall quality of the depth map.\n- **AVDepthData.Quality**: Values indicating the overall quality of a depth data map.\n\n## Transforming and processing\n\n- **applyingExifOrientation(_:)**: Returns a derivative depth data object by mirroring or rotating it to the specified orientation.\n- **converting(toDepthDataType:)**: Returns a derivative depth data object by converting the depth data map to the specified data type.\n- **availableDepthDataTypes**: The list of depth data formats to which you can convert this depth data.\n- **replacingDepthDataMap(with:)**: Returns a derivative depth data object by replacing the depth data map.\n\n## Using calibration data\n\n- **cameraCalibrationData**: The imaging parameters with which this depth data was captured.\n\n## Depth data capture\n\n- **Capturing photos with depth**: Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).\n- **Creating auxiliary depth data manually**: Generate a depth image and attach it to your own image.\n- **Capturing depth using the LiDAR camera**: Access the LiDAR camera on supporting devices to capture precise depth data.\n- **AVCamFilter: Applying filters to a capture stream**: Render a capture stream with rose-colored filtering and depth effects.\n- **Streaming depth data from the TrueDepth camera**: Visualize depth data in 2D and 3D from the TrueDepth camera.\n- **Enhancing live video by leveraging TrueDepth camera data**: Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.\n- **AVCaptureDepthDataOutput**: A capture output that records scene depth information on compatible camera devices.\n- **AVCameraCalibrationData**: Information about the camera characteristics used to capture images and depth data.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a depth data object from depth information such as that found in an image file.",
          "name" : "init(fromDictionaryRepresentation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/init(fromDictionaryRepresentation:)"
        },
        {
          "description" : "Returns a dictionary representation of the depth data suitable for writing into an image file.",
          "name" : "dictionaryRepresentation(forAuxiliaryDataType:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/dictionaryRepresentation(forAuxiliaryDataType:)"
        }
      ],
      "title" : "Creating depth data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A pixel buffer containing the depth data’s per-pixel depth or disparity data map.",
          "name" : "depthDataMap",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/depthDataMap"
        },
        {
          "description" : "The pixel format of the depth data map.",
          "name" : "depthDataType",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/depthDataType"
        }
      ],
      "title" : "Reading pixel depth information"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value indicating whether the depth map contains temporally smoothed data.",
          "name" : "isDepthDataFiltered",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/isDepthDataFiltered"
        },
        {
          "description" : "The general accuracy of depth data map values.",
          "name" : "depthDataAccuracy",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/depthDataAccuracy"
        },
        {
          "description" : "Values indicating the general accuracy of a depth data map.",
          "name" : "AVDepthData.Accuracy",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/Accuracy"
        },
        {
          "description" : "The overall quality of the depth map.",
          "name" : "depthDataQuality",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/depthDataQuality"
        },
        {
          "description" : "Values indicating the overall quality of a depth data map.",
          "name" : "AVDepthData.Quality",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/Quality"
        }
      ],
      "title" : "Evaluating depth data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Returns a derivative depth data object by mirroring or rotating it to the specified orientation.",
          "name" : "applyingExifOrientation(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/applyingExifOrientation(_:)"
        },
        {
          "description" : "Returns a derivative depth data object by converting the depth data map to the specified data type.",
          "name" : "converting(toDepthDataType:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/converting(toDepthDataType:)"
        },
        {
          "description" : "The list of depth data formats to which you can convert this depth data.",
          "name" : "availableDepthDataTypes",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/availableDepthDataTypes-3ifx1"
        },
        {
          "description" : "Returns a derivative depth data object by replacing the depth data map.",
          "name" : "replacingDepthDataMap(with:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/replacingDepthDataMap(with:)"
        }
      ],
      "title" : "Transforming and processing"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The imaging parameters with which this depth data was captured.",
          "name" : "cameraCalibrationData",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData\/cameraCalibrationData"
        }
      ],
      "title" : "Using calibration data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).",
          "name" : "Capturing photos with depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-with-depth"
        },
        {
          "description" : "Generate a depth image and attach it to your own image.",
          "name" : "Creating auxiliary depth data manually",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/creating-auxiliary-depth-data-manually"
        },
        {
          "description" : "Access the LiDAR camera on supporting devices to capture precise depth data.",
          "name" : "Capturing depth using the LiDAR camera",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-depth-using-the-lidar-camera"
        },
        {
          "description" : "Render a capture stream with rose-colored filtering and depth effects.",
          "name" : "AVCamFilter: Applying filters to a capture stream",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/avcamfilter-applying-filters-to-a-capture-stream"
        },
        {
          "description" : "Visualize depth data in 2D and 3D from the TrueDepth camera.",
          "name" : "Streaming depth data from the TrueDepth camera",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/streaming-depth-data-from-the-truedepth-camera"
        },
        {
          "description" : "Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.",
          "name" : "Enhancing live video by leveraging TrueDepth camera data",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/enhancing-live-video-by-leveraging-truedepth-camera-data"
        },
        {
          "description" : "A capture output that records scene depth information on compatible camera devices.",
          "name" : "AVCaptureDepthDataOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureDepthDataOutput"
        },
        {
          "description" : "Information about the camera characteristics used to capture images and depth data.",
          "name" : "AVCameraCalibrationData",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData"
        }
      ],
      "title" : "Depth data capture"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVDepthData",
  "url" : "https:\/\/developer.apple.com\/documentation\/avfoundation\/avdepthdata"
}