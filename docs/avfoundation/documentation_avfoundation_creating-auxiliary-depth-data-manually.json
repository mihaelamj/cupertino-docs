{
  "abstract" : "Generate a depth image and attach it to your own image.",
  "codeExamples" : [
    {
      "code" : "\/\/ Add an image to the destination.\nCGImageDestinationAddImage(cgImageDestination, renderedCGImage, attachments)  \n\n\/\/ Use AVDepthData to get the auxiliary data dictionary.         \nvar auxDataType :NSString? \nlet auxData = depthData.dictionaryRepresentation(forAuxiliaryDataType: &auxDataType)  \n\n\/\/ Add auxiliary data to the image destination. \nCGImageDestinationAddAuxiliaryDataInfo(cgImageDestination, auxDataType!, auxData! as CFDictionary)  \n\nif CGImageDestinationFinalize(cgImageDestination) {  \n\treturn data as Data\n}  ",
      "language" : "swift"
    }
  ],
  "contentHash" : "dbe5c894e77823fc5ff2f7ee2b3f391ed414ebc57abfa6777b92a61962cebf76",
  "crawledAt" : "2025-12-02T16:09:49Z",
  "id" : "E06FBC29-D178-4301-9C30-22E2022A957E",
  "kind" : "article",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\niOS Portrait Mode generates a depth map and attaches it to the image as auxiliary metadata, but for custom effects, you can generate your own auxiliary depth image, one not taken with iOS Portrait Mode or another depth-enabled capture device. This article shows you how to generate this map and attach it to your image.\n\n### Convert pixel values into a compatible floating-point format\n\nThe depth image is a single-component image that must be converted per-pixel from grayscale pixel values (`0` = black to `1` = white, zNear to zFar) to either depth (in meters) or disparity (in 1\/meters). Then adjust these values to fit your desired floating-point format.\n\nThe supported pixel formats for disparity or depth images are:\n\nLoad the grayscale image into a [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e]. Load its base address, attained via [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferLockBaseAddress(_:_:)], as data ([doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFData]) and pass it as the [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImageAuxiliaryDataInfoData] value into a dictionary ([doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFDictionary]).\n\n### Parse metadata dictionaries\n\nThe format of the dictionary is documented in `CGImageSource.h`. Access this dictionary with [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/CGImageSourceCopyAuxiliaryDataInfoAtIndex(_:_:_:)]. The dictionary supports JPEG, HEIF, and DNG images. The [doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFDictionary] contains auxiliary data in the following format:\n\n[doc:\/\/com.apple.documentation\/documentation\/ImageIO\/CGImageSourceCopyAuxiliaryDataInfoAtIndex(_:_:_:)] returns `nil` if the image doesn’t contain `auxiliaryImageDataType` data.\n\nThe value for key [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImageAuxiliaryDataInfoDataDescription] is a [doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFDictionary] that you populate to tell the image system how to interpret the depth map. It can contain the following depth data parameters:\n\n### Attach your custom depth map to an image\n\nAttach the depth or disparity dictionary to an image as follows:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/creating-auxiliary-depth-data-manually\ncrawled: 2025-12-02T16:09:49Z\n---\n\n# Creating auxiliary depth data manually\n\n**Article**\n\nGenerate a depth image and attach it to your own image.\n\n## Overview\n\niOS Portrait Mode generates a depth map and attaches it to the image as auxiliary metadata, but for custom effects, you can generate your own auxiliary depth image, one not taken with iOS Portrait Mode or another depth-enabled capture device. This article shows you how to generate this map and attach it to your image.\n\n### Convert pixel values into a compatible floating-point format\n\nThe depth image is a single-component image that must be converted per-pixel from grayscale pixel values (`0` = black to `1` = white, zNear to zFar) to either depth (in meters) or disparity (in 1\/meters). Then adjust these values to fit your desired floating-point format.\n\nThe supported pixel formats for disparity or depth images are:\n\n- `kCVPixelFormatType_DisparityFloat16 = 'hdis'`: An IEEE754-2008 binary16 (half float), describing the normalized shift when comparing two images. Units are 1\/meters: (pixelShift \/ (pixelFocalLength * baselineInMeters))\n- `kCVPixelFormatType_DisparityFloat32 = 'fdis'`: An IEEE754-2008 binary32 float, describing the normalized shift when comparing two images. Units are 1\/meters: (pixelShift \/ (pixelFocalLength * baselineInMeters))\n- `kCVPixelFormatType_DepthFloat16 = 'hdep'`: An IEEE754-2008 binary16 (half float), describing the depth (distance to an object) in meters\n- `kCVPixelFormatType_DepthFloat32 = 'fdep'`: An IEEE754-2008 binary32 float, describing the depth (distance to an object) in meters\n\nLoad the grayscale image into a [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/cvpixelbuffer-q2e]. Load its base address, attained via [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/CVPixelBufferLockBaseAddress(_:_:)], as data ([doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFData]) and pass it as the [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImageAuxiliaryDataInfoData] value into a dictionary ([doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFDictionary]).\n\n### Parse metadata dictionaries\n\nThe format of the dictionary is documented in `CGImageSource.h`. Access this dictionary with [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/CGImageSourceCopyAuxiliaryDataInfoAtIndex(_:_:_:)]. The dictionary supports JPEG, HEIF, and DNG images. The [doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFDictionary] contains auxiliary data in the following format:\n\n- [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImageAuxiliaryDataInfoData] → Depth data ([doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFData])\n- [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImageAuxiliaryDataInfoDataDescription] → Depth data description ([doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFDictionary]: See below for more details.)\n- [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImageAuxiliaryDataInfoMetadata] → Optional metadata ([doc:\/\/com.apple.documentation\/documentation\/ImageIO\/CGImageMetadata])\n\n[doc:\/\/com.apple.documentation\/documentation\/ImageIO\/CGImageSourceCopyAuxiliaryDataInfoAtIndex(_:_:_:)] returns `nil` if the image doesn’t contain `auxiliaryImageDataType` data.\n\nThe value for key [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImageAuxiliaryDataInfoDataDescription] is a [doc:\/\/com.apple.documentation\/documentation\/CoreFoundation\/CFDictionary] that you populate to tell the image system how to interpret the depth map. It can contain the following depth data parameters:\n\n- [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImagePropertyPixelFormat] → One of the Core Video `CVPixelBuffer.h` depth or disparity formats\n- [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImagePropertyWidth] and [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImagePropertyHeight] → Pixel dimensions\n- [doc:\/\/com.apple.documentation\/documentation\/ImageIO\/kCGImagePropertyBytesPerRow] → The number of bytes per row in the depth map\n\n### Attach your custom depth map to an image\n\nAttach the depth or disparity dictionary to an image as follows:\n\n1. Create [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData] with [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVDepthData\/init(fromDictionaryRepresentation:)], passing in the depth or disparity dictionary.\n2. Create the image destination.\n3. Create the image, using helper methods from [doc:\/\/com.apple.documentation\/documentation\/ImageIO].\n\n```swift\n\/\/ Add an image to the destination.\nCGImageDestinationAddImage(cgImageDestination, renderedCGImage, attachments)  \n\n\/\/ Use AVDepthData to get the auxiliary data dictionary.         \nvar auxDataType :NSString? \nlet auxData = depthData.dictionaryRepresentation(forAuxiliaryDataType: &auxDataType)  \n\n\/\/ Add auxiliary data to the image destination. \nCGImageDestinationAddAuxiliaryDataInfo(cgImageDestination, auxDataType!, auxData! as CFDictionary)  \n\nif CGImageDestinationFinalize(cgImageDestination) {  \n\treturn data as Data\n}  \n```\n\n## Depth data capture\n\n- **Capturing photos with depth**: Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).\n- **Capturing depth using the LiDAR camera**: Access the LiDAR camera on supporting devices to capture precise depth data.\n- **AVCamFilter: Applying filters to a capture stream**: Render a capture stream with rose-colored filtering and depth effects.\n- **Streaming depth data from the TrueDepth camera**: Visualize depth data in 2D and 3D from the TrueDepth camera.\n- **Enhancing live video by leveraging TrueDepth camera data**: Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.\n- **AVCaptureDepthDataOutput**: A capture output that records scene depth information on compatible camera devices.\n- **AVDepthData**: A container for per-pixel distance or disparity information captured by compatible camera devices.\n- **AVCameraCalibrationData**: Information about the camera characteristics used to capture images and depth data.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).",
          "name" : "Capturing photos with depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-with-depth"
        },
        {
          "description" : "Access the LiDAR camera on supporting devices to capture precise depth data.",
          "name" : "Capturing depth using the LiDAR camera",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-depth-using-the-lidar-camera"
        },
        {
          "description" : "Render a capture stream with rose-colored filtering and depth effects.",
          "name" : "AVCamFilter: Applying filters to a capture stream",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/avcamfilter-applying-filters-to-a-capture-stream"
        },
        {
          "description" : "Visualize depth data in 2D and 3D from the TrueDepth camera.",
          "name" : "Streaming depth data from the TrueDepth camera",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/streaming-depth-data-from-the-truedepth-camera"
        },
        {
          "description" : "Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.",
          "name" : "Enhancing live video by leveraging TrueDepth camera data",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/enhancing-live-video-by-leveraging-truedepth-camera-data"
        },
        {
          "description" : "A capture output that records scene depth information on compatible camera devices.",
          "name" : "AVCaptureDepthDataOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureDepthDataOutput"
        },
        {
          "description" : "A container for per-pixel distance or disparity information captured by compatible camera devices.",
          "name" : "AVDepthData",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVDepthData"
        },
        {
          "description" : "Information about the camera characteristics used to capture images and depth data.",
          "name" : "AVCameraCalibrationData",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCameraCalibrationData"
        }
      ],
      "title" : "Depth data capture"
    }
  ],
  "source" : "appleJSON",
  "title" : "Creating auxiliary depth data manually",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/creating-auxiliary-depth-data-manually"
}