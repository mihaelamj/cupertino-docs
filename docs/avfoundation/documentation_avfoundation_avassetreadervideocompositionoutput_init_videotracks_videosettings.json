{
  "abstract" : "Creates an object that reads composited video frames from the specified video tracks.",
  "codeExamples" : [

  ],
  "contentHash" : "6b7e8b3769ec916b3c6306cb024f3ec8185abc2022fee6db86bda63f1c6211e0",
  "crawledAt" : "2025-11-30T23:13:26Z",
  "declaration" : {
    "code" : "init(videoTracks: [AVAssetTrack], videoSettings: [String : Any]?)",
    "language" : "swift"
  },
  "id" : "F3C0BAAD-0FB6-4CFB-8968-04264539C10C",
  "kind" : "unknown",
  "module" : "AVFoundation",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderVideoCompositionOutput\/init(videoTracks:videoSettings:)\ncrawled: 2025-11-30T23:13:26Z\n---\n\n# init(videoTracks:videoSettings:)\n\n**Initializer**\n\nCreates an object that reads composited video frames from the specified video tracks.\n\n## Declaration\n\n```swift\ninit(videoTracks: [AVAssetTrack], videoSettings: [String : Any]?)\n```\n\n## Parameters\n\n- **videoTracks**: An array of asset tracks from which to read video frames for compositing. The media type of each track must be [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMediaType\/video].\n- **videoSettings**: Specifying a `nil` value configures the output to return samples in an uncompressed format.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "init(videoTracks:videoSettings:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderVideoCompositionOutput\/init(videoTracks:videoSettings:)"
}