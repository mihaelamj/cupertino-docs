{
  "abstract" : "The width and height, in pixels, of the frame being processed.",
  "codeExamples" : [

  ],
  "contentHash" : "fbc12ee14b9e8b876b5d065fb0209ff13918b2b58b4691ba8bc6ca49165e37cc",
  "crawledAt" : "2025-12-01T16:50:20Z",
  "declaration" : {
    "code" : "var renderSize: CGSize { get }",
    "language" : "swift"
  },
  "id" : "210CD378-C16F-432E-BDE9-21E4C866006E",
  "kind" : "property",
  "module" : "AVFoundation",
  "overview" : "## Discussion\n\nYou can use this property if you need to work with Core Image filters that apply transforms to the image.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/renderSize\ncrawled: 2025-12-01T16:50:20Z\n---\n\n# renderSize\n\n**Instance Property**\n\nThe width and height, in pixels, of the frame being processed.\n\n## Declaration\n\n```swift\nvar renderSize: CGSize { get }\n```\n\n## Discussion\n\nYou can use this property if you need to work with Core Image filters that apply transforms to the image.\n\n## Getting contextual information for filtering\n\n- **compositionTime**: The time in the video composition corresponding to the frame being processed.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The time in the video composition corresponding to the frame being processed.",
          "name" : "compositionTime",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/compositionTime"
        }
      ],
      "title" : "Getting contextual information for filtering"
    }
  ],
  "source" : "appleJSON",
  "title" : "renderSize",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/renderSize"
}