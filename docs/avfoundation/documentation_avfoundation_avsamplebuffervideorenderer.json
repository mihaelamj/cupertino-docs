{
  "abstract" : "An object that enqueues video sample buffers for rendering.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "AVQueuedSampleBufferRendering",
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "d00b8ef4668f0e3723fecc227f2a5ced5d85268cb7232257bc201e61389e53e7",
  "crawledAt" : "2025-12-07T14:57:43Z",
  "declaration" : {
    "code" : "class AVSampleBufferVideoRenderer",
    "language" : "swift"
  },
  "id" : "C5B15B7F-A92F-4FD2-9D07-1C8D7C632246",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/avfoundation\/avsamplebuffervideorenderer\ncrawled: 2025-12-07T14:57:43Z\n---\n\n# AVSampleBufferVideoRenderer\n\n**Class**\n\nAn object that enqueues video sample buffers for rendering.\n\n## Declaration\n\n```swift\nclass AVSampleBufferVideoRenderer\n```\n\n## Flushing the renderer\n\n- **requiresFlushToResumeDecoding**: A Boolean value that Indicates whether the renderer requires flushing to continue decoding frames.\n- **requiresFlushToResumeDecodingDidChangeNotification**: A notification that indicates that the video renderer requires flushing to continue rendering sample buffers.\n- **flush(removingDisplayedImage:completionHandler:)**: Tells the video renderer to discard pending enqueued sample buffers.\n\n## Setting presentation time expectations\n\n- **presentationTimeExpectation**\n- **AVSampleBufferVideoRenderer.PresentationTimeExpectation**: Options that specify the expected presentation time stamps of enqueue samples.\n\n## Inspecting the status\n\n- **status**: A status value that indicates whether this object can enqueue and render sample buffers.\n- **error**: An object the describes the error that caused the rendering failure.\n\n## Accessing the pixel buffer\n\n- **displayedPixelBuffer()**\n- **recommendedPixelBufferAttributes**: Recommended pixel buffer attributes for optimal performance when using CMSampleBuffers containing CVPixelbuffers.\n\n## Handling decode failures\n\n- **didFailToDecodeNotification**: A notification that indicates the video renderer fails to decode a sample buffer.\n- **didFailToDecodeNotificationErrorKey**: A key to retrieve an error object that provides the details of the failure.\n\n## Capturing performance metrics\n\n- **loadVideoPerformanceMetrics(completionHandler:)**\n\n## Presentation\n\n- **AVQueuedSampleBufferRendering**: Methods you can implement to enqueue sample buffers for presentation.\n- **AVSampleBufferRenderSynchronizer**: An object used to synchronize multiple queued sample buffers to a single timeline.\n- **AVSampleBufferDisplayLayer**: An object that displays compressed or uncompressed video frames.\n- **AVSampleBufferAudioRenderer**: An object used to decompress audio and play compressed or uncompressed audio.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- AVQueuedSampleBufferRendering\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that Indicates whether the renderer requires flushing to continue decoding frames.",
          "name" : "requiresFlushToResumeDecoding",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/requiresFlushToResumeDecoding"
        },
        {
          "description" : "A notification that indicates that the video renderer requires flushing to continue rendering sample buffers.",
          "name" : "requiresFlushToResumeDecodingDidChangeNotification",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/requiresFlushToResumeDecodingDidChangeNotification"
        },
        {
          "description" : "Tells the video renderer to discard pending enqueued sample buffers.",
          "name" : "flush(removingDisplayedImage:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/flush(removingDisplayedImage:completionHandler:)"
        }
      ],
      "title" : "Flushing the renderer"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "presentationTimeExpectation",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/presentationTimeExpectation-swift.property"
        },
        {
          "description" : "Options that specify the expected presentation time stamps of enqueue samples.",
          "name" : "AVSampleBufferVideoRenderer.PresentationTimeExpectation",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/PresentationTimeExpectation-swift.enum"
        }
      ],
      "title" : "Setting presentation time expectations"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A status value that indicates whether this object can enqueue and render sample buffers.",
          "name" : "status",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/status"
        },
        {
          "description" : "An object the describes the error that caused the rendering failure.",
          "name" : "error",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/error"
        }
      ],
      "title" : "Inspecting the status"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "displayedPixelBuffer()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/displayedPixelBuffer()"
        },
        {
          "description" : "Recommended pixel buffer attributes for optimal performance when using CMSampleBuffers containing CVPixelbuffers.",
          "name" : "recommendedPixelBufferAttributes",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/recommendedPixelBufferAttributes-6zrqb"
        }
      ],
      "title" : "Accessing the pixel buffer"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A notification that indicates the video renderer fails to decode a sample buffer.",
          "name" : "didFailToDecodeNotification",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/didFailToDecodeNotification"
        },
        {
          "description" : "A key to retrieve an error object that provides the details of the failure.",
          "name" : "didFailToDecodeNotificationErrorKey",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/didFailToDecodeNotificationErrorKey"
        }
      ],
      "title" : "Handling decode failures"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "loadVideoPerformanceMetrics(completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer\/loadVideoPerformanceMetrics(completionHandler:)"
        }
      ],
      "title" : "Capturing performance metrics"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Methods you can implement to enqueue sample buffers for presentation.",
          "name" : "AVQueuedSampleBufferRendering",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering"
        },
        {
          "description" : "An object used to synchronize multiple queued sample buffers to a single timeline.",
          "name" : "AVSampleBufferRenderSynchronizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer"
        },
        {
          "description" : "An object that displays compressed or uncompressed video frames.",
          "name" : "AVSampleBufferDisplayLayer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferDisplayLayer"
        },
        {
          "description" : "An object used to decompress audio and play compressed or uncompressed audio.",
          "name" : "AVSampleBufferAudioRenderer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer"
        }
      ],
      "title" : "Presentation"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVSampleBufferVideoRenderer",
  "url" : "https:\/\/developer.apple.com\/documentation\/avfoundation\/avsamplebuffervideorenderer"
}