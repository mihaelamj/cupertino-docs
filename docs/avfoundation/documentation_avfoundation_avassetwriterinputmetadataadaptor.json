{
  "abstract" : "An object that appends timed metadata groups to an asset writer input.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "be808b2657e29e32a7c4c5d035e83923a0338a5bcf1061df1dd7db1c8b85f1fd",
  "crawledAt" : "2025-12-02T16:04:29Z",
  "declaration" : {
    "code" : "class AVAssetWriterInputMetadataAdaptor",
    "language" : "swift"
  },
  "id" : "9BBA623E-2C78-465B-8F30-12B33D953EF4",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nUse a metadata adaptor to append track-level metadata, packaged as instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVTimedMetadataGroup], to an asset writer input.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor\ncrawled: 2025-12-02T16:04:29Z\n---\n\n# AVAssetWriterInputMetadataAdaptor\n\n**Class**\n\nAn object that appends timed metadata groups to an asset writer input.\n\n## Declaration\n\n```swift\nclass AVAssetWriterInputMetadataAdaptor\n```\n\n## Overview\n\nUse a metadata adaptor to append track-level metadata, packaged as instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVTimedMetadataGroup], to an asset writer input.\n\n## Creating an input metadata adaptor\n\n- **init(assetWriterInput:)**: Creates a metadata group adaptor to append timed metadata groups to write to an output file.\n\n## Appending timed metadata\n\n- **append(_:)**: Appends a timed metadata group to the adaptor.\n\n## Accessing the input\n\n- **assetWriterInput**: The input for the metadata adaptor.\n\n## Media writing\n\n- **Converting projected video to Apple Projected Media Profile**: Convert content with equirectangular or half-equirectangular projection to APMP.\n- **Converting side-by-side 3D video to multiview HEVC and spatial video**: Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.\n- **Writing fragmented MPEG-4 files for HTTP Live Streaming**: Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.\n- **Creating spatial photos and videos with spatial metadata**: Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.\n- **Tagging media with video color information**: Inspect and set video color space information when writing and transcoding media.\n- **Evaluating an app’s video color**: Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.\n- **AVOutputSettingsAssistant**: An object that builds audio and video output settings dictionaries.\n- **AVAssetWriter**: An object that writes media data to a container file.\n- **AVAssetWriterInput**: An object that appends media samples to a track in an asset writer’s output file.\n- **AVAssetWriterInputPixelBufferAdaptor**: An object that appends video samples to an asset writer input.\n- **AVAssetWriterInputTaggedPixelBufferGroupAdaptor**: An object that appends tagged buffer groups to an asset writer input.\n- **AVAssetWriterInputGroup**: A group of inputs with tracks that are mutually exclusive to each other for playback or processing.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a metadata group adaptor to append timed metadata groups to write to an output file.",
          "name" : "init(assetWriterInput:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor\/init(assetWriterInput:)"
        }
      ],
      "title" : "Creating an input metadata adaptor"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Appends a timed metadata group to the adaptor.",
          "name" : "append(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor\/append(_:)"
        }
      ],
      "title" : "Appending timed metadata"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The input for the metadata adaptor.",
          "name" : "assetWriterInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor\/assetWriterInput"
        }
      ],
      "title" : "Accessing the input"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert content with equirectangular or half-equirectangular projection to APMP.",
          "name" : "Converting projected video to Apple Projected Media Profile",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-projected-video-to-apple-projected-media-profile"
        },
        {
          "description" : "Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.",
          "name" : "Converting side-by-side 3D video to multiview HEVC and spatial video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video"
        },
        {
          "description" : "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.",
          "name" : "Writing fragmented MPEG-4 files for HTTP Live Streaming",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/writing-fragmented-mpeg-4-files-for-http-live-streaming"
        },
        {
          "description" : "Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.",
          "name" : "Creating spatial photos and videos with spatial metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/ImageIO\/Creating-spatial-photos-and-videos-with-spatial-metadata"
        },
        {
          "description" : "Inspect and set video color space information when writing and transcoding media.",
          "name" : "Tagging media with video color information",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information"
        },
        {
          "description" : "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.",
          "name" : "Evaluating an app’s video color",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color"
        },
        {
          "description" : "An object that builds audio and video output settings dictionaries.",
          "name" : "AVOutputSettingsAssistant",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant"
        },
        {
          "description" : "An object that writes media data to a container file.",
          "name" : "AVAssetWriter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriter"
        },
        {
          "description" : "An object that appends media samples to a track in an asset writer’s output file.",
          "name" : "AVAssetWriterInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput"
        },
        {
          "description" : "An object that appends video samples to an asset writer input.",
          "name" : "AVAssetWriterInputPixelBufferAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPixelBufferAdaptor"
        },
        {
          "description" : "An object that appends tagged buffer groups to an asset writer input.",
          "name" : "AVAssetWriterInputTaggedPixelBufferGroupAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputTaggedPixelBufferGroupAdaptor"
        },
        {
          "description" : "A group of inputs with tracks that are mutually exclusive to each other for playback or processing.",
          "name" : "AVAssetWriterInputGroup",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup"
        }
      ],
      "title" : "Media writing"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAssetWriterInputMetadataAdaptor",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor"
}