{
  "abstract" : "Enable high-quality photo and video capture by using an iPhone camera as an external capture device.",
  "codeExamples" : [
    {
      "code" : "\/\/ Observe device cameras. Specify `.externalUnknown` to access an iPhone camera as an `AVCaptureDevice`.\nvideoDiscoverySession = AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInWideAngleCamera, .externalUnknown],\n                                                         mediaType: .video,\n                                                         position: .unspecified)\n\/\/ Observe device microphones. Specify `.externalUnknown` to access an iPhone microphone as an `AVCaptureDevice`.\naudioDiscoverySession = AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInMicrophone, .externalUnknown],\n                                                         mediaType: .audio,\n                                                         position: .unspecified)",
      "language" : "swift"
    },
    {
      "code" : "private var defaultVideoCaptureDevice: AVCaptureDevice {\n    get throws {\n        \/\/ Access the system's preferred camera.\n        if let device = AVCaptureDevice.systemPreferredCamera {\n            return device\n        } else {\n            \/\/ No camera is available on the host system.\n            throw Error.noVideoDeviceAvailable\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "class PreferredCameraObserver: NSObject, ObservableObject {\n    \n    private let systemPreferredKeyPath = \"systemPreferredCamera\"\n    \n    @Published private(set) var systemPreferredCamera: AVCaptureDevice?\n    \n    override init() {\n        super.init()\n        \/\/ Key-value observe the `systemPreferredCamera` class property on `AVCaptureDevice`.\n        AVCaptureDevice.self.addObserver(self, forKeyPath: systemPreferredKeyPath, options: [.new], context: nil)\n    }\n    \n    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey: Any]?, context: UnsafeMutableRawPointer?) {\n        switch keyPath {\n        case systemPreferredKeyPath:\n            \/\/ Update the observer's system-preferred camera value.\n            systemPreferredCamera = change?[.newKey] as? AVCaptureDevice\n        default:\n            super.observeValue(forKeyPath: keyPath, of: object, change: change, context: context)\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ The app calls this method when the system-preferred camera changes.\nprivate func systemPreferredCameraChanged(to captureDevice: AVCaptureDevice) async {\n    \n    \/\/ If the SPC changes due to a device disconnection, reset the app\n    \/\/ to its default device selections.\n    guard isActiveVideoInputDeviceConnected else {\n        resetToDefaultDevices()\n        return\n    }\n    \n    \/\/ If the \"Automatic Camera Selection\" checkbox is in an enabled state,\n    \/\/ automatically select the new capture device.\n    if isAutomaticCameraSelectionEnabled {\n        await selectCaptureDevice(captureDevice)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Remove the current input from the session.\nsession.removeInput(currentInput)\n\n\/\/ Attempt to add the new device to the capture session.\nlet newInput = try addInput(for: device)\n\n\/\/ Camera\nif mediaType == .video {\n    activeVideoInput = newInput\n    if isUserSelection {\n        \/\/ If the device change is due to user selection, set the UPC value,\n        \/\/ which updates the state of the system-preferred camera.\n        AVCaptureDevice.userPreferredCamera = device\n    }\n}\n\/\/ Microphone\nelse {\n    activeAudioInput = newInput\n}",
      "language" : "swift"
    },
    {
      "code" : "@Published var isCenterStageEnabled = false {\n    didSet {\n        guard isCenterStageEnabled != AVCaptureDevice.isCenterStageEnabled else { return }\n        AVCaptureDevice.centerStageControlMode = .cooperative\n        AVCaptureDevice.isCenterStageEnabled = isCenterStageEnabled\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "AVCaptureDevice.self.addObserver(self, forKeyPath: centerStageKeyPath, options: [.new], context: nil)\nAVCaptureDevice.self.addObserver(self, forKeyPath: portraitEffectKeyPath, options: [.new], context: nil)\nAVCaptureDevice.self.addObserver(self, forKeyPath: studioLightKeyPath, options: [.new], context: nil)",
      "language" : "swift"
    }
  ],
  "contentHash" : "ca3f7e644d1009316821f4e38321025a65743cb0baf23da39ff2fa8698d8023b",
  "crawledAt" : "2025-12-02T15:48:17Z",
  "id" : "D9AF2925-966A-4237-BC27-A3620CD348BB",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nContinuity Camera brings the power of an iPhone device’s camera and image signal processing to the Mac. It lets you use the rear-facing, wide-angle camera of iPhone to support high-quality photo and video capture in your macOS app. Continuity Camera also brings advanced features like Center Stage, Portrait mode, and Studio Light to all Mac devices. An important part of adopting this feature in your app is supporting automatic camera selection.\n\nStarting in macOS 13, the operating system remembers the camera that it prefers to use for capture. It bases its preference on factors including capture quality, device positioning, and user preference. Apps observe the state of the system-preferred camera, and automatically update their camera selection as the value changes.\n\nThe sample app shows you how to access the iPhone camera and microphone, adopt automatic camera selection, and control and observe the state of system video effects.\n\n### Configure the sample code project\n\nTo run this sample app, you’ll need the following:\n\nConnect the iPhone to the Mac over USB. The first time you run this sample, the system prompts you to grant the app access to the camera and microphone. You must allow the sample app to access both devices for it to function correctly.\n\n### Configure device discovery\n\nWhen the app performs its initial setup, it configures two instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/DiscoverySession]: one to discover video devices, and the other to discover audio devices. It initializes each discovery session with a list of devices that includes a built-in device, and also an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/DeviceType-swift.struct\/externalUnknown] device. Specifying an external unknown device type enables the discovery session to find compatible iPhone cameras and microphones, as well as supported capture devices from other vendors.\n\nThe app observes the state of each discovery session’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/DiscoverySession\/devices] array, and as devices connect and disconnect from the system, it updates the list of devices it presents in the user interface.\n\n### Set the initial video device selection\n\nThe sample app enables automatic camera selection by default, so when it performs its initial capture session configuration, it uses the system’s preferred camera as its default camera device as shown below.\n\nThe [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/systemPreferredCamera] property of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice] provides an optional capture device value. However, it always provides a valid capture device unless the host system provides no built-in or connected devices.\n\n### Respond to system-preferred camera changes\n\nThe system-preferred camera changes based on device availability and user camera selection. The sample app provides a `PreferredCameraObserver` object that key-value observes the `systemPreferredCamera` property to monitor changes. When it observes a change to the value, it updates the state of its `@Published` property value as shown below.\n\nIf the app has automatic camera selection enabled, when it observes a change to the system-preferred camera, it automatically switches to the new device.\n\n### Update the user-preferred camera selection\n\nWhen the app selects a new device, it removes the old device input, attempts to add an input for the new device, and if it succeeds, updates the state of the appropriate active input device as shown below.\n\nIn the case of a camera device, if the selection request came from user input, the app also updates the state of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/userPreferredCamera], which persists the user’s preferred camera selection across app and device restarts.\n\n### Support system video effects\n\nWhen the app’s selected camera changes, the system evaluates the new capture device’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/activeFormat] to determine if it supports Center Stage. If it does, the app enables the Center Stage checkbox so you can change its value. Toggling the state of the feature sets the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/centerStageControlMode-swift.type.property] to [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/CenterStageControlMode-swift.enum\/cooperative] and updates its enabled state.\n\nYou can also enable Center Stage, along with video effects like Portrait mode and Studio Light, in Control Center. Because the enabled state of each effect can change externally, the app also key-value observes the state of these effects. Similar to how the app observes changes to the system-preferred camera, the app key-value observes the state of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/isCenterStageEnabled], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/isPortraitEffectEnabled], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/isStudioLightEnabled] properties and updates the user interface state as the values change.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/supporting-continuity-camera-in-your-macos-app\ncrawled: 2025-12-02T15:48:17Z\n---\n\n# Supporting Continuity Camera in your macOS app\n\n**Sample Code**\n\nEnable high-quality photo and video capture by using an iPhone camera as an external capture device.\n\n## Overview\n\nContinuity Camera brings the power of an iPhone device’s camera and image signal processing to the Mac. It lets you use the rear-facing, wide-angle camera of iPhone to support high-quality photo and video capture in your macOS app. Continuity Camera also brings advanced features like Center Stage, Portrait mode, and Studio Light to all Mac devices. An important part of adopting this feature in your app is supporting automatic camera selection.\n\nStarting in macOS 13, the operating system remembers the camera that it prefers to use for capture. It bases its preference on factors including capture quality, device positioning, and user preference. Apps observe the state of the system-preferred camera, and automatically update their camera selection as the value changes.\n\nThe sample app shows you how to access the iPhone camera and microphone, adopt automatic camera selection, and control and observe the state of system video effects.\n\n\n\n### Configure the sample code project\n\nTo run this sample app, you’ll need the following:\n\n- A Mac with macOS 13 beta or later.\n- An iPhone with iOS 16 beta or later.\n- Xcode 14 beta or later.\n- Both devices must be signed into an Apple ID account that uses two-factor authentication.\n\nConnect the iPhone to the Mac over USB. The first time you run this sample, the system prompts you to grant the app access to the camera and microphone. You must allow the sample app to access both devices for it to function correctly.\n\n### Configure device discovery\n\nWhen the app performs its initial setup, it configures two instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/DiscoverySession]: one to discover video devices, and the other to discover audio devices. It initializes each discovery session with a list of devices that includes a built-in device, and also an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/DeviceType-swift.struct\/externalUnknown] device. Specifying an external unknown device type enables the discovery session to find compatible iPhone cameras and microphones, as well as supported capture devices from other vendors.\n\n```swift\n\/\/ Observe device cameras. Specify `.externalUnknown` to access an iPhone camera as an `AVCaptureDevice`.\nvideoDiscoverySession = AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInWideAngleCamera, .externalUnknown],\n                                                         mediaType: .video,\n                                                         position: .unspecified)\n\/\/ Observe device microphones. Specify `.externalUnknown` to access an iPhone microphone as an `AVCaptureDevice`.\naudioDiscoverySession = AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInMicrophone, .externalUnknown],\n                                                         mediaType: .audio,\n                                                         position: .unspecified)\n```\n\nThe app observes the state of each discovery session’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/DiscoverySession\/devices] array, and as devices connect and disconnect from the system, it updates the list of devices it presents in the user interface.\n\n### Set the initial video device selection\n\nThe sample app enables automatic camera selection by default, so when it performs its initial capture session configuration, it uses the system’s preferred camera as its default camera device as shown below.\n\n```swift\nprivate var defaultVideoCaptureDevice: AVCaptureDevice {\n    get throws {\n        \/\/ Access the system's preferred camera.\n        if let device = AVCaptureDevice.systemPreferredCamera {\n            return device\n        } else {\n            \/\/ No camera is available on the host system.\n            throw Error.noVideoDeviceAvailable\n        }\n    }\n}\n```\n\nThe [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/systemPreferredCamera] property of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice] provides an optional capture device value. However, it always provides a valid capture device unless the host system provides no built-in or connected devices.\n\n### Respond to system-preferred camera changes\n\nThe system-preferred camera changes based on device availability and user camera selection. The sample app provides a `PreferredCameraObserver` object that key-value observes the `systemPreferredCamera` property to monitor changes. When it observes a change to the value, it updates the state of its `@Published` property value as shown below.\n\n```swift\nclass PreferredCameraObserver: NSObject, ObservableObject {\n    \n    private let systemPreferredKeyPath = \"systemPreferredCamera\"\n    \n    @Published private(set) var systemPreferredCamera: AVCaptureDevice?\n    \n    override init() {\n        super.init()\n        \/\/ Key-value observe the `systemPreferredCamera` class property on `AVCaptureDevice`.\n        AVCaptureDevice.self.addObserver(self, forKeyPath: systemPreferredKeyPath, options: [.new], context: nil)\n    }\n    \n    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey: Any]?, context: UnsafeMutableRawPointer?) {\n        switch keyPath {\n        case systemPreferredKeyPath:\n            \/\/ Update the observer's system-preferred camera value.\n            systemPreferredCamera = change?[.newKey] as? AVCaptureDevice\n        default:\n            super.observeValue(forKeyPath: keyPath, of: object, change: change, context: context)\n        }\n    }\n}\n```\n\nIf the app has automatic camera selection enabled, when it observes a change to the system-preferred camera, it automatically switches to the new device.\n\n```swift\n\/\/ The app calls this method when the system-preferred camera changes.\nprivate func systemPreferredCameraChanged(to captureDevice: AVCaptureDevice) async {\n    \n    \/\/ If the SPC changes due to a device disconnection, reset the app\n    \/\/ to its default device selections.\n    guard isActiveVideoInputDeviceConnected else {\n        resetToDefaultDevices()\n        return\n    }\n    \n    \/\/ If the \"Automatic Camera Selection\" checkbox is in an enabled state,\n    \/\/ automatically select the new capture device.\n    if isAutomaticCameraSelectionEnabled {\n        await selectCaptureDevice(captureDevice)\n    }\n}\n```\n\n### Update the user-preferred camera selection\n\nWhen the app selects a new device, it removes the old device input, attempts to add an input for the new device, and if it succeeds, updates the state of the appropriate active input device as shown below.\n\n```swift\n\/\/ Remove the current input from the session.\nsession.removeInput(currentInput)\n\n\/\/ Attempt to add the new device to the capture session.\nlet newInput = try addInput(for: device)\n\n\/\/ Camera\nif mediaType == .video {\n    activeVideoInput = newInput\n    if isUserSelection {\n        \/\/ If the device change is due to user selection, set the UPC value,\n        \/\/ which updates the state of the system-preferred camera.\n        AVCaptureDevice.userPreferredCamera = device\n    }\n}\n\/\/ Microphone\nelse {\n    activeAudioInput = newInput\n}\n```\n\nIn the case of a camera device, if the selection request came from user input, the app also updates the state of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/userPreferredCamera], which persists the user’s preferred camera selection across app and device restarts.\n\n\n\n### Support system video effects\n\nWhen the app’s selected camera changes, the system evaluates the new capture device’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/activeFormat] to determine if it supports Center Stage. If it does, the app enables the Center Stage checkbox so you can change its value. Toggling the state of the feature sets the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/centerStageControlMode-swift.type.property] to [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/CenterStageControlMode-swift.enum\/cooperative] and updates its enabled state.\n\n```swift\n@Published var isCenterStageEnabled = false {\n    didSet {\n        guard isCenterStageEnabled != AVCaptureDevice.isCenterStageEnabled else { return }\n        AVCaptureDevice.centerStageControlMode = .cooperative\n        AVCaptureDevice.isCenterStageEnabled = isCenterStageEnabled\n    }\n}\n```\n\nYou can also enable Center Stage, along with video effects like Portrait mode and Studio Light, in Control Center. Because the enabled state of each effect can change externally, the app also key-value observes the state of these effects. Similar to how the app observes changes to the system-preferred camera, the app key-value observes the state of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/isCenterStageEnabled], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/isPortraitEffectEnabled], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureDevice\/isStudioLightEnabled] properties and updates the user interface state as the values change.\n\n```swift\nAVCaptureDevice.self.addObserver(self, forKeyPath: centerStageKeyPath, options: [.new], context: nil)\nAVCaptureDevice.self.addObserver(self, forKeyPath: portraitEffectKeyPath, options: [.new], context: nil)\nAVCaptureDevice.self.addObserver(self, forKeyPath: studioLightKeyPath, options: [.new], context: nil)\n```\n\n## Continuity Camera\n\n- **Supporting Continuity Camera in your tvOS app**: Capture high-quality photos, video, and audio in your Apple TV app by connecting an iPhone or iPad as a continuity device.\n- **AVCaptureDeskViewApplication**: An object that programmatically presents Desk View.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Capture high-quality photos, video, and audio in your Apple TV app by connecting an iPhone or iPad as a continuity device.",
          "name" : "Supporting Continuity Camera in your tvOS app",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/supporting-continuity-camera-in-your-tvos-app"
        },
        {
          "description" : "An object that programmatically presents Desk View.",
          "name" : "AVCaptureDeskViewApplication",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureDeskViewApplication"
        }
      ],
      "title" : "Continuity Camera"
    }
  ],
  "source" : "appleJSON",
  "title" : "Supporting Continuity Camera in your macOS app",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/supporting-continuity-camera-in-your-macos-app"
}