{
  "abstract" : "Gives the delegate the opportunity to inspect samples as they are received by the output and start and stop recording at exact times.",
  "codeExamples" : [

  ],
  "contentHash" : "7beeee6953836adaa557f83651f6b5907415f13a0622c34513176d898ee0a294",
  "crawledAt" : "2025-12-04T16:56:30Z",
  "declaration" : {
    "code" : "optional func fileOutput(_ output: AVCaptureFileOutput, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)",
    "language" : "swift"
  },
  "id" : "DD59B451-D5FE-4741-8F88-14D7325E095F",
  "kind" : "method",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Discussion\n\nThis method is called whenever the file output receives a single sample buffer (a single video frame or audio buffer, for example) from the given connection. This gives delegates an opportunity to start and stop recording or change output files at an exact sample boundary. If called from within this method, the file output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/startRecording(to:recordingDelegate:)] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/resumeRecording()] methods are guaranteed to include the received sample buffer in the new file, whereas calls to [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/stopRecording()] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/pauseRecording()] are guaranteed to include all samples leading up to those in the current sample buffer in the existing file.\n\nYou can gather information particular to the samples by inspecting the `CMSampleBuffer` object. Sample buffers always contain a single frame of video if called from this method but may also contain multiple samples of audio. For B-frame video formats, samples are always delivered in presentation order.\n\nIf you need to reference the `CMSampleBuffer` object outside of the scope of this method, you must retain it and then release it when you have finished with it.\n\nTo maintain optimal performance, some sample buffers directly reference pools of memory that may need to be reused by the device system and other capture inputs. This is frequently the case for uncompressed device native capture where memory blocks are copied as little as possible. If multiple sample buffers reference such pools of memory for too long, inputs will no longer be able to copy new samples into memory and those samples will be dropped. If your application is causing samples to be dropped by retaining the provided `CMSampleBuffer` objects for too long, but it needs access to the sample data for a long period of time, consider copying the data into a new buffer and then calling `CFRelease` on the sample buffer (if it was previously retained) so that the memory it references can be reused.\n\nYou should not assume that this method will be called on a specific thread. In addition, this method is called frequently, so it must be efficient to prevent capture performance problems.",
  "platforms" : [
    "macOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureFileOutputDelegate\/fileOutput(_:didOutputSampleBuffer:from:)\ncrawled: 2025-12-04T16:56:30Z\n---\n\n# fileOutput(_:didOutputSampleBuffer:from:)\n\n**Instance Method**\n\nGives the delegate the opportunity to inspect samples as they are received by the output and start and stop recording at exact times.\n\n## Declaration\n\n```swift\noptional func fileOutput(_ output: AVCaptureFileOutput, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)\n```\n\n## Parameters\n\n- **output**: The capture file output that is receiving the media data.\n- **sampleBuffer**: A `CMSampleBuffer` object containing the sample data and additional information about the sample, such as its format and presentation time.\n- **connection**: The [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureConnection] object attached to the file output from which the sample data was received.\n\n## Discussion\n\nThis method is called whenever the file output receives a single sample buffer (a single video frame or audio buffer, for example) from the given connection. This gives delegates an opportunity to start and stop recording or change output files at an exact sample boundary. If called from within this method, the file output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/startRecording(to:recordingDelegate:)] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/resumeRecording()] methods are guaranteed to include the received sample buffer in the new file, whereas calls to [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/stopRecording()] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutput\/pauseRecording()] are guaranteed to include all samples leading up to those in the current sample buffer in the existing file.\n\nYou can gather information particular to the samples by inspecting the `CMSampleBuffer` object. Sample buffers always contain a single frame of video if called from this method but may also contain multiple samples of audio. For B-frame video formats, samples are always delivered in presentation order.\n\nIf you need to reference the `CMSampleBuffer` object outside of the scope of this method, you must retain it and then release it when you have finished with it.\n\nTo maintain optimal performance, some sample buffers directly reference pools of memory that may need to be reused by the device system and other capture inputs. This is frequently the case for uncompressed device native capture where memory blocks are copied as little as possible. If multiple sample buffers reference such pools of memory for too long, inputs will no longer be able to copy new samples into memory and those samples will be dropped. If your application is causing samples to be dropped by retaining the provided `CMSampleBuffer` objects for too long, but it needs access to the sample data for a long period of time, consider copying the data into a new buffer and then calling `CFRelease` on the sample buffer (if it was previously retained) so that the memory it references can be reused.\n\nYou should not assume that this method will be called on a specific thread. In addition, this method is called frequently, so it must be efficient to prevent capture performance problems.\n\n## Sample processing\n\n- **fileOutputShouldProvideSampleAccurateRecordingStart(_:)**: Allows a client to opt in to frame accurate recording in [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutputDelegate\/fileOutput(_:didOutputSampleBuffer:from:)].\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Allows a client to opt in to frame accurate recording in [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureFileOutputDelegate\/fileOutput(_:didOutputSampleBuffer:from:)].",
          "name" : "fileOutputShouldProvideSampleAccurateRecordingStart(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureFileOutputDelegate\/fileOutputShouldProvideSampleAccurateRecordingStart(_:)"
        }
      ],
      "title" : "Sample processing"
    }
  ],
  "source" : "appleJSON",
  "title" : "fileOutput(_:didOutputSampleBuffer:from:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureFileOutputDelegate\/fileOutput(_:didOutputSampleBuffer:from:)"
}