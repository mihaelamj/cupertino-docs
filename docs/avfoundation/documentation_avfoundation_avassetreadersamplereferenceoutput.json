{
  "abstract" : "An object that reads sample references from an asset track.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "dcefbc6bdc39665ce6c96f9ebb885bd6d920072b62742f745237d765f71d1d13",
  "crawledAt" : "2025-12-02T15:51:22Z",
  "declaration" : {
    "code" : "class AVAssetReaderSampleReferenceOutput",
    "language" : "swift"
  },
  "id" : "BE735D28-7FD6-4647-BB67-21D938F9ACB8",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nApps can extract information about the location of samples in a track — the file URL and offset — by adding an instance of this class to an asset reader. Read the [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/kCMSampleBufferAttachmentKey_SampleReferenceURL] and [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/kCMSampleBufferAttachmentKey_SampleReferenceByteOffset] attachments on the extracted sample buffers to get the location of the sample data.\n\nYou can also append sample buffers that you extract using this class to an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput] instance to create movie tracks that aren’t self-contained and reference data in the original file instead. To write tracks that aren’t self-contained, use instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriter] that you configure to write files of type [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVFileType\/mov].\n\nBecause this output doesn’t return sample data, it ignores the value of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetReaderOutput\/alwaysCopiesSampleData] property.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderSampleReferenceOutput\ncrawled: 2025-12-02T15:51:22Z\n---\n\n# AVAssetReaderSampleReferenceOutput\n\n**Class**\n\nAn object that reads sample references from an asset track.\n\n## Declaration\n\n```swift\nclass AVAssetReaderSampleReferenceOutput\n```\n\n## Overview\n\nApps can extract information about the location of samples in a track — the file URL and offset — by adding an instance of this class to an asset reader. Read the [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/kCMSampleBufferAttachmentKey_SampleReferenceURL] and [doc:\/\/com.apple.documentation\/documentation\/CoreMedia\/kCMSampleBufferAttachmentKey_SampleReferenceByteOffset] attachments on the extracted sample buffers to get the location of the sample data.\n\nYou can also append sample buffers that you extract using this class to an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriterInput] instance to create movie tracks that aren’t self-contained and reference data in the original file instead. To write tracks that aren’t self-contained, use instances of [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetWriter] that you configure to write files of type [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVFileType\/mov].\n\nBecause this output doesn’t return sample data, it ignores the value of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAssetReaderOutput\/alwaysCopiesSampleData] property.\n\n## Creating a sample reference output\n\n- **init(track:)**: Creates an object that supplies sample references.\n\n## Inspecting the track\n\n- **track**: The track from which the output reads sample references.\n\n## Media reading\n\n- **Reading multiview 3D video files**: Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.\n- **AVAssetReader**: An object that reads media data from an asset.\n- **AVAssetReaderOutput**: An abstract class that defines the interface to read media samples from an asset reader.\n- **AVAssetReaderTrackOutput**: An object that reads media data from a single track of an asset.\n- **AVAssetReaderAudioMixOutput**: An object that reads audio samples that result from mixing audio from one or more tracks.\n- **AVAssetReaderVideoCompositionOutput**: An object that reads composited video frames from one or more tracks of an asset.\n- **AVAssetReaderOutputMetadataAdaptor**: An object that creates timed metadata group objects for an asset track.\n\n## Inherits From\n\n- AVAssetReaderOutput\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an object that supplies sample references.",
          "name" : "init(track:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderSampleReferenceOutput\/init(track:)"
        }
      ],
      "title" : "Creating a sample reference output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The track from which the output reads sample references.",
          "name" : "track",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderSampleReferenceOutput\/track"
        }
      ],
      "title" : "Inspecting the track"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.",
          "name" : "Reading multiview 3D video files",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/reading-multiview-3d-video-files"
        },
        {
          "description" : "An object that reads media data from an asset.",
          "name" : "AVAssetReader",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReader"
        },
        {
          "description" : "An abstract class that defines the interface to read media samples from an asset reader.",
          "name" : "AVAssetReaderOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutput"
        },
        {
          "description" : "An object that reads media data from a single track of an asset.",
          "name" : "AVAssetReaderTrackOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput"
        },
        {
          "description" : "An object that reads audio samples that result from mixing audio from one or more tracks.",
          "name" : "AVAssetReaderAudioMixOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput"
        },
        {
          "description" : "An object that reads composited video frames from one or more tracks of an asset.",
          "name" : "AVAssetReaderVideoCompositionOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderVideoCompositionOutput"
        },
        {
          "description" : "An object that creates timed metadata group objects for an asset track.",
          "name" : "AVAssetReaderOutputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutputMetadataAdaptor"
        }
      ],
      "title" : "Media reading"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "AVAssetReaderOutput"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAssetReaderSampleReferenceOutput",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderSampleReferenceOutput"
}