{
  "abstract" : "Methods you can implement to enqueue sample buffers for presentation.",
  "codeExamples" : [

  ],
  "conformingTypes" : [
    "AVSampleBufferAudioRenderer",
    "AVSampleBufferDisplayLayer",
    "AVSampleBufferVideoRenderer"
  ],
  "contentHash" : "574e42cf6336922b32fa342f0eca164e2250161f56661169b4fabf06e7152cc6",
  "crawledAt" : "2025-12-02T00:53:28Z",
  "declaration" : {
    "code" : "protocol AVQueuedSampleBufferRendering : NSObjectProtocol",
    "language" : "swift"
  },
  "id" : "4CD9020E-C849-4FD8-A8FC-8D3796A18DFB",
  "kind" : "protocol",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\n[doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferDisplayLayer] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer] conform to this protocol. When used in conjunction with an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer], an object conforming to `AVQueuedSampleBufferRendering` can only be attached to a single synchronizer.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\ncrawled: 2025-12-02T00:53:28Z\n---\n\n# AVQueuedSampleBufferRendering\n\n**Protocol**\n\nMethods you can implement to enqueue sample buffers for presentation.\n\n## Declaration\n\n```swift\nprotocol AVQueuedSampleBufferRendering : NSObjectProtocol\n```\n\n## Overview\n\n[doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferDisplayLayer] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer] conform to this protocol. When used in conjunction with an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer], an object conforming to `AVQueuedSampleBufferRendering` can only be attached to a single synchronizer.\n\n## Requesting media\n\n- **isReadyForMoreMediaData**: A Boolean value that indicates whether the receiver is able to accept more sample buffers.\n- **enqueue(_:)**: Sends a sample buffer to the queue for rendering.\n- **requestMediaDataWhenReady(on:using:)**: Tells the target to invoke a client-supplied block in order to gather sample buffers for playback.\n- **stopRequestingMediaData()**: Cancels any current [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/requestMediaDataWhenReady(on:using:)] call.\n\n## Determining playback readiness\n\n- **hasSufficientMediaDataForReliablePlaybackStart**: A Boolean value that indicates whether the enqued media meets the required preroll level for reliable playback.\n\n## Clearing queued sample buffers\n\n- **flush()**: Discards all pending enqueued sample buffers.\n\n## Indentifying the timebase\n\n- **timebase**: The timebase for a renderer.\n\n## Presentation\n\n- **AVSampleBufferRenderSynchronizer**: An object used to synchronize multiple queued sample buffers to a single timeline.\n- **AVSampleBufferDisplayLayer**: An object that displays compressed or uncompressed video frames.\n- **AVSampleBufferVideoRenderer**: An object that enqueues video sample buffers for rendering.\n- **AVSampleBufferAudioRenderer**: An object used to decompress audio and play compressed or uncompressed audio.\n\n## Inherits From\n\n- NSObjectProtocol\n\n## Conforming Types\n\n- AVSampleBufferAudioRenderer\n- AVSampleBufferDisplayLayer\n- AVSampleBufferVideoRenderer\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the receiver is able to accept more sample buffers.",
          "name" : "isReadyForMoreMediaData",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/isReadyForMoreMediaData"
        },
        {
          "description" : "Sends a sample buffer to the queue for rendering.",
          "name" : "enqueue(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/enqueue(_:)"
        },
        {
          "description" : "Tells the target to invoke a client-supplied block in order to gather sample buffers for playback.",
          "name" : "requestMediaDataWhenReady(on:using:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/requestMediaDataWhenReady(on:using:)"
        },
        {
          "description" : "Cancels any current [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/requestMediaDataWhenReady(on:using:)] call.",
          "name" : "stopRequestingMediaData()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/stopRequestingMediaData()"
        }
      ],
      "title" : "Requesting media"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether the enqued media meets the required preroll level for reliable playback.",
          "name" : "hasSufficientMediaDataForReliablePlaybackStart",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/hasSufficientMediaDataForReliablePlaybackStart"
        }
      ],
      "title" : "Determining playback readiness"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Discards all pending enqueued sample buffers.",
          "name" : "flush()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/flush()"
        }
      ],
      "title" : "Clearing queued sample buffers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The timebase for a renderer.",
          "name" : "timebase",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering\/timebase"
        }
      ],
      "title" : "Indentifying the timebase"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object used to synchronize multiple queued sample buffers to a single timeline.",
          "name" : "AVSampleBufferRenderSynchronizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer"
        },
        {
          "description" : "An object that displays compressed or uncompressed video frames.",
          "name" : "AVSampleBufferDisplayLayer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferDisplayLayer"
        },
        {
          "description" : "An object that enqueues video sample buffers for rendering.",
          "name" : "AVSampleBufferVideoRenderer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer"
        },
        {
          "description" : "An object used to decompress audio and play compressed or uncompressed audio.",
          "name" : "AVSampleBufferAudioRenderer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer"
        }
      ],
      "title" : "Presentation"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObjectProtocol"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVQueuedSampleBufferRendering",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering"
}