{
  "abstract" : "An object that reads audio samples that result from mixing audio from one or more tracks.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "5810ffe16ae8fa5cee53279710f12686c5b76b6645d5a783d1ebb9b3a0e22fbe",
  "crawledAt" : "2025-12-02T15:51:20Z",
  "declaration" : {
    "code" : "class AVAssetReaderAudioMixOutput",
    "language" : "swift"
  },
  "id" : "07A776B6-96AF-43CB-8E62-4A805C564BAE",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nRead audio data that you mix from one or more asset tracks by adding an audio mix output to an asset reader. You can read the samples in their stored format or you can convert them to an alternative format.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput\ncrawled: 2025-12-02T15:51:20Z\n---\n\n# AVAssetReaderAudioMixOutput\n\n**Class**\n\nAn object that reads audio samples that result from mixing audio from one or more tracks.\n\n## Declaration\n\n```swift\nclass AVAssetReaderAudioMixOutput\n```\n\n## Overview\n\nRead audio data that you mix from one or more asset tracks by adding an audio mix output to an asset reader. You can read the samples in their stored format or you can convert them to an alternative format.\n\n## Creating an audio mix output\n\n- **init(audioTracks:audioSettings:)**: Creates an object that reads mixed audio from the specified audio tracks.\n\n## Configuring audio settings\n\n- **audioMix**: The audio mix to use with this output.\n- **audioTimePitchAlgorithm**: The processing algorithm to use for scaled audio edits.\n\n## Inspecting an output\n\n- **audioTracks**: The tracks from which the output reads audio.\n- **audioSettings**: The audio settings that the output uses.\n\n## Media reading\n\n- **Reading multiview 3D video files**: Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.\n- **AVAssetReader**: An object that reads media data from an asset.\n- **AVAssetReaderOutput**: An abstract class that defines the interface to read media samples from an asset reader.\n- **AVAssetReaderTrackOutput**: An object that reads media data from a single track of an asset.\n- **AVAssetReaderVideoCompositionOutput**: An object that reads composited video frames from one or more tracks of an asset.\n- **AVAssetReaderSampleReferenceOutput**: An object that reads sample references from an asset track.\n- **AVAssetReaderOutputMetadataAdaptor**: An object that creates timed metadata group objects for an asset track.\n\n## Inherits From\n\n- AVAssetReaderOutput\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates an object that reads mixed audio from the specified audio tracks.",
          "name" : "init(audioTracks:audioSettings:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput\/init(audioTracks:audioSettings:)"
        }
      ],
      "title" : "Creating an audio mix output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The audio mix to use with this output.",
          "name" : "audioMix",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput\/audioMix"
        },
        {
          "description" : "The processing algorithm to use for scaled audio edits.",
          "name" : "audioTimePitchAlgorithm",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput\/audioTimePitchAlgorithm"
        }
      ],
      "title" : "Configuring audio settings"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The tracks from which the output reads audio.",
          "name" : "audioTracks",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput\/audioTracks"
        },
        {
          "description" : "The audio settings that the output uses.",
          "name" : "audioSettings",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput\/audioSettings"
        }
      ],
      "title" : "Inspecting an output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.",
          "name" : "Reading multiview 3D video files",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/reading-multiview-3d-video-files"
        },
        {
          "description" : "An object that reads media data from an asset.",
          "name" : "AVAssetReader",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReader"
        },
        {
          "description" : "An abstract class that defines the interface to read media samples from an asset reader.",
          "name" : "AVAssetReaderOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutput"
        },
        {
          "description" : "An object that reads media data from a single track of an asset.",
          "name" : "AVAssetReaderTrackOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderTrackOutput"
        },
        {
          "description" : "An object that reads composited video frames from one or more tracks of an asset.",
          "name" : "AVAssetReaderVideoCompositionOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderVideoCompositionOutput"
        },
        {
          "description" : "An object that reads sample references from an asset track.",
          "name" : "AVAssetReaderSampleReferenceOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderSampleReferenceOutput"
        },
        {
          "description" : "An object that creates timed metadata group objects for an asset track.",
          "name" : "AVAssetReaderOutputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderOutputMetadataAdaptor"
        }
      ],
      "title" : "Media reading"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "AVAssetReaderOutput"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAssetReaderAudioMixOutput",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetReaderAudioMixOutput"
}