{
  "abstract" : "An object that supports using Core Image filters to process an individual video frame in a video composition.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol"
  ],
  "contentHash" : "8d31ea3e9209fa262e23b5343cf84a0298b7d20dd31310e5498b3f39a3314e63",
  "crawledAt" : "2025-12-03T12:04:02Z",
  "declaration" : {
    "code" : "class AVAsynchronousCIImageFilteringRequest",
    "language" : "swift"
  },
  "id" : "30BFC452-A591-40BE-8E7A-5A51361F5EC4",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nYou use this class when creating a composition for Core Image filtering with the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoComposition\/init(asset:applyingCIFiltersWithHandler:)] method. In that method call, you provide a block to be called by AVFoundation as it processes each frame of video, and the block’s sole parameter is a [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest] object. Use that object both to the video frame image to be filtered and allows you to return a filtered image to AVFoundation for display or export. The code listing below shows an example of applying a filter to an asset.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/avfoundation\/avasynchronousciimagefilteringrequest\ncrawled: 2025-12-03T12:04:02Z\n---\n\n# AVAsynchronousCIImageFilteringRequest\n\n**Class**\n\nAn object that supports using Core Image filters to process an individual video frame in a video composition.\n\n## Declaration\n\n```swift\nclass AVAsynchronousCIImageFilteringRequest\n```\n\n## Overview\n\nYou use this class when creating a composition for Core Image filtering with the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoComposition\/init(asset:applyingCIFiltersWithHandler:)] method. In that method call, you provide a block to be called by AVFoundation as it processes each frame of video, and the block’s sole parameter is a [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest] object. Use that object both to the video frame image to be filtered and allows you to return a filtered image to AVFoundation for display or export. The code listing below shows an example of applying a filter to an asset.\n\n\n\n\n\n## Getting the image to be filtered\n\n- **sourceImage**: The current video frame image.\n\n## Getting contextual information for filtering\n\n- **compositionTime**: The time in the video composition corresponding to the frame being processed.\n- **renderSize**: The width and height, in pixels, of the frame being processed.\n\n## Returning the filtered image\n\n- **finish(with:context:)**: Provides the filtered video frame image to AVFoundation for further processing or display.\n- **finish(with:)**: Notifies AVFoundation that you cannot fulfill the image filtering request.\n\n## Creating a video composition\n\n- **init(configuration:)**: Initialize an AVVideoComposition with a configuration.\n- **AVVideoComposition.Configuration**: Configurable properties for initializing a new AVVideoComposition instance.\n- **init(applyingFiltersTo:applier:)**: Creates a video composition configured to apply Core Image filters to each video frame of the specified asset.\n- **videoComposition(with:applyingCIFiltersWithHandler:completionHandler:)**: Returns a new video composition that’s configured to apply Core Image filters to each video frame of the specified asset.\n- **AVCIImageFilteringParameters**\n- **AVCIImageFilteringResult**: An output video frame processed with Core Image filtering.\n- **videoComposition(withPropertiesOf:completionHandler:)**: Returns a new video composition that’s configured to present the video tracks of the specified asset.\n- **init(propertiesOf:)**: Creates a video composition object configured to present the video tracks of the specified asset.\n- **init(asset:applyingCIFiltersWithHandler:)**: Creates a video composition configured to apply Core Image filters to each video frame of the specified asset.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The current video frame image.",
          "name" : "sourceImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/sourceImage"
        }
      ],
      "title" : "Getting the image to be filtered"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The time in the video composition corresponding to the frame being processed.",
          "name" : "compositionTime",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/compositionTime"
        },
        {
          "description" : "The width and height, in pixels, of the frame being processed.",
          "name" : "renderSize",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/renderSize"
        }
      ],
      "title" : "Getting contextual information for filtering"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Provides the filtered video frame image to AVFoundation for further processing or display.",
          "name" : "finish(with:context:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/finish(with:context:)"
        },
        {
          "description" : "Notifies AVFoundation that you cannot fulfill the image filtering request.",
          "name" : "finish(with:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/finish(with:)"
        }
      ],
      "title" : "Returning the filtered image"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Initialize an AVVideoComposition with a configuration.",
          "name" : "init(configuration:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition\/init(configuration:)"
        },
        {
          "description" : "Configurable properties for initializing a new AVVideoComposition instance.",
          "name" : "AVVideoComposition.Configuration",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition\/Configuration"
        },
        {
          "description" : "Creates a video composition configured to apply Core Image filters to each video frame of the specified asset.",
          "name" : "init(applyingFiltersTo:applier:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition\/init(applyingFiltersTo:applier:)"
        },
        {
          "description" : "Returns a new video composition that’s configured to apply Core Image filters to each video frame of the specified asset.",
          "name" : "videoComposition(with:applyingCIFiltersWithHandler:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition\/videoComposition(with:applyingCIFiltersWithHandler:completionHandler:)"
        },
        {
          "description" : "",
          "name" : "AVCIImageFilteringParameters",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCIImageFilteringParameters"
        },
        {
          "description" : "An output video frame processed with Core Image filtering.",
          "name" : "AVCIImageFilteringResult",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCIImageFilteringResult"
        },
        {
          "description" : "Returns a new video composition that’s configured to present the video tracks of the specified asset.",
          "name" : "videoComposition(withPropertiesOf:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition\/videoComposition(withPropertiesOf:completionHandler:)"
        },
        {
          "description" : "Creates a video composition object configured to present the video tracks of the specified asset.",
          "name" : "init(propertiesOf:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition\/init(propertiesOf:)"
        },
        {
          "description" : "Creates a video composition configured to apply Core Image filters to each video frame of the specified asset.",
          "name" : "init(asset:applyingCIFiltersWithHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition\/init(asset:applyingCIFiltersWithHandler:)"
        }
      ],
      "title" : "Creating a video composition"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVAsynchronousCIImageFilteringRequest",
  "url" : "https:\/\/developer.apple.com\/documentation\/avfoundation\/avasynchronousciimagefilteringrequest"
}