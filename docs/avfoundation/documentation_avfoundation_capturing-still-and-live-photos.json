{
  "abstract" : "Configure and capture single or multiple still images, Live Photos, and other forms of photography.",
  "codeExamples" : [
    {
      "code" : "self.captureSession.beginConfiguration()\n\nlet photoOutput = AVCapturePhotoOutput()\nphotoOutput.isHighResolutionCaptureEnabled = true\nphotoOutput.isLivePhotoCaptureEnabled = photoOutput.isLivePhotoCaptureSupported\n\nguard self.captureSession.canAddOutput(photoOutput) else { return }\nself.captureSession.sessionPreset = .photo\nself.captureSession.addOutput(photoOutput)\n\nself.previewView.session = captureSession\n\nself.captureSession.commitConfiguration()\nself.captureSession.startRunning()",
      "language" : "swift"
    },
    {
      "code" : "let photoSettings: AVCapturePhotoSettings\nif self.photoOutput.availablePhotoCodecTypes.contains(.hevc) {\n    photoSettings = AVCapturePhotoSettings(format:\n        [AVVideoCodecKey: AVVideoCodecType.hevc])\n} else {\n    photoSettings = AVCapturePhotoSettings()\n}\nphotoSettings.flashMode = .auto\nphotoSettings.isAutoStillImageStabilizationEnabled =\n    self.photoOutput.isStillImageStabilizationSupported\n",
      "language" : "swift"
    },
    {
      "code" : "class PhotoCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {\n    \/\/ ...\n}\n\nlet captureProcessor = PhotoCaptureProcessor()\nself.photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)",
      "language" : "swift"
    }
  ],
  "contentHash" : "c2030d6d4a02355542184ed93bc5f5e98fa79b227e10f18badc4e9e553534c86",
  "crawledAt" : "2025-12-02T15:51:01Z",
  "id" : "E1BEF768-38DD-445B-8E44-8CD1D9C7B553",
  "kind" : "collection",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nVideo captured on the iPhone 8, iPhone 8 Plus, and iPhone X running iOS 11 or later uses the HEVC codec by default. If your app shares the captured video using a system share sheet, the video will be automatically converted to a format compatible with the destination device.\n\nAVFoundation supports many ways to capture photos. You can simply capture still HEIF or JPEG images, capture in RAW format for custom processing, snap several images in one shot, create Live Photos with motion and sound, and much more. In iOS, all photography workflows use the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput] class.\n\n### Prepare for photo capture\n\nFirst, set up an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureSession] containing a supported camera device as one of its inputs and an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput] as one of its outputs. (For details, see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/choosing-a-capture-device] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/setting-up-a-capture-session].) Each camera device supports a wide range of resolution and frame rate settings. To easily get the best photo quality for the user’s device, you can use the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureSession\/Preset\/photo] session preset instead of directly choosing individual settings.\n\nSome capture options affect the internal configuration of the media capture pipeline. Because changing those options causes the pipeline to reconfigure itself, which takes time, enable them before offering the user the ability to shoot photos with those settings. Otherwise, the configuration delay could prevent the user from capturing a photo at the right moment.\n\nFor example, to configure the capture pipleline to support Live Photos, enable that property on the photo output, as shown below. After you’ve enabled Live Photo capture, you can choose for each individual shot whether to use still or Live Photo capture for each shot (see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/capturing-and-saving-live-photos]).\n\n### Choose settings\n\nTo capture a photo, first create an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings] object describing the settings you want to use for that shot and the data format for the resulting still photo. For example:\n\nAfter creating a photo settings object, you can choose other settings for the photo. For example, the code below creates a settings object for HEIF\/HEVC shooting, with automatic flash and image stabilization.\n\nOther possible photo settings include Live Photos, depth data capture, and multi-image (bracketed) capture, as well as options for embedding preview or thumbnail images in output image files. For more information, see Next Steps and More Capture Options below.\n\n### Capture the photo\n\nPass your photo settings object to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/capturePhoto(with:delegate:)] method to trigger photo capture with the settings you’ve chosen.\n\n### Handle capture results\n\nThe `delegate` you pass to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/capturePhoto(with:delegate:)] method is an object to track the progress of and handle results from that photo capture. Capturing a photo is an asynchronous process with multiple steps that unfold over time. Because your app can trigger additional captures while earlier captures are still processing, your delegate implementation should be able to handle multiple captures at once. An easy way to handle concurrent captures is to define a class adopting the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate] protocol and create a separate instance of that class for each capture:\n\nWhen your captured image data is ready for use, the photo output calls your delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method. You can use the resulting [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto] object there to display, process or save the image.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-still-and-live-photos\ncrawled: 2025-12-02T15:51:01Z\n---\n\n# Capturing still and Live Photos\n\nConfigure and capture single or multiple still images, Live Photos, and other forms of photography.\n\n## Overview\n\nVideo captured on the iPhone 8, iPhone 8 Plus, and iPhone X running iOS 11 or later uses the HEVC codec by default. If your app shares the captured video using a system share sheet, the video will be automatically converted to a format compatible with the destination device.\n\nAVFoundation supports many ways to capture photos. You can simply capture still HEIF or JPEG images, capture in RAW format for custom processing, snap several images in one shot, create Live Photos with motion and sound, and much more. In iOS, all photography workflows use the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput] class.\n\n\n\n### Prepare for photo capture\n\nFirst, set up an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureSession] containing a supported camera device as one of its inputs and an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput] as one of its outputs. (For details, see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/choosing-a-capture-device] and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/setting-up-a-capture-session].) Each camera device supports a wide range of resolution and frame rate settings. To easily get the best photo quality for the user’s device, you can use the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCaptureSession\/Preset\/photo] session preset instead of directly choosing individual settings.\n\nSome capture options affect the internal configuration of the media capture pipeline. Because changing those options causes the pipeline to reconfigure itself, which takes time, enable them before offering the user the ability to shoot photos with those settings. Otherwise, the configuration delay could prevent the user from capturing a photo at the right moment.\n\nFor example, to configure the capture pipleline to support Live Photos, enable that property on the photo output, as shown below. After you’ve enabled Live Photo capture, you can choose for each individual shot whether to use still or Live Photo capture for each shot (see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/capturing-and-saving-live-photos]).\n\n```swift\nself.captureSession.beginConfiguration()\n\nlet photoOutput = AVCapturePhotoOutput()\nphotoOutput.isHighResolutionCaptureEnabled = true\nphotoOutput.isLivePhotoCaptureEnabled = photoOutput.isLivePhotoCaptureSupported\n\nguard self.captureSession.canAddOutput(photoOutput) else { return }\nself.captureSession.sessionPreset = .photo\nself.captureSession.addOutput(photoOutput)\n\nself.previewView.session = captureSession\n\nself.captureSession.commitConfiguration()\nself.captureSession.startRunning()\n```\n\n### Choose settings\n\nTo capture a photo, first create an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings] object describing the settings you want to use for that shot and the data format for the resulting still photo. For example:\n\n- On supported devices, you can use the HEIF\/HEVC format for improved image quality at smaller file sizes: use [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings\/init(format:)] and choose [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCodecType\/hevc] for the video codec. On devices without HEVC support, use the default initializer [doc:\/\/com.apple.documentation\/documentation\/ObjectiveC\/NSObject-swift.class\/init()] to fall back to JPEG format.\n- To shoot in RAW format, use [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings\/init(rawPixelFormatType:)] with one of the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/availableRawPhotoPixelFormatTypes-5fatm] supported by the photo output.\n\nAfter creating a photo settings object, you can choose other settings for the photo. For example, the code below creates a settings object for HEIF\/HEVC shooting, with automatic flash and image stabilization.\n\n```swift\nlet photoSettings: AVCapturePhotoSettings\nif self.photoOutput.availablePhotoCodecTypes.contains(.hevc) {\n    photoSettings = AVCapturePhotoSettings(format:\n        [AVVideoCodecKey: AVVideoCodecType.hevc])\n} else {\n    photoSettings = AVCapturePhotoSettings()\n}\nphotoSettings.flashMode = .auto\nphotoSettings.isAutoStillImageStabilizationEnabled =\n    self.photoOutput.isStillImageStabilizationSupported\n\n```\n\nOther possible photo settings include Live Photos, depth data capture, and multi-image (bracketed) capture, as well as options for embedding preview or thumbnail images in output image files. For more information, see Next Steps and More Capture Options below.\n\n### Capture the photo\n\nPass your photo settings object to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/capturePhoto(with:delegate:)] method to trigger photo capture with the settings you’ve chosen.\n\n\n\n### Handle capture results\n\nThe `delegate` you pass to the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/capturePhoto(with:delegate:)] method is an object to track the progress of and handle results from that photo capture. Capturing a photo is an asynchronous process with multiple steps that unfold over time. Because your app can trigger additional captures while earlier captures are still processing, your delegate implementation should be able to handle multiple captures at once. An easy way to handle concurrent captures is to define a class adopting the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate] protocol and create a separate instance of that class for each capture:\n\n```swift\nclass PhotoCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {\n    \/\/ ...\n}\n\nlet captureProcessor = PhotoCaptureProcessor()\nself.photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)\n```\n\nWhen your captured image data is ready for use, the photo output calls your delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method. You can use the resulting [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto] object there to display, process or save the image.\n\n## Next steps\n\n- **Saving captured photos**: Add an image and other data from a photo capture to the photo library.\n- **Tracking photo capture progress**: Monitor key events during capture to provide feedback in your camera UI.\n- **Capturing and saving Live Photos**: Capture Live Photos like those created in the system Camera app and save them to the Photos library.\n\n## More capture options\n\n- **Capturing photos with depth**: Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).\n- **Capturing a bracketed photo sequence**: Capture several photos at once, varying parameters like exposure duration or light sensitivity.\n- **Capturing uncompressed image data**: Get processed image data without compression to use for filtering or lossless output.\n- **Capturing thumbnail and preview images**: Enable delivery of reduced-size images with the main image in a photo capture.\n\n## Photo capture\n\n- **Capturing consistent color images**: Add the power of a photography studio and lighting rig to your app with the new Constant Color API.\n- **Capturing photos in RAW and Apple ProRAW formats**: Support professional photography workflows by enabling minimally processed image capture in your camera app.\n- **Supporting Continuity Camera in Your Mac App**: Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.\n- **AVCapturePhoto**: A container for image data from a photo capture output.\n- **AVCaptureDeferredPhotoProxy**: A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.\n- **AVCapturePhotoOutput**: A capture output for still image, Live Photos, and other photography workflows.\n- **AVCapturePhotoCaptureDelegate**: Methods for monitoring progress and receiving results from a photo capture output.\n- **AVCapturePhotoOutputReadinessCoordinator**: An object that monitors changes to a photo output’s capture readiness.\n- **AVCapturePhotoOutputReadinessCoordinatorDelegate**: A delegate protocol to receive updates about a photo output’s capture readiness.\n- **AVCaptureStillImageOutput**: A capture output for capturing still photos.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Add an image and other data from a photo capture to the photo library.",
          "name" : "Saving captured photos",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/saving-captured-photos"
        },
        {
          "description" : "Monitor key events during capture to provide feedback in your camera UI.",
          "name" : "Tracking photo capture progress",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tracking-photo-capture-progress"
        },
        {
          "description" : "Capture Live Photos like those created in the system Camera app and save them to the Photos library.",
          "name" : "Capturing and saving Live Photos",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-and-saving-live-photos"
        }
      ],
      "title" : "Next steps"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).",
          "name" : "Capturing photos with depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-with-depth"
        },
        {
          "description" : "Capture several photos at once, varying parameters like exposure duration or light sensitivity.",
          "name" : "Capturing a bracketed photo sequence",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-a-bracketed-photo-sequence"
        },
        {
          "description" : "Get processed image data without compression to use for filtering or lossless output.",
          "name" : "Capturing uncompressed image data",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-uncompressed-image-data"
        },
        {
          "description" : "Enable delivery of reduced-size images with the main image in a photo capture.",
          "name" : "Capturing thumbnail and preview images",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-thumbnail-and-preview-images"
        }
      ],
      "title" : "More capture options"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Add the power of a photography studio and lighting rig to your app with the new Constant Color API.",
          "name" : "Capturing consistent color images",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-consistent-color-images"
        },
        {
          "description" : "Support professional photography workflows by enabling minimally processed image capture in your camera app.",
          "name" : "Capturing photos in RAW and Apple ProRAW formats",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-in-raw-and-apple-proraw-formats"
        },
        {
          "description" : "Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.",
          "name" : "Supporting Continuity Camera in Your Mac App",
          "url" : "https:\/\/developer.apple.com\/documentation\/AppKit\/supporting-continuity-camera-in-your-mac-app"
        },
        {
          "description" : "A container for image data from a photo capture output.",
          "name" : "AVCapturePhoto",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhoto"
        },
        {
          "description" : "A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.",
          "name" : "AVCaptureDeferredPhotoProxy",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureDeferredPhotoProxy"
        },
        {
          "description" : "A capture output for still image, Live Photos, and other photography workflows.",
          "name" : "AVCapturePhotoOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoOutput"
        },
        {
          "description" : "Methods for monitoring progress and receiving results from a photo capture output.",
          "name" : "AVCapturePhotoCaptureDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate"
        },
        {
          "description" : "An object that monitors changes to a photo output’s capture readiness.",
          "name" : "AVCapturePhotoOutputReadinessCoordinator",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoOutputReadinessCoordinator"
        },
        {
          "description" : "A delegate protocol to receive updates about a photo output’s capture readiness.",
          "name" : "AVCapturePhotoOutputReadinessCoordinatorDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCapturePhotoOutputReadinessCoordinatorDelegate"
        },
        {
          "description" : "A capture output for capturing still photos.",
          "name" : "AVCaptureStillImageOutput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVCaptureStillImageOutput"
        }
      ],
      "title" : "Photo capture"
    }
  ],
  "source" : "appleJSON",
  "title" : "Capturing still and Live Photos",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-still-and-live-photos"
}