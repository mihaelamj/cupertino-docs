{
  "abstract" : "Get processed image data without compression to use for filtering or lossless output.",
  "codeExamples" : [
    {
      "code" : "\/\/ Choose a 32-bit BGRA pixel format and verify the camera supports it.\nlet pixelFormatType = kCVPixelFormatType_32BGRA\nguard self.photoOutput.availablePhotoPixelFormatTypes.contains(pixelFormatType) else { return }\nlet photoSettings = AVCapturePhotoSettings(format:\n    [ kCVPixelBufferPixelFormatTypeKey as String : pixelFormatType ])\n\n\/\/ Shoot the photo, using a custom class to handle capture delegate callbacks.\nlet layerOrientation = previewView.videoPreviewLayer.connection!.videoOrientation\nlet colorSpace = self.videoCaptureDevice.activeColorSpace\nlet captureProcessor = UncompressedCaptureProcessor(orientation: layerOrientation,\n                                                    colorSpace: colorSpace)\nself.photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)\n",
      "language" : "swift"
    },
    {
      "code" : "class UncompressedCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {\n    \n    \/\/ Hold on to the separately delivered RAW and compressed photo data until capture is finished.\n    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {\n        guard error != nil else { print(\"Error capturing photo: \\(error!)\"); return }\n        \n        \/\/ Create a CIImage from the pixel buffer and apply a filter\n        let image = CIImage(cvPixelBuffer: photo.pixelBuffer!)\n        let imageOrientation = self.imageOrientation(for: videoOrientation)\n        let filteredImage = image.oriented(imageOrientation)\n            .applyingFilter(\"CIPhotoEffectNoir\", parameters: [:])\n        \n        let imageColorSpace = self.imageColorSpace(for: colorSpace)\n        guard let pngData = CIContext()\n            .pngRepresentation(of: filteredImage, format: kCIFormatBGRA8, colorSpace: imageColorSpace)\n            else { print(\"Error creating filtered PNG image\"); return }\n        self.exportToFile(pngData)\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "b0c2302815d007f9eb1a5aa2a29c5d0148de41a1200951f86e7eac407199e217",
  "crawledAt" : "2025-12-02T19:05:02Z",
  "id" : "FE6029CD-006C-4EAF-8F5B-23E02BCD7665",
  "kind" : "article",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nTypical photography workflows save images in a compressed format such as HEIF\/HEVC or JPEG. These formats use lossy compression to strike a balance between preserving noticeable details in the image and reducing its data storage requirements. However, sometimes it’s more helpful to work with uncompressed image data—for example, some image processing and analysis algorithms can be confused by the visual artifacts introduced by lossy compression.\n\nIn iOS, capturing uncompressed image data requires minor changes to the basic photography workflow covered in [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/capturing-still-and-live-photos].\n\n### Choose uncompressed format settings\n\nTo capture in an uncompressed format, create a photo settings object with [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings\/init(format:)]. In the format dictionary, specify the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelBufferPixelFormatTypeKey] with one of the values listed in the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/availablePhotoPixelFormatTypes-6eyb] array. The example below chooses a 32-bit BGRA pixel format, which is useful in some GPU processing workflows:\n\n### Handle results\n\nAs with other formats, you receive uncompressed data capture results to your delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method as an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto] object. To access the uncompressed pixel data directly, use the photo’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/pixelBuffer] property.\n\nFor example, the following code applies a Core Image filter directly to the pixel buffer and writes the filtered image to a PNG file:\n\nAlternatively, to get an uncompressed photo ready for writing to a file, use the photo’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation()] method to get the data formatted as a TIFF file.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-uncompressed-image-data\ncrawled: 2025-12-02T19:05:02Z\n---\n\n# Capturing uncompressed image data\n\n**Article**\n\nGet processed image data without compression to use for filtering or lossless output.\n\n## Overview\n\nTypical photography workflows save images in a compressed format such as HEIF\/HEVC or JPEG. These formats use lossy compression to strike a balance between preserving noticeable details in the image and reducing its data storage requirements. However, sometimes it’s more helpful to work with uncompressed image data—for example, some image processing and analysis algorithms can be confused by the visual artifacts introduced by lossy compression.\n\n\n\nIn iOS, capturing uncompressed image data requires minor changes to the basic photography workflow covered in [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/capturing-still-and-live-photos].\n\n### Choose uncompressed format settings\n\nTo capture in an uncompressed format, create a photo settings object with [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoSettings\/init(format:)]. In the format dictionary, specify the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelBufferPixelFormatTypeKey] with one of the values listed in the photo output’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoOutput\/availablePhotoPixelFormatTypes-6eyb] array. The example below chooses a 32-bit BGRA pixel format, which is useful in some GPU processing workflows:\n\n```swift\n\/\/ Choose a 32-bit BGRA pixel format and verify the camera supports it.\nlet pixelFormatType = kCVPixelFormatType_32BGRA\nguard self.photoOutput.availablePhotoPixelFormatTypes.contains(pixelFormatType) else { return }\nlet photoSettings = AVCapturePhotoSettings(format:\n    [ kCVPixelBufferPixelFormatTypeKey as String : pixelFormatType ])\n\n\/\/ Shoot the photo, using a custom class to handle capture delegate callbacks.\nlet layerOrientation = previewView.videoPreviewLayer.connection!.videoOrientation\nlet colorSpace = self.videoCaptureDevice.activeColorSpace\nlet captureProcessor = UncompressedCaptureProcessor(orientation: layerOrientation,\n                                                    colorSpace: colorSpace)\nself.photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)\n\n```\n\n### Handle results\n\nAs with other formats, you receive uncompressed data capture results to your delegate’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhotoCaptureDelegate\/photoOutput(_:didFinishProcessingPhoto:error:)] method as an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto] object. To access the uncompressed pixel data directly, use the photo’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/pixelBuffer] property.\n\nFor example, the following code applies a Core Image filter directly to the pixel buffer and writes the filtered image to a PNG file:\n\n```swift\nclass UncompressedCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {\n    \n    \/\/ Hold on to the separately delivered RAW and compressed photo data until capture is finished.\n    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {\n        guard error != nil else { print(\"Error capturing photo: \\(error!)\"); return }\n        \n        \/\/ Create a CIImage from the pixel buffer and apply a filter\n        let image = CIImage(cvPixelBuffer: photo.pixelBuffer!)\n        let imageOrientation = self.imageOrientation(for: videoOrientation)\n        let filteredImage = image.oriented(imageOrientation)\n            .applyingFilter(\"CIPhotoEffectNoir\", parameters: [:])\n        \n        let imageColorSpace = self.imageColorSpace(for: colorSpace)\n        guard let pngData = CIContext()\n            .pngRepresentation(of: filteredImage, format: kCIFormatBGRA8, colorSpace: imageColorSpace)\n            else { print(\"Error creating filtered PNG image\"); return }\n        self.exportToFile(pngData)\n    }\n}\n```\n\nAlternatively, to get an uncompressed photo ready for writing to a file, use the photo’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVCapturePhoto\/fileDataRepresentation()] method to get the data formatted as a TIFF file.\n\n## More capture options\n\n- **Capturing photos with depth**: Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).\n- **Capturing a bracketed photo sequence**: Capture several photos at once, varying parameters like exposure duration or light sensitivity.\n- **Capturing thumbnail and preview images**: Enable delivery of reduced-size images with the main image in a photo capture.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).",
          "name" : "Capturing photos with depth",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-photos-with-depth"
        },
        {
          "description" : "Capture several photos at once, varying parameters like exposure duration or light sensitivity.",
          "name" : "Capturing a bracketed photo sequence",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-a-bracketed-photo-sequence"
        },
        {
          "description" : "Enable delivery of reduced-size images with the main image in a photo capture.",
          "name" : "Capturing thumbnail and preview images",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-thumbnail-and-preview-images"
        }
      ],
      "title" : "More capture options"
    }
  ],
  "source" : "appleJSON",
  "title" : "Capturing uncompressed image data",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/capturing-uncompressed-image-data"
}