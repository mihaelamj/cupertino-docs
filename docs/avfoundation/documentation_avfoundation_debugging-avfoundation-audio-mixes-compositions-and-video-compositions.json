{
  "abstract" : "Resolve common problems when creating compositions, video compositions, and audio mixes.",
  "codeExamples" : [
    {
      "code" : "@IBOutlet weak var compositionDebugView: CompositionDebugView!",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create a player item from the simple editor composition.\nself.playerItem = AVPlayerItem(asset: self.editor.composition())\n\/*\n Set the player item's video composition and audio mix playback\n settings from the corresponding values in the simple editor.\n*\/\nself.playerItem.videoComposition = self.editor.videoComposition()\nself.playerItem.audioMix = self.editor.audioMix()",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Set the player item on the debug view to synchronize playback.\nself.compositionDebugView.synchronize(with: self.playerItem)",
      "language" : "swift"
    },
    {
      "code" : "func synchronize(with playerItem: AVPlayerItem) {\n    self.playerItem = playerItem\n    \n    if let composition = playerItem.asset as? AVMutableComposition {\n        compositionTrackSegmentInfo = trackSegmentInfo(from: composition.tracks)\n        duration = CMTimeMaximum(duration, composition.duration)\n    }\n\n    if let audioMix = playerItem.audioMix {\n        volumeRampAsPoints = volumeRampPoints(from: audioMix, duration: duration)\n    }\n\n    if let videoComposition = playerItem.videoComposition {\n        videoCompositionStages = videoCompStageInfo(from: videoComposition.instructions)\n    }\n\n    drawingLayer.setNeedsDisplay()\n    self.setNeedsDisplay()\n}",
      "language" : "swift"
    },
    {
      "code" : "private lazy var editorComposition: AVMutableComposition = {\n    var comp = AVMutableComposition()",
      "language" : "swift"
    },
    {
      "code" : "\/*\n Place clips into alternating video and audio tracks in the composition,\n and overlap them with transitionDuration. Set up the video composition to cycle\n between \"pass through A\", \"transition from A to B\", and \"pass through B\".\n*\/\nvar nextClipStart = CMTime.zero\nfor clipIndex in 0..<clips.count {\n    \/\/ Alternating targets: 0, 1, 0, 1, ...\n    let asset = clips[clipIndex].asset\n    let clipTimeRange = clips[clipIndex].availableTimeRange\n    do {\n        let clipVideoTrack = asset.tracks(withMediaType: AVMediaType.video)[0]\n        try compVideoTrks[clipIndex % 2].insertTimeRange(clipTimeRange, of: clipVideoTrack, at: nextClipStart)\n        let clipAudioTracks = asset.tracks(withMediaType: AVMediaType.audio)\n        if clipAudioTracks.isEmpty {\n            SimpleEditorUtils.display(\"Each clip must have an audio track.\")\n            return false\n        }\n        try compAudioTrks[clipIndex % 2].insertTimeRange(clipTimeRange, of: clipAudioTracks[0], at: nextClipStart)",
      "language" : "swift"
    },
    {
      "code" : "passThroughTimeRanges[clipIndex] = CMTimeRangeMake(start: nextClipStart, duration: clipTimeRange.duration)\nif clipIndex > 0 {\n    passThroughTimeRanges[clipIndex].start = CMTimeAdd(passThroughTimeRanges[clipIndex].start,\n                    transitionDuration)\n}\npassThroughTimeRanges[clipIndex].duration = CMTimeSubtract(passThroughTimeRanges[clipIndex].duration,\n                    transitionDuration)\n\n\/*\n The end of this clip overlaps the start of the next by\n transitionDuration.\n*\/\nnextClipStart = CMTimeSubtract(CMTimeAdd(nextClipStart, clipTimeRange.duration), transitionDuration)\n\n\/\/ Retain the time range for the transition to the next item.\nif clipIndex + 1 < clips.count {\n    transitionTimeRanges[clipIndex] = CMTimeRangeMake(start: nextClipStart, duration: transitionDuration)\n}",
      "language" : "swift"
    },
    {
      "code" : "private var editorAudioMix = AVMutableAudioMix()\n\nprivate lazy var editorVideoComposition: AVMutableVideoComposition = {\n    var videoComp = AVMutableVideoComposition()\n    \/\/ Every videoComposition needs these properties to be set:\n    videoComp.frameDuration = CMTimeMake(value: 1, timescale: frameDuration)\n    videoComp.renderSize = editorComposition.naturalSize\n    return videoComp\n}()",
      "language" : "swift"
    },
    {
      "code" : "instructions.append(passThroughInstruction)\n\nif currIndex + 1 < clips.count {\n    \/\/ Add a transition from clip i to clip i+1.\n    let transitionInstruction = AVMutableVideoCompositionInstruction()\n    transitionInstruction.timeRange = transitionTimeRanges[currIndex]\n    let fromLayer = AVMutableVideoCompositionLayerInstruction(assetTrack:\n                        compVideoTracks[alternatingIndex])\n    let toLayer = AVMutableVideoCompositionLayerInstruction(assetTrack:\n                    compVideoTracks[1 - alternatingIndex])\n    \/\/ Sets an opacity ramp to apply during the specified time range.\n    toLayer.setOpacityRamp(fromStartOpacity: 0.0, toEndOpacity: 1.0,\n                        timeRange: transitionTimeRanges[currIndex])\n\n    transitionInstruction.layerInstructions = [toLayer, fromLayer]\n\n    instructions.append(transitionInstruction)\n\n    \/\/ Add an audio mix to the first clip to fade in the volume ramps.\n    let trackMix1 = AVMutableAudioMixInputParameters(track: compAudioTracks[0])\n    trackMix1.setVolumeRamp(fromStartVolume: 1.0, toEndVolume: 0.0,\n                            timeRange: transitionTimeRanges[0])\n\n    trackMixArray.append(trackMix1)\n\n    \/\/ Add an audio mix to the second clip to fade out the volume ramps.\n    let trackMix2 = AVMutableAudioMixInputParameters(track: compAudioTracks[1])\n    trackMix2.setVolumeRamp(fromStartVolume: 0.0, toEndVolume: 1.0,\n                            timeRange: transitionTimeRanges[0])\n    trackMix2.setVolumeRamp(fromStartVolume: 1.0, toEndVolume: 1.0,\n                            timeRange: passThroughTimeRanges[1])\n    trackMixArray.append(trackMix2)\n}\n\neditorAudioMix.inputParameters = trackMixArray\neditorVideoComposition.instructions = instructions",
      "language" : "swift"
    },
    {
      "code" : "func videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingEmptyTimeRange timeRange: CMTimeRange) -> Bool {\n        SimpleEditorUtils.display(\"Empty time range detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}\n\nfunc videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingInvalidTimeRangeIn videoCompositionInstruction: AVVideoCompositionInstructionProtocol) -> Bool {\n        SimpleEditorUtils.display(\"Invalid time range detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}\n\nfunc videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingInvalidValueForKey key: String) -> Bool {\n        SimpleEditorUtils.display(\"Invalid value for \\(key) detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}\n\nfunc videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingInvalidTrackIDIn videoCompositionInstruction: AVVideoCompositionInstructionProtocol, layerInstruction: AVVideoCompositionLayerInstruction, asset: AVAsset) -> Bool {\n        SimpleEditorUtils.display(\"Invalid track ID detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "220bbe1a482c70d0225e40f5a08ae1887f58311e34bc80b9d8a018100ab88172",
  "crawledAt" : "2025-12-02T15:48:11Z",
  "id" : "1EE364F4-6D2D-437C-B400-AABF2C44E1CA",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nYou can construct elaborate and complex compositions, video compositions, and audio mixes with entirely valid values that produce unexpected results. This sample code project visualizes the composition on the screen and adopts the video composition validation-handling protocol to debug common pitfalls in compositions and audio mixes.\n\n### Configure the sample code project\n\nBuild and run the app on any supported device. Use the play, pause, and scrubber controls to play and scrub through the composition in the upper portion of the screen. The debug view in the lower portion of the screen visualizes the composition, video composition, and audio mix.\n\n### Visualize the composition\n\n*Visualization* is looking at a picture of a composition rather than looking at its code. This sample implements the `CompositionDebugView` class to present a visual description on the screen of the underlying [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVComposition], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoComposition], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAudioMix] objects that form the composition. Developers can drop the `CompositionDebugView` into their own apps. Itʼs a noninteractive view, and developers can extend it to draw their own video instructions. It helps in identifying any overlaps and gaps in the composition tracks, video instructions, and audio mix.\n\n### Synchronize the visualized composition\n\nThe `PlayerViewController` class has an outlet to the `CompositionDebugView` object in the `Main.storyboard`.\n\nThe `PlayerViewController` creates a player item to display the composition in the upper portion of the screen using an [doc:\/\/com.apple.documentation\/documentation\/AVKit\/AVPlayerViewController] that presents a native user interface to control playback. It creates this player item from the composition, video composition, and audio mix that the `SimpleEditor` creates from the video files in the project.\n\nTo synchronize its player item with the `CompositionDebugView`, the `PlayerViewController` calls the `CompositionDebugView` `synchronize` function, passing the player item as a parameter.\n\nThe `CompositionDebugView` `synchronize` function uses the passed-in player item parameter to synchronize with its own drawing. It builds its visual display from the composition, video composition, and audio mix associated with the player item.\n\n### Create the composition\n\nThe `SimpleEditor` class initialization creates an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableComposition] to merge the videos.\n\nThen the `SimpleEditor` initializer calls the `createComposition` function to stitch the provided video clips together. It inserts the clips into alternating video and audio tracks in the composition.\n\nThe sample overlaps the end of the first clip with the start of the second clip, and creates time ranges for a transition effect during the overlap period. The first clip ends with the transition, and the second clip begins with the transition. To set up the transition effect for the overlap period only, the sample enables compositing during the overlap, and disables it for the rest of the video composition. To do that, the sample creates a passthrough time range for each clip that excludes the transition period. This passthrough time range instructs the video compositor to pass through the frames without compositing.\n\n### Create the video composition and audio mix\n\nThe `SimpleEditor` class initialization creates an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition] to apply effects between clips, and an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableAudioMix] for mixing the audio tracks.\n\nThen the `SimpleEditor` initializer calls the `createVideoCompAndAudioMix` function to add an opacity ramp transition between the video clips, and a volume ramp between the audio tracks.\n\n### Debug video compositions\n\nThe sample implements the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositionValidationHandling] protocol methods in the `SimpleEditor` class to debug the video composition. These methods identify errors and indicate whether validation of a video composition needs to continue after finding specific errors.\n\nThe sample’s implementation of each of these functions displays an appropriate error dialog, and returns `false` to stop any further validation of the video composition. See the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositionValidationHandling] documentation for more information.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/debugging-avfoundation-audio-mixes-compositions-and-video-compositions\ncrawled: 2025-12-02T15:48:11Z\n---\n\n# Debugging AVFoundation audio mixes, compositions, and video compositions\n\n**Sample Code**\n\nResolve common problems when creating compositions, video compositions, and audio mixes.\n\n## Overview\n\nYou can construct elaborate and complex compositions, video compositions, and audio mixes with entirely valid values that produce unexpected results. This sample code project visualizes the composition on the screen and adopts the video composition validation-handling protocol to debug common pitfalls in compositions and audio mixes.\n\n### Configure the sample code project\n\n- Build the sample with Xcode 13.4.1 or later, and Swift 5.5 or later.\n- This sample runs on physical devices with iPadOS 13.5 or later.\n\nBuild and run the app on any supported device. Use the play, pause, and scrubber controls to play and scrub through the composition in the upper portion of the screen. The debug view in the lower portion of the screen visualizes the composition, video composition, and audio mix.\n\n### Visualize the composition\n\n*Visualization* is looking at a picture of a composition rather than looking at its code. This sample implements the `CompositionDebugView` class to present a visual description on the screen of the underlying [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVComposition], [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoComposition], and [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAudioMix] objects that form the composition. Developers can drop the `CompositionDebugView` into their own apps. Itʼs a noninteractive view, and developers can extend it to draw their own video instructions. It helps in identifying any overlaps and gaps in the composition tracks, video instructions, and audio mix.\n\n### Synchronize the visualized composition\n\nThe `PlayerViewController` class has an outlet to the `CompositionDebugView` object in the `Main.storyboard`.\n\n```swift\n@IBOutlet weak var compositionDebugView: CompositionDebugView!\n```\n\nThe `PlayerViewController` creates a player item to display the composition in the upper portion of the screen using an [doc:\/\/com.apple.documentation\/documentation\/AVKit\/AVPlayerViewController] that presents a native user interface to control playback. It creates this player item from the composition, video composition, and audio mix that the `SimpleEditor` creates from the video files in the project.\n\n```swift\n\/\/ Create a player item from the simple editor composition.\nself.playerItem = AVPlayerItem(asset: self.editor.composition())\n\/*\n Set the player item's video composition and audio mix playback\n settings from the corresponding values in the simple editor.\n*\/\nself.playerItem.videoComposition = self.editor.videoComposition()\nself.playerItem.audioMix = self.editor.audioMix()\n```\n\nTo synchronize its player item with the `CompositionDebugView`, the `PlayerViewController` calls the `CompositionDebugView` `synchronize` function, passing the player item as a parameter.\n\n```swift\n\/\/ Set the player item on the debug view to synchronize playback.\nself.compositionDebugView.synchronize(with: self.playerItem)\n```\n\nThe `CompositionDebugView` `synchronize` function uses the passed-in player item parameter to synchronize with its own drawing. It builds its visual display from the composition, video composition, and audio mix associated with the player item.\n\n```swift\nfunc synchronize(with playerItem: AVPlayerItem) {\n    self.playerItem = playerItem\n    \n    if let composition = playerItem.asset as? AVMutableComposition {\n        compositionTrackSegmentInfo = trackSegmentInfo(from: composition.tracks)\n        duration = CMTimeMaximum(duration, composition.duration)\n    }\n\n    if let audioMix = playerItem.audioMix {\n        volumeRampAsPoints = volumeRampPoints(from: audioMix, duration: duration)\n    }\n\n    if let videoComposition = playerItem.videoComposition {\n        videoCompositionStages = videoCompStageInfo(from: videoComposition.instructions)\n    }\n\n    drawingLayer.setNeedsDisplay()\n    self.setNeedsDisplay()\n}\n```\n\n### Create the composition\n\nThe `SimpleEditor` class initialization creates an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableComposition] to merge the videos.\n\n```swift\nprivate lazy var editorComposition: AVMutableComposition = {\n    var comp = AVMutableComposition()\n```\n\nThen the `SimpleEditor` initializer calls the `createComposition` function to stitch the provided video clips together. It inserts the clips into alternating video and audio tracks in the composition.\n\n```swift\n\/*\n Place clips into alternating video and audio tracks in the composition,\n and overlap them with transitionDuration. Set up the video composition to cycle\n between \"pass through A\", \"transition from A to B\", and \"pass through B\".\n*\/\nvar nextClipStart = CMTime.zero\nfor clipIndex in 0..<clips.count {\n    \/\/ Alternating targets: 0, 1, 0, 1, ...\n    let asset = clips[clipIndex].asset\n    let clipTimeRange = clips[clipIndex].availableTimeRange\n    do {\n        let clipVideoTrack = asset.tracks(withMediaType: AVMediaType.video)[0]\n        try compVideoTrks[clipIndex % 2].insertTimeRange(clipTimeRange, of: clipVideoTrack, at: nextClipStart)\n        let clipAudioTracks = asset.tracks(withMediaType: AVMediaType.audio)\n        if clipAudioTracks.isEmpty {\n            SimpleEditorUtils.display(\"Each clip must have an audio track.\")\n            return false\n        }\n        try compAudioTrks[clipIndex % 2].insertTimeRange(clipTimeRange, of: clipAudioTracks[0], at: nextClipStart)\n```\n\nThe sample overlaps the end of the first clip with the start of the second clip, and creates time ranges for a transition effect during the overlap period. The first clip ends with the transition, and the second clip begins with the transition. To set up the transition effect for the overlap period only, the sample enables compositing during the overlap, and disables it for the rest of the video composition. To do that, the sample creates a passthrough time range for each clip that excludes the transition period. This passthrough time range instructs the video compositor to pass through the frames without compositing.\n\n```swift\npassThroughTimeRanges[clipIndex] = CMTimeRangeMake(start: nextClipStart, duration: clipTimeRange.duration)\nif clipIndex > 0 {\n    passThroughTimeRanges[clipIndex].start = CMTimeAdd(passThroughTimeRanges[clipIndex].start,\n                    transitionDuration)\n}\npassThroughTimeRanges[clipIndex].duration = CMTimeSubtract(passThroughTimeRanges[clipIndex].duration,\n                    transitionDuration)\n\n\/*\n The end of this clip overlaps the start of the next by\n transitionDuration.\n*\/\nnextClipStart = CMTimeSubtract(CMTimeAdd(nextClipStart, clipTimeRange.duration), transitionDuration)\n\n\/\/ Retain the time range for the transition to the next item.\nif clipIndex + 1 < clips.count {\n    transitionTimeRanges[clipIndex] = CMTimeRangeMake(start: nextClipStart, duration: transitionDuration)\n}\n```\n\n### Create the video composition and audio mix\n\nThe `SimpleEditor` class initialization creates an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableVideoComposition] to apply effects between clips, and an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVMutableAudioMix] for mixing the audio tracks.\n\n```swift\nprivate var editorAudioMix = AVMutableAudioMix()\n\nprivate lazy var editorVideoComposition: AVMutableVideoComposition = {\n    var videoComp = AVMutableVideoComposition()\n    \/\/ Every videoComposition needs these properties to be set:\n    videoComp.frameDuration = CMTimeMake(value: 1, timescale: frameDuration)\n    videoComp.renderSize = editorComposition.naturalSize\n    return videoComp\n}()\n```\n\nThen the `SimpleEditor` initializer calls the `createVideoCompAndAudioMix` function to add an opacity ramp transition between the video clips, and a volume ramp between the audio tracks.\n\n```swift\ninstructions.append(passThroughInstruction)\n\nif currIndex + 1 < clips.count {\n    \/\/ Add a transition from clip i to clip i+1.\n    let transitionInstruction = AVMutableVideoCompositionInstruction()\n    transitionInstruction.timeRange = transitionTimeRanges[currIndex]\n    let fromLayer = AVMutableVideoCompositionLayerInstruction(assetTrack:\n                        compVideoTracks[alternatingIndex])\n    let toLayer = AVMutableVideoCompositionLayerInstruction(assetTrack:\n                    compVideoTracks[1 - alternatingIndex])\n    \/\/ Sets an opacity ramp to apply during the specified time range.\n    toLayer.setOpacityRamp(fromStartOpacity: 0.0, toEndOpacity: 1.0,\n                        timeRange: transitionTimeRanges[currIndex])\n\n    transitionInstruction.layerInstructions = [toLayer, fromLayer]\n\n    instructions.append(transitionInstruction)\n\n    \/\/ Add an audio mix to the first clip to fade in the volume ramps.\n    let trackMix1 = AVMutableAudioMixInputParameters(track: compAudioTracks[0])\n    trackMix1.setVolumeRamp(fromStartVolume: 1.0, toEndVolume: 0.0,\n                            timeRange: transitionTimeRanges[0])\n\n    trackMixArray.append(trackMix1)\n\n    \/\/ Add an audio mix to the second clip to fade out the volume ramps.\n    let trackMix2 = AVMutableAudioMixInputParameters(track: compAudioTracks[1])\n    trackMix2.setVolumeRamp(fromStartVolume: 0.0, toEndVolume: 1.0,\n                            timeRange: transitionTimeRanges[0])\n    trackMix2.setVolumeRamp(fromStartVolume: 1.0, toEndVolume: 1.0,\n                            timeRange: passThroughTimeRanges[1])\n    trackMixArray.append(trackMix2)\n}\n\neditorAudioMix.inputParameters = trackMixArray\neditorVideoComposition.instructions = instructions\n```\n\n### Debug video compositions\n\nThe sample implements the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositionValidationHandling] protocol methods in the `SimpleEditor` class to debug the video composition. These methods identify errors and indicate whether validation of a video composition needs to continue after finding specific errors.\n\nThe sample’s implementation of each of these functions displays an appropriate error dialog, and returns `false` to stop any further validation of the video composition. See the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositionValidationHandling] documentation for more information.\n\n```swift\nfunc videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingEmptyTimeRange timeRange: CMTimeRange) -> Bool {\n        SimpleEditorUtils.display(\"Empty time range detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}\n\nfunc videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingInvalidTimeRangeIn videoCompositionInstruction: AVVideoCompositionInstructionProtocol) -> Bool {\n        SimpleEditorUtils.display(\"Invalid time range detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}\n\nfunc videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingInvalidValueForKey key: String) -> Bool {\n        SimpleEditorUtils.display(\"Invalid value for \\(key) detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}\n\nfunc videoComposition(_ videoComposition: AVVideoComposition, shouldContinueValidatingAfterFindingInvalidTrackIDIn videoCompositionInstruction: AVVideoCompositionInstructionProtocol, layerInstruction: AVVideoCompositionLayerInstruction, asset: AVAsset) -> Bool {\n        SimpleEditorUtils.display(\"Invalid track ID detected during validation.\")\n        return false \/\/ Stop validation after finding errors.\n}\n```\n\n## Built-in video compositing\n\n- **Editing and playing HDR video**: Support high-dynamic-range (HDR) video content in your app by using the HDR editing and playback capabilities of AVFoundation.\n- **AVVideoComposition**: An object that describes how to compose video frames at particular points in time.\n- **AVVideoCompositionInstruction**: An operation that a compositor performs.\n- **AVVideoCompositionLayerInstruction**: An object used to modify the transform, cropping, and opacity ramps applied to a given track in a composition.\n- **AVMutableVideoComposition**: A mutable video composition subclass.\n- **AVMutableVideoCompositionInstruction**: A mutable video composition instruction subclass.\n- **AVMutableVideoCompositionLayerInstruction**: An object used to modify the transform, cropping, and opacity ramps applied to a given track in a mutable composition.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Support high-dynamic-range (HDR) video content in your app by using the HDR editing and playback capabilities of AVFoundation.",
          "name" : "Editing and playing HDR video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/editing-and-playing-hdr-video"
        },
        {
          "description" : "An object that describes how to compose video frames at particular points in time.",
          "name" : "AVVideoComposition",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoComposition"
        },
        {
          "description" : "An operation that a compositor performs.",
          "name" : "AVVideoCompositionInstruction",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoCompositionInstruction-swift.class"
        },
        {
          "description" : "An object used to modify the transform, cropping, and opacity ramps applied to a given track in a composition.",
          "name" : "AVVideoCompositionLayerInstruction",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVVideoCompositionLayerInstruction"
        },
        {
          "description" : "A mutable video composition subclass.",
          "name" : "AVMutableVideoComposition",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVMutableVideoComposition"
        },
        {
          "description" : "A mutable video composition instruction subclass.",
          "name" : "AVMutableVideoCompositionInstruction",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVMutableVideoCompositionInstruction"
        },
        {
          "description" : "An object used to modify the transform, cropping, and opacity ramps applied to a given track in a mutable composition.",
          "name" : "AVMutableVideoCompositionLayerInstruction",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVMutableVideoCompositionLayerInstruction"
        }
      ],
      "title" : "Built-in video compositing"
    }
  ],
  "source" : "appleJSON",
  "title" : "Debugging AVFoundation audio mixes, compositions, and video compositions",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/debugging-avfoundation-audio-mixes-compositions-and-video-compositions"
}