{
  "abstract" : "An object used to decompress audio and play compressed or uncompressed audio.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "AVQueuedSampleBufferRendering",
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "5948882d1ae4c847ce6aa3213c81c0a676d38c0d2a372812b4345c2a82de3aa8",
  "crawledAt" : "2025-12-03T19:49:30Z",
  "declaration" : {
    "code" : "class AVSampleBufferAudioRenderer",
    "language" : "swift"
  },
  "id" : "4AD25BFA-7DB2-447C-9D2F-C83B85A46D4E",
  "kind" : "class",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nYou must add an instance of this class to an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer] before queuing the first sample buffer.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\ncrawled: 2025-12-03T19:49:30Z\n---\n\n# AVSampleBufferAudioRenderer\n\n**Class**\n\nAn object used to decompress audio and play compressed or uncompressed audio.\n\n## Declaration\n\n```swift\nclass AVSampleBufferAudioRenderer\n```\n\n## Overview\n\nYou must add an instance of this class to an [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer] before queuing the first sample buffer.\n\n## Determining rendering status\n\n- **status**: The status of the audio renderer.\n- **AVQueuedSampleBufferRenderingStatus**: The statuses for sample buffer rendering.\n\n## Removing queued buffers\n\n- **flush(fromSourceTime:completionHandler:)**: Flushes queued sample buffers with presentation time stamps later than or equal to the specified time.\n- **AVSampleBufferAudioRendererFlushTimeKey**: The key that indicates the presentation timestamp of the first queued sample that was flushed.\n\n## Configuring time and pitch\n\n- **audioTimePitchAlgorithm**: The processing algorithm used to manage audio pitch at different rates.\n- **AVAudioTimePitchAlgorithm**: An algorithm used to set the audio pitch as the rate changes.\n\n## Configuring audio spatialization\n\n- **allowedAudioSpatializationFormats**: The source audio channel layouts the audio renderer supports for spatialization.\n\n## Managing audio output\n\n- **volume**: The current audio volume for the audio renderer.\n- **isMuted**: A Boolean value that indicates whether audio for the renderer is in a muted state.\n- **audioOutputDeviceUniqueID**: The unique identifier of the output device used to play audio.\n\n## Responding to errors\n\n- **error**: The error that caused the renderer to no longer render sample buffers.\n\n## Presentation\n\n- **AVQueuedSampleBufferRendering**: Methods you can implement to enqueue sample buffers for presentation.\n- **AVSampleBufferRenderSynchronizer**: An object used to synchronize multiple queued sample buffers to a single timeline.\n- **AVSampleBufferDisplayLayer**: An object that displays compressed or uncompressed video frames.\n- **AVSampleBufferVideoRenderer**: An object that enqueues video sample buffers for rendering.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- AVQueuedSampleBufferRendering\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The status of the audio renderer.",
          "name" : "status",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/status"
        },
        {
          "description" : "The statuses for sample buffer rendering.",
          "name" : "AVQueuedSampleBufferRenderingStatus",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRenderingStatus"
        }
      ],
      "title" : "Determining rendering status"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Flushes queued sample buffers with presentation time stamps later than or equal to the specified time.",
          "name" : "flush(fromSourceTime:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/flush(fromSourceTime:completionHandler:)"
        },
        {
          "description" : "The key that indicates the presentation timestamp of the first queued sample that was flushed.",
          "name" : "AVSampleBufferAudioRendererFlushTimeKey",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRendererFlushTimeKey"
        }
      ],
      "title" : "Removing queued buffers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The processing algorithm used to manage audio pitch at different rates.",
          "name" : "audioTimePitchAlgorithm",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/audioTimePitchAlgorithm"
        },
        {
          "description" : "An algorithm used to set the audio pitch as the rate changes.",
          "name" : "AVAudioTimePitchAlgorithm",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAudioTimePitchAlgorithm"
        }
      ],
      "title" : "Configuring time and pitch"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The source audio channel layouts the audio renderer supports for spatialization.",
          "name" : "allowedAudioSpatializationFormats",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/allowedAudioSpatializationFormats"
        }
      ],
      "title" : "Configuring audio spatialization"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The current audio volume for the audio renderer.",
          "name" : "volume",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/volume"
        },
        {
          "description" : "A Boolean value that indicates whether audio for the renderer is in a muted state.",
          "name" : "isMuted",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/isMuted"
        },
        {
          "description" : "The unique identifier of the output device used to play audio.",
          "name" : "audioOutputDeviceUniqueID",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/audioOutputDeviceUniqueID"
        }
      ],
      "title" : "Managing audio output"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The error that caused the renderer to no longer render sample buffers.",
          "name" : "error",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer\/error"
        }
      ],
      "title" : "Responding to errors"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Methods you can implement to enqueue sample buffers for presentation.",
          "name" : "AVQueuedSampleBufferRendering",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVQueuedSampleBufferRendering"
        },
        {
          "description" : "An object used to synchronize multiple queued sample buffers to a single timeline.",
          "name" : "AVSampleBufferRenderSynchronizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer"
        },
        {
          "description" : "An object that displays compressed or uncompressed video frames.",
          "name" : "AVSampleBufferDisplayLayer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferDisplayLayer"
        },
        {
          "description" : "An object that enqueues video sample buffers for rendering.",
          "name" : "AVSampleBufferVideoRenderer",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferVideoRenderer"
        }
      ],
      "title" : "Presentation"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "AVSampleBufferAudioRenderer",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVSampleBufferAudioRenderer"
}