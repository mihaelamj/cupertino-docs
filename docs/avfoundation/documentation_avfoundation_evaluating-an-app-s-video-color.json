{
  "abstract" : "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.",
  "codeExamples" : [

  ],
  "contentHash" : "9e6a14e3856848b5da6458fa7cb97e991be9ecfb7a5601ac1f52ea6a13b38cef",
  "crawledAt" : "2025-12-02T16:04:25Z",
  "id" : "6FAB9CC2-57D0-4EFF-A2CF-21E7332D3FA1",
  "kind" : "collection",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Overview\n\nAVFoundation automatically applies color management to video during playback. ColorSync creates a color transform that provides a color match between the video’s color space (as specified by the color tag in the media) and the specific chromaticity and gamma characteristics of your display.\n\nColorSync uses the display’s ICC profile to obtain its chromaticity and gamma characteristics. It then performs the color match using perceptual rendering intent to scale the video colors so they fit into the destination gamut specified by the display. AVFoundation applies this color transformation to each pixel of each frame in real time during video playback, ensuring the color fidelity of the original video.\n\n### Manage color reproduction\n\nDuring playback, the color-management process changes the pixel values encoded in the video file to make them appear true to the original on the display. As a result of this color management, the [https:\/\/support.apple.com\/guide\/digital-color-meter\/welcome\/mac] reports values from the display buffer that are different from the actual pixels encoded in the video file. Further, the Digital Color Meter app may report unequal pixel values between seemingly identical displays if their display profiles differ.\n\nYou can use a variety of techniques to verify that the system properly manages color in your video:\n\nAppropriate color management of your video during playback requires tagging your content, using frameworks that offer implicit color management of video, and evaluating your results.\n\nFor more information about color tags, see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/tagging-media-with-video-color-information].\n\n### Evaluate video using test pattern files\n\nUse test pattern files to evaluate the color characteristics of your AVFoundation-based app or workflow. These files produce expected results when displayed on Apple devices and operating systems. Open these files in the QuickTime Player App or with other apps or workflows that properly support the QuickTime File Format Specification. Read the display buffer pixel values using the Digital Color Meter app. See [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/evaluating-video-using-quicktime-test-pattern-files].\n\n### Evaluate video using a vectorscope or waveform analyzer\n\nOutput test patterns to a vectorscope or waveform analyzer to analyze the video signals. View the test pattern on a vectorscope and verify the correct colorspace conversion matrices. Verify the gamma, quantization errors, and range expansion and compression on a waveform monitor. See [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/evaluating-an-app-s-video-color-using-video-test-equipment].\n\n### Evaluate video using a spectroradiometer or colorimeter\n\nOutput the test pattern files to a spectroradiometer or colorimeter to measure front-of-screen (FoS) luminance. Measure and compare your results against the expected FoS values. See [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/evaluating-an-app-s-video-color-using-light-measurement-instruments].\n\n### Ensure accurate color application of your app’s video\n\nTo ensure application of the appropriate color management to your video during playback:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color\ncrawled: 2025-12-02T16:04:25Z\n---\n\n# Evaluating an app’s video color\n\nCheck color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.\n\n## Overview\n\nAVFoundation automatically applies color management to video during playback. ColorSync creates a color transform that provides a color match between the video’s color space (as specified by the color tag in the media) and the specific chromaticity and gamma characteristics of your display.\n\nColorSync uses the display’s ICC profile to obtain its chromaticity and gamma characteristics. It then performs the color match using perceptual rendering intent to scale the video colors so they fit into the destination gamut specified by the display. AVFoundation applies this color transformation to each pixel of each frame in real time during video playback, ensuring the color fidelity of the original video.\n\n\n\n### Manage color reproduction\n\nDuring playback, the color-management process changes the pixel values encoded in the video file to make them appear true to the original on the display. As a result of this color management, the [https:\/\/support.apple.com\/guide\/digital-color-meter\/welcome\/mac] reports values from the display buffer that are different from the actual pixels encoded in the video file. Further, the Digital Color Meter app may report unequal pixel values between seemingly identical displays if their display profiles differ.\n\nYou can use a variety of techniques to verify that the system properly manages color in your video:\n\n- Use test pattern files to evaluate the color characteristics of your app or workflow.\n- Output the test pattern files to a vectorscope or waveform analyzer to review video signals.\n- Use the test pattern files with a spectroradiometer or colorimeter to measure front-of-screen (FoS) luminance.\n\nAppropriate color management of your video during playback requires tagging your content, using frameworks that offer implicit color management of video, and evaluating your results.\n\nFor more information about color tags, see [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/tagging-media-with-video-color-information].\n\n### Evaluate video using test pattern files\n\nUse test pattern files to evaluate the color characteristics of your AVFoundation-based app or workflow. These files produce expected results when displayed on Apple devices and operating systems. Open these files in the QuickTime Player App or with other apps or workflows that properly support the QuickTime File Format Specification. Read the display buffer pixel values using the Digital Color Meter app. See [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/evaluating-video-using-quicktime-test-pattern-files].\n\n### Evaluate video using a vectorscope or waveform analyzer\n\nOutput test patterns to a vectorscope or waveform analyzer to analyze the video signals. View the test pattern on a vectorscope and verify the correct colorspace conversion matrices. Verify the gamma, quantization errors, and range expansion and compression on a waveform monitor. See [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/evaluating-an-app-s-video-color-using-video-test-equipment].\n\n### Evaluate video using a spectroradiometer or colorimeter\n\nOutput the test pattern files to a spectroradiometer or colorimeter to measure front-of-screen (FoS) luminance. Measure and compare your results against the expected FoS values. See [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/evaluating-an-app-s-video-color-using-light-measurement-instruments].\n\n### Ensure accurate color application of your app’s video\n\nTo ensure application of the appropriate color management to your video during playback:\n\n- Use high-level frameworks integrated with ColorSync, such as AVFoundation, for implicit color management.\n- Tag all video content with color information to avoid inconsistent color across different devices. In most cases, the system treats untagged media as if the author created it in the SD color space. See [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/tagging-media-with-video-color-information].\n- Evaluate all results using the techniques described here.\n\n## Video evaluation\n\n- **Evaluating video using QuickTime test pattern files**: Check color reproduction of your app or workflow by using test pattern files.\n- **Evaluating an app’s video color using video test equipment**: Output test pattern files to a vectorscope or waveform analyzer to review the video signals.\n- **Evaluating an app’s video color using light-measurement Instruments**: Measure front-of-screen luminance by using test pattern files with a spectroradiometer or colorimeter.\n\n## Media writing\n\n- **Converting projected video to Apple Projected Media Profile**: Convert content with equirectangular or half-equirectangular projection to APMP.\n- **Converting side-by-side 3D video to multiview HEVC and spatial video**: Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.\n- **Writing fragmented MPEG-4 files for HTTP Live Streaming**: Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.\n- **Creating spatial photos and videos with spatial metadata**: Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.\n- **Tagging media with video color information**: Inspect and set video color space information when writing and transcoding media.\n- **AVOutputSettingsAssistant**: An object that builds audio and video output settings dictionaries.\n- **AVAssetWriter**: An object that writes media data to a container file.\n- **AVAssetWriterInput**: An object that appends media samples to a track in an asset writer’s output file.\n- **AVAssetWriterInputPixelBufferAdaptor**: An object that appends video samples to an asset writer input.\n- **AVAssetWriterInputTaggedPixelBufferGroupAdaptor**: An object that appends tagged buffer groups to an asset writer input.\n- **AVAssetWriterInputMetadataAdaptor**: An object that appends timed metadata groups to an asset writer input.\n- **AVAssetWriterInputGroup**: A group of inputs with tracks that are mutually exclusive to each other for playback or processing.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Check color reproduction of your app or workflow by using test pattern files.",
          "name" : "Evaluating video using QuickTime test pattern files",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-video-using-quicktime-test-pattern-files"
        },
        {
          "description" : "Output test pattern files to a vectorscope or waveform analyzer to review the video signals.",
          "name" : "Evaluating an app’s video color using video test equipment",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color-using-video-test-equipment"
        },
        {
          "description" : "Measure front-of-screen luminance by using test pattern files with a spectroradiometer or colorimeter.",
          "name" : "Evaluating an app’s video color using light-measurement Instruments",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color-using-light-measurement-instruments"
        }
      ],
      "title" : "Video evaluation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Convert content with equirectangular or half-equirectangular projection to APMP.",
          "name" : "Converting projected video to Apple Projected Media Profile",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-projected-video-to-apple-projected-media-profile"
        },
        {
          "description" : "Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.",
          "name" : "Converting side-by-side 3D video to multiview HEVC and spatial video",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video"
        },
        {
          "description" : "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.",
          "name" : "Writing fragmented MPEG-4 files for HTTP Live Streaming",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/writing-fragmented-mpeg-4-files-for-http-live-streaming"
        },
        {
          "description" : "Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.",
          "name" : "Creating spatial photos and videos with spatial metadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/ImageIO\/Creating-spatial-photos-and-videos-with-spatial-metadata"
        },
        {
          "description" : "Inspect and set video color space information when writing and transcoding media.",
          "name" : "Tagging media with video color information",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/tagging-media-with-video-color-information"
        },
        {
          "description" : "An object that builds audio and video output settings dictionaries.",
          "name" : "AVOutputSettingsAssistant",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVOutputSettingsAssistant"
        },
        {
          "description" : "An object that writes media data to a container file.",
          "name" : "AVAssetWriter",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriter"
        },
        {
          "description" : "An object that appends media samples to a track in an asset writer’s output file.",
          "name" : "AVAssetWriterInput",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInput"
        },
        {
          "description" : "An object that appends video samples to an asset writer input.",
          "name" : "AVAssetWriterInputPixelBufferAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputPixelBufferAdaptor"
        },
        {
          "description" : "An object that appends tagged buffer groups to an asset writer input.",
          "name" : "AVAssetWriterInputTaggedPixelBufferGroupAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputTaggedPixelBufferGroupAdaptor"
        },
        {
          "description" : "An object that appends timed metadata groups to an asset writer input.",
          "name" : "AVAssetWriterInputMetadataAdaptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputMetadataAdaptor"
        },
        {
          "description" : "A group of inputs with tracks that are mutually exclusive to each other for playback or processing.",
          "name" : "AVAssetWriterInputGroup",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAssetWriterInputGroup"
        }
      ],
      "title" : "Media writing"
    }
  ],
  "source" : "appleJSON",
  "title" : "Evaluating an app’s video color",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/evaluating-an-app-s-video-color"
}