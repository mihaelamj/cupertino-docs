{
  "abstract" : "The current video frame image.",
  "codeExamples" : [

  ],
  "contentHash" : "38a5e48b2d4d5abb9073f18a36da20c351c47b444e9410525aa591fb03a1b026",
  "crawledAt" : "2025-12-03T11:44:33Z",
  "declaration" : {
    "code" : "var sourceImage: CIImage { get }",
    "language" : "swift"
  },
  "id" : "B12C9EFD-9F84-43E3-8A57-89AD01695782",
  "kind" : "property",
  "language" : "swift",
  "module" : "AVFoundation",
  "overview" : "## Discussion\n\nTo apply a Core Image filter to this image, assign it to the `inputImage` parameter of a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFilter-swift.class] object, or use a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage] convenience method such as the [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage\/applyingFilter(_:parameters:)] method.\n\nThe pixel format for this image is the [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/BGRA8] format (of the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_32BGRA] type). Unlike when processing video with the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousVideoCompositionRequest] class, the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousVideoCompositionRequest\/renderContext] object’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositionRenderContext\/renderTransform] property is already applied to this image.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/sourceImage\ncrawled: 2025-12-03T11:44:33Z\n---\n\n# sourceImage\n\n**Instance Property**\n\nThe current video frame image.\n\n## Declaration\n\n```swift\nvar sourceImage: CIImage { get }\n```\n\n## Discussion\n\nTo apply a Core Image filter to this image, assign it to the `inputImage` parameter of a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFilter-swift.class] object, or use a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage] convenience method such as the [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage\/applyingFilter(_:parameters:)] method.\n\nThe pixel format for this image is the [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIFormat\/BGRA8] format (of the [doc:\/\/com.apple.documentation\/documentation\/CoreVideo\/kCVPixelFormatType_32BGRA] type). Unlike when processing video with the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousVideoCompositionRequest] class, the [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVAsynchronousVideoCompositionRequest\/renderContext] object’s [doc:\/\/com.apple.avfoundation\/documentation\/AVFoundation\/AVVideoCompositionRenderContext\/renderTransform] property is already applied to this image.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "sourceImage",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVFoundation\/AVAsynchronousCIImageFilteringRequest\/sourceImage"
}