{
  "abstract" : "Draw a scene without rendering hidden geometry by checking whether each object in the scene is visible.",
  "codeExamples" : [
    {
      "code" : "\/\/ Initialize the visibility result buffers.\nfor (size_t i = 0; i < AAPLNumVisibilityBuffers; ++i)\n{\n    _visibilityBuffer[i] = [_device newBufferWithLength:AAPLNumObjectsXYZ * sizeof(uint64_t)\n                                                options:MTLResourceStorageModeShared];\n    _visibilityBuffer[i].label = @\"visibilitybuffer\";\n}",
      "language" : "objective-c"
    },
    {
      "code" : "[commandBuffer addCompletedHandler:^(id<MTLCommandBuffer> buffer)\n {\n    \/\/ Avoid a data race condition by updating the visibility buffer's read index when the command buffer finishes.\n    self->_visibilityBufferReadIndex = (self->_visibilityBufferReadIndex + 1) % AAPLNumVisibilityBuffers;\n\n    \/\/ Allow the app to start another frame by dispatching the in-flight semaphore.\n    dispatch_semaphore_signal(block_sema);\n}];",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Update the state of the constant data buffers before rendering.\n_frameDataBufferIndex = (_frameDataBufferIndex + 1) % AAPLMaxBuffersInFlight;\n_visibilityBufferWriteIndex = (_visibilityBufferWriteIndex + 1) % AAPLNumVisibilityBuffers;\n\n\/\/ Read the visibility buffer result from the previous frame.\n_readFromVisibilityResultBuffer = _visibilityBuffer[_visibilityBufferReadIndex].contents;",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/\/ A sphere's radius that allows plenty of space between spheres with a grid spacing of two units.\nconst double sphereRadius = 0.7;\n\n\/\/\/ An adjustment factor that scales up the proxy geometry size.\n\/\/\/\n\/\/\/ The sample sets the factor small enough to avoid a \"pop in\" effect when the spheres move.\n\/\/\/ In other words, the sphere may not be visible in the current frame, but visible in the next.\n\/\/\/ For example, a sphere that's moving behind another sphere may cause the occlusion query to return `false`.\n\/\/\/ This causes the renderer to erroneously omit the sphere in the next frame.\n\/\/\/\n\/\/\/ The app uses a simple approach that sizes up the icosahedrons by an adjustment factor.\n\/\/\/ Sizing up the icosahedron gives each object extra pixels for the occlusion query to return `true`.\n\/\/\/ Since the renderer doesn't know exactly where the objects are located on the next frame,\n\/\/\/ this is like giving each object a little wiggle room.\n\/\/\/ If the adjustment value is too small, the renderer may not draw objects that are visible in the current frame.\n\/\/\/ If it's too large, then renderer may draw more spheres that are hidden by nearer spheres.\n\/\/\/ A lower value of `1` is best for a stationary scene and does not size up the proxy geometry.\n\/\/\/ A higher value of `8` sizes the proxy geometry significantly and reduces the occlusion query effectiveness.\nconst double animationAdjustmentFactor = 4;\n\n\/\/\/ An icosahedron size that's large enough to inscribe a sphere.\n\/\/\/\n\/\/\/ The icosahedron radius includes the previous animation adjustment.\nconst double icosahedronRadius = animationAdjustmentFactor * sphereRadius;",
      "language" : "objective-c"
    },
    {
      "code" : "typedef struct\n{\n    matrix_float4x4 modelViewMatrix;\n    matrix_float4x4 modelViewProjMatrix;\n    vector_float3 color;\n} AAPLFrameDataPerObject;\n\ntypedef struct\n{\n    AAPLFrameDataPerObject objects[AAPLNumObjectsXYZ];\n} AAPLFrameData;",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/\/ Renders a mesh and sets the index of the mesh so the shader can reference its appearance and location data.\n- (void)renderMeshWithIndex:(uint32_t)meshIndex\n{\n    [_renderEncoder setVertexBytes:&meshIndex\n                            length:sizeof(uint32_t)\n                           atIndex:AAPLBufferIndexMeshIndex];\n    [_renderEncoder drawIndexedPrimitives:MTLPrimitiveTypeTriangle\n                               indexCount:_curMeshIndexCount\n                                indexType:MTLIndexTypeUInt32\n                              indexBuffer:_curMeshIndexBuffer\n                        indexBufferOffset:0];\n}",
      "language" : "objective-c"
    },
    {
      "code" : "self->_numVisibleFragments = _readFromVisibilityResultBuffer[AAPLGreenSphereIndex];",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Add the visibility result buffer to this render pass.\nrenderPassDescriptor.visibilityResultBuffer = _visibilityBuffer[_visibilityBufferWriteIndex];\n\n\/\/ Create a render encoder for drawing.\n_renderEncoder = [commandBuffer renderCommandEncoderWithDescriptor:renderPassDescriptor];",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Encode the sphere's vertex data.\n[self setMeshBuffers:_sphereVertices indexBuffer:_sphereIndices indexCount:_sphereIndexCount];\n\n\/\/ Encode the red sphere mesh for drawing.\n[self renderMeshWithIndex:(uint32_t)AAPLRedSphereIndex];\n\n\/\/ Set the offset into the visibility result buffer.\n[_renderEncoder setVisibilityResultMode:MTLVisibilityResultModeCounting\n                                 offset:AAPLGreenSphereIndex * sizeof(uint64_t)];\n\n\/\/ Encode the green sphere for drawing.\n[self renderMeshWithIndex:(uint32_t)AAPLGreenSphereIndex];",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Encode the sphere's vertex data.\n[self setMeshBuffers:_sphereVertices indexBuffer:_sphereIndices indexCount:_sphereIndexCount];\n\n\/\/ Draw a visible sphere for every corresponding visible icosahedron.\nfor (size_t i = 0; i < AAPLNumObjectsXYZ; ++i)\n{\n    \/\/ If an icosahedron is visible, draw the sphere.\n    if (_readFromVisibilityResultBuffer[i])\n    {\n        [self renderMeshWithIndex:(uint32_t)i];\n        numDrawCalls++;\n    }\n}",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Configure the pipeline state object and depth state to disable writing to the color and depth attachments.\n[_renderEncoder setRenderPipelineState:_pipelineStateNoRender];\n[_renderEncoder setDepthStencilState:_depthStateDisableWrites];",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Encode the icosahedron's vertices.\n[self setMeshBuffers:_icosahedronVertices indexBuffer:_icosahedronIndices indexCount:_icosahedronIndexCount];\n\n\/\/ Draw each icosahedron and check its visibility.\nfor (size_t i = 0; i < AAPLNumObjectsXYZ; ++i)\n{\n    [_renderEncoder setVisibilityResultMode:MTLVisibilityResultModeBoolean\n                                     offset:i * sizeof(uint64_t)];\n    [self renderMeshWithIndex:(uint32_t)i];\n}",
      "language" : "objective-c"
    }
  ],
  "contentHash" : "70adcd122551a7de3b7cc3949c71dde301eea6105b3fd01f0cc6275ff5a3c180",
  "crawledAt" : "2025-12-02T15:49:20Z",
  "id" : "BE1327C6-4826-4A08-BB30-6C1F525EF69D",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Metal",
  "overview" : "## Overview\n\nThis sample demonstrates how to use a visibility result buffer to perform *fragment counting* and *occlusion culling*. The visibility result buffer stores an array of integers that contain the number of times a fragment passes the depth and stencil tests. Before a draw call, the app sets the location of the 64-bit counter in the buffer and the hardware increments the counter during rasterization.\n\nThe first mode of the app shows how to use fragment counting to determine the number of pixels that pass the depth and stencil tests. You can use this information to choose the level of detail for a 3D model, or to include or exclude the model from rendering. The second mode shows how to use the occlusion-culling technique to reduce the rendering load by eliminating invisible objects. To use this technique, the app renders a second pass of the objects it wants to test using proxy geometry instead of the full-resolution 3D model. It skips any object in the next frame if the number of pixels that passed the depth test is zero. You can toggle between the two modes by using the segment control in the upper-left corner of the window.\n\nThe fragment-counting mode shows a stationary red sphere and a smaller green sphere, and counts the number of fragments rendered for the green sphere. The slider on the lower-left corner of the app moves the green sphere left and right. The top-right corner of the window shows the number of fragments drawn from the green sphere. The number of fragments decrease to zero as the red sphere occludes the green sphere.\n\n\n\nThe occlusion-culling mode is more complex, rendering multiple spheres and using the visibility results to skip the draw calls for occluded spheres. It renders *icosahedrons*, a 20-sided polyhedron serving as a type of proxy geometry for a sphere, to the previous frame. If the fragment count is zero because it’s *occluded* (hidden), the renderer *culls* (skips drawing) it in the next frame. The slider at the bottom left moves the spheres left and right, and the label in the upper right shows the number of rendered spheres.\n\n\n\nThe app creates Metal objects, renders 3D objects, and demonstrates two ways to use the visibility result buffer. First, it initializes the visibility result buffers and creates the sphere and icosahedron geometry. Next, it uses shared code to position and render the sphere and icosahedron geometry. Lastly, the app uses the state of the segment control to render either the fragment-counting mode or occlusion-culling mode.\n\n### Configure the sample code project\n\nTo run this sample, you need Xcode 12 and a physical device that supports [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLGPUFamily\/apple3], such as:\n\nThis sample can only run on a physical device because it uses the counting occlusion query features that Simulator doesn’t support.\n\n### Create the visibility result buffer\n\nAt initialization time, the app creates a set of visibility result buffers used in the fragment-counting and occlusion-culling modes. A visibility result buffer is an array of `uint64_t` integers stored in an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer]. The app allows up to three frames to be in flight with the `AAPLMaxBuffersInFlight` constant. However, if the app uses only a single buffer for recording and reading visibility results, a data race condition might occur if the GPU simultaneously writes to the visibility result buffer while the CPU reads from that same buffer. To prevent this, the app uses a ring of buffers that contains one more buffer than the number of frames in flight. The `AAPLNumVisibilityBuffers` constant stores this value. At the end of the `loadMetalWithView:` method, the app creates the buffers using the shared resource storage mode to allow CPU access.\n\nBefore rendering either of the two modes, the app chooses which visibility buffer to read from and write to. The `_visibilityBufferReadIndex` variable stores the index of the last completed visibility result buffer. The `_visibilityBufferWriteIndex` stores the index of the next visibility result buffer. The completion handler for the command buffer increments the read index as shown in the following code.\n\nBefore rendering, the `drawInMTKView:` method updates the current `_frameDataBuffer` and `_visibilityBuffer` indices for the frame. It also stores the pointer for the recently completed visibility result buffer in the `_readFromVisibilityResultBuffer` variable to use in both modes, as shown below.\n\n### Create the proxy geometry\n\nFor the occlusion-culling mode, the app procedurally generates two geometric 3D primitives: a sphere and an icosahedron. The app uses an icosahedron as proxy geometry for the sphere in occlusion testing because it approximates a sphere using only 20 vertices.\n\nBecause proxy geometries are efficient to render, the occlusion culling uses them to quickly test visibility. If the visibility result buffer contains a nonzero value, the proxy geometry isn’t occluded and the app presumes the original geometry is also not occluded. However, to use proxy geometry for visibility testing, the 3D primitive needs to cover at least the same pixels as the original geometry. For the occlusion-culling mode, the app generates an icosahedron so that it fully inscribes (contains) a sphere.\n\nUsing proxy geometry that only covers the original model works well for stationary geometry but may not be sufficient for animated geometry. In the occlusion-culling mode, the sample uses the geometry visible in the current frame to determine the objects to draw on the next frame. This is an efficient approach for apps encoding work on the CPU. However, as objects change positions, the visibility results of one frame may not be accurate for the next frame, which may lead to objects popping in on subsequent frames.\n\nTo minimize this undesirable pop-in effect, the app scales the proxy geometry with an animation-adjustment factor. Increasing the size of the proxy geometry increases the screen area the app uses for testing the occluding geometry, making it less likely for the renderer to omit drawing occluded objects moving behind foreground objects that are visible in the next frame. Apps that choose larger-scale factors may reduce the amount of popping in but increase the draw count of occluded objects. Smaller-scale factors reduce the draw count but can cause objects farther away to pop into view more often.\n\nThe following code initializes the icosahedron radius by a scale factor of four. In the occlusion-culling mode, this factor reduces the amount of pop-in while also significantly reducing the number of spheres drawn.\n\n### Render the geometry\n\nFor convenience, the app stores all the matrices and colors for each object in a single array of `AAPLFrameDataPerObject` structures.\n\nThe vertex shader uses the `meshIndex` value to get the index to retrieve the matrices and colors for each object. During rendering, the following code shows both the `setVertexBytes` call to set the index and the `drawIndexedPrimitives` to draw the geometry.\n\n### Count the visible fragments\n\nThe fragment-counting mode of the app counts the number of fragments rendered for the green sphere. It has two main steps performed by the `updateFragmentCountingMode:` and `renderFragmentCountingMode:` methods. The update method sets the projection and view matrices and the color for the first object, the red sphere. Then it sets up the matrices and color for the second object, the green sphere. Next comes the rendering phase in the `renderFragmentCountingMode:` method. Before the app renders the frame, it reads the first element from the visibility result buffer and copies it to the `numVisibleFragments` property. The view controller uses this value to update the label.\n\nThe rendering process starts with configuring the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLRenderPassDescriptor\/visibilityResultBuffer] in the render pass descriptor to point to the current write buffer.\n\nNext, it sets the render pipeline, depth state, and per-frame constant data buffers. The following code shows how the renderer draws the red and green spheres. It uses the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLRenderCommandEncoder\/setVisibilityResultMode(_:offset:)] API to set the visibility result buffer mode to [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLVisibilityResultMode\/counting]. The offset into the buffer is defined by the constant `AAPLGreenSphereIndex` (which is set to `1`), that means that the second element gets the result. Then it encodes the green sphere. When rendering completes, the visibility result buffer contains the number of fragments that passed the depth and stencil tests.\n\n### Skip the draw calls with occlusion culling\n\nIn the occlusion-culling mode, the app uses the visibility result buffer to determine which spheres to draw. Then it disables depth writes (but not the depth test) and tests proxy geometry against the image to generate visibility results for the next frame. It counts the number of drawn spheres in the `numSpheresDrawn` property for the view controller to use to update the UI label. Like the first mode, there’s an update method `updateOcclusionCullingMode:` that sets the projection and model-view matrices and the color for each sphere.\n\nThe `renderOcclusionCullingMode:` method divides the occlusion testing into two parts: rendering the spheres and performing the occlusion query. In the following code, the app draws sphere `i` if the value `isVisibleResult[i]` is not zero.\n\nAfter this loop, the occlusion query stage begins. First, the draw code disables color and depth writes using the `_pipelineStateNoRender` pipeline state object and the `_depthStateDisableWrites` depth stencil state. In addition, the `_pipelineStateNoRender` object doesn’t have a fragment function because fragment processing isn’t necessary to get visibility results.\n\nThen the render method encodes all the icosahedron draw calls. It calculates the offset into the visibility result buffer by multiplying the index of the icosahedron with the size of a `uint64_t`.\n\nWhen Metal renders the frame, the GPU updates the visibility result buffer with a nonzero value if any fragment passes the depth and stencil test. Drawing with proxy geometry allows the testing to remain efficient.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Metal\/culling-occluded-geometry-using-the-visibility-result-buffer\ncrawled: 2025-12-02T15:49:20Z\n---\n\n# Culling occluded geometry using the visibility result buffer\n\n**Sample Code**\n\nDraw a scene without rendering hidden geometry by checking whether each object in the scene is visible.\n\n## Overview\n\nThis sample demonstrates how to use a visibility result buffer to perform *fragment counting* and *occlusion culling*. The visibility result buffer stores an array of integers that contain the number of times a fragment passes the depth and stencil tests. Before a draw call, the app sets the location of the 64-bit counter in the buffer and the hardware increments the counter during rasterization.\n\nThe first mode of the app shows how to use fragment counting to determine the number of pixels that pass the depth and stencil tests. You can use this information to choose the level of detail for a 3D model, or to include or exclude the model from rendering. The second mode shows how to use the occlusion-culling technique to reduce the rendering load by eliminating invisible objects. To use this technique, the app renders a second pass of the objects it wants to test using proxy geometry instead of the full-resolution 3D model. It skips any object in the next frame if the number of pixels that passed the depth test is zero. You can toggle between the two modes by using the segment control in the upper-left corner of the window.\n\nThe fragment-counting mode shows a stationary red sphere and a smaller green sphere, and counts the number of fragments rendered for the green sphere. The slider on the lower-left corner of the app moves the green sphere left and right. The top-right corner of the window shows the number of fragments drawn from the green sphere. The number of fragments decrease to zero as the red sphere occludes the green sphere.\n\n\n\nThe occlusion-culling mode is more complex, rendering multiple spheres and using the visibility results to skip the draw calls for occluded spheres. It renders *icosahedrons*, a 20-sided polyhedron serving as a type of proxy geometry for a sphere, to the previous frame. If the fragment count is zero because it’s *occluded* (hidden), the renderer *culls* (skips drawing) it in the next frame. The slider at the bottom left moves the spheres left and right, and the label in the upper right shows the number of rendered spheres.\n\n\n\nThe app creates Metal objects, renders 3D objects, and demonstrates two ways to use the visibility result buffer. First, it initializes the visibility result buffers and creates the sphere and icosahedron geometry. Next, it uses shared code to position and render the sphere and icosahedron geometry. Lastly, the app uses the state of the segment control to render either the fragment-counting mode or occlusion-culling mode.\n\n### Configure the sample code project\n\nTo run this sample, you need Xcode 12 and a physical device that supports [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLGPUFamily\/apple3], such as:\n\n- A Mac with Apple silicon running macOS 11 or later\n- An iOS device with an A9 chip or later running iOS 12 or later\n- A tvOS device with an A12 chip or later running tvOS 13 or later\n\nThis sample can only run on a physical device because it uses the counting occlusion query features that Simulator doesn’t support.\n\n### Create the visibility result buffer\n\nAt initialization time, the app creates a set of visibility result buffers used in the fragment-counting and occlusion-culling modes. A visibility result buffer is an array of `uint64_t` integers stored in an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer]. The app allows up to three frames to be in flight with the `AAPLMaxBuffersInFlight` constant. However, if the app uses only a single buffer for recording and reading visibility results, a data race condition might occur if the GPU simultaneously writes to the visibility result buffer while the CPU reads from that same buffer. To prevent this, the app uses a ring of buffers that contains one more buffer than the number of frames in flight. The `AAPLNumVisibilityBuffers` constant stores this value. At the end of the `loadMetalWithView:` method, the app creates the buffers using the shared resource storage mode to allow CPU access.\n\n```objective-c\n\/\/ Initialize the visibility result buffers.\nfor (size_t i = 0; i < AAPLNumVisibilityBuffers; ++i)\n{\n    _visibilityBuffer[i] = [_device newBufferWithLength:AAPLNumObjectsXYZ * sizeof(uint64_t)\n                                                options:MTLResourceStorageModeShared];\n    _visibilityBuffer[i].label = @\"visibilitybuffer\";\n}\n```\n\nBefore rendering either of the two modes, the app chooses which visibility buffer to read from and write to. The `_visibilityBufferReadIndex` variable stores the index of the last completed visibility result buffer. The `_visibilityBufferWriteIndex` stores the index of the next visibility result buffer. The completion handler for the command buffer increments the read index as shown in the following code.\n\n```objective-c\n[commandBuffer addCompletedHandler:^(id<MTLCommandBuffer> buffer)\n {\n    \/\/ Avoid a data race condition by updating the visibility buffer's read index when the command buffer finishes.\n    self->_visibilityBufferReadIndex = (self->_visibilityBufferReadIndex + 1) % AAPLNumVisibilityBuffers;\n\n    \/\/ Allow the app to start another frame by dispatching the in-flight semaphore.\n    dispatch_semaphore_signal(block_sema);\n}];\n```\n\nBefore rendering, the `drawInMTKView:` method updates the current `_frameDataBuffer` and `_visibilityBuffer` indices for the frame. It also stores the pointer for the recently completed visibility result buffer in the `_readFromVisibilityResultBuffer` variable to use in both modes, as shown below.\n\n```objective-c\n\/\/ Update the state of the constant data buffers before rendering.\n_frameDataBufferIndex = (_frameDataBufferIndex + 1) % AAPLMaxBuffersInFlight;\n_visibilityBufferWriteIndex = (_visibilityBufferWriteIndex + 1) % AAPLNumVisibilityBuffers;\n\n\/\/ Read the visibility buffer result from the previous frame.\n_readFromVisibilityResultBuffer = _visibilityBuffer[_visibilityBufferReadIndex].contents;\n```\n\n### Create the proxy geometry\n\nFor the occlusion-culling mode, the app procedurally generates two geometric 3D primitives: a sphere and an icosahedron. The app uses an icosahedron as proxy geometry for the sphere in occlusion testing because it approximates a sphere using only 20 vertices.\n\nBecause proxy geometries are efficient to render, the occlusion culling uses them to quickly test visibility. If the visibility result buffer contains a nonzero value, the proxy geometry isn’t occluded and the app presumes the original geometry is also not occluded. However, to use proxy geometry for visibility testing, the 3D primitive needs to cover at least the same pixels as the original geometry. For the occlusion-culling mode, the app generates an icosahedron so that it fully inscribes (contains) a sphere.\n\nUsing proxy geometry that only covers the original model works well for stationary geometry but may not be sufficient for animated geometry. In the occlusion-culling mode, the sample uses the geometry visible in the current frame to determine the objects to draw on the next frame. This is an efficient approach for apps encoding work on the CPU. However, as objects change positions, the visibility results of one frame may not be accurate for the next frame, which may lead to objects popping in on subsequent frames.\n\nTo minimize this undesirable pop-in effect, the app scales the proxy geometry with an animation-adjustment factor. Increasing the size of the proxy geometry increases the screen area the app uses for testing the occluding geometry, making it less likely for the renderer to omit drawing occluded objects moving behind foreground objects that are visible in the next frame. Apps that choose larger-scale factors may reduce the amount of popping in but increase the draw count of occluded objects. Smaller-scale factors reduce the draw count but can cause objects farther away to pop into view more often.\n\nThe following code initializes the icosahedron radius by a scale factor of four. In the occlusion-culling mode, this factor reduces the amount of pop-in while also significantly reducing the number of spheres drawn.\n\n```objective-c\n\/\/\/ A sphere's radius that allows plenty of space between spheres with a grid spacing of two units.\nconst double sphereRadius = 0.7;\n\n\/\/\/ An adjustment factor that scales up the proxy geometry size.\n\/\/\/\n\/\/\/ The sample sets the factor small enough to avoid a \"pop in\" effect when the spheres move.\n\/\/\/ In other words, the sphere may not be visible in the current frame, but visible in the next.\n\/\/\/ For example, a sphere that's moving behind another sphere may cause the occlusion query to return `false`.\n\/\/\/ This causes the renderer to erroneously omit the sphere in the next frame.\n\/\/\/\n\/\/\/ The app uses a simple approach that sizes up the icosahedrons by an adjustment factor.\n\/\/\/ Sizing up the icosahedron gives each object extra pixels for the occlusion query to return `true`.\n\/\/\/ Since the renderer doesn't know exactly where the objects are located on the next frame,\n\/\/\/ this is like giving each object a little wiggle room.\n\/\/\/ If the adjustment value is too small, the renderer may not draw objects that are visible in the current frame.\n\/\/\/ If it's too large, then renderer may draw more spheres that are hidden by nearer spheres.\n\/\/\/ A lower value of `1` is best for a stationary scene and does not size up the proxy geometry.\n\/\/\/ A higher value of `8` sizes the proxy geometry significantly and reduces the occlusion query effectiveness.\nconst double animationAdjustmentFactor = 4;\n\n\/\/\/ An icosahedron size that's large enough to inscribe a sphere.\n\/\/\/\n\/\/\/ The icosahedron radius includes the previous animation adjustment.\nconst double icosahedronRadius = animationAdjustmentFactor * sphereRadius;\n```\n\n### Render the geometry\n\nFor convenience, the app stores all the matrices and colors for each object in a single array of `AAPLFrameDataPerObject` structures.\n\n```objective-c\ntypedef struct\n{\n    matrix_float4x4 modelViewMatrix;\n    matrix_float4x4 modelViewProjMatrix;\n    vector_float3 color;\n} AAPLFrameDataPerObject;\n\ntypedef struct\n{\n    AAPLFrameDataPerObject objects[AAPLNumObjectsXYZ];\n} AAPLFrameData;\n```\n\nThe vertex shader uses the `meshIndex` value to get the index to retrieve the matrices and colors for each object. During rendering, the following code shows both the `setVertexBytes` call to set the index and the `drawIndexedPrimitives` to draw the geometry.\n\n```objective-c\n\/\/\/ Renders a mesh and sets the index of the mesh so the shader can reference its appearance and location data.\n- (void)renderMeshWithIndex:(uint32_t)meshIndex\n{\n    [_renderEncoder setVertexBytes:&meshIndex\n                            length:sizeof(uint32_t)\n                           atIndex:AAPLBufferIndexMeshIndex];\n    [_renderEncoder drawIndexedPrimitives:MTLPrimitiveTypeTriangle\n                               indexCount:_curMeshIndexCount\n                                indexType:MTLIndexTypeUInt32\n                              indexBuffer:_curMeshIndexBuffer\n                        indexBufferOffset:0];\n}\n```\n\n### Count the visible fragments\n\nThe fragment-counting mode of the app counts the number of fragments rendered for the green sphere. It has two main steps performed by the `updateFragmentCountingMode:` and `renderFragmentCountingMode:` methods. The update method sets the projection and view matrices and the color for the first object, the red sphere. Then it sets up the matrices and color for the second object, the green sphere. Next comes the rendering phase in the `renderFragmentCountingMode:` method. Before the app renders the frame, it reads the first element from the visibility result buffer and copies it to the `numVisibleFragments` property. The view controller uses this value to update the label.\n\n```objective-c\nself->_numVisibleFragments = _readFromVisibilityResultBuffer[AAPLGreenSphereIndex];\n```\n\nThe rendering process starts with configuring the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLRenderPassDescriptor\/visibilityResultBuffer] in the render pass descriptor to point to the current write buffer.\n\n```objective-c\n\/\/ Add the visibility result buffer to this render pass.\nrenderPassDescriptor.visibilityResultBuffer = _visibilityBuffer[_visibilityBufferWriteIndex];\n\n\/\/ Create a render encoder for drawing.\n_renderEncoder = [commandBuffer renderCommandEncoderWithDescriptor:renderPassDescriptor];\n```\n\nNext, it sets the render pipeline, depth state, and per-frame constant data buffers. The following code shows how the renderer draws the red and green spheres. It uses the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLRenderCommandEncoder\/setVisibilityResultMode(_:offset:)] API to set the visibility result buffer mode to [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLVisibilityResultMode\/counting]. The offset into the buffer is defined by the constant `AAPLGreenSphereIndex` (which is set to `1`), that means that the second element gets the result. Then it encodes the green sphere. When rendering completes, the visibility result buffer contains the number of fragments that passed the depth and stencil tests.\n\n```objective-c\n\/\/ Encode the sphere's vertex data.\n[self setMeshBuffers:_sphereVertices indexBuffer:_sphereIndices indexCount:_sphereIndexCount];\n\n\/\/ Encode the red sphere mesh for drawing.\n[self renderMeshWithIndex:(uint32_t)AAPLRedSphereIndex];\n\n\/\/ Set the offset into the visibility result buffer.\n[_renderEncoder setVisibilityResultMode:MTLVisibilityResultModeCounting\n                                 offset:AAPLGreenSphereIndex * sizeof(uint64_t)];\n\n\/\/ Encode the green sphere for drawing.\n[self renderMeshWithIndex:(uint32_t)AAPLGreenSphereIndex];\n```\n\n### Skip the draw calls with occlusion culling\n\nIn the occlusion-culling mode, the app uses the visibility result buffer to determine which spheres to draw. Then it disables depth writes (but not the depth test) and tests proxy geometry against the image to generate visibility results for the next frame. It counts the number of drawn spheres in the `numSpheresDrawn` property for the view controller to use to update the UI label. Like the first mode, there’s an update method `updateOcclusionCullingMode:` that sets the projection and model-view matrices and the color for each sphere.\n\nThe `renderOcclusionCullingMode:` method divides the occlusion testing into two parts: rendering the spheres and performing the occlusion query. In the following code, the app draws sphere `i` if the value `isVisibleResult[i]` is not zero.\n\n```objective-c\n\/\/ Encode the sphere's vertex data.\n[self setMeshBuffers:_sphereVertices indexBuffer:_sphereIndices indexCount:_sphereIndexCount];\n\n\/\/ Draw a visible sphere for every corresponding visible icosahedron.\nfor (size_t i = 0; i < AAPLNumObjectsXYZ; ++i)\n{\n    \/\/ If an icosahedron is visible, draw the sphere.\n    if (_readFromVisibilityResultBuffer[i])\n    {\n        [self renderMeshWithIndex:(uint32_t)i];\n        numDrawCalls++;\n    }\n}\n```\n\nAfter this loop, the occlusion query stage begins. First, the draw code disables color and depth writes using the `_pipelineStateNoRender` pipeline state object and the `_depthStateDisableWrites` depth stencil state. In addition, the `_pipelineStateNoRender` object doesn’t have a fragment function because fragment processing isn’t necessary to get visibility results.\n\n```objective-c\n\/\/ Configure the pipeline state object and depth state to disable writing to the color and depth attachments.\n[_renderEncoder setRenderPipelineState:_pipelineStateNoRender];\n[_renderEncoder setDepthStencilState:_depthStateDisableWrites];\n```\n\nThen the render method encodes all the icosahedron draw calls. It calculates the offset into the visibility result buffer by multiplying the index of the icosahedron with the size of a `uint64_t`.\n\n```objective-c\n\/\/ Encode the icosahedron's vertices.\n[self setMeshBuffers:_icosahedronVertices indexBuffer:_icosahedronIndices indexCount:_icosahedronIndexCount];\n\n\/\/ Draw each icosahedron and check its visibility.\nfor (size_t i = 0; i < AAPLNumObjectsXYZ; ++i)\n{\n    [_renderEncoder setVisibilityResultMode:MTLVisibilityResultModeBoolean\n                                     offset:i * sizeof(uint64_t)];\n    [self renderMeshWithIndex:(uint32_t)i];\n}\n```\n\nWhen Metal renders the frame, the GPU updates the visibility result buffer with a nonzero value if any fragment passes the depth and stencil test. Drawing with proxy geometry allows the testing to remain efficient.\n\n## Render workflows\n\n- **Using Metal to draw a view’s contents**: Create a MetalKit view and a render pass to draw the view’s contents.\n- **Drawing a triangle with Metal 4**: Render a colorful, rotating 2D triangle by running draw commands with a render pipeline on a GPU.\n- **Selecting device objects for graphics rendering**: Switch dynamically between multiple GPUs to efficiently render to a display.\n- **Customizing render pass setup**: Render into an offscreen texture by creating a custom render pass.\n- **Creating a custom Metal view**: Implement a lightweight view for Metal rendering that’s customized to your app’s needs.\n- **Calculating primitive visibility using depth testing**: Determine which pixels are visible in a scene by using a depth texture.\n- **Encoding indirect command buffers on the CPU**: Reduce CPU overhead and simplify your command execution by reusing commands.\n- **Implementing order-independent transparency with image blocks**: Draw overlapping, transparent surfaces in any order by using tile shaders and image blocks.\n- **Loading textures and models using Metal fast resource loading**: Stream texture and buffer data directly from disk into Metal resources using fast resource loading.\n- **Adjusting the level of detail using Metal mesh shaders**: Choose and render meshes with several levels of detail using object and mesh shaders.\n- **Creating a 3D application with hydra rendering**: Build a 3D application that integrates with Hydra and USD.\n- **Improving edge-rendering quality with multisample antialiasing (MSAA)**: Apply MSAA to enhance the rendering of edges with custom resolve options and immediate and tile-based resolve paths.\n- **Achieving smooth frame rates with a Metal display link**: Pace rendering with minimal input latency while providing essential information to the operating system for power-efficient rendering, thermal mitigation, and the scheduling of sustainable workloads.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create a MetalKit view and a render pass to draw the view’s contents.",
          "name" : "Using Metal to draw a view’s contents",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/using-metal-to-draw-a-view's-contents"
        },
        {
          "description" : "Render a colorful, rotating 2D triangle by running draw commands with a render pipeline on a GPU.",
          "name" : "Drawing a triangle with Metal 4",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/drawing-a-triangle-with-metal-4"
        },
        {
          "description" : "Switch dynamically between multiple GPUs to efficiently render to a display.",
          "name" : "Selecting device objects for graphics rendering",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/selecting-device-objects-for-graphics-rendering"
        },
        {
          "description" : "Render into an offscreen texture by creating a custom render pass.",
          "name" : "Customizing render pass setup",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/customizing-render-pass-setup"
        },
        {
          "description" : "Implement a lightweight view for Metal rendering that’s customized to your app’s needs.",
          "name" : "Creating a custom Metal view",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/creating-a-custom-metal-view"
        },
        {
          "description" : "Determine which pixels are visible in a scene by using a depth texture.",
          "name" : "Calculating primitive visibility using depth testing",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/calculating-primitive-visibility-using-depth-testing"
        },
        {
          "description" : "Reduce CPU overhead and simplify your command execution by reusing commands.",
          "name" : "Encoding indirect command buffers on the CPU",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/encoding-indirect-command-buffers-on-the-cpu"
        },
        {
          "description" : "Draw overlapping, transparent surfaces in any order by using tile shaders and image blocks.",
          "name" : "Implementing order-independent transparency with image blocks",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/implementing-order-independent-transparency-with-image-blocks"
        },
        {
          "description" : "Stream texture and buffer data directly from disk into Metal resources using fast resource loading.",
          "name" : "Loading textures and models using Metal fast resource loading",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/loading-textures-and-models-using-metal-fast-resource-loading"
        },
        {
          "description" : "Choose and render meshes with several levels of detail using object and mesh shaders.",
          "name" : "Adjusting the level of detail using Metal mesh shaders",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/adjusting-the-level-of-detail-using-metal-mesh-shaders"
        },
        {
          "description" : "Build a 3D application that integrates with Hydra and USD.",
          "name" : "Creating a 3D application with hydra rendering",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/creating-a-3d-application-with-hydra-rendering"
        },
        {
          "description" : "Apply MSAA to enhance the rendering of edges with custom resolve options and immediate and tile-based resolve paths.",
          "name" : "Improving edge-rendering quality with multisample antialiasing (MSAA)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/improving-edge-rendering-quality-with-multisample-antialiasing-msaa"
        },
        {
          "description" : "Pace rendering with minimal input latency while providing essential information to the operating system for power-efficient rendering, thermal mitigation, and the scheduling of sustainable workloads.",
          "name" : "Achieving smooth frame rates with a Metal display link",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/achieving-smooth-frame-rates-with-a-metal-display-link"
        }
      ],
      "title" : "Render workflows"
    }
  ],
  "source" : "appleJSON",
  "title" : "Culling occluded geometry using the visibility result buffer",
  "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/culling-occluded-geometry-using-the-visibility-result-buffer"
}