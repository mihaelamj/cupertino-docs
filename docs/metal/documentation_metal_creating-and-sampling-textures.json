{
  "abstract" : "Load image data into a texture and apply it to a quadrangle.",
  "codeExamples" : [
    {
      "code" : "\/\/ Initialize a source pointer with the source image data that's in BGR form\nuint8_t *srcImageData = ((uint8_t*)fileData.bytes +\n                         sizeof(TGAHeader) +\n                         tgaInfo->IDSize);\n\n\/\/ Initialize a destination pointer to which you'll store the converted BGRA\n\/\/ image data\nuint8_t *dstImageData = mutableData.mutableBytes;\n\n\/\/ For every row of the image\nfor(NSUInteger y = 0; y < _height; y++)\n{\n    \/\/ If bit 5 of the descriptor is not set, flip vertically\n    \/\/ to transform the data to the Metal texture origin, which is the top-left.\n    NSUInteger srcRow = (tgaInfo->topOrigin) ? y : _height - 1 - y;\n\n    \/\/ For every column of the current row\n    for(NSUInteger x = 0; x < _width; x++)\n    {\n        \/\/ If bit 4 of the descriptor is set, flip horizontally\n        \/\/ to transform the data to the Metal texture origin, which is the top-left.\n        NSUInteger srcColumn = (tgaInfo->rightOrigin) ? _width - 1 - x : x;\n\n        \/\/ Calculate the index for the first byte of the pixel you're\n        \/\/ converting in both the source and destination images\n        NSUInteger srcPixelIndex = srcBytesPerPixel * (srcRow * _width + srcColumn);\n        NSUInteger dstPixelIndex = 4 * (y * _width + x);\n\n        \/\/ Copy BGR channels from the source to the destination\n        \/\/ Set the alpha channel of the destination pixel to 255\n        dstImageData[dstPixelIndex + 0] = srcImageData[srcPixelIndex + 0];\n        dstImageData[dstPixelIndex + 1] = srcImageData[srcPixelIndex + 1];\n        dstImageData[dstPixelIndex + 2] = srcImageData[srcPixelIndex + 2];\n\n        if(tgaInfo->bitsPerPixel == 32)\n        {\n            dstImageData[dstPixelIndex + 3] =  srcImageData[srcPixelIndex + 3];\n        }\n        else\n        {\n            dstImageData[dstPixelIndex + 3] = 255;\n        }\n    }\n}\n_data = mutableData;",
      "language" : "objective-c"
    },
    {
      "code" : "MTLTextureDescriptor *textureDescriptor = [[MTLTextureDescriptor alloc] init];\n\n\/\/ Indicate that each pixel has a blue, green, red, and alpha channel, where each channel is\n\/\/ an 8-bit unsigned normalized value (i.e. 0 maps to 0.0 and 255 maps to 1.0)\ntextureDescriptor.pixelFormat = MTLPixelFormatBGRA8Unorm;\n\n\/\/ Set the pixel dimensions of the texture\ntextureDescriptor.width = image.width;\ntextureDescriptor.height = image.height;\n\n\/\/ Create the texture from the device by using the descriptor\nid<MTLTexture> texture = [_device newTextureWithDescriptor:textureDescriptor];",
      "language" : "objective-c"
    },
    {
      "code" : "MTLRegion region = {\n    { 0, 0, 0 },                   \/\/ MTLOrigin\n    {image.width, image.height, 1} \/\/ MTLSize\n};",
      "language" : "objective-c"
    },
    {
      "code" : "NSUInteger bytesPerRow = 4 * image.width;",
      "language" : "objective-c"
    },
    {
      "code" : "[texture replaceRegion:region\n            mipmapLevel:0\n              withBytes:image.data.bytes\n            bytesPerRow:bytesPerRow];",
      "language" : "objective-c"
    },
    {
      "code" : "typedef struct\n{\n    \/\/ Positions in pixel space. A value of 100 indicates 100 pixels from the origin\/center.\n    vector_float2 position;\n\n    \/\/ 2D texture coordinate\n    vector_float2 textureCoordinate;\n} AAPLVertex;",
      "language" : "objective-c"
    },
    {
      "code" : "static const AAPLVertex quadVertices[] =\n{\n    \/\/ Pixel positions, Texture coordinates\n    { {  250,  -250 },  { 1.f, 1.f } },\n    { { -250,  -250 },  { 0.f, 1.f } },\n    { { -250,   250 },  { 0.f, 0.f } },\n\n    { {  250,  -250 },  { 1.f, 1.f } },\n    { { -250,   250 },  { 0.f, 0.f } },\n    { {  250,   250 },  { 1.f, 0.f } },\n};",
      "language" : "objective-c"
    },
    {
      "code" : "struct RasterizerData\n{\n    \/\/ The [[position]] attribute qualifier of this member indicates this value is\n    \/\/ the clip space position of the vertex when this structure is returned from\n    \/\/ the vertex shader\n    float4 position [[position]];\n\n    \/\/ Since this member does not have a special attribute qualifier, the rasterizer\n    \/\/ will interpolate its value with values of other vertices making up the triangle\n    \/\/ and pass that interpolated value to the fragment shader for each fragment in\n    \/\/ that triangle.\n    float2 textureCoordinate;\n\n};",
      "language" : "metal"
    },
    {
      "code" : "out.textureCoordinate = vertexArray[vertexID].textureCoordinate;",
      "language" : "metal"
    },
    {
      "code" : "fragment float4\nsamplingShader(RasterizerData in [[stage_in]],\n               texture2d<half> colorTexture [[ texture(AAPLTextureIndexBaseColor) ]])",
      "language" : "metal"
    },
    {
      "code" : "constexpr sampler textureSampler (mag_filter::linear,\n                                  min_filter::linear);\n\n\/\/ Sample the texture to obtain a color\nconst half4 colorSample = colorTexture.sample(textureSampler, in.textureCoordinate);",
      "language" : "metal"
    },
    {
      "code" : "[renderEncoder setFragmentTexture:_texture\n                          atIndex:AAPLTextureIndexBaseColor];",
      "language" : "objective-c"
    }
  ],
  "contentHash" : "57bd3793ef7c464f0401fbcd44a2e57d7fde857888471525a133aed4a7e5557e",
  "crawledAt" : "2025-12-02T15:49:19Z",
  "id" : "738DD115-0B90-4188-B4AD-5DE24B1AFF88",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Metal",
  "overview" : "## Overview\n\nYou use textures to draw and process images in Metal. A texture is a structured collection of texture elements, often called *texels* or *pixels*. The exact configuration of these texture elements depends on the type of texture. This sample uses a texture structured as a 2D array of elements, each of which contains color data, to hold an image. The texture is drawn onto geometric primitives through a process called *texture mapping*. The fragment function generates colors for each fragment by sampling the texture.\n\nTextures are managed by `MTLTexture` objects. A `MTLTexture` object defines the texture’s format, including the size and layout of elements, the number of elements in the texture, and how those elements are organized. Once created, a texture’s format and organization never change. However, you can change the contents of the texture, either by rendering to it or copying data into it.\n\nThe Metal framework doesn’t provide an API to directly load image data from a file to a texture. Metal itself only allocates texture resources and provides methods that copy data to and from the texture. Metal apps rely on custom code or other frameworks, like MetalKit, Image I\/O, UIKit, or AppKit, to handle image files. For example, you can use [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKTextureLoader] to perform simple texture loading. This sample shows how to write a custom texture loader.\n\n### Load and format image data\n\nYou can create a texture or update its contents manually, a process that’s covered in the next few sections. You might do this for multiple reasons:\n\nIn the sample, the `AAPLImage` class loads and parses image data from TGA files. The class converts pixel data from the TGA file into a pixel format that Metal understands. The sample uses the image’s metadata to create a new Metal texture and copies the pixel data into the texture.\n\nMetal requires all textures to be formatted with a specific [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLPixelFormat] value. The pixel format describes the layout of pixel data in the texture. This sample uses the `MTLPixelFormat\/bgra8Unorm` pixel format, which uses 32 bits per pixel, arranged into 8 bits per component, in blue, green, red, and alpha order:\n\n\n\nBefore you can populate a Metal texture, you need to format the image data into the texture’s pixel format. TGA files can provide pixel data either in a 32-bit-per-pixel format or a 24-bit-per-pixel format. TGA files that use 32 bits per pixel are already arranged in this format, so you just copy the pixel data. To convert a 24-bit-per-pixel BGR image, copy the red, green, and blue channels and set the alpha channel to 255, indicating a fully opaque pixel.\n\n### Create a texture from a texture descriptor\n\nUse an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLTextureDescriptor] object to configure properties like texture dimensions and pixel format for an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLTexture] object. Then call the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice\/makeTexture(descriptor:)] method to create a texture.\n\nMetal creates an `MTLTexture` object and allocates memory for the texture data. This memory is uninitialized when the texture is created, so the next step is to copy your data into the texture.\n\n### Copy the image data into the texture\n\nMetal manages memory for textures and doesn’t provide you direct access to it. So you can’t get a pointer to the texture data in memory and copy the pixels yourself. Instead, you call methods on an `MTLTexture` object to copy data from memory you can access into the texture and vice versa.\n\nIn this sample, the `AAPLImage` object allocated memory for the image data, so you’ll tell the texture object to copy this data.\n\nUse a `MTLRegion` structure to identify which part of the texture you want to update. This sample populates the entire texture with image data; so create a region that covers the entire texture.\n\nImage data is typically organized in rows, and you need to tell Metal the offset between rows in the source image. The image loading code creates image data in a *tightly packed* format, so the data of subsequent pixel rows immediately follows the previous row. Calculate the offset between rows to be the exact length (in bytes) of a row — the number of bytes per pixel multiplied by the image width.\n\nCall the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLTexture\/replace(region:mipmapLevel:withBytes:bytesPerRow:)] method on the texture to copy pixel data from the `AAPLImage` object into the texture.\n\n### Map the texture onto a geometric primitive\n\nYou can’t render a texture on its own; you need to map it onto geometric primitives (in this example, a pair of triangles) that are output by the vertex stage and turned into fragments by the rasterizer. Each fragment needs to know which part of the texture should be applied to it. You define this mapping with *texture coordinates*: floating-point positions that map locations on a texture image to locations on the geometric surface.\n\nFor 2D textures, normalized texture coordinates are values from 0.0 to 1.0 in both x and y directions. A value of (0.0, 0.0) specifies the texel at the first byte of the texture data (the top-left corner of the image). A value of (1.0, 1.0) specifies the texel at the last byte of the texture data (the bottom-right corner of the image).\n\n\n\nAdd a field to the vertex format to hold texture coordinates:\n\nIn the vertex data, map the quad’s corners to the texture’s corners:\n\nTo send the texture coordinates to the fragment shader, add a `textureCoordinate` value to the `RasterizerData` data structure:\n\nIn the vertex shader, pass the texture coordinates to the rasterizer stage by writing them into the `textureCoordinate` field. The rasterizer stage interpolates these coordinates across the quad’s triangle fragments.\n\n### Calculate a color from a location in the texture\n\nYou sample a texture to calculate a color from a location in the texture. To sample the texture data, the fragment function needs the texture coordinates and a reference to the texture to sample. In addition to the arguments passed in from the rasterizer stage, pass in a `colorTexture` argument with a `texture2d` type and the `[[texture(index)]]` attribute qualifier. This argument is a reference to the `MTLTexture` object to be sampled.\n\nUse the built-in texture `sample()` function to sample texel data. The `sample()` function takes two arguments: a sampler (`textureSampler`) that describes how you want to sample the texture, and texture coordinates (`in.textureCoordinate`) that describe the position in the texture to sample. The `sample()` function fetches one or more pixels from the texture and returns a color calculated from those pixels.\n\nWhen the area being rendered to isn’t the same size as the texture, the sampler can use different algorithms to calculate exactly what texel color the `sample()` function should return. Set the `mag_filter` mode to specify how the sampler should calculate the returned color when the area is larger than the size of the texture, and the `min_filter` mode to specify how the sampler should calculate the returned color when the area is smaller than the size of the texture. Setting a `linear` mode for both filters makes the sampler average the color of pixels surrounding the given texture coordinate, resulting in a smoother output image.\n\n### Encode the draw parameters\n\nThe process for encoding and submitting drawing commands is the same as that shown in Using a Render Pipeline to Render Primitives, so the complete code is not shown below. The difference in this sample is that the fragment shader has an additional parameter. When you encode the command’s arguments, set the fragment function’s texture argument. This sample uses the `AAPLTextureIndexBaseColor` index to identify the texture in both Objective-C and Metal Shading Language code.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Metal\/creating-and-sampling-textures\ncrawled: 2025-12-02T15:49:19Z\n---\n\n# Creating and sampling textures\n\n**Sample Code**\n\nLoad image data into a texture and apply it to a quadrangle.\n\n## Overview\n\nYou use textures to draw and process images in Metal. A texture is a structured collection of texture elements, often called *texels* or *pixels*. The exact configuration of these texture elements depends on the type of texture. This sample uses a texture structured as a 2D array of elements, each of which contains color data, to hold an image. The texture is drawn onto geometric primitives through a process called *texture mapping*. The fragment function generates colors for each fragment by sampling the texture.\n\nTextures are managed by `MTLTexture` objects. A `MTLTexture` object defines the texture’s format, including the size and layout of elements, the number of elements in the texture, and how those elements are organized. Once created, a texture’s format and organization never change. However, you can change the contents of the texture, either by rendering to it or copying data into it.\n\nThe Metal framework doesn’t provide an API to directly load image data from a file to a texture. Metal itself only allocates texture resources and provides methods that copy data to and from the texture. Metal apps rely on custom code or other frameworks, like MetalKit, Image I\/O, UIKit, or AppKit, to handle image files. For example, you can use [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKTextureLoader] to perform simple texture loading. This sample shows how to write a custom texture loader.\n\n\n\n### Load and format image data\n\nYou can create a texture or update its contents manually, a process that’s covered in the next few sections. You might do this for multiple reasons:\n\n- You have image data stored in a custom format.\n- You have textures whose contents need to be generated at runtime.\n- You are streaming texture data from a server or otherwise need to dynamically update a texture’s contents.\n\nIn the sample, the `AAPLImage` class loads and parses image data from TGA files. The class converts pixel data from the TGA file into a pixel format that Metal understands. The sample uses the image’s metadata to create a new Metal texture and copies the pixel data into the texture.\n\n\n\nMetal requires all textures to be formatted with a specific [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLPixelFormat] value. The pixel format describes the layout of pixel data in the texture. This sample uses the `MTLPixelFormat\/bgra8Unorm` pixel format, which uses 32 bits per pixel, arranged into 8 bits per component, in blue, green, red, and alpha order:\n\n\n\nBefore you can populate a Metal texture, you need to format the image data into the texture’s pixel format. TGA files can provide pixel data either in a 32-bit-per-pixel format or a 24-bit-per-pixel format. TGA files that use 32 bits per pixel are already arranged in this format, so you just copy the pixel data. To convert a 24-bit-per-pixel BGR image, copy the red, green, and blue channels and set the alpha channel to 255, indicating a fully opaque pixel.\n\n```objective-c\n\/\/ Initialize a source pointer with the source image data that's in BGR form\nuint8_t *srcImageData = ((uint8_t*)fileData.bytes +\n                         sizeof(TGAHeader) +\n                         tgaInfo->IDSize);\n\n\/\/ Initialize a destination pointer to which you'll store the converted BGRA\n\/\/ image data\nuint8_t *dstImageData = mutableData.mutableBytes;\n\n\/\/ For every row of the image\nfor(NSUInteger y = 0; y < _height; y++)\n{\n    \/\/ If bit 5 of the descriptor is not set, flip vertically\n    \/\/ to transform the data to the Metal texture origin, which is the top-left.\n    NSUInteger srcRow = (tgaInfo->topOrigin) ? y : _height - 1 - y;\n\n    \/\/ For every column of the current row\n    for(NSUInteger x = 0; x < _width; x++)\n    {\n        \/\/ If bit 4 of the descriptor is set, flip horizontally\n        \/\/ to transform the data to the Metal texture origin, which is the top-left.\n        NSUInteger srcColumn = (tgaInfo->rightOrigin) ? _width - 1 - x : x;\n\n        \/\/ Calculate the index for the first byte of the pixel you're\n        \/\/ converting in both the source and destination images\n        NSUInteger srcPixelIndex = srcBytesPerPixel * (srcRow * _width + srcColumn);\n        NSUInteger dstPixelIndex = 4 * (y * _width + x);\n\n        \/\/ Copy BGR channels from the source to the destination\n        \/\/ Set the alpha channel of the destination pixel to 255\n        dstImageData[dstPixelIndex + 0] = srcImageData[srcPixelIndex + 0];\n        dstImageData[dstPixelIndex + 1] = srcImageData[srcPixelIndex + 1];\n        dstImageData[dstPixelIndex + 2] = srcImageData[srcPixelIndex + 2];\n\n        if(tgaInfo->bitsPerPixel == 32)\n        {\n            dstImageData[dstPixelIndex + 3] =  srcImageData[srcPixelIndex + 3];\n        }\n        else\n        {\n            dstImageData[dstPixelIndex + 3] = 255;\n        }\n    }\n}\n_data = mutableData;\n```\n\n### Create a texture from a texture descriptor\n\nUse an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLTextureDescriptor] object to configure properties like texture dimensions and pixel format for an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLTexture] object. Then call the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice\/makeTexture(descriptor:)] method to create a texture.\n\n```objective-c\nMTLTextureDescriptor *textureDescriptor = [[MTLTextureDescriptor alloc] init];\n\n\/\/ Indicate that each pixel has a blue, green, red, and alpha channel, where each channel is\n\/\/ an 8-bit unsigned normalized value (i.e. 0 maps to 0.0 and 255 maps to 1.0)\ntextureDescriptor.pixelFormat = MTLPixelFormatBGRA8Unorm;\n\n\/\/ Set the pixel dimensions of the texture\ntextureDescriptor.width = image.width;\ntextureDescriptor.height = image.height;\n\n\/\/ Create the texture from the device by using the descriptor\nid<MTLTexture> texture = [_device newTextureWithDescriptor:textureDescriptor];\n```\n\nMetal creates an `MTLTexture` object and allocates memory for the texture data. This memory is uninitialized when the texture is created, so the next step is to copy your data into the texture.\n\n### Copy the image data into the texture\n\nMetal manages memory for textures and doesn’t provide you direct access to it. So you can’t get a pointer to the texture data in memory and copy the pixels yourself. Instead, you call methods on an `MTLTexture` object to copy data from memory you can access into the texture and vice versa.\n\nIn this sample, the `AAPLImage` object allocated memory for the image data, so you’ll tell the texture object to copy this data.\n\nUse a `MTLRegion` structure to identify which part of the texture you want to update. This sample populates the entire texture with image data; so create a region that covers the entire texture.\n\n```objective-c\nMTLRegion region = {\n    { 0, 0, 0 },                   \/\/ MTLOrigin\n    {image.width, image.height, 1} \/\/ MTLSize\n};\n```\n\nImage data is typically organized in rows, and you need to tell Metal the offset between rows in the source image. The image loading code creates image data in a *tightly packed* format, so the data of subsequent pixel rows immediately follows the previous row. Calculate the offset between rows to be the exact length (in bytes) of a row — the number of bytes per pixel multiplied by the image width.\n\n```objective-c\nNSUInteger bytesPerRow = 4 * image.width;\n```\n\nCall the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLTexture\/replace(region:mipmapLevel:withBytes:bytesPerRow:)] method on the texture to copy pixel data from the `AAPLImage` object into the texture.\n\n```objective-c\n[texture replaceRegion:region\n            mipmapLevel:0\n              withBytes:image.data.bytes\n            bytesPerRow:bytesPerRow];\n```\n\n### Map the texture onto a geometric primitive\n\nYou can’t render a texture on its own; you need to map it onto geometric primitives (in this example, a pair of triangles) that are output by the vertex stage and turned into fragments by the rasterizer. Each fragment needs to know which part of the texture should be applied to it. You define this mapping with *texture coordinates*: floating-point positions that map locations on a texture image to locations on the geometric surface.\n\nFor 2D textures, normalized texture coordinates are values from 0.0 to 1.0 in both x and y directions. A value of (0.0, 0.0) specifies the texel at the first byte of the texture data (the top-left corner of the image). A value of (1.0, 1.0) specifies the texel at the last byte of the texture data (the bottom-right corner of the image).\n\n\n\nAdd a field to the vertex format to hold texture coordinates:\n\n```objective-c\ntypedef struct\n{\n    \/\/ Positions in pixel space. A value of 100 indicates 100 pixels from the origin\/center.\n    vector_float2 position;\n\n    \/\/ 2D texture coordinate\n    vector_float2 textureCoordinate;\n} AAPLVertex;\n```\n\nIn the vertex data, map the quad’s corners to the texture’s corners:\n\n```objective-c\nstatic const AAPLVertex quadVertices[] =\n{\n    \/\/ Pixel positions, Texture coordinates\n    { {  250,  -250 },  { 1.f, 1.f } },\n    { { -250,  -250 },  { 0.f, 1.f } },\n    { { -250,   250 },  { 0.f, 0.f } },\n\n    { {  250,  -250 },  { 1.f, 1.f } },\n    { { -250,   250 },  { 0.f, 0.f } },\n    { {  250,   250 },  { 1.f, 0.f } },\n};\n```\n\nTo send the texture coordinates to the fragment shader, add a `textureCoordinate` value to the `RasterizerData` data structure:\n\n```metal\nstruct RasterizerData\n{\n    \/\/ The [[position]] attribute qualifier of this member indicates this value is\n    \/\/ the clip space position of the vertex when this structure is returned from\n    \/\/ the vertex shader\n    float4 position [[position]];\n\n    \/\/ Since this member does not have a special attribute qualifier, the rasterizer\n    \/\/ will interpolate its value with values of other vertices making up the triangle\n    \/\/ and pass that interpolated value to the fragment shader for each fragment in\n    \/\/ that triangle.\n    float2 textureCoordinate;\n\n};\n```\n\nIn the vertex shader, pass the texture coordinates to the rasterizer stage by writing them into the `textureCoordinate` field. The rasterizer stage interpolates these coordinates across the quad’s triangle fragments.\n\n```metal\nout.textureCoordinate = vertexArray[vertexID].textureCoordinate;\n```\n\n### Calculate a color from a location in the texture\n\nYou sample a texture to calculate a color from a location in the texture. To sample the texture data, the fragment function needs the texture coordinates and a reference to the texture to sample. In addition to the arguments passed in from the rasterizer stage, pass in a `colorTexture` argument with a `texture2d` type and the `[[texture(index)]]` attribute qualifier. This argument is a reference to the `MTLTexture` object to be sampled.\n\n```metal\nfragment float4\nsamplingShader(RasterizerData in [[stage_in]],\n               texture2d<half> colorTexture [[ texture(AAPLTextureIndexBaseColor) ]])\n```\n\nUse the built-in texture `sample()` function to sample texel data. The `sample()` function takes two arguments: a sampler (`textureSampler`) that describes how you want to sample the texture, and texture coordinates (`in.textureCoordinate`) that describe the position in the texture to sample. The `sample()` function fetches one or more pixels from the texture and returns a color calculated from those pixels.\n\nWhen the area being rendered to isn’t the same size as the texture, the sampler can use different algorithms to calculate exactly what texel color the `sample()` function should return. Set the `mag_filter` mode to specify how the sampler should calculate the returned color when the area is larger than the size of the texture, and the `min_filter` mode to specify how the sampler should calculate the returned color when the area is smaller than the size of the texture. Setting a `linear` mode for both filters makes the sampler average the color of pixels surrounding the given texture coordinate, resulting in a smoother output image.\n\n```metal\nconstexpr sampler textureSampler (mag_filter::linear,\n                                  min_filter::linear);\n\n\/\/ Sample the texture to obtain a color\nconst half4 colorSample = colorTexture.sample(textureSampler, in.textureCoordinate);\n```\n\n\n\n### Encode the draw parameters\n\nThe process for encoding and submitting drawing commands is the same as that shown in Using a Render Pipeline to Render Primitives, so the complete code is not shown below. The difference in this sample is that the fragment shader has an additional parameter. When you encode the command’s arguments, set the fragment function’s texture argument. This sample uses the `AAPLTextureIndexBaseColor` index to identify the texture in both Objective-C and Metal Shading Language code.\n\n```objective-c\n[renderEncoder setFragmentTexture:_texture\n                          atIndex:AAPLTextureIndexBaseColor];\n```\n\n## Textures\n\n- **Processing a texture in a compute function**: Create textures by running copy and dispatch commands in a compute pass on a GPU.\n- **Reading pixel data from a drawable texture**: Access texture data from the CPU by copying it to a buffer.\n- **Streaming large images with Metal sparse textures**: Limit texture memory usage for large textures by loading or unloading image detail on the basis of MIP and tile region.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create textures by running copy and dispatch commands in a compute pass on a GPU.",
          "name" : "Processing a texture in a compute function",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/processing-a-texture-in-a-compute-function"
        },
        {
          "description" : "Access texture data from the CPU by copying it to a buffer.",
          "name" : "Reading pixel data from a drawable texture",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/reading-pixel-data-from-a-drawable-texture"
        },
        {
          "description" : "Limit texture memory usage for large textures by loading or unloading image detail on the basis of MIP and tile region.",
          "name" : "Streaming large images with Metal sparse textures",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/streaming-large-images-with-metal-sparse-textures"
        }
      ],
      "title" : "Textures"
    }
  ],
  "source" : "appleJSON",
  "title" : "Creating and sampling textures",
  "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/creating-and-sampling-textures"
}