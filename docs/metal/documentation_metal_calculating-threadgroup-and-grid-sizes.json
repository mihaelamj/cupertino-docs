{
  "abstract" : "Calculate the optimum sizes for threadgroups and grids when dispatching compute-processing workloads.",
  "codeExamples" : [
    {
      "code" : "kernel void\nsimpleKernelFunction(texture2d<float, access::write> outputTexture [[texture(0)]],\n                     uint2 position [[thread_position_in_grid]]) {\n    \n    if (position.x >= outputTexture.get_width() || position.y >= outputTexture.get_height()) {\n        return;\n    }\n    \n    outputTexture.write(float4(1.0), position);\n}",
      "language" : "metal"
    }
  ],
  "contentHash" : "6676c86f5361f882185ded7a36d0ccf24a951bc69e464c6f5625561f3faf7274",
  "crawledAt" : "2025-12-02T05:46:38Z",
  "id" : "ECB3D48F-36D2-459A-ACC7-601C4A7E96B6",
  "kind" : "article",
  "module" : "Metal",
  "overview" : "## Overview\n\nYou can ensure your app doesn’t underuse threads by specifying the size of the grid and the number of threads per threadgroup. In iOS 11 and macOS 10.13 and later on devices that support nonuniform dispatch sizes, Metal calculates the number of threadgroups and provides nonuniform threadgroups if the grid size isn’t a multiple of the threadgroup size.\n\nIn earlier versions of iOS and macOS, you specify the size and number of the threadgroups. Metal composes grids of uniform threadgroups that may not match the size of your data. You can ensure your kernel code doesn’t execute outside the bounds of the data by adding defensive code to it.\n\n### Calculate threads per threadgroup\n\nYou calculate the number of threads per threadgroup based on two [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState] properties:\n\nFor example, consider a compute pipeline state with `512` maximum threads per threadgroup and a thread execution width of `16`. For that compute pipeline state, you can launch the largest possible threadgroup by setting the following:\n\nOn devices that support nonuniform threadgroup sizes, Metal divides a grid into nonuniform, arbitrarily sized threadgroups, such as for an image or texture. The compute command encoder’s [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputeCommandEncoder\/dispatchThreads(_:threadsPerThreadgroup:)] method requires the total number of threads because each thread corresponds to a single pixel.\n\nWhen Metal performs this calculation, it can generate smaller threadgroups along the edges of your grid. Compared to uniform threadgroups, this technique simplifies kernel code and improves GPU performance.\n\nTo determine if a device supports nonuniform threadgroups, see [https:\/\/developer.apple.com\/metal\/Metal-Feature-Set-Tables.pdf]\n\n\n\n### Calculate threadgroups per grid\n\nIf you need fine control over the size and number of threadgroups, you can manually calculate how to divide the grid. In your code, ensure that there are sufficient threadgroups to cover the entire image.\n\nFor a texture that’s 1024 by 768 pixels in size, the code above returns an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLSize] instance with a width of `32`, a height of `48`, and a depth of `1`. These values divide the texture into 1536 threadgroups, each of which contains 512 threads, for a total of 786,432 threads. In this case, that number of threads matches the number of pixels in the image, and the GPU processes the entire image with no underuse of threads.\n\nHowever, the code may round up to ensure there are sufficient threads to process the entire image, such as for an image of 1920 by 1080 pixels in size. This approach can result in the threadgroups generating a grid that’s larger than your data.\n\n\n\nTo compensate for the extra threads, you can make your code exit early if the thread position in the grid is outside the bounds of the data.\n\nEncode the command that executes your custom threadgroup size by calling the encoder’s [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputeCommandEncoder\/dispatchThreadgroups(_:threadsPerThreadgroup:)] method.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Metal\/calculating-threadgroup-and-grid-sizes\ncrawled: 2025-12-02T05:46:38Z\n---\n\n# Calculating threadgroup and grid sizes\n\n**Article**\n\nCalculate the optimum sizes for threadgroups and grids when dispatching compute-processing workloads.\n\n## Overview\n\nYou can ensure your app doesn’t underuse threads by specifying the size of the grid and the number of threads per threadgroup. In iOS 11 and macOS 10.13 and later on devices that support nonuniform dispatch sizes, Metal calculates the number of threadgroups and provides nonuniform threadgroups if the grid size isn’t a multiple of the threadgroup size.\n\nIn earlier versions of iOS and macOS, you specify the size and number of the threadgroups. Metal composes grids of uniform threadgroups that may not match the size of your data. You can ensure your kernel code doesn’t execute outside the bounds of the data by adding defensive code to it.\n\n### Calculate threads per threadgroup\n\nYou calculate the number of threads per threadgroup based on two [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState] properties:\n\n\n\n\n\nFor example, consider a compute pipeline state with `512` maximum threads per threadgroup and a thread execution width of `16`. For that compute pipeline state, you can launch the largest possible threadgroup by setting the following:\n\n- The second dimension to the maximum threads per thread group divided by the thread execution width\n- The third dimension to `1`\n\n\n\nOn devices that support nonuniform threadgroup sizes, Metal divides a grid into nonuniform, arbitrarily sized threadgroups, such as for an image or texture. The compute command encoder’s [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputeCommandEncoder\/dispatchThreads(_:threadsPerThreadgroup:)] method requires the total number of threads because each thread corresponds to a single pixel.\n\n\n\nWhen Metal performs this calculation, it can generate smaller threadgroups along the edges of your grid. Compared to uniform threadgroups, this technique simplifies kernel code and improves GPU performance.\n\nTo determine if a device supports nonuniform threadgroups, see [https:\/\/developer.apple.com\/metal\/Metal-Feature-Set-Tables.pdf]\n\n\n\n### Calculate threadgroups per grid\n\nIf you need fine control over the size and number of threadgroups, you can manually calculate how to divide the grid. In your code, ensure that there are sufficient threadgroups to cover the entire image.\n\n\n\nFor a texture that’s 1024 by 768 pixels in size, the code above returns an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLSize] instance with a width of `32`, a height of `48`, and a depth of `1`. These values divide the texture into 1536 threadgroups, each of which contains 512 threads, for a total of 786,432 threads. In this case, that number of threads matches the number of pixels in the image, and the GPU processes the entire image with no underuse of threads.\n\nHowever, the code may round up to ensure there are sufficient threads to process the entire image, such as for an image of 1920 by 1080 pixels in size. This approach can result in the threadgroups generating a grid that’s larger than your data.\n\n\n\nTo compensate for the extra threads, you can make your code exit early if the thread position in the grid is outside the bounds of the data.\n\n```metal\nkernel void\nsimpleKernelFunction(texture2d<float, access::write> outputTexture [[texture(0)]],\n                     uint2 position [[thread_position_in_grid]]) {\n    \n    if (position.x >= outputTexture.get_width() || position.y >= outputTexture.get_height()) {\n        return;\n    }\n    \n    outputTexture.write(float4(1.0), position);\n}\n```\n\n\n\nEncode the command that executes your custom threadgroup size by calling the encoder’s [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputeCommandEncoder\/dispatchThreadgroups(_:threadsPerThreadgroup:)] method.\n\n\n\n## Encoding a compute pass\n\n- **Creating threads and threadgroups**: Learn how Metal organizes compute-processing workloads.\n- **MTL4ComputeCommandEncoder**: Encodes a compute pass and other memory operations into a command buffer.\n- **MTLComputeCommandEncoder**: An interface for dispatching commands to encode in a compute pass.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Learn how Metal organizes compute-processing workloads.",
          "name" : "Creating threads and threadgroups",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/creating-threads-and-threadgroups"
        },
        {
          "description" : "Encodes a compute pass and other memory operations into a command buffer.",
          "name" : "MTL4ComputeCommandEncoder",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTL4ComputeCommandEncoder"
        },
        {
          "description" : "An interface for dispatching commands to encode in a compute pass.",
          "name" : "MTLComputeCommandEncoder",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLComputeCommandEncoder"
        }
      ],
      "title" : "Encoding a compute pass"
    }
  ],
  "source" : "appleJSON",
  "title" : "Calculating threadgroup and grid sizes",
  "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/calculating-threadgroup-and-grid-sizes"
}