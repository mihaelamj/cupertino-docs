{
  "abstract" : "Use Metal to find GPUs and perform calculations on them.",
  "codeExamples" : [
    {
      "code" : "void add_arrays(const float* inA,\n                const float* inB,\n                float* result,\n                int length)\n{\n    for (int index = 0; index < length ; index++)\n    {\n        result[index] = inA[index] + inB[index];\n    }\n}",
      "language" : "c"
    },
    {
      "code" : "kernel void add_arrays(device const float* inA,\n                       device const float* inB,\n                       device float* result,\n                       uint index [[thread_position_in_grid]])\n{\n    \/\/ the for-loop is replaced with a collection of threads, each of which\n    \/\/ calls this function.\n    result[index] = inA[index] + inB[index];\n}",
      "language" : "metal"
    },
    {
      "code" : "id<MTLDevice> device = MTLCreateSystemDefaultDevice();",
      "language" : "objective-c"
    },
    {
      "code" : "MetalAdder* adder = [[MetalAdder alloc] initWithDevice:device];",
      "language" : "objective-c"
    },
    {
      "code" : "- (instancetype) initWithDevice: (id<MTLDevice>) device\n{\n    self = [super init];\n    if (self)\n    {\n        _mDevice = device;\n\n        NSError* error = nil;\n\n        \/\/ Load the shader files with a .metal file extension in the project\n\n        id<MTLLibrary> defaultLibrary = [_mDevice newDefaultLibrary];\n        if (defaultLibrary == nil)\n        {\n            NSLog(@\"Failed to find the default library.\");\n            return nil;\n        }\n\n        id<MTLFunction> addFunction = [defaultLibrary newFunctionWithName:@\"add_arrays\"];\n        if (addFunction == nil)\n        {\n            NSLog(@\"Failed to find the adder function.\");\n            return nil;\n        }",
      "language" : "objective-c"
    },
    {
      "code" : "_mAddFunctionPSO = [_mDevice newComputePipelineStateWithFunction: addFunction error:&error];",
      "language" : "objective-c"
    },
    {
      "code" : "_mCommandQueue = [_mDevice newCommandQueue];",
      "language" : "objective-c"
    },
    {
      "code" : "_mBufferA = [_mDevice newBufferWithLength:bufferSize options:MTLResourceStorageModeShared];\n_mBufferB = [_mDevice newBufferWithLength:bufferSize options:MTLResourceStorageModeShared];\n_mBufferResult = [_mDevice newBufferWithLength:bufferSize options:MTLResourceStorageModeShared];\n\n[self generateRandomFloatData:_mBufferA];\n[self generateRandomFloatData:_mBufferB];",
      "language" : "objective-c"
    },
    {
      "code" : "- (void) generateRandomFloatData: (id<MTLBuffer>) buffer\n{\n    float* dataPtr = buffer.contents;\n\n    for (unsigned long index = 0; index < arrayLength; index++)\n    {\n        dataPtr[index] = (float)rand()\/(float)(RAND_MAX);\n    }\n}",
      "language" : "objective-c"
    },
    {
      "code" : "id<MTLCommandBuffer> commandBuffer = [_mCommandQueue commandBuffer];",
      "language" : "objective-c"
    },
    {
      "code" : "id<MTLComputeCommandEncoder> computeEncoder = [commandBuffer computeCommandEncoder];",
      "language" : "objective-c"
    },
    {
      "code" : "[computeEncoder setComputePipelineState:_mAddFunctionPSO];\n[computeEncoder setBuffer:_mBufferA offset:0 atIndex:0];\n[computeEncoder setBuffer:_mBufferB offset:0 atIndex:1];\n[computeEncoder setBuffer:_mBufferResult offset:0 atIndex:2];",
      "language" : "objective-c"
    },
    {
      "code" : "MTLSize gridSize = MTLSizeMake(arrayLength, 1, 1);",
      "language" : "objective-c"
    },
    {
      "code" : "NSUInteger threadGroupSize = _mAddFunctionPSO.maxTotalThreadsPerThreadgroup;\nif (threadGroupSize > arrayLength)\n{\n    threadGroupSize = arrayLength;\n}\nMTLSize threadgroupSize = MTLSizeMake(threadGroupSize, 1, 1);",
      "language" : "objective-c"
    },
    {
      "code" : "[computeEncoder dispatchThreads:gridSize\n          threadsPerThreadgroup:threadgroupSize];",
      "language" : "objective-c"
    },
    {
      "code" : "[computeEncoder endEncoding];",
      "language" : "objective-c"
    },
    {
      "code" : "[commandBuffer commit];",
      "language" : "objective-c"
    },
    {
      "code" : "[commandBuffer waitUntilCompleted];",
      "language" : "objective-c"
    },
    {
      "code" : "- (void) verifyResults\n{\n    float* a = _mBufferA.contents;\n    float* b = _mBufferB.contents;\n    float* result = _mBufferResult.contents;\n\n    for (unsigned long index = 0; index < arrayLength; index++)\n    {\n        if (result[index] != (a[index] + b[index]))\n        {\n            printf(\"Compute ERROR: index=%lu result=%g vs %g=a+b\\n\",\n                   index, result[index], a[index] + b[index]);\n            assert(result[index] == (a[index] + b[index]));\n        }\n    }\n    printf(\"Compute results as expected\\n\");\n}",
      "language" : "objective-c"
    }
  ],
  "contentHash" : "9c248f2560cf59eccb83360b3aa2d3dc836724e7ab04a59055296f1304870e9a",
  "crawledAt" : "2025-12-02T19:56:03Z",
  "id" : "129AE22B-F470-470C-BCF6-C518A30DAA21",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Metal",
  "overview" : "## Overview\n\nIn this sample, you’ll learn essential tasks that are used in all Metal apps. You’ll see how to convert a simple function written in C to Metal Shading Language (MSL) so that it can be run on a GPU. You’ll find a GPU, prepare the MSL function to run on it by creating a pipeline, and create data objects accessible to the GPU. To execute the pipeline against your data, create a *command buffer*, write commands into it, and commit the buffer to a command queue. Metal sends the commands to the GPU to be executed.\n\n### Write a GPU function to perform calculations\n\nTo illustrate GPU programming, the app adds corresponding elements of two arrays, and stores the results to a third array. The C example below makes this calculation on the CPU by looping over the index and calculating one value at a time.\n\nEach value is calculated independently, so the values can be safely calculated concurrently. To perform the calculation on the GPU, you need to rewrite this function in Metal Shading Language (MSL). MSL is a variant of C++ designed for GPU programming. In Metal, code that runs on GPUs is called a *shader*, because historically they were first used to calculate colors in 3D graphics. The next example shows a shader in MSL that performs the same calculation as the previous example. The sample project defines this function in the `add.metal` file. Xcode builds all `.metal` files in the application target and creates a default Metal library, which it embeds in your app. You’ll see how to load the default library later in this sample.\n\nThe two examples are similar, but there are some important differences in the MSL version.\n\nIn the MSL example, the function adds the `kernel` keyword, which declares that the function is:\n\nSee [doc:\/\/com.apple.metal\/documentation\/Metal\/drawing-a-triangle-with-metal-4] to learn other keywords for declaring public graphics functions.\n\nThe `add_arrays` function declares three of its arguments with the `device` keyword, which says that these pointers are in the `device` address space. MSL defines several disjoint address spaces for memory. Whenever you declare a pointer in MSL, you need to supply a keyword to declare its address space. Use the `device` address space to declare persistent memory that the GPU can read from and write to.\n\nThe MSL version removes the for-loop from the C version because the GPU calls the function with multiple threads in the compute grid. This sample creates a 1D grid of threads that exactly matches the array’s dimensions, so that each entry in the array is calculated by a different thread.\n\nTo replace the index previously provided by the for-loop, the function takes a new `index` argument, with another MSL keyword, `thread_position_in_grid`, specified using C++ attribute syntax. This keyword declares that Metal should calculate a unique index for each thread and pass that index in this argument. Because `add_arrays` uses a 1D grid, the index is defined as a scalar integer. Even though the MSL example removes the loop, both examples use the same line of code to add the two numbers together. If you want to convert similar code from C or C++ to MSL, replace the loop logic with a grid in the same way.\n\n### Find a GPU\n\nIn your app, an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] object is a thin abstraction for a GPU; you use it to communicate with a GPU. Metal creates a `MTLDevice` for each GPU. You get the default device object by calling [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCreateSystemDefaultDevice()]. In macOS, where a Mac can have multiple GPUs, Metal chooses one of the GPUs as the default and returns that GPU’s device object. In macOS, Metal provides other APIs that you can use to retrieve all of the device objects, but this sample just uses the default.\n\n### Initialize Metal objects\n\nMetal represents other GPU-related entities, like compiled shaders, memory buffers and textures, as objects. To create these GPU-specific objects, you call methods on an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] or you call methods on objects created by an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice]. All objects created directly or indirectly by a device object are usable only with that device object. Apps that work with multiple GPUs have a device instance for each and create a similar hierarchy of Metal type instances them.\n\nThe sample app uses a custom `MetalAdder` class to manage the objects it needs to communicate with the GPU. The class’s initializer creates these objects and stores them in its properties. The app creates an instance of this class, passing in the Metal device object to use to create the secondary objects. The `MetalAdder` object keeps strong references to the Metal objects until it finishes executing.\n\nIn Metal, expensive initialization tasks can be run once and the results retained and used inexpensively. You rarely need to run such tasks in performance-sensitive code.\n\n### Get a reference to the Metal function\n\nThe first thing the initializer does is load the function and prepare it to run on the GPU. When you build the app, Xcode compiles the `add_arrays` function and adds it to a default Metal library that it embeds in the app. You use [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLLibrary] and [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLFunction] objects to get information about Metal libraries and the functions contained in them. To get an object representing the `add_arrays` function, ask the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] to create an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLLibrary] object for the default library, and then ask the library for an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLFunction] object that represents the shader function.\n\n### Prepare a Metal pipeline\n\nThe function object is a proxy for the MSL function, but it’s not executable code. You convert the function into executable code by creating a *pipeline*. A pipeline specifies the steps that the GPU performs to complete a specific task. In Metal, a pipeline is represented by a *pipeline state object*. Because this sample uses a compute function, the app creates an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState] object.\n\nA compute pipeline runs a single compute function, optionally manipulating the input data before running the function, and the output data afterwards.\n\nWhen you create a pipeline state object, the device object finishes compiling the function for this specific GPU. This sample creates the pipeline state object synchronously and returns it directly to the app. Because compiling does take a while, avoid creating pipeline state objects synchronously in performance-sensitive code.\n\n### Create a command queue\n\nTo send work to the GPU, you need a command queue. Metal uses command queues to schedule commands. Create a command queue by asking the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] for one.\n\n### Create data buffers and load data\n\nAfter initializing the basic Metal objects, you load data for the GPU to execute. This task is less performance critical, but still useful to do early in your app’s launch.\n\nA GPU can have its own dedicated memory, or it can share memory with the operating system. Metal and the operating system kernel need to perform additional work to let you store data in memory and make that data available to the GPU. Metal abstracts this memory management using *resource* objects. ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLResource]). A resource is an allocation of memory that the GPU can access when running commands. Use an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] to create resources for its GPU.\n\nThe sample app creates three buffers, fills the first two with random data, and stores the results from `add_arrays` in the third buffer.\n\nThe resources in this sample are ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer]) objects, which are allocations of memory without a predefined format. Metal manages each buffer as an opaque collection of bytes. However, you specify the format when you use a buffer in a shader. This means that your shaders and your app need to agree on the format of any data being passed back and forth.\n\nWhen you allocate a buffer, you provide a storage mode to determine some of its performance characteristics and whether the CPU or GPU can access it. The sample app uses shared memory ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLResourceOptions\/storageModeShared]), which both the CPU and GPU can access.\n\nTo fill a buffer with random data, the app gets a pointer to the buffer’s memory and writes data to it on the CPU. The `add_arrays` function in the MSL example declares the parameters as arrays of floating-point numbers, which means you need to provide buffers in the same format:\n\n### Create a command buffer\n\nAsk the command queue to create a command buffer.\n\n### Create a command encoder\n\nTo write commands into a command buffer, you use a *command encoder* for the specific kind of commands you want to code. This sample creates a compute command encoder, which encodes a *compute pass*. A compute pass holds a list of commands that execute compute pipelines. Each compute command causes the GPU to create a grid of threads to execute on the GPU.\n\nTo encode a command, you make a series of method calls on the encoder. Some methods set state information, like the pipeline state object (PSO) or the arguments to be passed to the pipeline. After you make those state changes, you encode a command to execute the pipeline. The encoder writes all of the state changes and command parameters into the command buffer.\n\n\n\n### Set pipeline state and argument data\n\nSet the pipeline state object of the pipeline you want the command to execute. Then set data for any arguments that the pipeline needs to send into the `add_arrays` function. For this pipeline, that means providing references to three buffers. Metal automatically assigns indices for the buffer arguments in the order that the arguments appear in the function declaration in MSL example, starting with `0`. You provide arguments using the same indices.\n\nYou also specify an offset for each argument. An offset of `0` means the command accesses the data from the beginning of a buffer. However, you could use one buffer to store multiple arguments, specifying an offset for each argument.\n\nYou don’t specify any data for the index argument because the `add_arrays` function defined its values as being provided by the GPU.\n\n### Specify thread count and organization\n\nNext, decide how many threads to create and how to organize those threads. Metal can create 1D, 2D, or 3D grids. The `add_arrays` function uses a 1D array, so the sample creates a 1D grid of size (`dataSize` x 1 x 1), from which Metal generates indices between 0 and `dataSize`-1.\n\n### Specify threadgroup size\n\nMetal subdivides the grid into smaller grids called *threadgroups*. Each threadgroup is calculated separately. Metal can dispatch threadgroups to different processing elements on the GPU to speed up processing. You also need to decide how large to make the threadgroups for your command.\n\nThe app asks the pipeline state object for the largest possible threadgroup and shrinks it if that size is larger than the size of the data set. The [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState\/maxTotalThreadsPerThreadgroup] property gives the maximum number of threads allowed in the threadgroup, which varies depending on the complexity of the function used to create the pipeline state object.\n\n### Encode the compute command to execute the threads\n\nFinally, encode the command to dispatch the grid of threads.\n\nWhen the GPU executes this command, it uses the state you previously set and the command’s parameters to dispatch threads to perform the computation.\n\nYou can follow the same steps using the encoder to encode multiple compute commands into the compute pass without performing any redundant steps. For example, you might set the pipeline state object once, and then set arguments and encode a command for each collection of buffers to process.\n\n### End the compute pass\n\nWhen you have no more commands to add to the compute pass, you end the encoding process to close out the compute pass.\n\n### Commit the command buffer to execute its commands\n\nRun the commands in the command buffer by committing the command buffer to the queue.\n\nThe command queue created the command buffer, so committing the buffer always places it on that queue. After you commit the command buffer, Metal asynchronously prepares the commands for execution and then schedules the command buffer to execute on the GPU. After the GPU executes all the commands in the command buffer, Metal marks the command buffer as complete.\n\n### Wait for the calculation to complete\n\nYour app can do other work while the GPU is processing your commands. This sample doesn’t need to do any additional work, so it simply waits until the command buffer is complete.\n\nAlternatively, to be notified when Metal has processed all of the commands, add a completion handler to the command buffer ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCommandBuffer\/addCompletedHandler(_:)]), or check the status of a command buffer by reading its [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCommandBuffer\/status] property.\n\n### Read the results from the buffer\n\nAfter the command buffer completes, the GPU’s calculations are stored in the output buffer and Metal performs any necessary steps to make sure the CPU can see them. In a real app, you would read the results from the buffer and do something with them, such as displaying the results onscreen or writing them to a file. Because the calculations are only used to illustrate the process of creating a Metal app, the sample reads the values stored in the output buffer and tests to make sure the CPU and the GPU calculated the same results.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/metal\/performing-calculations-on-a-gpu\ncrawled: 2025-12-02T19:56:03Z\n---\n\n# Performing calculations on a GPU\n\n**Sample Code**\n\nUse Metal to find GPUs and perform calculations on them.\n\n## Overview\n\nIn this sample, you’ll learn essential tasks that are used in all Metal apps. You’ll see how to convert a simple function written in C to Metal Shading Language (MSL) so that it can be run on a GPU. You’ll find a GPU, prepare the MSL function to run on it by creating a pipeline, and create data objects accessible to the GPU. To execute the pipeline against your data, create a *command buffer*, write commands into it, and commit the buffer to a command queue. Metal sends the commands to the GPU to be executed.\n\n### Write a GPU function to perform calculations\n\nTo illustrate GPU programming, the app adds corresponding elements of two arrays, and stores the results to a third array. The C example below makes this calculation on the CPU by looping over the index and calculating one value at a time.\n\n```c\nvoid add_arrays(const float* inA,\n                const float* inB,\n                float* result,\n                int length)\n{\n    for (int index = 0; index < length ; index++)\n    {\n        result[index] = inA[index] + inB[index];\n    }\n}\n```\n\nEach value is calculated independently, so the values can be safely calculated concurrently. To perform the calculation on the GPU, you need to rewrite this function in Metal Shading Language (MSL). MSL is a variant of C++ designed for GPU programming. In Metal, code that runs on GPUs is called a *shader*, because historically they were first used to calculate colors in 3D graphics. The next example shows a shader in MSL that performs the same calculation as the previous example. The sample project defines this function in the `add.metal` file. Xcode builds all `.metal` files in the application target and creates a default Metal library, which it embeds in your app. You’ll see how to load the default library later in this sample.\n\n```metal\nkernel void add_arrays(device const float* inA,\n                       device const float* inB,\n                       device float* result,\n                       uint index [[thread_position_in_grid]])\n{\n    \/\/ the for-loop is replaced with a collection of threads, each of which\n    \/\/ calls this function.\n    result[index] = inA[index] + inB[index];\n}\n```\n\nThe two examples are similar, but there are some important differences in the MSL version.\n\nIn the MSL example, the function adds the `kernel` keyword, which declares that the function is:\n\n- A *public GPU function*. Public functions are the only functions that your app can see. Public functions also can’t be called by other shader functions.\n- A *compute function* (also known as a compute kernel), which performs a parallel calculation using a grid of threads.\n\nSee [doc:\/\/com.apple.metal\/documentation\/Metal\/drawing-a-triangle-with-metal-4] to learn other keywords for declaring public graphics functions.\n\nThe `add_arrays` function declares three of its arguments with the `device` keyword, which says that these pointers are in the `device` address space. MSL defines several disjoint address spaces for memory. Whenever you declare a pointer in MSL, you need to supply a keyword to declare its address space. Use the `device` address space to declare persistent memory that the GPU can read from and write to.\n\nThe MSL version removes the for-loop from the C version because the GPU calls the function with multiple threads in the compute grid. This sample creates a 1D grid of threads that exactly matches the array’s dimensions, so that each entry in the array is calculated by a different thread.\n\nTo replace the index previously provided by the for-loop, the function takes a new `index` argument, with another MSL keyword, `thread_position_in_grid`, specified using C++ attribute syntax. This keyword declares that Metal should calculate a unique index for each thread and pass that index in this argument. Because `add_arrays` uses a 1D grid, the index is defined as a scalar integer. Even though the MSL example removes the loop, both examples use the same line of code to add the two numbers together. If you want to convert similar code from C or C++ to MSL, replace the loop logic with a grid in the same way.\n\n### Find a GPU\n\nIn your app, an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] object is a thin abstraction for a GPU; you use it to communicate with a GPU. Metal creates a `MTLDevice` for each GPU. You get the default device object by calling [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCreateSystemDefaultDevice()]. In macOS, where a Mac can have multiple GPUs, Metal chooses one of the GPUs as the default and returns that GPU’s device object. In macOS, Metal provides other APIs that you can use to retrieve all of the device objects, but this sample just uses the default.\n\n```objective-c\nid<MTLDevice> device = MTLCreateSystemDefaultDevice();\n```\n\n### Initialize Metal objects\n\nMetal represents other GPU-related entities, like compiled shaders, memory buffers and textures, as objects. To create these GPU-specific objects, you call methods on an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] or you call methods on objects created by an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice]. All objects created directly or indirectly by a device object are usable only with that device object. Apps that work with multiple GPUs have a device instance for each and create a similar hierarchy of Metal type instances them.\n\nThe sample app uses a custom `MetalAdder` class to manage the objects it needs to communicate with the GPU. The class’s initializer creates these objects and stores them in its properties. The app creates an instance of this class, passing in the Metal device object to use to create the secondary objects. The `MetalAdder` object keeps strong references to the Metal objects until it finishes executing.\n\n```objective-c\nMetalAdder* adder = [[MetalAdder alloc] initWithDevice:device];\n```\n\nIn Metal, expensive initialization tasks can be run once and the results retained and used inexpensively. You rarely need to run such tasks in performance-sensitive code.\n\n### Get a reference to the Metal function\n\nThe first thing the initializer does is load the function and prepare it to run on the GPU. When you build the app, Xcode compiles the `add_arrays` function and adds it to a default Metal library that it embeds in the app. You use [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLLibrary] and [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLFunction] objects to get information about Metal libraries and the functions contained in them. To get an object representing the `add_arrays` function, ask the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] to create an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLLibrary] object for the default library, and then ask the library for an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLFunction] object that represents the shader function.\n\n```objective-c\n- (instancetype) initWithDevice: (id<MTLDevice>) device\n{\n    self = [super init];\n    if (self)\n    {\n        _mDevice = device;\n\n        NSError* error = nil;\n\n        \/\/ Load the shader files with a .metal file extension in the project\n\n        id<MTLLibrary> defaultLibrary = [_mDevice newDefaultLibrary];\n        if (defaultLibrary == nil)\n        {\n            NSLog(@\"Failed to find the default library.\");\n            return nil;\n        }\n\n        id<MTLFunction> addFunction = [defaultLibrary newFunctionWithName:@\"add_arrays\"];\n        if (addFunction == nil)\n        {\n            NSLog(@\"Failed to find the adder function.\");\n            return nil;\n        }\n```\n\n### Prepare a Metal pipeline\n\nThe function object is a proxy for the MSL function, but it’s not executable code. You convert the function into executable code by creating a *pipeline*. A pipeline specifies the steps that the GPU performs to complete a specific task. In Metal, a pipeline is represented by a *pipeline state object*. Because this sample uses a compute function, the app creates an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState] object.\n\n```objective-c\n_mAddFunctionPSO = [_mDevice newComputePipelineStateWithFunction: addFunction error:&error];\n```\n\nA compute pipeline runs a single compute function, optionally manipulating the input data before running the function, and the output data afterwards.\n\nWhen you create a pipeline state object, the device object finishes compiling the function for this specific GPU. This sample creates the pipeline state object synchronously and returns it directly to the app. Because compiling does take a while, avoid creating pipeline state objects synchronously in performance-sensitive code.\n\n\n\n### Create a command queue\n\nTo send work to the GPU, you need a command queue. Metal uses command queues to schedule commands. Create a command queue by asking the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] for one.\n\n```objective-c\n_mCommandQueue = [_mDevice newCommandQueue];\n```\n\n### Create data buffers and load data\n\nAfter initializing the basic Metal objects, you load data for the GPU to execute. This task is less performance critical, but still useful to do early in your app’s launch.\n\nA GPU can have its own dedicated memory, or it can share memory with the operating system. Metal and the operating system kernel need to perform additional work to let you store data in memory and make that data available to the GPU. Metal abstracts this memory management using *resource* objects. ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLResource]). A resource is an allocation of memory that the GPU can access when running commands. Use an [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice] to create resources for its GPU.\n\nThe sample app creates three buffers, fills the first two with random data, and stores the results from `add_arrays` in the third buffer.\n\n```objective-c\n_mBufferA = [_mDevice newBufferWithLength:bufferSize options:MTLResourceStorageModeShared];\n_mBufferB = [_mDevice newBufferWithLength:bufferSize options:MTLResourceStorageModeShared];\n_mBufferResult = [_mDevice newBufferWithLength:bufferSize options:MTLResourceStorageModeShared];\n\n[self generateRandomFloatData:_mBufferA];\n[self generateRandomFloatData:_mBufferB];\n```\n\nThe resources in this sample are ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer]) objects, which are allocations of memory without a predefined format. Metal manages each buffer as an opaque collection of bytes. However, you specify the format when you use a buffer in a shader. This means that your shaders and your app need to agree on the format of any data being passed back and forth.\n\nWhen you allocate a buffer, you provide a storage mode to determine some of its performance characteristics and whether the CPU or GPU can access it. The sample app uses shared memory ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLResourceOptions\/storageModeShared]), which both the CPU and GPU can access.\n\nTo fill a buffer with random data, the app gets a pointer to the buffer’s memory and writes data to it on the CPU. The `add_arrays` function in the MSL example declares the parameters as arrays of floating-point numbers, which means you need to provide buffers in the same format:\n\n```objective-c\n- (void) generateRandomFloatData: (id<MTLBuffer>) buffer\n{\n    float* dataPtr = buffer.contents;\n\n    for (unsigned long index = 0; index < arrayLength; index++)\n    {\n        dataPtr[index] = (float)rand()\/(float)(RAND_MAX);\n    }\n}\n```\n\n### Create a command buffer\n\nAsk the command queue to create a command buffer.\n\n```objective-c\nid<MTLCommandBuffer> commandBuffer = [_mCommandQueue commandBuffer];\n```\n\n### Create a command encoder\n\nTo write commands into a command buffer, you use a *command encoder* for the specific kind of commands you want to code. This sample creates a compute command encoder, which encodes a *compute pass*. A compute pass holds a list of commands that execute compute pipelines. Each compute command causes the GPU to create a grid of threads to execute on the GPU.\n\n```objective-c\nid<MTLComputeCommandEncoder> computeEncoder = [commandBuffer computeCommandEncoder];\n```\n\nTo encode a command, you make a series of method calls on the encoder. Some methods set state information, like the pipeline state object (PSO) or the arguments to be passed to the pipeline. After you make those state changes, you encode a command to execute the pipeline. The encoder writes all of the state changes and command parameters into the command buffer.\n\n\n\n### Set pipeline state and argument data\n\nSet the pipeline state object of the pipeline you want the command to execute. Then set data for any arguments that the pipeline needs to send into the `add_arrays` function. For this pipeline, that means providing references to three buffers. Metal automatically assigns indices for the buffer arguments in the order that the arguments appear in the function declaration in MSL example, starting with `0`. You provide arguments using the same indices.\n\n```objective-c\n[computeEncoder setComputePipelineState:_mAddFunctionPSO];\n[computeEncoder setBuffer:_mBufferA offset:0 atIndex:0];\n[computeEncoder setBuffer:_mBufferB offset:0 atIndex:1];\n[computeEncoder setBuffer:_mBufferResult offset:0 atIndex:2];\n```\n\nYou also specify an offset for each argument. An offset of `0` means the command accesses the data from the beginning of a buffer. However, you could use one buffer to store multiple arguments, specifying an offset for each argument.\n\nYou don’t specify any data for the index argument because the `add_arrays` function defined its values as being provided by the GPU.\n\n### Specify thread count and organization\n\nNext, decide how many threads to create and how to organize those threads. Metal can create 1D, 2D, or 3D grids. The `add_arrays` function uses a 1D array, so the sample creates a 1D grid of size (`dataSize` x 1 x 1), from which Metal generates indices between 0 and `dataSize`-1.\n\n```objective-c\nMTLSize gridSize = MTLSizeMake(arrayLength, 1, 1);\n```\n\n### Specify threadgroup size\n\nMetal subdivides the grid into smaller grids called *threadgroups*. Each threadgroup is calculated separately. Metal can dispatch threadgroups to different processing elements on the GPU to speed up processing. You also need to decide how large to make the threadgroups for your command.\n\n```objective-c\nNSUInteger threadGroupSize = _mAddFunctionPSO.maxTotalThreadsPerThreadgroup;\nif (threadGroupSize > arrayLength)\n{\n    threadGroupSize = arrayLength;\n}\nMTLSize threadgroupSize = MTLSizeMake(threadGroupSize, 1, 1);\n```\n\nThe app asks the pipeline state object for the largest possible threadgroup and shrinks it if that size is larger than the size of the data set. The [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState\/maxTotalThreadsPerThreadgroup] property gives the maximum number of threads allowed in the threadgroup, which varies depending on the complexity of the function used to create the pipeline state object.\n\n### Encode the compute command to execute the threads\n\nFinally, encode the command to dispatch the grid of threads.\n\n```objective-c\n[computeEncoder dispatchThreads:gridSize\n          threadsPerThreadgroup:threadgroupSize];\n```\n\nWhen the GPU executes this command, it uses the state you previously set and the command’s parameters to dispatch threads to perform the computation.\n\nYou can follow the same steps using the encoder to encode multiple compute commands into the compute pass without performing any redundant steps. For example, you might set the pipeline state object once, and then set arguments and encode a command for each collection of buffers to process.\n\n### End the compute pass\n\nWhen you have no more commands to add to the compute pass, you end the encoding process to close out the compute pass.\n\n```objective-c\n[computeEncoder endEncoding];\n```\n\n### Commit the command buffer to execute its commands\n\nRun the commands in the command buffer by committing the command buffer to the queue.\n\n```objective-c\n[commandBuffer commit];\n```\n\nThe command queue created the command buffer, so committing the buffer always places it on that queue. After you commit the command buffer, Metal asynchronously prepares the commands for execution and then schedules the command buffer to execute on the GPU. After the GPU executes all the commands in the command buffer, Metal marks the command buffer as complete.\n\n### Wait for the calculation to complete\n\nYour app can do other work while the GPU is processing your commands. This sample doesn’t need to do any additional work, so it simply waits until the command buffer is complete.\n\n```objective-c\n[commandBuffer waitUntilCompleted];\n```\n\nAlternatively, to be notified when Metal has processed all of the commands, add a completion handler to the command buffer ([doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCommandBuffer\/addCompletedHandler(_:)]), or check the status of a command buffer by reading its [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCommandBuffer\/status] property.\n\n### Read the results from the buffer\n\nAfter the command buffer completes, the GPU’s calculations are stored in the output buffer and Metal performs any necessary steps to make sure the CPU can see them. In a real app, you would read the results from the buffer and do something with them, such as displaying the results onscreen or writing them to a file. Because the calculations are only used to illustrate the process of creating a Metal app, the sample reads the values stored in the output buffer and tests to make sure the CPU and the GPU calculated the same results.\n\n```objective-c\n- (void) verifyResults\n{\n    float* a = _mBufferA.contents;\n    float* b = _mBufferB.contents;\n    float* result = _mBufferResult.contents;\n\n    for (unsigned long index = 0; index < arrayLength; index++)\n    {\n        if (result[index] != (a[index] + b[index]))\n        {\n            printf(\"Compute ERROR: index=%lu result=%g vs %g=a+b\\n\",\n                   index, result[index], a[index] + b[index]);\n            assert(result[index] == (a[index] + b[index]));\n        }\n    }\n    printf(\"Compute results as expected\\n\");\n}\n```\n\n## Essentials\n\n- **Understanding the Metal 4 core API**: Discover the features and functionality in the Metal 4 foundational APIs.\n- **Drawing a triangle with Metal 4**: Render a colorful, rotating 2D triangle by running draw commands with a render pipeline on a GPU.\n- **Using Metal to draw a view’s contents**: Create a MetalKit view and a render pass to draw the view’s contents.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Discover the features and functionality in the Metal 4 foundational APIs.",
          "name" : "Understanding the Metal 4 core API",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/understanding-the-metal-4-core-api"
        },
        {
          "description" : "Render a colorful, rotating 2D triangle by running draw commands with a render pipeline on a GPU.",
          "name" : "Drawing a triangle with Metal 4",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/drawing-a-triangle-with-metal-4"
        },
        {
          "description" : "Create a MetalKit view and a render pass to draw the view’s contents.",
          "name" : "Using Metal to draw a view’s contents",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/using-metal-to-draw-a-view's-contents"
        }
      ],
      "title" : "Essentials"
    }
  ],
  "source" : "appleJSON",
  "title" : "Performing calculations on a GPU",
  "url" : "https:\/\/developer.apple.com\/documentation\/metal\/performing-calculations-on-a-gpu"
}