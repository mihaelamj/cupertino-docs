{
  "abstract" : "Switch dynamically between multiple GPUs to efficiently execute a compute-intensive simulation.",
  "codeExamples" : [
    {
      "code" : "void *updateAddress;\nkern_return_t err = vm_allocate((vm_map_t)mach_task_self(),\n                                (vm_address_t*)&updateAddress,\n                                updateDataSize,\n                                VM_FLAGS_ANYWHERE);\n\nassert(err == KERN_SUCCESS);\n\n_updateBuffer[i] = [_device newBufferWithBytesNoCopy:updateAddress\n                                              length:updateDataSize\n                                             options:MTLResourceStorageModeShared\n                                         deallocator:nil];",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Block to deallocate memory created with vm_allocate when the NSData object is no\n\/\/ longer referenced\nvoid (^deallocProvidedAddress)(void *bytes, NSUInteger length) =\n    ^(void *bytes, NSUInteger length)\n    {\n        vm_deallocate((vm_map_t)mach_task_self(),\n                      (vm_address_t)bytes,\n                      length);\n    };\n\n\/\/ Create a data object to wrap system memory and pass a deallocator to free the\n\/\/ memory allocated with vm_allocate when the data object has been released\n_updateData[i] = [[NSData alloc] initWithBytesNoCopy:updateAddress\n                                              length:updateDataSize\n                                         deallocator:deallocProvidedAddress];",
      "language" : "objective-c"
    }
  ],
  "contentHash" : "81e907146e54694328f981881c7f19129d03c80ed72ce7910bc77766995e94be",
  "crawledAt" : "2025-12-02T15:49:41Z",
  "id" : "C54ED301-AE43-4B93-B8D5-E0A3D16AB776",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Metal",
  "overview" : "## Overview\n\nmacOS supports systems that have multiple GPUs, enabling Metal apps to increase their computational power. An example is an iMac Pro that has a built-in discrete GPU and is connected to multiple external GPUs. External GPUs can be more powerful than built-in GPUs, so they’re a great choice for compute-intensive workloads. However, to take advantage of this added power, Metal apps should be prepared to safely handle adding and removing any external GPUs for more robust execution. Metal apps should always perform well, whether one GPU or multiple GPUs are available to the system.\n\n### Getting started\n\nNot all Mac computers have multiple GPUs. To check the GPUs in your Mac, choose Apple menu > About this Mac, press the System Report button, and select Graphics\/Displays on the left. The GPUs are listed under Video Card.\n\nOptionally, you may connect an external GPU to your Mac via Thunderbolt 3. For this system setup, your Mac needs to be running macOS 10.13.4 or later. Connecting an external GPU allows the sample to perform compute processing on an external GPU and perform graphics rendering on a built-in GPU.\n\n### Sample simulation modes\n\nThis sample executes an N-body simulation and continuously renders a subset of the simulation’s intermediate results as it progresses to completion. After the simulation has completed, the sample renders all the N-body particles in their final state, presenting the full set of final results.\n\nThe sample runs in one of two modes, depending on how many GPUs are available to the system.\n\n**Simulation with a single Metal device.** When only one Metal device is available, the sample executes the simulation and renders the intermediate results serially. The compute simulation and the graphics rendering are performed on the same thread by the same device.\n\n\n\n**Simulation with multiple Metal devices.** When multiple Metal devices are available, the sample spawns a second thread to separate the compute processing and graphics rendering work between two GPUs. The threads run concurrently and repeatedly, sharing data as follows:\n\n\n\nThe threads don’t wait on each other; they work independently at different rates. The simulation thread runs as fast as possible and the render thread runs as fast as the display’s frame rate.\n\n### Handle external GPU notifications\n\nWhen an external GPU is connected to the system, this sample performs compute simulations on that external GPU and graphics rendering on a built-in GPU. Otherwise, the sample performs both compute and graphics work on a single built-in GPU.\n\nWhen the sample receives a notification for an external GPU removal, it transfers all compute simulation data from the external GPU to the app’s view controller, which then transfers the data to a built-in GPU. This dynamic response ensures that the results of the compute simulation are efficiently retained and transferred for continued processing on a new GPU. It also ensures that the work in progress isn’t discarded and the simulation isn’t restarted.\n\nWhen the sample receives a notification for an external GPU addition, it first completes the current simulation with the built-in GPU and then starts the next simulation with the external GPU.\n\nThis sample implements many techniques described in [doc:\/\/com.apple.metal\/documentation\/Metal\/selecting-device-objects-for-graphics-rendering]. For information about handling external GPU notifications, see the following sections from that sample:\n\n### Transfer simulation data between devices\n\nThis sample uses two separate classes to encode Metal commands: `AAPLSimulation` for compute commands and `AAPLRenderer` for graphics commands. The sample uses the simulation class to create a compute pipeline, initialize an N-body data set, and execute the simulation. The sample uses the renderer class to create a render pipeline and draw N-body data produced by the simulation. (The sample uses the `AAPLViewController` class to separate work between the simulation and renderer classes.)\n\nWhen the sample runs on a single device, the view controller executes the simulation and renderer work serially. For each frame, they both encode commands to the same [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCommandBuffer] and they both share the positions of the N-body particles via the same [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer].\n\n\n\nWhen the sample runs on multiple devices, the view controller assigns the simulation work to one device and the renderer work to another. The simulation executes repeatedly in a loop on a separate simulation thread. For each iteration, it updates the positions of the N-body particles and blits this data to a new [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer] backed by system memory. The sample passes this system memory backing to the view controller, which then passes it along to the renderer. The renderer executes repeatedly in a loop on the main thread. For each iteration, it creates a new [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer], backed by the same system memory populated by the simulation thread, and renders the N-body particles based on the latest available position data.\n\n\n\n### Allocate system memory for a buffer\n\nThe sample calls the `vm_allocate` function to allocate a page-aligned buffer, `updateAddress`, backed by system memory. The sample then calls the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice\/makeBuffer(bytesNoCopy:length:options:deallocator:)] method to create a new [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer], `_updateBuffer`, backed by the same system memory used for the previous buffer.\n\nBecause the app is directly responsible for managing this system memory, the sample calls the `initWithBytesNoCopy:length:deallocator` method to wrap the `updateAddress` buffer in an `NSData` object. This method allows the sample to register a deallocator, `deallocProvidedAddress`, to free the system memory when the app has no more references to the buffer.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Metal\/selecting-device-objects-for-compute-processing\ncrawled: 2025-12-02T15:49:41Z\n---\n\n# Selecting device objects for compute processing\n\n**Sample Code**\n\nSwitch dynamically between multiple GPUs to efficiently execute a compute-intensive simulation.\n\n## Overview\n\nmacOS supports systems that have multiple GPUs, enabling Metal apps to increase their computational power. An example is an iMac Pro that has a built-in discrete GPU and is connected to multiple external GPUs. External GPUs can be more powerful than built-in GPUs, so they’re a great choice for compute-intensive workloads. However, to take advantage of this added power, Metal apps should be prepared to safely handle adding and removing any external GPUs for more robust execution. Metal apps should always perform well, whether one GPU or multiple GPUs are available to the system.\n\n### Getting started\n\nNot all Mac computers have multiple GPUs. To check the GPUs in your Mac, choose Apple menu > About this Mac, press the System Report button, and select Graphics\/Displays on the left. The GPUs are listed under Video Card.\n\nOptionally, you may connect an external GPU to your Mac via Thunderbolt 3. For this system setup, your Mac needs to be running macOS 10.13.4 or later. Connecting an external GPU allows the sample to perform compute processing on an external GPU and perform graphics rendering on a built-in GPU.\n\n### Sample simulation modes\n\nThis sample executes an N-body simulation and continuously renders a subset of the simulation’s intermediate results as it progresses to completion. After the simulation has completed, the sample renders all the N-body particles in their final state, presenting the full set of final results.\n\nThe sample runs in one of two modes, depending on how many GPUs are available to the system.\n\n**Simulation with a single Metal device.** When only one Metal device is available, the sample executes the simulation and renders the intermediate results serially. The compute simulation and the graphics rendering are performed on the same thread by the same device.\n\n\n\n**Simulation with multiple Metal devices.** When multiple Metal devices are available, the sample spawns a second thread to separate the compute processing and graphics rendering work between two GPUs. The threads run concurrently and repeatedly, sharing data as follows:\n\n- The simulation thread produces and transfers intermediate results to system memory.\n- The render thread—the main thread—consumes and renders intermediate results from system memory. (All graphics rendering occurs on the main thread.)\n\n\n\nThe threads don’t wait on each other; they work independently at different rates. The simulation thread runs as fast as possible and the render thread runs as fast as the display’s frame rate.\n\n### Handle external GPU notifications\n\nWhen an external GPU is connected to the system, this sample performs compute simulations on that external GPU and graphics rendering on a built-in GPU. Otherwise, the sample performs both compute and graphics work on a single built-in GPU.\n\nWhen the sample receives a notification for an external GPU removal, it transfers all compute simulation data from the external GPU to the app’s view controller, which then transfers the data to a built-in GPU. This dynamic response ensures that the results of the compute simulation are efficiently retained and transferred for continued processing on a new GPU. It also ensures that the work in progress isn’t discarded and the simulation isn’t restarted.\n\nWhen the sample receives a notification for an external GPU addition, it first completes the current simulation with the built-in GPU and then starts the next simulation with the external GPU.\n\nThis sample implements many techniques described in [doc:\/\/com.apple.metal\/documentation\/Metal\/selecting-device-objects-for-graphics-rendering]. For information about handling external GPU notifications, see the following sections from that sample:\n\n- Set a GPU Eject Policy\n- Register for External GPU Notifications\n- Respond to External GPU Notifications\n- Deregister from Notifications\n\n### Transfer simulation data between devices\n\nThis sample uses two separate classes to encode Metal commands: `AAPLSimulation` for compute commands and `AAPLRenderer` for graphics commands. The sample uses the simulation class to create a compute pipeline, initialize an N-body data set, and execute the simulation. The sample uses the renderer class to create a render pipeline and draw N-body data produced by the simulation. (The sample uses the `AAPLViewController` class to separate work between the simulation and renderer classes.)\n\nWhen the sample runs on a single device, the view controller executes the simulation and renderer work serially. For each frame, they both encode commands to the same [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLCommandBuffer] and they both share the positions of the N-body particles via the same [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer].\n\n\n\nWhen the sample runs on multiple devices, the view controller assigns the simulation work to one device and the renderer work to another. The simulation executes repeatedly in a loop on a separate simulation thread. For each iteration, it updates the positions of the N-body particles and blits this data to a new [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer] backed by system memory. The sample passes this system memory backing to the view controller, which then passes it along to the renderer. The renderer executes repeatedly in a loop on the main thread. For each iteration, it creates a new [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer], backed by the same system memory populated by the simulation thread, and renders the N-body particles based on the latest available position data.\n\n\n\n\n\n### Allocate system memory for a buffer\n\nThe sample calls the `vm_allocate` function to allocate a page-aligned buffer, `updateAddress`, backed by system memory. The sample then calls the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLDevice\/makeBuffer(bytesNoCopy:length:options:deallocator:)] method to create a new [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLBuffer], `_updateBuffer`, backed by the same system memory used for the previous buffer.\n\n```objective-c\nvoid *updateAddress;\nkern_return_t err = vm_allocate((vm_map_t)mach_task_self(),\n                                (vm_address_t*)&updateAddress,\n                                updateDataSize,\n                                VM_FLAGS_ANYWHERE);\n\nassert(err == KERN_SUCCESS);\n\n_updateBuffer[i] = [_device newBufferWithBytesNoCopy:updateAddress\n                                              length:updateDataSize\n                                             options:MTLResourceStorageModeShared\n                                         deallocator:nil];\n```\n\nBecause the app is directly responsible for managing this system memory, the sample calls the `initWithBytesNoCopy:length:deallocator` method to wrap the `updateAddress` buffer in an `NSData` object. This method allows the sample to register a deallocator, `deallocProvidedAddress`, to free the system memory when the app has no more references to the buffer.\n\n```objective-c\n\/\/ Block to deallocate memory created with vm_allocate when the NSData object is no\n\/\/ longer referenced\nvoid (^deallocProvidedAddress)(void *bytes, NSUInteger length) =\n    ^(void *bytes, NSUInteger length)\n    {\n        vm_deallocate((vm_map_t)mach_task_self(),\n                      (vm_address_t)bytes,\n                      length);\n    };\n\n\/\/ Create a data object to wrap system memory and pass a deallocator to free the\n\/\/ memory allocated with vm_allocate when the data object has been released\n_updateData[i] = [[NSData alloc] initWithBytesNoCopy:updateAddress\n                                              length:updateDataSize\n                                         deallocator:deallocProvidedAddress];\n```\n\n## Compute workflows\n\n- **Performing calculations on a GPU**: Use Metal to find GPUs and perform calculations on them.\n- **Customizing a TensorFlow operation**: Implement a custom operation that uses Metal kernels to accelerate neural-network training performance.\n- **Customizing a PyTorch operation**: Implement a custom operation in PyTorch that uses Metal kernels to improve performance.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use Metal to find GPUs and perform calculations on them.",
          "name" : "Performing calculations on a GPU",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/performing-calculations-on-a-gpu"
        },
        {
          "description" : "Implement a custom operation that uses Metal kernels to accelerate neural-network training performance.",
          "name" : "Customizing a TensorFlow operation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/customizing-a-tensorflow-operation"
        },
        {
          "description" : "Implement a custom operation in PyTorch that uses Metal kernels to improve performance.",
          "name" : "Customizing a PyTorch operation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/customizing-a-pytorch-operation"
        }
      ],
      "title" : "Compute workflows"
    }
  ],
  "source" : "appleJSON",
  "title" : "Selecting device objects for compute processing",
  "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/selecting-device-objects-for-compute-processing"
}