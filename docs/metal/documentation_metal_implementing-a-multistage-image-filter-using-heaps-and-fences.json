{
  "abstract" : "Use fences to synchronize access to resources allocated on a heap.",
  "codeExamples" : [
    {
      "code" : "for(uint32_t i = 0; i < AAPLNumImages; i++)\n{\n    \/\/ Create a descriptor using the texture's properties\n    MTLTextureDescriptor *descriptor = [AAPLRenderer newDescriptorFromTexture:_imageTextures[i]\n                                                                  storageMode:heapDescriptor.storageMode];\n\n    \/\/ Determine the size needed for the heap from the given descriptor\n    MTLSizeAndAlign sizeAndAlign = [_device heapTextureSizeAndAlignWithDescriptor:descriptor];\n\n    \/\/ Align the size so that more resources will fit after this texture\n    sizeAndAlign.size = alignUp(sizeAndAlign.size, sizeAndAlign.align);\n\n    \/\/ Accumulate the size required for the heap to hold this texture\n    heapDescriptor.size += sizeAndAlign.size;\n}\n\n\/\/ Create a heap large enough to hold all resources\n_imageHeap = [_device newHeapWithDescriptor:heapDescriptor];",
      "language" : "objective-c"
    },
    {
      "code" : "MTLTextureDescriptor *descriptor = [AAPLRenderer newDescriptorFromTexture:_imageTextures[i]\n                                                              storageMode:_imageHeap.storageMode];\n\n\/\/ Create a texture from the heap\nid<MTLTexture> heapTexture = [_imageHeap newTextureWithDescriptor:descriptor];",
      "language" : "objective-c"
    },
    {
      "code" : "MTLRegion region = MTLRegionMake2D(0, 0, _imageTextures[i].width, _imageTextures[i].height);\n\nfor(NSUInteger level = 0; level < _imageTextures[i].mipmapLevelCount;  level++)\n{\n    for(NSUInteger slice = 0; slice < _imageTextures[i].arrayLength; slice++)\n    {\n        [blitEncoder copyFromTexture:_imageTextures[i]\n                         sourceSlice:slice\n                         sourceLevel:level\n                        sourceOrigin:region.origin\n                          sourceSize:region.size\n                           toTexture:heapTexture\n                    destinationSlice:slice\n                    destinationLevel:level\n                   destinationOrigin:region.origin];\n    }\n\n    region.size.width \/= 2;\n    region.size.height \/= 2;\n    if(region.size.width == 0) region.size.width = 1;\n    if(region.size.height == 0) region.size.height = 1;\n}\n\n\/\/ Replace the original texture with new texture from the heap\n_imageTextures[i] = heapTexture;",
      "language" : "objective-c"
    },
    {
      "code" : "id<MTLTexture> inTexture = _imageTextures[_currentImageIndex];\n\n[self createScratchHeap:inTexture];",
      "language" : "objective-c"
    },
    {
      "code" : "MTLSizeAndAlign downsampleSizeAndAlignRequirement = [_downsample heapSizeAndAlignWithInputTextureDescriptor:descriptor];\nMTLSizeAndAlign gaussianBlurSizeAndAlignRequirement = [_gaussianBlur heapSizeAndAlignWithInputTextureDescriptor:descriptor];\n\nNSUInteger requiredAlignment = MAX(gaussianBlurSizeAndAlignRequirement.align, downsampleSizeAndAlignRequirement.align);\nNSUInteger gaussianBlurSizeAligned = alignUp(gaussianBlurSizeAndAlignRequirement.size, requiredAlignment);\nNSUInteger downsampleSizeAligned = alignUp(downsampleSizeAndAlignRequirement.size, requiredAlignment);\nNSUInteger requiredSize = gaussianBlurSizeAligned + downsampleSizeAligned;\n\nif(!_scratchHeap || requiredSize > [_scratchHeap maxAvailableSizeWithAlignment:requiredAlignment])\n{\n    MTLHeapDescriptor *heapDesc = [[MTLHeapDescriptor alloc] init];\n\n    heapDesc.size        = requiredSize;\n    heapDesc.storageMode = heapStorageMode;\n\n    _scratchHeap = [_device newHeapWithDescriptor:heapDesc];\n}",
      "language" : "objective-c"
    },
    {
      "code" : "MTLTextureDescriptor *textureDescriptor = [MTLTextureDescriptor texture2DDescriptorWithPixelFormat:inTexture.pixelFormat\n                                                                                             width:inTexture.width\n                                                                                            height:inTexture.height\n                                                                                         mipmapped:YES];\ntextureDescriptor.storageMode = heap.storageMode;\ntextureDescriptor.usage = MTLTextureUsageShaderWrite | MTLTextureUsageShaderRead;\n\nid <MTLTexture> outTexture = [heap newTextureWithDescriptor:textureDescriptor];",
      "language" : "objective-c"
    },
    {
      "code" : "[blitCommandEncoder copyFromTexture:inTexture\n                        sourceSlice:0\n                        sourceLevel:0\n                       sourceOrigin:(MTLOrigin){ 0, 0, 0 }\n                         sourceSize:(MTLSize){ inTexture.width, inTexture.height, inTexture.depth }\n                          toTexture:outTexture\n                   destinationSlice:0\n                   destinationLevel:0\n                  destinationOrigin:(MTLOrigin){ 0, 0, 0}];\n\n[blitCommandEncoder generateMipmapsForTexture:outTexture];",
      "language" : "objective-c"
    },
    {
      "code" : "[blitCommandEncoder updateFence:fence];\n\n[blitCommandEncoder endEncoding];",
      "language" : "objective-c"
    },
    {
      "code" : "[computeEncoder waitForFence:fence];",
      "language" : "objective-c"
    },
    {
      "code" : "id <MTLTexture> intermediaryTexture = [heap newTextureWithDescriptor:textureDescriptor];",
      "language" : "objective-c"
    },
    {
      "code" : "\/\/ Perform horizontal blur using the input texture as an input\n\/\/ and a view of the mipmap level of input texture as the output\n\n[computeEncoder setComputePipelineState:_horizontalKernel];\n\n[computeEncoder setTexture:inTexture\n                   atIndex:AAPLBlurTextureIndexInput];\n\n[computeEncoder setTexture:intermediaryTexture\n                   atIndex:AAPLBlurTextureIndexOutput];\n\n[computeEncoder setBytes:&mipmapLevel\n                  length:sizeof(mipmapLevel)\n                 atIndex:AAPLBlurBufferIndexLOD];\n\n[computeEncoder dispatchThreadgroups:threadgroupCount\n               threadsPerThreadgroup:threadgroupSize];\n\n\/\/ Perform vertical blur using the horizontally blurred texture as an input\n\/\/ and a view of the mipmap level of the input texture as the output\n\n[computeEncoder setComputePipelineState:_verticalKernel];\n\n[computeEncoder setTexture:intermediaryTexture\n                   atIndex:AAPLBlurTextureIndexInput];\n\n[computeEncoder setTexture:outTexture\n                   atIndex:AAPLBlurTextureIndexOutput];\n\nstatic const uint32_t mipmapLevelZero = 0;\n[computeEncoder setBytes:&mipmapLevelZero\n                  length:sizeof(mipmapLevelZero)\n                 atIndex:AAPLBlurBufferIndexLOD];\n\n[computeEncoder dispatchThreadgroups:threadgroupCount\n               threadsPerThreadgroup:threadgroupSize];",
      "language" : "objective-c"
    },
    {
      "code" : "[intermediaryTexture makeAliasable];",
      "language" : "objective-c"
    },
    {
      "code" : "[computeEncoder updateFence:fence];\n\n[computeEncoder endEncoding];",
      "language" : "objective-c"
    }
  ],
  "contentHash" : "ccf85fdb5abeb75a17d44d7fa5e587bd23ef4be297e2b4dfda59d18a823f307d",
  "crawledAt" : "2025-12-02T15:31:18Z",
  "id" : "9939B2FB-ABAC-43C0-9847-41FE07C16FA6",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Metal",
  "overview" : "## Overview\n\nThis sample demonstrates:\n\nThis implementation minimizes memory usage in an orderly fashion for a filter graph with a downsample and a Gaussian blur filter.\n\n\n\n### Getting started\n\nThe Xcode project contains schemes for running the sample on macOS, iOS, or tvOS. Metal is not supported in the iOS or tvOS Simulator, so the iOS and tvOS schemes require a physical device to run the sample. The default scheme is macOS, which runs the sample as is on your Mac.\n\n### Optimize resource allocation and performance\n\nStoring textures in a heap gives the sample more control over how resource memory is allocated and accessed. It’s also much faster to allocate resources from a heap than from a device. When resources are allocated from a device, Metal creates and tracks additional state to ensure that the resource memory is allocated, synchronized, and made available throughout the lifetime of any command buffer that needs the given resource. It does so even if the resource itself is destroyed before the command buffer begins execution.\n\nAlthough Metal also carries out this process for heaps, it doesn’t do so for resources within the heap. Instead, the app needs to perform explicit fine-grained synchronization when it creates objects from the heap and reuses memory. However, the overall cost of allocating resources from a heap is much lower than that of allocating resources from a device, particularly in the middle of a frame.\n\n### Create a heap for static textures\n\nThe sample loads image files into an array called `_imageTextures`. Instead of using `_imageTextures` directly, the sample uses `_imageHeap`, from which it allocates static textures. The sample creates a heap large enough to store all the static textures by aggregating their sizes. For each texture in `_imageTextures`, the sample calls the `heapTextureSizeAndAlignWithDescriptor:` method to calculate the size and alignment values required to allocate sufficient memory backing for each texture.\n\nFor each texture in `_imageTextures`, the sample allocates a new texture, `heapTexture`, from the heap.\n\nThe sample blits the contents of `_imageTextures[i]` to `heapTexture`, and then replaces `_imageTextures[i]` with `heapTexture`.\n\n\n\n### Create a heap for dynamic textures\n\nThe sample uses a separate heap, `_scratchHeap`, from which it allocates dynamic textures with a temporary lifetime. These textures have the same properties of the static texture being filtered in a given frame.\n\nThe sample uses `_scratchHeap` to quickly allocate temporary textures for the downsample and Gaussian blur filters. Thus, the required size and alignment values for `_scratchHeap` are equal to the sum of the same required values for each filter.\n\nAny textures allocated from `_scratchHeap` can also be deallocated, which allows the sample to reuse that same memory backing to allocate another texture.\n\n\n\n### Manage dependencies between filters\n\nThe sample uses `_fence` to control access to dynamic textures allocated from `_scratchHeap` and prevent GPU race conditions in the filter graph. This fence ensures that operations on dynamic textures are completed before the filter graph begins subsequent operations that depend on the results of previous operations.\n\nThe first filter, implemented by the sample in `AAPLDownsampleFilter`, creates a dynamic texture, `outTexture`, from the heap and allocates enough space for mipmaps.\n\nThe downsample filter then blits a source texture, `inTexture`, to `outTexture` and generates the mipmaps.\n\nFinally, the downsample filter calls the `updateFence:` and `endEncoding` methods to indicate that its operations are complete.\n\nThe second filter, implemented by the sample in `AAPLGaussianBlurFilter`, calls `waitForFence:` immediately after creating a compute command encoder. This forces the Gaussian blur filter to wait for the downsample filter to complete its work before beginning its own work. A waiting period is necessary because the Gaussian blur filter depends on dynamic texture data generated by the downsample filter. Without the fence, the GPU could execute both filters in parallel, and thus read uninitialized dynamic texture data allocated from the heap.\n\n\n\n### Reuse memory and manage dependencies within a filter\n\nThe Gaussian blur filter performs a horizontal blur and a vertical blur for each mipmap level of the dynamic texture produced by the downsample filter. For each mipmap level, the sample allocates a temporary texture, `intermediaryTexture`, from the dynamic textures heap.\n\nThis texture is temporary because it’s used only as an output destination from the horizontal blur and as an input source to the vertical blur. After the sample executes these blurs, the final texture data is stored in `outTexture` (which is a texture view of `inTexture`). Therefore, the texture data contained in `intermediaryTexture` is unused after each mipmap level iteration.\n\nInstead of allocating new memory for each mipmap level, the sample reuses the existing memory allocated for `intermediaryTexture`. After each mipmap level iteration, the sample calls the `makeAliasable` method to indicate that this memory can be reused by subsequent allocations from the same dynamic textures heap.\n\nThis memory reuse creates dynamic texture dependencies between mipmap levels. Therefore, after blurring each mipmap level, the sample calls the `updateFence:` and `endEncoding` methods to indicate that the blur operations are complete.\n\nBecause the sample already calls the `waitForFence:` method to wait for the downsample filter to complete its work, the sample leverages this same call to wait for any previous mipmap levels to complete their work before beginning a new mipmap level iteration.\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Metal\/implementing-a-multistage-image-filter-using-heaps-and-fences\ncrawled: 2025-12-02T15:31:18Z\n---\n\n# Implementing a multistage image filter using heaps and fences\n\n**Sample Code**\n\nUse fences to synchronize access to resources allocated on a heap.\n\n## Overview\n\nThis sample demonstrates:\n\n- Creating heaps for static and dynamic textures\n- Using aliasing to reduce the amount of memory used for temporary resources\n- Using fences to manage dependencies between encoders that produce and consume dynamic textures\n\nThis implementation minimizes memory usage in an orderly fashion for a filter graph with a downsample and a Gaussian blur filter.\n\n\n\n### Getting started\n\nThe Xcode project contains schemes for running the sample on macOS, iOS, or tvOS. Metal is not supported in the iOS or tvOS Simulator, so the iOS and tvOS schemes require a physical device to run the sample. The default scheme is macOS, which runs the sample as is on your Mac.\n\n### Optimize resource allocation and performance\n\nStoring textures in a heap gives the sample more control over how resource memory is allocated and accessed. It’s also much faster to allocate resources from a heap than from a device. When resources are allocated from a device, Metal creates and tracks additional state to ensure that the resource memory is allocated, synchronized, and made available throughout the lifetime of any command buffer that needs the given resource. It does so even if the resource itself is destroyed before the command buffer begins execution.\n\nAlthough Metal also carries out this process for heaps, it doesn’t do so for resources within the heap. Instead, the app needs to perform explicit fine-grained synchronization when it creates objects from the heap and reuses memory. However, the overall cost of allocating resources from a heap is much lower than that of allocating resources from a device, particularly in the middle of a frame.\n\n### Create a heap for static textures\n\nThe sample loads image files into an array called `_imageTextures`. Instead of using `_imageTextures` directly, the sample uses `_imageHeap`, from which it allocates static textures. The sample creates a heap large enough to store all the static textures by aggregating their sizes. For each texture in `_imageTextures`, the sample calls the `heapTextureSizeAndAlignWithDescriptor:` method to calculate the size and alignment values required to allocate sufficient memory backing for each texture.\n\n```objective-c\nfor(uint32_t i = 0; i < AAPLNumImages; i++)\n{\n    \/\/ Create a descriptor using the texture's properties\n    MTLTextureDescriptor *descriptor = [AAPLRenderer newDescriptorFromTexture:_imageTextures[i]\n                                                                  storageMode:heapDescriptor.storageMode];\n\n    \/\/ Determine the size needed for the heap from the given descriptor\n    MTLSizeAndAlign sizeAndAlign = [_device heapTextureSizeAndAlignWithDescriptor:descriptor];\n\n    \/\/ Align the size so that more resources will fit after this texture\n    sizeAndAlign.size = alignUp(sizeAndAlign.size, sizeAndAlign.align);\n\n    \/\/ Accumulate the size required for the heap to hold this texture\n    heapDescriptor.size += sizeAndAlign.size;\n}\n\n\/\/ Create a heap large enough to hold all resources\n_imageHeap = [_device newHeapWithDescriptor:heapDescriptor];\n```\n\nFor each texture in `_imageTextures`, the sample allocates a new texture, `heapTexture`, from the heap.\n\n```objective-c\nMTLTextureDescriptor *descriptor = [AAPLRenderer newDescriptorFromTexture:_imageTextures[i]\n                                                              storageMode:_imageHeap.storageMode];\n\n\/\/ Create a texture from the heap\nid<MTLTexture> heapTexture = [_imageHeap newTextureWithDescriptor:descriptor];\n```\n\nThe sample blits the contents of `_imageTextures[i]` to `heapTexture`, and then replaces `_imageTextures[i]` with `heapTexture`.\n\n```objective-c\nMTLRegion region = MTLRegionMake2D(0, 0, _imageTextures[i].width, _imageTextures[i].height);\n\nfor(NSUInteger level = 0; level < _imageTextures[i].mipmapLevelCount;  level++)\n{\n    for(NSUInteger slice = 0; slice < _imageTextures[i].arrayLength; slice++)\n    {\n        [blitEncoder copyFromTexture:_imageTextures[i]\n                         sourceSlice:slice\n                         sourceLevel:level\n                        sourceOrigin:region.origin\n                          sourceSize:region.size\n                           toTexture:heapTexture\n                    destinationSlice:slice\n                    destinationLevel:level\n                   destinationOrigin:region.origin];\n    }\n\n    region.size.width \/= 2;\n    region.size.height \/= 2;\n    if(region.size.width == 0) region.size.width = 1;\n    if(region.size.height == 0) region.size.height = 1;\n}\n\n\/\/ Replace the original texture with new texture from the heap\n_imageTextures[i] = heapTexture;\n```\n\n\n\n### Create a heap for dynamic textures\n\nThe sample uses a separate heap, `_scratchHeap`, from which it allocates dynamic textures with a temporary lifetime. These textures have the same properties of the static texture being filtered in a given frame.\n\n```objective-c\nid<MTLTexture> inTexture = _imageTextures[_currentImageIndex];\n\n[self createScratchHeap:inTexture];\n```\n\nThe sample uses `_scratchHeap` to quickly allocate temporary textures for the downsample and Gaussian blur filters. Thus, the required size and alignment values for `_scratchHeap` are equal to the sum of the same required values for each filter.\n\n```objective-c\nMTLSizeAndAlign downsampleSizeAndAlignRequirement = [_downsample heapSizeAndAlignWithInputTextureDescriptor:descriptor];\nMTLSizeAndAlign gaussianBlurSizeAndAlignRequirement = [_gaussianBlur heapSizeAndAlignWithInputTextureDescriptor:descriptor];\n\nNSUInteger requiredAlignment = MAX(gaussianBlurSizeAndAlignRequirement.align, downsampleSizeAndAlignRequirement.align);\nNSUInteger gaussianBlurSizeAligned = alignUp(gaussianBlurSizeAndAlignRequirement.size, requiredAlignment);\nNSUInteger downsampleSizeAligned = alignUp(downsampleSizeAndAlignRequirement.size, requiredAlignment);\nNSUInteger requiredSize = gaussianBlurSizeAligned + downsampleSizeAligned;\n\nif(!_scratchHeap || requiredSize > [_scratchHeap maxAvailableSizeWithAlignment:requiredAlignment])\n{\n    MTLHeapDescriptor *heapDesc = [[MTLHeapDescriptor alloc] init];\n\n    heapDesc.size        = requiredSize;\n    heapDesc.storageMode = heapStorageMode;\n\n    _scratchHeap = [_device newHeapWithDescriptor:heapDesc];\n}\n```\n\nAny textures allocated from `_scratchHeap` can also be deallocated, which allows the sample to reuse that same memory backing to allocate another texture.\n\n\n\n### Manage dependencies between filters\n\nThe sample uses `_fence` to control access to dynamic textures allocated from `_scratchHeap` and prevent GPU race conditions in the filter graph. This fence ensures that operations on dynamic textures are completed before the filter graph begins subsequent operations that depend on the results of previous operations.\n\nThe first filter, implemented by the sample in `AAPLDownsampleFilter`, creates a dynamic texture, `outTexture`, from the heap and allocates enough space for mipmaps.\n\n```objective-c\nMTLTextureDescriptor *textureDescriptor = [MTLTextureDescriptor texture2DDescriptorWithPixelFormat:inTexture.pixelFormat\n                                                                                             width:inTexture.width\n                                                                                            height:inTexture.height\n                                                                                         mipmapped:YES];\ntextureDescriptor.storageMode = heap.storageMode;\ntextureDescriptor.usage = MTLTextureUsageShaderWrite | MTLTextureUsageShaderRead;\n\nid <MTLTexture> outTexture = [heap newTextureWithDescriptor:textureDescriptor];\n```\n\nThe downsample filter then blits a source texture, `inTexture`, to `outTexture` and generates the mipmaps.\n\n```objective-c\n[blitCommandEncoder copyFromTexture:inTexture\n                        sourceSlice:0\n                        sourceLevel:0\n                       sourceOrigin:(MTLOrigin){ 0, 0, 0 }\n                         sourceSize:(MTLSize){ inTexture.width, inTexture.height, inTexture.depth }\n                          toTexture:outTexture\n                   destinationSlice:0\n                   destinationLevel:0\n                  destinationOrigin:(MTLOrigin){ 0, 0, 0}];\n\n[blitCommandEncoder generateMipmapsForTexture:outTexture];\n```\n\nFinally, the downsample filter calls the `updateFence:` and `endEncoding` methods to indicate that its operations are complete.\n\n```objective-c\n[blitCommandEncoder updateFence:fence];\n\n[blitCommandEncoder endEncoding];\n```\n\nThe second filter, implemented by the sample in `AAPLGaussianBlurFilter`, calls `waitForFence:` immediately after creating a compute command encoder. This forces the Gaussian blur filter to wait for the downsample filter to complete its work before beginning its own work. A waiting period is necessary because the Gaussian blur filter depends on dynamic texture data generated by the downsample filter. Without the fence, the GPU could execute both filters in parallel, and thus read uninitialized dynamic texture data allocated from the heap.\n\n```objective-c\n[computeEncoder waitForFence:fence];\n```\n\n\n\n### Reuse memory and manage dependencies within a filter\n\nThe Gaussian blur filter performs a horizontal blur and a vertical blur for each mipmap level of the dynamic texture produced by the downsample filter. For each mipmap level, the sample allocates a temporary texture, `intermediaryTexture`, from the dynamic textures heap.\n\n```objective-c\nid <MTLTexture> intermediaryTexture = [heap newTextureWithDescriptor:textureDescriptor];\n```\n\nThis texture is temporary because it’s used only as an output destination from the horizontal blur and as an input source to the vertical blur. After the sample executes these blurs, the final texture data is stored in `outTexture` (which is a texture view of `inTexture`). Therefore, the texture data contained in `intermediaryTexture` is unused after each mipmap level iteration.\n\n```objective-c\n\/\/ Perform horizontal blur using the input texture as an input\n\/\/ and a view of the mipmap level of input texture as the output\n\n[computeEncoder setComputePipelineState:_horizontalKernel];\n\n[computeEncoder setTexture:inTexture\n                   atIndex:AAPLBlurTextureIndexInput];\n\n[computeEncoder setTexture:intermediaryTexture\n                   atIndex:AAPLBlurTextureIndexOutput];\n\n[computeEncoder setBytes:&mipmapLevel\n                  length:sizeof(mipmapLevel)\n                 atIndex:AAPLBlurBufferIndexLOD];\n\n[computeEncoder dispatchThreadgroups:threadgroupCount\n               threadsPerThreadgroup:threadgroupSize];\n\n\/\/ Perform vertical blur using the horizontally blurred texture as an input\n\/\/ and a view of the mipmap level of the input texture as the output\n\n[computeEncoder setComputePipelineState:_verticalKernel];\n\n[computeEncoder setTexture:intermediaryTexture\n                   atIndex:AAPLBlurTextureIndexInput];\n\n[computeEncoder setTexture:outTexture\n                   atIndex:AAPLBlurTextureIndexOutput];\n\nstatic const uint32_t mipmapLevelZero = 0;\n[computeEncoder setBytes:&mipmapLevelZero\n                  length:sizeof(mipmapLevelZero)\n                 atIndex:AAPLBlurBufferIndexLOD];\n\n[computeEncoder dispatchThreadgroups:threadgroupCount\n               threadsPerThreadgroup:threadgroupSize];\n```\n\nInstead of allocating new memory for each mipmap level, the sample reuses the existing memory allocated for `intermediaryTexture`. After each mipmap level iteration, the sample calls the `makeAliasable` method to indicate that this memory can be reused by subsequent allocations from the same dynamic textures heap.\n\n```objective-c\n[intermediaryTexture makeAliasable];\n```\n\nThis memory reuse creates dynamic texture dependencies between mipmap levels. Therefore, after blurring each mipmap level, the sample calls the `updateFence:` and `endEncoding` methods to indicate that the blur operations are complete.\n\n```objective-c\n[computeEncoder updateFence:fence];\n\n[computeEncoder endEncoding];\n```\n\nBecause the sample already calls the `waitForFence:` method to wait for the downsample filter to complete its work, the sample leverages this same call to wait for any previous mipmap levels to complete their work before beginning a new mipmap level iteration.\n\n\n\n## Resource memory allocation and management\n\n- **Using argument buffers with resource heaps**: Reduce CPU overhead by using arrays inside argument buffers and combining them with resource heaps.\n- **Implementing a multistage image filter using heaps and events**: Use events to synchronize access to resources allocated on a heap.\n- **MTLHeap**: A memory pool from which you can suballocate resources.\n- **MTLHeapDescriptor**: A configuration that customizes the behavior for a Metal memory heap.\n- **MTLHeapType**: The options you use to choose the heap type.\n- **MTLSizeAndAlign**: The size and alignment of a resource, in bytes.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Reduce CPU overhead by using arrays inside argument buffers and combining them with resource heaps.",
          "name" : "Using argument buffers with resource heaps",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/using-argument-buffers-with-resource-heaps"
        },
        {
          "description" : "Use events to synchronize access to resources allocated on a heap.",
          "name" : "Implementing a multistage image filter using heaps and events",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/implementing-a-multistage-image-filter-using-heaps-and-events"
        },
        {
          "description" : "A memory pool from which you can suballocate resources.",
          "name" : "MTLHeap",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLHeap"
        },
        {
          "description" : "A configuration that customizes the behavior for a Metal memory heap.",
          "name" : "MTLHeapDescriptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLHeapDescriptor"
        },
        {
          "description" : "The options you use to choose the heap type.",
          "name" : "MTLHeapType",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLHeapType"
        },
        {
          "description" : "The size and alignment of a resource, in bytes.",
          "name" : "MTLSizeAndAlign",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLSizeAndAlign"
        }
      ],
      "title" : "Resource memory allocation and management"
    }
  ],
  "source" : "appleJSON",
  "title" : "Implementing a multistage image filter using heaps and fences",
  "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/implementing-a-multistage-image-filter-using-heaps-and-fences"
}