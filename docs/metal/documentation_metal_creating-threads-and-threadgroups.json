{
  "abstract" : "Learn how Metal organizes compute-processing workloads.",
  "codeExamples" : [
    {
      "code" : "kernel void\ngrayscaleKernel(texture2d<half, access::read>  inTexture  [[texture(AAPLTextureIndexInput)]],\n                texture2d<half, access::write> outTexture [[texture(AAPLTextureIndexOutput)]],\n                uint2                          gid        [[thread_position_in_grid]])\n{\n    if((gid.x >= outTexture.get_width()) || (gid.y >= outTexture.get_height()))\n    {\n        return;\n    }\n    half4 inColor  = inTexture.read(gid);\n    half  gray     = dot(inColor.rgb, kRec709Luma);\n    outTexture.write(half4(gray, gray, gray, 1.0), gid);\n}",
      "language" : "metal"
    },
    {
      "code" : "kernel void \nmyKernel(uint2 threadgroup_position_in_grid   [[ threadgroup_position_in_grid ]],\n         uint2 thread_position_in_threadgroup [[ thread_position_in_threadgroup ]],\n         uint2 threads_per_threadgroup        [[ threads_per_threadgroup ]]) \n{\n    \n    uint2 thread_position_in_grid = \n        (threadgroup_position_in_grid * threads_per_threadgroup) + \n        thread_position_in_threadgroup;\n}",
      "language" : "metal"
    }
  ],
  "contentHash" : "38f37c83df65c90c4e18ee050fca68d094c92bf59c318a480cbe7855969ded80",
  "crawledAt" : "2025-12-04T02:16:20Z",
  "id" : "653B7DD2-F494-4ADE-8492-CE62E9B1DFB9",
  "kind" : "article",
  "language" : "swift",
  "module" : "Metal",
  "overview" : "## Overview\n\nRecall from [doc:\/\/com.apple.metal\/documentation\/Metal\/processing-a-texture-in-a-compute-function] that when you dispatch your compute pass, Metal executes your kernel function over a 1D, 2D, or 3D grid. Each point in the grid represents a single instance of your kernel function, referred to as a *thread*. For example, in image processing, the grid is typically a 2D matrix of threads—representing the entire image—with each thread corresponding to a single pixel of the image being processed.\n\nThreads are organized into *threadgroups* that are executed together and can share a common block of memory. While sometimes kernel functions are designed so that threads run independently of each other, it’s also common for threads in a threadgroup to collaborate on their working set.\n\n### Identification of threads by position in grid\n\n[\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2928936] shows how an image being processed by a compute kernel is divided into threadgroups and how each threadgroup is composed of individual threads. Each thread processes a single pixel.\n\n\n\nA thread can be identified by its position in the grid; it’s this unique position that allows your kernel function to do something different for each thread. The sample kernel function in [doc:\/\/com.apple.metal\/documentation\/Metal\/processing-a-texture-in-a-compute-function], below, shows how a thread’s position in the grid is passed into the function as a parameter. In this case, the parameter, `gid`, is a vector representing 2D coordinates and is used to both read from and write to a particular location in a texture.\n\n`[[thread_position_in_grid]]` is an *attribute qualifier*. Attribute qualifiers, identifiable by their double square-bracket syntax, allow kernel parameters to be bound to resources and built-in variables, in this case the thread’s position in the grid to the kernel function.\n\nFor example, given a grid of 16 x 16 threads partitioned into 2 x 4 threadgroups of 8 x 4 threads, a single thread (shown in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929009] in red) has a position in the grid of (9,10):\n\n\n\n### Identification of threads by position in threadgroup\n\nA thread’s position in its threadgroup is also available as the attribute qualifier `[[thread_position_in_threadgroup]]`, and a threadgroup’s position in the grid is available as `[[threadgroup_position_in_grid]]`.\n\nDepending on the shape of the grid, these position attributes are either a scalar value, or a two- or three-element vector. In the case of a 2D grid, position attributes are two-element vectors, with the origin at the top-left.\n\nThe thread identified in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929009] is in the threadgroup with a position in the grid of (1,2), and its position in that threadgroup is (1,2), as shown in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929421]:\n\n\n\nUsing the following code, you can also calculate a thread’s position in the grid based on its position in its threadgroup and that threadgroup’s size and position in the grid:\n\n### SIMD groups\n\nThe threads in a threadgroup are further organized into single-instruction, multiple-data (SIMD) groups, also known as *warps* or *wavefronts*, that execute concurrently. The threads in a SIMD group execute the same code. Avoid writing code that could cause your kernel function to *diverge*; that is, to follow different code paths. A typical example of divergence is caused by using an *if* statement. Even if a single thread in a SIMD group takes a different path from the others, all threads in that group execute both branches, and the execution time for the group is the sum of the execution time of both branches.\n\nThe division of threadgroups into SIMD groups is defined by Metal. It remains constant for the duration of a kernel’s execution, across dispatches of a given kernel with the same launch parameters, and from one threadgroup to another within the dispatch.\n\nThe number of threads in a SIMD group is returned by the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState\/threadExecutionWidth] of your compute pipeline state object. Attribute qualifiers allow you to access a SIMD group’s scalar index within a threadgroup, and a thread’s scalar index within a SIMD group:\n\nAlthough threadgroups can be multidimensional, SIMD groups are 1D. Therefore, a thread’s position within a SIMD group is a scalar value for all threadgroup shapes. The SIMD group size remains constant and is unaffected by the threadgroup size.\n\nFor example, using the same 16 x 16 grid shown in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929009], with a thread execution width of 16, a single 8 x 4 threadgroup consists of 2 SIMD groups. Because a SIMD group contains 16 threads, each SIMD group constitutes 2 rows in the threadgroup:\n\n\n\nThe thread shown in red in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929426] has a `[[simdgroup_index_in_threadgroup]]` value of 1 and a `[[thread_index_in_simdgroup]]` value of 1:\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Metal\/creating-threads-and-threadgroups\ncrawled: 2025-12-04T02:16:20Z\n---\n\n# Creating threads and threadgroups\n\n**Article**\n\nLearn how Metal organizes compute-processing workloads.\n\n## Overview\n\nRecall from [doc:\/\/com.apple.metal\/documentation\/Metal\/processing-a-texture-in-a-compute-function] that when you dispatch your compute pass, Metal executes your kernel function over a 1D, 2D, or 3D grid. Each point in the grid represents a single instance of your kernel function, referred to as a *thread*. For example, in image processing, the grid is typically a 2D matrix of threads—representing the entire image—with each thread corresponding to a single pixel of the image being processed.\n\nThreads are organized into *threadgroups* that are executed together and can share a common block of memory. While sometimes kernel functions are designed so that threads run independently of each other, it’s also common for threads in a threadgroup to collaborate on their working set.\n\n### Identification of threads by position in grid\n\n[\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2928936] shows how an image being processed by a compute kernel is divided into threadgroups and how each threadgroup is composed of individual threads. Each thread processes a single pixel.\n\n\n\nA thread can be identified by its position in the grid; it’s this unique position that allows your kernel function to do something different for each thread. The sample kernel function in [doc:\/\/com.apple.metal\/documentation\/Metal\/processing-a-texture-in-a-compute-function], below, shows how a thread’s position in the grid is passed into the function as a parameter. In this case, the parameter, `gid`, is a vector representing 2D coordinates and is used to both read from and write to a particular location in a texture.\n\n```metal\nkernel void\ngrayscaleKernel(texture2d<half, access::read>  inTexture  [[texture(AAPLTextureIndexInput)]],\n                texture2d<half, access::write> outTexture [[texture(AAPLTextureIndexOutput)]],\n                uint2                          gid        [[thread_position_in_grid]])\n{\n    if((gid.x >= outTexture.get_width()) || (gid.y >= outTexture.get_height()))\n    {\n        return;\n    }\n    half4 inColor  = inTexture.read(gid);\n    half  gray     = dot(inColor.rgb, kRec709Luma);\n    outTexture.write(half4(gray, gray, gray, 1.0), gid);\n}\n```\n\n`[[thread_position_in_grid]]` is an *attribute qualifier*. Attribute qualifiers, identifiable by their double square-bracket syntax, allow kernel parameters to be bound to resources and built-in variables, in this case the thread’s position in the grid to the kernel function.\n\nFor example, given a grid of 16 x 16 threads partitioned into 2 x 4 threadgroups of 8 x 4 threads, a single thread (shown in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929009] in red) has a position in the grid of (9,10):\n\n\n\n### Identification of threads by position in threadgroup\n\nA thread’s position in its threadgroup is also available as the attribute qualifier `[[thread_position_in_threadgroup]]`, and a threadgroup’s position in the grid is available as `[[threadgroup_position_in_grid]]`.\n\nDepending on the shape of the grid, these position attributes are either a scalar value, or a two- or three-element vector. In the case of a 2D grid, position attributes are two-element vectors, with the origin at the top-left.\n\nThe thread identified in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929009] is in the threadgroup with a position in the grid of (1,2), and its position in that threadgroup is (1,2), as shown in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929421]:\n\n\n\nUsing the following code, you can also calculate a thread’s position in the grid based on its position in its threadgroup and that threadgroup’s size and position in the grid:\n\n```metal\nkernel void \nmyKernel(uint2 threadgroup_position_in_grid   [[ threadgroup_position_in_grid ]],\n         uint2 thread_position_in_threadgroup [[ thread_position_in_threadgroup ]],\n         uint2 threads_per_threadgroup        [[ threads_per_threadgroup ]]) \n{\n    \n    uint2 thread_position_in_grid = \n        (threadgroup_position_in_grid * threads_per_threadgroup) + \n        thread_position_in_threadgroup;\n}\n```\n\n### SIMD groups\n\nThe threads in a threadgroup are further organized into single-instruction, multiple-data (SIMD) groups, also known as *warps* or *wavefronts*, that execute concurrently. The threads in a SIMD group execute the same code. Avoid writing code that could cause your kernel function to *diverge*; that is, to follow different code paths. A typical example of divergence is caused by using an *if* statement. Even if a single thread in a SIMD group takes a different path from the others, all threads in that group execute both branches, and the execution time for the group is the sum of the execution time of both branches.\n\nThe division of threadgroups into SIMD groups is defined by Metal. It remains constant for the duration of a kernel’s execution, across dispatches of a given kernel with the same launch parameters, and from one threadgroup to another within the dispatch.\n\nThe number of threads in a SIMD group is returned by the [doc:\/\/com.apple.metal\/documentation\/Metal\/MTLComputePipelineState\/threadExecutionWidth] of your compute pipeline state object. Attribute qualifiers allow you to access a SIMD group’s scalar index within a threadgroup, and a thread’s scalar index within a SIMD group:\n\n\n\nAlthough threadgroups can be multidimensional, SIMD groups are 1D. Therefore, a thread’s position within a SIMD group is a scalar value for all threadgroup shapes. The SIMD group size remains constant and is unaffected by the threadgroup size.\n\nFor example, using the same 16 x 16 grid shown in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929009], with a thread execution width of 16, a single 8 x 4 threadgroup consists of 2 SIMD groups. Because a SIMD group contains 16 threads, each SIMD group constitutes 2 rows in the threadgroup:\n\n\n\nThe thread shown in red in [\/documentation\/metal\/compute_passes\/creating_threads_and_threadgroups#2929426] has a `[[simdgroup_index_in_threadgroup]]` value of 1 and a `[[thread_index_in_simdgroup]]` value of 1:\n\n\n\n## Encoding a compute pass\n\n- **Calculating threadgroup and grid sizes**: Calculate the optimum sizes for threadgroups and grids when dispatching compute-processing workloads.\n- **MTL4ComputeCommandEncoder**: Encodes computation dispatches, resource copying commands, and acceleration structure building commands for a single pass into a command buffer.\n- **MTLComputeCommandEncoder**: Encodes computation dispatch commands for a single compute pass into a command buffer.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Calculate the optimum sizes for threadgroups and grids when dispatching compute-processing workloads.",
          "name" : "Calculating threadgroup and grid sizes",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/calculating-threadgroup-and-grid-sizes"
        },
        {
          "description" : "Encodes computation dispatches, resource copying commands, and acceleration structure building commands for a single pass into a command buffer.",
          "name" : "MTL4ComputeCommandEncoder",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTL4ComputeCommandEncoder"
        },
        {
          "description" : "Encodes computation dispatch commands for a single compute pass into a command buffer.",
          "name" : "MTLComputeCommandEncoder",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLComputeCommandEncoder"
        }
      ],
      "title" : "Encoding a compute pass"
    }
  ],
  "source" : "appleJSON",
  "title" : "Creating threads and threadgroups",
  "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/creating-threads-and-threadgroups"
}