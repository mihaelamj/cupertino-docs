{
  "abstract" : "Train a machine learning model to classify images, and add it to your Core ML app.",
  "codeExamples" : [
    {
      "code" : "\/\/ Create an instance of the image classifier's wrapper class.\nlet imageClassifierWrapper = try? MobileNet(configuration: defaultConfig)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create an instance of the image classifier's wrapper class.\nlet imageClassifierWrapper = try? AnimalClassifier(configuration: defaultConfig)",
      "language" : "swift"
    }
  ],
  "contentHash" : "58671ac98d5eaf42709daf620c3eea1cd87811e53afaa684616148c2a62195b5",
  "crawledAt" : "2025-12-02T17:03:28Z",
  "id" : "E0BDD1E1-A712-4602-AF0D-46B3F34C6A54",
  "kind" : "article",
  "language" : "swift",
  "module" : "Create ML",
  "overview" : "## Overview\n\nAn *image classifier* is a machine learning model that recognizes images. When you give it an image, it responds with a category label for that image.\n\n\n\nYou train an image classifier by showing it many examples of images you’ve already labeled. For example, you can train an image classifier to recognize animals by gathering photos of elephants, giraffes, lions, and so on.\n\n\n\nAfter the image classifier finishes training, you assess its accuracy and, if it performs well enough, save it as a Core ML model file. You then import the model file into your Xcode project to use the image classifier in your app.\n\n### Gather Your Data\n\nUse at least 10 images per category, but keep in mind that an image classifier performs better with a more diverse set of images. Consider including images of each category from multiple angles and in different lighting conditions.\n\nBalance the number of images for each category. For example, don’t use 10 images for one category and then 1000 images for another.\n\nThe images can be in any format you can open in the Quicktime Player, such as JPEG and PNG. They don’t have to be a particular size, nor do they need to be the same size as each other. However, it’s best to use images that are at least 299 x 299 pixels.\n\nIf possible, gather images that best represent what you expect the model to see when you use it in your app. For example, if your app classifies images from a device’s camera in an outdoor setting, gather outdoor images from an identical or similar camera.\n\n### Organize Your Training Data\n\nPrepare a training dataset by sorting the images into subfolders. Give each subfolder a name for the category of images contained within it. For example, you might use the label `Cheetah` for all the images of cheetahs.\n\n\n\n### Organize Your Testing Data\n\nTesting your model with a testing dataset is a quick way to see how well your trained model might perform in the real world.\n\nIf your dataset has enough images, say 25 or more per category, create a testing dataset by duplicating the folder structure of the training dataset. Then move about 20 percent of the images from each category into the equivalent category folder in the testing dataset.\n\n### Create an Image Classifier Project\n\nUse Create ML to create an image classifier project. With Xcode open, Control-click the Xcode icon in the Dock and choose Open Developer Tool > Create ML. Or, from the Xcode menu, choose Open Developer Tool > Create ML.\n\nIn Create ML, choose File > New Project to see the list of model templates. Select Image Classification and click Next.\n\n\n\nChange the project’s default name to a more meaningful one. If applicable, enter additional information for the models that come from this project, such as one or more authors and a short description.\n\n\n\n### Configure the Training Session\n\nDrag the folder with your training dataset into the Training Data well in the project window.\n\n\n\nIf applicable, drag the folder with your testing dataset into the Testing Data well in the project window.\n\n\n\nYou can adjust the following parameters before training your image classifier:\n\n\n\n### Train the Image Classifier\n\nClick the Train button to start the training session. Create ML begins the session by quickly separating some of your training data into a validation dataset. Next, Create ML extracts features, such as edges, corners, textures, and regions of color, from the remaining training images. Create ML uses the images’ features to iteratively train the model and then checks its accuracy with the validation dataset.\n\n\n\nCreate ML shows its progress in a graph, where the black and gray lines represent the model’s accuracy with the training and validation datasets, respectively.\n\n### Assess the Model’s Accuracy\n\nWhen Create ML finishes training the model, it tests the model using the testing dataset. When it’s finished testing the model, Create ML shows the training, validation, and testing accuracy scores in the Evaluation tab. Models typically have higher accuracy scores on the training dataset because it learned from those images. In this example, the image classifier model correctly identified:\n\n\n\n*Precision* is the number of true positives divided by the sum of true positives and false positives. *Recall* is the number of true positives divided by the sum of true positives and false negatives.\n\nIf the evaluation performance isn’t good enough, you may need to train a new model with a dataset that has more variety. For example, you can gather additional images from new angles or in new environments, or add one or more image augmentation options. For details about evaluating a model, as well as strategies for improving the model’s performance, see [doc:\/\/com.apple.createml\/documentation\/CreateML\/improving-your-model-s-accuracy].\n\n### Preview the Model\n\nClick the Preview tab to try out the model with images it hasn’t seen before. To see the model’s predictions, drag image files to the column below the Train button.\n\n\n\n### Save the Model\n\nWhen you’re satisfied with the model’s performance, save it to the file system (in a Core ML format). From the Output tab, save the model using any of these options:\n\n\n\n### Add the Model to Your App\n\nThe last step is to add your trained model to an Xcode project. For example, your image classifier model can replace the model in the [doc:\/\/com.apple.documentation\/documentation\/CoreML\/classifying-images-with-vision-and-core-ml] sample.\n\nDownload the sample and open the project in Xcode. Drag your model file into the navigation pane. Xcode adds the model to your project and shows you the model’s metadata, operating system availability, class labels, and so on.\n\n\n\nTo use your model in code, you only need to change one line. The project instantiates the MobileNet model in exactly one place in the `ImagePredictor` class.\n\nChange this line to use your image classification model class instead:\n\nThese models are interchangeable because both take an image as input, and both output a label string. With your model substitution, the sample app classifies images as before, except now it uses your model and its associated labels.\n\n### Automate Model Training and Assessment\n\nYou can use Create ML to train a useful image classifier with very little code or machine learning expertise, as described in the sections above. However, you can also use an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier] instance to script the model training process. The general tasks are the same: prepare data, train a model, assess performance, and save the Core ML model file. The difference is that you do everything programmatically.\n\nFor example, you can initialize two [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/DataSource] instances, one for the training dataset and another for the testing dataset. Use the training data source to initialize an image classifier with [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/init(trainingData:parameters:)-4r6hr]. Then use the testing data source with its [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/evaluation(on:)-9p8mi] method, and assess the values in the [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLClassifierMetrics] instance it returns.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CreateML\/creating-an-image-classifier-model\ncrawled: 2025-12-02T17:03:28Z\n---\n\n# Creating an Image Classifier Model\n\n**Article**\n\nTrain a machine learning model to classify images, and add it to your Core ML app.\n\n## Overview\n\nAn *image classifier* is a machine learning model that recognizes images. When you give it an image, it responds with a category label for that image.\n\n\n\nYou train an image classifier by showing it many examples of images you’ve already labeled. For example, you can train an image classifier to recognize animals by gathering photos of elephants, giraffes, lions, and so on.\n\n\n\nAfter the image classifier finishes training, you assess its accuracy and, if it performs well enough, save it as a Core ML model file. You then import the model file into your Xcode project to use the image classifier in your app.\n\n### Gather Your Data\n\nUse at least 10 images per category, but keep in mind that an image classifier performs better with a more diverse set of images. Consider including images of each category from multiple angles and in different lighting conditions.\n\nBalance the number of images for each category. For example, don’t use 10 images for one category and then 1000 images for another.\n\nThe images can be in any format you can open in the Quicktime Player, such as JPEG and PNG. They don’t have to be a particular size, nor do they need to be the same size as each other. However, it’s best to use images that are at least 299 x 299 pixels.\n\nIf possible, gather images that best represent what you expect the model to see when you use it in your app. For example, if your app classifies images from a device’s camera in an outdoor setting, gather outdoor images from an identical or similar camera.\n\n\n\n### Organize Your Training Data\n\nPrepare a training dataset by sorting the images into subfolders. Give each subfolder a name for the category of images contained within it. For example, you might use the label `Cheetah` for all the images of cheetahs.\n\n\n\n### Organize Your Testing Data\n\nTesting your model with a testing dataset is a quick way to see how well your trained model might perform in the real world.\n\nIf your dataset has enough images, say 25 or more per category, create a testing dataset by duplicating the folder structure of the training dataset. Then move about 20 percent of the images from each category into the equivalent category folder in the testing dataset.\n\n### Create an Image Classifier Project\n\nUse Create ML to create an image classifier project. With Xcode open, Control-click the Xcode icon in the Dock and choose Open Developer Tool > Create ML. Or, from the Xcode menu, choose Open Developer Tool > Create ML.\n\nIn Create ML, choose File > New Project to see the list of model templates. Select Image Classification and click Next.\n\n\n\nChange the project’s default name to a more meaningful one. If applicable, enter additional information for the models that come from this project, such as one or more authors and a short description.\n\n\n\n### Configure the Training Session\n\nDrag the folder with your training dataset into the Training Data well in the project window.\n\n\n\nIf applicable, drag the folder with your testing dataset into the Testing Data well in the project window.\n\n\n\nYou can adjust the following parameters before training your image classifier:\n\n\n\n\n\n### Train the Image Classifier\n\nClick the Train button to start the training session. Create ML begins the session by quickly separating some of your training data into a validation dataset. Next, Create ML extracts features, such as edges, corners, textures, and regions of color, from the remaining training images. Create ML uses the images’ features to iteratively train the model and then checks its accuracy with the validation dataset.\n\n\n\nCreate ML shows its progress in a graph, where the black and gray lines represent the model’s accuracy with the training and validation datasets, respectively.\n\n### Assess the Model’s Accuracy\n\nWhen Create ML finishes training the model, it tests the model using the testing dataset. When it’s finished testing the model, Create ML shows the training, validation, and testing accuracy scores in the Evaluation tab. Models typically have higher accuracy scores on the training dataset because it learned from those images. In this example, the image classifier model correctly identified:\n\n- 100 percent of the training images\n- 95 percent of the validation images\n- 97 percent of the testing images\n\n\n\n*Precision* is the number of true positives divided by the sum of true positives and false positives. *Recall* is the number of true positives divided by the sum of true positives and false negatives.\n\nIf the evaluation performance isn’t good enough, you may need to train a new model with a dataset that has more variety. For example, you can gather additional images from new angles or in new environments, or add one or more image augmentation options. For details about evaluating a model, as well as strategies for improving the model’s performance, see [doc:\/\/com.apple.createml\/documentation\/CreateML\/improving-your-model-s-accuracy].\n\n### Preview the Model\n\nClick the Preview tab to try out the model with images it hasn’t seen before. To see the model’s predictions, drag image files to the column below the Train button.\n\n\n\n### Save the Model\n\nWhen you’re satisfied with the model’s performance, save it to the file system (in a Core ML format). From the Output tab, save the model using any of these options:\n\n- Click the Save button to save the model to the file system.\n- Click the Export button to open the model in Xcode.\n- Click the Share button to send the model to someone else, such as through Mail or Messages.\n- Drag the model’s icon anywhere that accepts a file.\n\n\n\n### Add the Model to Your App\n\nThe last step is to add your trained model to an Xcode project. For example, your image classifier model can replace the model in the [doc:\/\/com.apple.documentation\/documentation\/CoreML\/classifying-images-with-vision-and-core-ml] sample.\n\nDownload the sample and open the project in Xcode. Drag your model file into the navigation pane. Xcode adds the model to your project and shows you the model’s metadata, operating system availability, class labels, and so on.\n\n\n\nTo use your model in code, you only need to change one line. The project instantiates the MobileNet model in exactly one place in the `ImagePredictor` class.\n\n```swift\n\/\/ Create an instance of the image classifier's wrapper class.\nlet imageClassifierWrapper = try? MobileNet(configuration: defaultConfig)\n```\n\nChange this line to use your image classification model class instead:\n\n```swift\n\/\/ Create an instance of the image classifier's wrapper class.\nlet imageClassifierWrapper = try? AnimalClassifier(configuration: defaultConfig)\n```\n\nThese models are interchangeable because both take an image as input, and both output a label string. With your model substitution, the sample app classifies images as before, except now it uses your model and its associated labels.\n\n### Automate Model Training and Assessment\n\nYou can use Create ML to train a useful image classifier with very little code or machine learning expertise, as described in the sections above. However, you can also use an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier] instance to script the model training process. The general tasks are the same: prepare data, train a model, assess performance, and save the Core ML model file. The difference is that you do everything programmatically.\n\nFor example, you can initialize two [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/DataSource] instances, one for the training dataset and another for the testing dataset. Use the training data source to initialize an image classifier with [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/init(trainingData:parameters:)-4r6hr]. Then use the testing data source with its [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/evaluation(on:)-9p8mi] method, and assess the values in the [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLClassifierMetrics] instance it returns.\n\n## Image models\n\n- **MLImageClassifier**: A model you train to classify images.\n- **MLObjectDetector**: A model you train to classify one or more objects within an image.\n- **MLHandPoseClassifier**: A task that creates a hand pose classification model by training with images of people’s hands that you provide.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A model you train to classify images.",
          "name" : "MLImageClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier"
        },
        {
          "description" : "A model you train to classify one or more objects within an image.",
          "name" : "MLObjectDetector",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector"
        },
        {
          "description" : "A task that creates a hand pose classification model by training with images of people’s hands that you provide.",
          "name" : "MLHandPoseClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLHandPoseClassifier"
        }
      ],
      "title" : "Image models"
    }
  ],
  "source" : "appleJSON",
  "title" : "Creating an Image Classifier Model",
  "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/creating-an-image-classifier-model"
}