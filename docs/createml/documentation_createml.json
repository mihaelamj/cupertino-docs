{
  "abstract" : "Create machine learning models for use in your app.",
  "codeExamples" : [

  ],
  "contentHash" : "587b9d1598dc1976869eba053df4d24d5d5b82eba14006b44d3a903a8b3cc027",
  "crawledAt" : "2025-12-05T13:26:19Z",
  "id" : "93CB2869-834F-46B3-9CD9-08E722B4D0E9",
  "kind" : "framework",
  "language" : "swift",
  "module" : "Create ML",
  "overview" : "## Overview\n\nUse Create ML with familiar tools like Swift and macOS playgrounds to create and train custom machine learning models on your Mac. You can train models to perform tasks like recognizing images, extracting meaning from text, or finding relationships between numerical values.\n\n\n\nYou train a model to recognize patterns by showing it representative samples. For example, you can train a model to recognize dogs by showing it lots of images of different dogs. After you’ve trained the model, you test it out on data it hasn’t seen before, and evaluate how well it performed the task. When the model is performing well enough, you’re ready to integrate it into your app using [doc:\/\/com.apple.documentation\/documentation\/CoreML].\n\n\n\nCreate ML leverages the machine learning infrastructure built in to Apple products like Photos and Siri. This means your image classification and natural language models are smaller and take much less time to train.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/createml\ncrawled: 2025-12-05T13:26:19Z\n---\n\n# Create ML\n\n**Framework**\n\nCreate machine learning models for use in your app.\n\n## Overview\n\nUse Create ML with familiar tools like Swift and macOS playgrounds to create and train custom machine learning models on your Mac. You can train models to perform tasks like recognizing images, extracting meaning from text, or finding relationships between numerical values.\n\n\n\nYou train a model to recognize patterns by showing it representative samples. For example, you can train a model to recognize dogs by showing it lots of images of different dogs. After you’ve trained the model, you test it out on data it hasn’t seen before, and evaluate how well it performed the task. When the model is performing well enough, you’re ready to integrate it into your app using [doc:\/\/com.apple.documentation\/documentation\/CoreML].\n\n\n\nCreate ML leverages the machine learning infrastructure built in to Apple products like Photos and Siri. This means your image classification and natural language models are smaller and take much less time to train.\n\n## Image models\n\n- **Creating an Image Classifier Model**: Train a machine learning model to classify images, and add it to your Core ML app.\n- **MLImageClassifier**: A model you train to classify images.\n- **MLObjectDetector**: A model you train to classify one or more objects within an image.\n- **MLHandPoseClassifier**: A task that creates a hand pose classification model by training with images of people’s hands that you provide.\n\n## Video models\n\n- **Creating an Action Classifier Model**: Train a machine learning model to recognize a person’s body movements.\n- **Detecting human actions in a live video feed**: Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.\n- **MLActionClassifier**: A model you train with videos to classify a person’s body movements.\n- **MLHandActionClassifier**: A task that creates a hand action classification model by training with videos of people’s hand movements that you provide.\n- **MLStyleTransfer**: A model you train to apply an image’s style to other images or videos.\n\n## Text models\n\n- **Creating a text classifier model**: Train a machine learning model to classify natural language text.\n- **Creating a word tagger model**: Train a machine learning model to tag individual words in natural language text.\n- **MLTextClassifier**: A model you train to classify natural language text.\n- **MLWordTagger**: A word-tagging model you train to classify natural language text at the word level.\n- **MLGazetteer**: A collection of terms and their labels, which augments a tagger that analyzes natural language text.\n- **MLWordEmbedding**: A map of strings in a vector space that enable your app to find similar strings by looking at a string’s neighbors.\n\n## Sound models\n\n- **MLSoundClassifier**: A machine learning model you train with audio files to recognize and identify sounds on a device.\n\n## Motion models\n\n- **MLActivityClassifier**: A model you train to classify motion sensor data.\n\n## Tabular models\n\n- **Creating a model from tabular data**: Train a machine learning model by using Core ML to import and manage tabular data.\n- **MLClassifier**: A model you train to classify data into discrete categories.\n- **MLRegressor**: A model you train to estimate continuous values.\n- **MLRecommender**: A model you train to make recommendations based on item similarity, grouping, and, optionally, item ratings.\n\n## Tabular data\n\n- **MLDataTable**: A table of data for training or evaluating a machine learning model.\n- **MLDataValue**: The value of a cell in a data table.\n- **Data visualizations**: Render images of data tables and columns in a playground.\n\n## Model accuracy\n\n- **Improving Your Model’s Accuracy**: Use metrics to tune the performance of your machine learning model.\n- **MLClassifierMetrics**: Metrics you use to evaluate a classifier’s performance.\n- **MLRegressorMetrics**: Metrics you use to evaluate a regressor’s performance.\n- **MLWordTaggerMetrics**: Metrics you use to evaluate a word tagger’s performance.\n- **MLRecommenderMetrics**: Metrics you use to evaluate a recommender’s performance.\n- **MLObjectDetectorMetrics**: Metrics you use to evaluate an object detector’s performance.\n\n## Model training Control\n\n- **MLJob**: The representation of a model’s asynchronous training session you use to monitor the session’s progress or terminate its execution.\n- **MLTrainingSession**: The current state of a model’s asynchronous training session.\n- **MLTrainingSessionParameters**: The configuration settings for a training session.\n- **MLCheckpoint**: The state of a model’s asynchronous training session at a specific point in time during the feature extraction or training phase.\n\n## Supporting types\n\n- **MLCreateError**: The errors Create ML throws while performing various operations, such as training models, making predictions, writing models to a file system, and so on.\n- **MLModelMetadata**: Information about a model that’s stored in a Core ML model file.\n- **MLSplitStrategy**: Data partitioning approaches, typically for creating a validation dataset from a training dataset.\n\n## Articles\n\n- **Data visualizations**: Render images of data tables and columns in a playground.\n- **Detecting human actions in a live video feed**: Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.\n- **Gathering Training Videos for an Action Classifier**: Collect quality example videos that effectively train action classifiers.\n\n## Functions\n\n- **show(_:)**: Generates a streaming visualization of the untyped column.\n- **show(_:_:)**: Generates a streaming plot visualization of the two untyped columns.\n\n## Enumerations\n\n- **MLBoundingBoxAnchor**: A location within a bounding box that an annotation’s coordinates use as their reference point.\n- **MLBoundingBoxCoordinatesOrigin**: The location within an image that an annotation’s coordinates use as their origin.\n- **MLBoundingBoxUnits**: The units a bounding box annotation uses to define its position and size.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Train a machine learning model to classify images, and add it to your Core ML app.",
          "name" : "Creating an Image Classifier Model",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/creating-an-image-classifier-model"
        },
        {
          "description" : "A model you train to classify images.",
          "name" : "MLImageClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier"
        },
        {
          "description" : "A model you train to classify one or more objects within an image.",
          "name" : "MLObjectDetector",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector"
        },
        {
          "description" : "A task that creates a hand pose classification model by training with images of people’s hands that you provide.",
          "name" : "MLHandPoseClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLHandPoseClassifier"
        }
      ],
      "title" : "Image models"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Train a machine learning model to recognize a person’s body movements.",
          "name" : "Creating an Action Classifier Model",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/creating-an-action-classifier-model"
        },
        {
          "description" : "Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.",
          "name" : "Detecting human actions in a live video feed",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/detecting-human-actions-in-a-live-video-feed"
        },
        {
          "description" : "A model you train with videos to classify a person’s body movements.",
          "name" : "MLActionClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLActionClassifier"
        },
        {
          "description" : "A task that creates a hand action classification model by training with videos of people’s hand movements that you provide.",
          "name" : "MLHandActionClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLHandActionClassifier"
        },
        {
          "description" : "A model you train to apply an image’s style to other images or videos.",
          "name" : "MLStyleTransfer",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLStyleTransfer"
        }
      ],
      "title" : "Video models"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Train a machine learning model to classify natural language text.",
          "name" : "Creating a text classifier model",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/creating-a-text-classifier-model"
        },
        {
          "description" : "Train a machine learning model to tag individual words in natural language text.",
          "name" : "Creating a word tagger model",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/creating-a-word-tagger-model"
        },
        {
          "description" : "A model you train to classify natural language text.",
          "name" : "MLTextClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLTextClassifier"
        },
        {
          "description" : "A word-tagging model you train to classify natural language text at the word level.",
          "name" : "MLWordTagger",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLWordTagger"
        },
        {
          "description" : "A collection of terms and their labels, which augments a tagger that analyzes natural language text.",
          "name" : "MLGazetteer",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLGazetteer"
        },
        {
          "description" : "A map of strings in a vector space that enable your app to find similar strings by looking at a string’s neighbors.",
          "name" : "MLWordEmbedding",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLWordEmbedding"
        }
      ],
      "title" : "Text models"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A machine learning model you train with audio files to recognize and identify sounds on a device.",
          "name" : "MLSoundClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLSoundClassifier"
        }
      ],
      "title" : "Sound models"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A model you train to classify motion sensor data.",
          "name" : "MLActivityClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLActivityClassifier"
        }
      ],
      "title" : "Motion models"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Train a machine learning model by using Core ML to import and manage tabular data.",
          "name" : "Creating a model from tabular data",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/creating-a-model-from-tabular-data"
        },
        {
          "description" : "A model you train to classify data into discrete categories.",
          "name" : "MLClassifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLClassifier"
        },
        {
          "description" : "A model you train to estimate continuous values.",
          "name" : "MLRegressor",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLRegressor"
        },
        {
          "description" : "A model you train to make recommendations based on item similarity, grouping, and, optionally, item ratings.",
          "name" : "MLRecommender",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLRecommender"
        }
      ],
      "title" : "Tabular models"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A table of data for training or evaluating a machine learning model.",
          "name" : "MLDataTable",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLDataTable"
        },
        {
          "description" : "The value of a cell in a data table.",
          "name" : "MLDataValue",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLDataValue"
        },
        {
          "description" : "Render images of data tables and columns in a playground.",
          "name" : "Data visualizations",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/data-visualizations"
        }
      ],
      "title" : "Tabular data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use metrics to tune the performance of your machine learning model.",
          "name" : "Improving Your Model’s Accuracy",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/improving-your-model-s-accuracy"
        },
        {
          "description" : "Metrics you use to evaluate a classifier’s performance.",
          "name" : "MLClassifierMetrics",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLClassifierMetrics"
        },
        {
          "description" : "Metrics you use to evaluate a regressor’s performance.",
          "name" : "MLRegressorMetrics",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLRegressorMetrics"
        },
        {
          "description" : "Metrics you use to evaluate a word tagger’s performance.",
          "name" : "MLWordTaggerMetrics",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLWordTaggerMetrics"
        },
        {
          "description" : "Metrics you use to evaluate a recommender’s performance.",
          "name" : "MLRecommenderMetrics",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLRecommenderMetrics"
        },
        {
          "description" : "Metrics you use to evaluate an object detector’s performance.",
          "name" : "MLObjectDetectorMetrics",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetectorMetrics"
        }
      ],
      "title" : "Model accuracy"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The representation of a model’s asynchronous training session you use to monitor the session’s progress or terminate its execution.",
          "name" : "MLJob",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLJob"
        },
        {
          "description" : "The current state of a model’s asynchronous training session.",
          "name" : "MLTrainingSession",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLTrainingSession"
        },
        {
          "description" : "The configuration settings for a training session.",
          "name" : "MLTrainingSessionParameters",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLTrainingSessionParameters"
        },
        {
          "description" : "The state of a model’s asynchronous training session at a specific point in time during the feature extraction or training phase.",
          "name" : "MLCheckpoint",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLCheckpoint"
        }
      ],
      "title" : "Model training Control"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The errors Create ML throws while performing various operations, such as training models, making predictions, writing models to a file system, and so on.",
          "name" : "MLCreateError",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLCreateError"
        },
        {
          "description" : "Information about a model that’s stored in a Core ML model file.",
          "name" : "MLModelMetadata",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLModelMetadata"
        },
        {
          "description" : "Data partitioning approaches, typically for creating a validation dataset from a training dataset.",
          "name" : "MLSplitStrategy",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLSplitStrategy"
        }
      ],
      "title" : "Supporting types"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Render images of data tables and columns in a playground.",
          "name" : "Data visualizations",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/create-ml-utilties"
        },
        {
          "description" : "Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.",
          "name" : "Detecting human actions in a live video feed",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/detecting-human-actions-in-a-live-video-feed"
        },
        {
          "description" : "Collect quality example videos that effectively train action classifiers.",
          "name" : "Gathering Training Videos for an Action Classifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/recording-or-choosing-training-videos"
        }
      ],
      "title" : "Articles"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Generates a streaming visualization of the untyped column.",
          "name" : "show(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/show(_:)"
        },
        {
          "description" : "Generates a streaming plot visualization of the two untyped columns.",
          "name" : "show(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/show(_:_:)"
        }
      ],
      "title" : "Functions"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A location within a bounding box that an annotation’s coordinates use as their reference point.",
          "name" : "MLBoundingBoxAnchor",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLBoundingBoxAnchor"
        },
        {
          "description" : "The location within an image that an annotation’s coordinates use as their origin.",
          "name" : "MLBoundingBoxCoordinatesOrigin",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLBoundingBoxCoordinatesOrigin"
        },
        {
          "description" : "The units a bounding box annotation uses to define its position and size.",
          "name" : "MLBoundingBoxUnits",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLBoundingBoxUnits"
        }
      ],
      "title" : "Enumerations"
    }
  ],
  "source" : "appleJSON",
  "title" : "Create ML",
  "url" : "https:\/\/developer.apple.com\/documentation\/createml"
}