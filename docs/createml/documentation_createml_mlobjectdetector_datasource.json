{
  "abstract" : "A data source for an object detector.",
  "codeExamples" : [

  ],
  "contentHash" : "7bc23153ca70323101d1a2cb33944d3a02a676d4bf5f1531cc0807cda59d71ea",
  "crawledAt" : "2025-12-04T03:12:16Z",
  "declaration" : {
    "code" : "enum DataSource",
    "language" : "swift"
  },
  "id" : "89D998C6-5227-406E-A0AA-E08E7651CA81",
  "kind" : "enum",
  "language" : "swift",
  "module" : "Create ML",
  "overview" : "## Overview\n\nYou use a data source to specify the training dataset for an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLObjectDetector] training session. An object-detector data source represents a set of images and an annotation for each object in an image.\n\nEach object annotation consists of the object’s name, or *label*, and its location in the image. A single image can have multiple objects and, therefore, multiple annotations. For example, you can train an object detector with images of dining tables, along with annotations for bananas, croissants, and beverages. Each image can have one or more instances of an object, or any combination of objects.",
  "platforms" : [
    "macOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\ncrawled: 2025-12-04T03:12:16Z\n---\n\n# MLObjectDetector.DataSource\n\n**Enumeration**\n\nA data source for an object detector.\n\n## Declaration\n\n```swift\nenum DataSource\n```\n\n## Overview\n\nYou use a data source to specify the training dataset for an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLObjectDetector] training session. An object-detector data source represents a set of images and an annotation for each object in an image.\n\nEach object annotation consists of the object’s name, or *label*, and its location in the image. A single image can have multiple objects and, therefore, multiple annotations. For example, you can train an object detector with images of dining tables, along with annotations for bananas, croissants, and beverages. Each image can have one or more instances of an object, or any combination of objects.\n\n## Creating a data source\n\n- **MLObjectDetector.DataSource.directoryWithImagesAndJsonAnnotation(at:)**: An object-detector data source you create by selecting a directory that contains image files and exactly one JSON annotation file.\n- **MLObjectDetector.DataSource.directoryWithImages(at:annotationFile:)**: An object-detector data source you create by selecting the location of a directory of image files, and the location of a JSON annotation file.\n- **MLObjectDetector.DataSource.table(_:imageColumn:annotationColumn:)**: An object-detector data source you create with a data table.\n\n## Getting the annotated file names\n\n- **gatherAnnotatedFileNames()**: Processes the data source and returns a data frame that contains file URLs and annotations.\n\n## Getting the data frame\n\n- **MLObjectDetector.DataSource.frame(_:imageColumn:annotationColumn:)**: Data specified by a `DataFrame` containing a column for image file paths and a column with annotations.\n\n## Retrieving the data\n\n- **imagesWithObjectAnnotations()**: Generates a data table where each row represents an image, and its columns are the image file URLs and its annotations.\n\n## Splitting the data\n\n- **stratifiedSplit(proportions:seed:annotationColumn:)**: Generates a new data table by splitting the data source using the specified proportions.\n\n## Supporting types\n\n- **MLObjectDetector.AnnotationType**: The available types of image annotations.\n- **MLObjectDetector.ModelParameters**: Parameters that affect the process of training an object detection model.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object-detector data source you create by selecting a directory that contains image files and exactly one JSON annotation file.",
          "name" : "MLObjectDetector.DataSource.directoryWithImagesAndJsonAnnotation(at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\/directoryWithImagesAndJsonAnnotation(at:)"
        },
        {
          "description" : "An object-detector data source you create by selecting the location of a directory of image files, and the location of a JSON annotation file.",
          "name" : "MLObjectDetector.DataSource.directoryWithImages(at:annotationFile:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\/directoryWithImages(at:annotationFile:)"
        },
        {
          "description" : "An object-detector data source you create with a data table.",
          "name" : "MLObjectDetector.DataSource.table(_:imageColumn:annotationColumn:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\/table(_:imageColumn:annotationColumn:)"
        }
      ],
      "title" : "Creating a data source"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Processes the data source and returns a data frame that contains file URLs and annotations.",
          "name" : "gatherAnnotatedFileNames()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\/gatherAnnotatedFileNames()"
        }
      ],
      "title" : "Getting the annotated file names"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Data specified by a `DataFrame` containing a column for image file paths and a column with annotations.",
          "name" : "MLObjectDetector.DataSource.frame(_:imageColumn:annotationColumn:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\/frame(_:imageColumn:annotationColumn:)"
        }
      ],
      "title" : "Getting the data frame"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Generates a data table where each row represents an image, and its columns are the image file URLs and its annotations.",
          "name" : "imagesWithObjectAnnotations()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\/imagesWithObjectAnnotations()"
        }
      ],
      "title" : "Retrieving the data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Generates a new data table by splitting the data source using the specified proportions.",
          "name" : "stratifiedSplit(proportions:seed:annotationColumn:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource\/stratifiedSplit(proportions:seed:annotationColumn:)"
        }
      ],
      "title" : "Splitting the data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The available types of image annotations.",
          "name" : "MLObjectDetector.AnnotationType",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/AnnotationType"
        },
        {
          "description" : "Parameters that affect the process of training an object detection model.",
          "name" : "MLObjectDetector.ModelParameters",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/ModelParameters-swift.struct"
        }
      ],
      "title" : "Supporting types"
    }
  ],
  "source" : "appleJSON",
  "title" : "MLObjectDetector.DataSource",
  "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLObjectDetector\/DataSource"
}