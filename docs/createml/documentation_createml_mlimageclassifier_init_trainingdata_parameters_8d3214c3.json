{
  "abstract" : "Creates an image classifier with a training dataset represented by a data source.",
  "codeExamples" : [
    {
      "code" : "let parameters = MLImageClassifier.ModelParameters(\n    featureExtractor: .scenePrint(revision: 1),\n    validationData: nil,\n    maxIterations: 20,\n    augmentationOptions: [.crop]\n)",
      "language" : "swift"
    },
    {
      "code" : "if let downloads = FileManager.default.urls(for: .downloadsDirectory, in: .userDomainMask).first {\n    let trainingURL = downloads.appendingPathComponent(\"Training\")\n    let classifier = try MLImageClassifier(\n        trainingData: .labeledDirectories(at: trainingURL),\n        parameters: parameters\n    )\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "5a45362f8cd6557c6a3b41e6ae56ff03fdf46d4bf483aff098db0adbc773bdcc",
  "crawledAt" : "2025-12-04T03:11:26Z",
  "declaration" : {
    "code" : "init(trainingData: MLImageClassifier.DataSource, parameters: MLImageClassifier.ModelParameters = ModelParameters(\n            validation: .split(strategy: .automatic),\n            augmentation: [],\n            algorithm: .transferLearning(\n                featureExtractor: .scenePrint(revision: 1),\n                classifier: .logisticRegressor\n            )\n        )) throws",
    "language" : "swift"
  },
  "id" : "B22FF4EC-E4F5-4759-8420-BF786925710E",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Create ML",
  "overview" : "## Discussion\n\nWhen you create an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier] instance, initialize it with an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/ModelParameters-swift.struct] structure. This allows you to configure the image classifier training process. For example, you can explicitly define the validation dataset instead of allowing the model to choose a random selection of your training data. Alternatively, as shown in the following example, set `validationData` to `nil` to allow the classifier to choose the validation data for you from among your training data. This lets you set other parameters—like maximum iterations and augmentation options—to values other than the default.\n\nUse the parameter structure and your training data to build a classifier. The following example uses training data from labeled directories within a directory called `Training`, which resides in the `Downloads` directory:\n\nTraining begins immediately.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier\/init(trainingData:parameters:)\ncrawled: 2025-12-04T03:11:26Z\n---\n\n# init(trainingData:parameters:)\n\n**Initializer**\n\nCreates an image classifier with a training dataset represented by a data source.\n\n## Declaration\n\n```swift\ninit(trainingData: MLImageClassifier.DataSource, parameters: MLImageClassifier.ModelParameters = ModelParameters(\n            validation: .split(strategy: .automatic),\n            augmentation: [],\n            algorithm: .transferLearning(\n                featureExtractor: .scenePrint(revision: 1),\n                classifier: .logisticRegressor\n            )\n        )) throws\n```\n\n## Parameters\n\n- **trainingData**: A set of labeled images the task uses to train the image classifier model, contained in a data source.\n- **parameters**: An [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/ModelParameters-swift.struct] instance you use to configure the model for the training session.\n\n## Discussion\n\nWhen you create an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier] instance, initialize it with an [doc:\/\/com.apple.createml\/documentation\/CreateML\/MLImageClassifier\/ModelParameters-swift.struct] structure. This allows you to configure the image classifier training process. For example, you can explicitly define the validation dataset instead of allowing the model to choose a random selection of your training data. Alternatively, as shown in the following example, set `validationData` to `nil` to allow the classifier to choose the validation data for you from among your training data. This lets you set other parameters—like maximum iterations and augmentation options—to values other than the default.\n\n```swift\nlet parameters = MLImageClassifier.ModelParameters(\n    featureExtractor: .scenePrint(revision: 1),\n    validationData: nil,\n    maxIterations: 20,\n    augmentationOptions: [.crop]\n)\n```\n\nUse the parameter structure and your training data to build a classifier. The following example uses training data from labeled directories within a directory called `Training`, which resides in the `Downloads` directory:\n\n```swift\nif let downloads = FileManager.default.urls(for: .downloadsDirectory, in: .userDomainMask).first {\n    let trainingURL = downloads.appendingPathComponent(\"Training\")\n    let classifier = try MLImageClassifier(\n        trainingData: .labeledDirectories(at: trainingURL),\n        parameters: parameters\n    )\n}\n```\n\nTraining begins immediately.\n\n\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "init(trainingData:parameters:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier\/init(trainingData:parameters:)"
}