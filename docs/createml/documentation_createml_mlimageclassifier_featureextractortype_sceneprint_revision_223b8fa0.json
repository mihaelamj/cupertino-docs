{
  "abstract" : "A feature extractor trained on millions of images.",
  "codeExamples" : [

  ],
  "contentHash" : "8f0f2633cd35a40395f1e64103da4412c14027c3cdaf5b515cdad02902630b40",
  "crawledAt" : "2025-12-05T11:55:46Z",
  "declaration" : {
    "code" : "case scenePrint(revision: Int?)",
    "language" : "swift"
  },
  "id" : "C69ECE95-6084-4AE1-9A08-1D5D3CF6324E",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Create ML",
  "overview" : "## Discussion\n\nThe scene print feature extractor works best with images of real world objects because it trained on millions of such images. Scene print is not suitable for character recognition, because the input images are highly binary in nature (pixels are either on or off).\n\nWhen you train an image classifier using scene print, or make predictions with the resulting model, use images with 299x299 pixels or more. The model upscales smaller images, to 299x299 before it feeds them to the feature extractor, which may result in poor accuracy.\n\nTypically, scene print works best if the source of your training data matches the source of the images you want to classify. For example, if your app classifies images captured with an iPhone camera, train your model using images captured in the same way, if possible.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier\/FeatureExtractorType\/scenePrint(revision:)\ncrawled: 2025-12-05T11:55:46Z\n---\n\n# MLImageClassifier.FeatureExtractorType.scenePrint(revision:)\n\n**Case**\n\nA feature extractor trained on millions of images.\n\n## Declaration\n\n```swift\ncase scenePrint(revision: Int?)\n```\n\n## Parameters\n\n- **revision**: The sceneprint version. The supported versions include 1 and 2. If `nil` defaults to the latest version.\n\n## Discussion\n\n\n\nThe scene print feature extractor works best with images of real world objects because it trained on millions of such images. Scene print is not suitable for character recognition, because the input images are highly binary in nature (pixels are either on or off).\n\nWhen you train an image classifier using scene print, or make predictions with the resulting model, use images with 299x299 pixels or more. The model upscales smaller images, to 299x299 before it feeds them to the feature extractor, which may result in poor accuracy.\n\nTypically, scene print works best if the source of your training data matches the source of the images you want to classify. For example, if your app classifies images captured with an iPhone camera, train your model using images captured in the same way, if possible.\n\n## Selecting a feature extractor type\n\n- **MLImageClassifier.FeatureExtractorType.custom(_:)**: A feature extractor that you provide as a Core ML model file or a layer within that file.\n- **MLImageClassifier.CustomFeatureExtractor**: A custom feature extractor a training session uses to train an image classifier.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A feature extractor that you provide as a Core ML model file or a layer within that file.",
          "name" : "MLImageClassifier.FeatureExtractorType.custom(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier\/FeatureExtractorType\/custom(_:)"
        },
        {
          "description" : "A custom feature extractor a training session uses to train an image classifier.",
          "name" : "MLImageClassifier.CustomFeatureExtractor",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier\/CustomFeatureExtractor"
        }
      ],
      "title" : "Selecting a feature extractor type"
    }
  ],
  "source" : "appleJSON",
  "title" : "MLImageClassifier.FeatureExtractorType.scenePrint(revision:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/MLImageClassifier\/FeatureExtractorType\/scenePrint(revision:)"
}