{
  "abstract" : "Animate a filtered image to a Metal view in a SwiftUI app using a Core Image Render Destination.",
  "codeExamples" : [
    {
      "code" : "final class Renderer: NSObject, MTKViewDelegate, ObservableObject {",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create a Metal view with its own renderer.\nlet renderer = Renderer(imageProvider: { (time: CFTimeInterval, scaleFactor: CGFloat, headroom: CGFloat) -> CIImage in\n    \n    var image: CIImage\n    \n    \/\/ Animate a shifting red and yellow checkerboard pattern.\n    let pointsShiftPerSecond = 25.0\n    let checkerFilter = CIFilter.checkerboardGenerator()\n    checkerFilter.width = 20.0 * Float(scaleFactor)\n    checkerFilter.color0 = CIColor.red\n    checkerFilter.color1 = CIColor.yellow\n    checkerFilter.center = CGPoint(x: time * pointsShiftPerSecond, y: time * pointsShiftPerSecond)\n    image = checkerFilter.outputImage ?? CIImage.empty()\n    \n    \/\/ Animate the hue of the image with time.\n    let colorFilter = CIFilter.hueAdjust()\n    colorFilter.inputImage = image\n    colorFilter.angle = Float(time)\n    image = colorFilter.outputImage ?? CIImage.empty()",
      "language" : "swift"
    },
    {
      "code" : "if let commandBuffer = commandQueue.makeCommandBuffer() {\n    \n    \/\/ Add a completion handler that signals `inFlightSemaphore` when Metal and the GPU have fully\n    \/\/ finished processing the commands that the app encoded for this frame.\n    \/\/ This completion indicates that Metal and the GPU no longer need the dynamic buffers that\n    \/\/ Core Image writes to in this frame.\n    \/\/ Therefore, the CPU can overwrite the buffer contents without corrupting any rendering operations.\n    let semaphore = inFlightSemaphore\n    commandBuffer.addCompletedHandler { (_ commandBuffer)-> Swift.Void in\n        semaphore.signal()\n    }\n    \n    if let drawable = view.currentDrawable {",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create a destination the Core Image context uses to render to the drawable's Metal texture.\nlet destination = CIRenderDestination(width: Int(dSize.width),\n                                      height: Int(dSize.height),\n                                      pixelFormat: view.colorPixelFormat,\n                                      commandBuffer: commandBuffer,\n                                      mtlTextureProvider: { () -> MTLTexture in\n    \/\/ Core Image calls the texture provider block lazily when starting a task to render to the destination.\n    return drawable.texture\n})",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create a displayable image for the current time.\nlet time = CFTimeInterval(CFAbsoluteTimeGetCurrent() - self.startTime)\nvar image = self.imageProvider(time, contentScaleFactor, headroom)\n\n\/\/ Center the image in the view's visible area.\nlet iRect = image.extent\nlet backBounds = CGRect(x: 0, y: 0, width: dSize.width, height: dSize.height)\nlet shiftX = round((backBounds.size.width + iRect.origin.x - iRect.size.width) * 0.5)\nlet shiftY = round((backBounds.size.height + iRect.origin.y - iRect.size.height) * 0.5)\nimage = image.transformed(by: CGAffineTransform(translationX: shiftX, y: shiftY))\n\n\/\/ Blend the image over an opaque background image.\n\/\/ This is needed if the image is smaller than the view, or if it has transparent pixels.\nimage = image.composited(over: self.opaqueBackground)\n\n\/\/ Start a task that renders to the texture destination.\n_ = try? self.cicontext.startTask(toRender: image, from: backBounds,\n                                  to: destination, at: CGPoint.zero)\n\n\/\/ Insert a command to present the drawable when the buffer has been scheduled for execution.\ncommandBuffer.present(drawable)\n\n\/\/ Commit the command buffer so that the GPU executes the work that the Core Image Render Task issues.\ncommandBuffer.commit()",
      "language" : "swift"
    },
    {
      "code" : "if let layer = view.layer as? CAMetalLayer {\n    \/\/ Enable EDR with a color space that supports values greater than SDR.\n    if #available(iOS 16.0, *) {\n        layer.wantsExtendedDynamicRangeContent = true\n    }\n    layer.colorspace = CGColorSpace(name: CGColorSpace.extendedLinearDisplayP3)\n    \/\/ Ensure the render view supports pixel values in EDR.\n    view.colorPixelFormat = MTLPixelFormat.rgba16Float\n}",
      "language" : "swift"
    },
    {
      "code" : "                \/\/ Determine EDR headroom and fallback to SDR, as needed.\n                \/\/ Note: The headroom must be determined every frame to include changes in environmental lighting conditions.\n                let screen = view.window?.screen\n#if os(iOS)\n                var headroom = CGFloat(1.0)\n                if #available(iOS 16.0, *) {\n                    headroom = screen?.currentEDRHeadroom ?? 1.0\n                }\n#else\n                let headroom = screen?.maximumExtendedDynamicRangeColorComponentValue ?? 1.0\n#endif",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Compute a shading image for the ripple effect below.\n\/\/ Cast light on the upper-left corner of the shading gradient image.\nlet angle = 135.0 * (.pi \/ 180.0)\nlet gradient = CIFilter.linearGradient()\n\/\/ Create a bright white color for a specular highlight with the current\n\/\/ maximum possible pixel component values within headroom\n\/\/ or a reasonable alternative.\nlet maxRGB = min(headroom, 8.0)\ngradient.color0 = CIColor(red: maxRGB, green: maxRGB, blue: maxRGB,\n                          colorSpace: CGColorSpace(name: CGColorSpace.extendedLinearSRGB)!)!\ngradient.color1 = CIColor.clear\ngradient.point0 = CGPoint(x: sin(angle) * 90.0 + 100.0,\n                          y: cos(angle) * 90.0 + 100.0)\ngradient.point1 = CGPoint(x: sin(angle) * 85.0 + 100.0,\n                          y: cos(angle) * 85.0 + 100.0)\nlet shading = gradient.outputImage?.cropped(to: CGRect(x: 0, y: 0,\n                                                       width: 200, height: 200))\n\n\/\/ Add a shiny ripple effect to the image.\nlet ripple = CIFilter.rippleTransition()\nripple.inputImage = image\nripple.targetImage = image\nripple.center = CGPoint(x: 256.0 * scaleFactor,\n                        y: 192.0 * scaleFactor)\nripple.time = Float(fmod(time * 0.25, 1.0))\nripple.shadingImage = shading\nimage = ripple.outputImage ?? CIImage()\n\nreturn image.cropped(to: CGRect(x: 0, y: 0,\n                                width: 512.0 * scaleFactor,\n                                height: 384.0 * scaleFactor))",
      "language" : "swift"
    }
  ],
  "contentHash" : "7ae0c70b473d9e809b940e1cd7c2317fe490d3b85bd0bf3b2571cb17f49ed7e2",
  "crawledAt" : "2025-12-02T15:48:44Z",
  "id" : "50BF1C98-5E1D-43CF-A14E-4F8536CD9FE7",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Core Image",
  "overview" : "## Overview\n\nThis sample shows how to assemble a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI] app that displays a Metal view with animated images that you generate procedurally from Core Image.\n\nTo accomplish this, the sample sets up a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Scene] in a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/WindowGroup] with a single content view. The sample’s `ContentView` adopts the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/View] protocol and initializes a `Renderer` using a closure to vend a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage]. It then adds a `MetalView`, with the instantiated `Renderer`, to the content [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/View\/body-8kl5o].\n\nThe sample combines view update and state changes to produce the animation:\n\n### Generate an animation\n\nThe `Renderer` class generates an image for an animation frame by conforming to the MetalKit [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKViewDelegate] delegate protocol. The protocol’s [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKViewDelegate\/draw(in:)] function commits render destination work to the GPU using a render task in a Metal command buffer.\n\nFor more information about drawing with MetalKit see [doc:\/\/com.apple.documentation\/documentation\/Metal\/drawing-a-triangle-with-metal-4].\n\nMetalKit calls the `draw(in:)` delegate function of the `Renderer` automatically.\n\nAn image-supplying function parameterized by both timestamp and scale factor initializes the `Renderer`. This function combines checkerboard and hue-adjustment filters to generate animated checkerboard pattern images cropped to a fixed size.\n\nAfter the sample initializes the `Renderer`, the `Renderer` makes a command buffer and gets the [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKView\/currentDrawable].\n\nThe `Renderer` then configures a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIRenderDestination] with the command buffer, `currentDrawable`, dimensions, and pixel format, along with a closure that returns the [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalDrawable\/texture] for the `currentDrawable`.\n\nThe sample uses the render destination to create an animation frame at a specific timestamp.\n\nFinally, the sample composites the render destination’s centered image on a background and submits work to the GPU to render and present the result.\n\n### Add an EDR effect\n\nThe sample adds an EDR effect, a shiny ripple with a bright specular highlight, to the rendered checkerboard animation in three steps:\n\nFor more information about adding an EDR effect, see [https:\/\/developer.apple.com\/videos\/play\/wwdc2022\/10114\/].\n\n### Configure the view for EDR support\n\nThe `MetalView` opts into EDR support setting [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer\/wantsExtendedDynamicRangeContent] to true on the backing [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer]. When enabled, the layer uses a wide gamut [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer\/colorspace] to render colors beyond SDR range. Similarly, the [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKView] sets a wide gamut [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer\/pixelFormat] to render the generated EDR image.\n\n### Query EDR headroom\n\nThe `Renderer` queries the current EDR headroom for each draw call using either [doc:\/\/com.apple.documentation\/documentation\/AppKit\/NSScreen\/maximumPotentialExtendedDynamicRangeColorComponentValue] ([doc:\/\/com.apple.documentation\/documentation\/AppKit\/NSScreen]) or [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScreen\/currentEDRHeadroom] ([doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScreen]). If EDR headroom is unavailable the sample sets `headroom` to `1.0` clamping to SDR.\n\n### Leverage EDR headroom\n\nThe sample’s ripple effect takes a gradient [doc:\/\/com.apple.documentation\/documentation\/coreimage\/cirippletransition\/3228695-shadingimage] to shade the contor of the ripple so that it appears to reflect light from the upper-left corner. [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CILinearGradient] generates the gradient shading image between the current maximum RGB white, [doc:\/\/com.apple.documentation\/documentation\/coreimage\/cilineargradient\/3228542-color0], and a fully transparent clear color, [doc:\/\/com.apple.documentation\/documentation\/coreimage\/cilineargradient\/3228543-color1].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CoreImage\/generating-an-animation-with-a-core-image-render-destination\ncrawled: 2025-12-02T15:48:44Z\n---\n\n# Generating an animation with a Core Image Render Destination\n\n**Sample Code**\n\nAnimate a filtered image to a Metal view in a SwiftUI app using a Core Image Render Destination.\n\n## Overview\n\nThis sample shows how to assemble a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI] app that displays a Metal view with animated images that you generate procedurally from Core Image.\n\nTo accomplish this, the sample sets up a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Scene] in a [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/WindowGroup] with a single content view. The sample’s `ContentView` adopts the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/View] protocol and initializes a `Renderer` using a closure to vend a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIImage]. It then adds a `MetalView`, with the instantiated `Renderer`, to the content [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/View\/body-8kl5o].\n\nThe sample combines view update and state changes to produce the animation:\n\n- For view update, the `MetalView` structure conforms to the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/UIViewRepresentable] or [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/NSViewRepresentable] protocol of the SwiftUI life cycle.\n- For state changes, the Renderer is a `StateObject` conforming to the [doc:\/\/com.apple.documentation\/documentation\/Combine\/ObservableObject] protocol.\n\n### Generate an animation\n\nThe `Renderer` class generates an image for an animation frame by conforming to the MetalKit [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKViewDelegate] delegate protocol. The protocol’s [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKViewDelegate\/draw(in:)] function commits render destination work to the GPU using a render task in a Metal command buffer.\n\nFor more information about drawing with MetalKit see [doc:\/\/com.apple.documentation\/documentation\/Metal\/drawing-a-triangle-with-metal-4].\n\nMetalKit calls the `draw(in:)` delegate function of the `Renderer` automatically.\n\n```swift\nfinal class Renderer: NSObject, MTKViewDelegate, ObservableObject {\n```\n\nAn image-supplying function parameterized by both timestamp and scale factor initializes the `Renderer`. This function combines checkerboard and hue-adjustment filters to generate animated checkerboard pattern images cropped to a fixed size.\n\n```swift\n\/\/ Create a Metal view with its own renderer.\nlet renderer = Renderer(imageProvider: { (time: CFTimeInterval, scaleFactor: CGFloat, headroom: CGFloat) -> CIImage in\n    \n    var image: CIImage\n    \n    \/\/ Animate a shifting red and yellow checkerboard pattern.\n    let pointsShiftPerSecond = 25.0\n    let checkerFilter = CIFilter.checkerboardGenerator()\n    checkerFilter.width = 20.0 * Float(scaleFactor)\n    checkerFilter.color0 = CIColor.red\n    checkerFilter.color1 = CIColor.yellow\n    checkerFilter.center = CGPoint(x: time * pointsShiftPerSecond, y: time * pointsShiftPerSecond)\n    image = checkerFilter.outputImage ?? CIImage.empty()\n    \n    \/\/ Animate the hue of the image with time.\n    let colorFilter = CIFilter.hueAdjust()\n    colorFilter.inputImage = image\n    colorFilter.angle = Float(time)\n    image = colorFilter.outputImage ?? CIImage.empty()\n```\n\nAfter the sample initializes the `Renderer`, the `Renderer` makes a command buffer and gets the [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKView\/currentDrawable].\n\n```swift\nif let commandBuffer = commandQueue.makeCommandBuffer() {\n    \n    \/\/ Add a completion handler that signals `inFlightSemaphore` when Metal and the GPU have fully\n    \/\/ finished processing the commands that the app encoded for this frame.\n    \/\/ This completion indicates that Metal and the GPU no longer need the dynamic buffers that\n    \/\/ Core Image writes to in this frame.\n    \/\/ Therefore, the CPU can overwrite the buffer contents without corrupting any rendering operations.\n    let semaphore = inFlightSemaphore\n    commandBuffer.addCompletedHandler { (_ commandBuffer)-> Swift.Void in\n        semaphore.signal()\n    }\n    \n    if let drawable = view.currentDrawable {\n```\n\nThe `Renderer` then configures a [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CIRenderDestination] with the command buffer, `currentDrawable`, dimensions, and pixel format, along with a closure that returns the [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalDrawable\/texture] for the `currentDrawable`.\n\n```swift\n\/\/ Create a destination the Core Image context uses to render to the drawable's Metal texture.\nlet destination = CIRenderDestination(width: Int(dSize.width),\n                                      height: Int(dSize.height),\n                                      pixelFormat: view.colorPixelFormat,\n                                      commandBuffer: commandBuffer,\n                                      mtlTextureProvider: { () -> MTLTexture in\n    \/\/ Core Image calls the texture provider block lazily when starting a task to render to the destination.\n    return drawable.texture\n})\n```\n\nThe sample uses the render destination to create an animation frame at a specific timestamp.\n\nFinally, the sample composites the render destination’s centered image on a background and submits work to the GPU to render and present the result.\n\n```swift\n\/\/ Create a displayable image for the current time.\nlet time = CFTimeInterval(CFAbsoluteTimeGetCurrent() - self.startTime)\nvar image = self.imageProvider(time, contentScaleFactor, headroom)\n\n\/\/ Center the image in the view's visible area.\nlet iRect = image.extent\nlet backBounds = CGRect(x: 0, y: 0, width: dSize.width, height: dSize.height)\nlet shiftX = round((backBounds.size.width + iRect.origin.x - iRect.size.width) * 0.5)\nlet shiftY = round((backBounds.size.height + iRect.origin.y - iRect.size.height) * 0.5)\nimage = image.transformed(by: CGAffineTransform(translationX: shiftX, y: shiftY))\n\n\/\/ Blend the image over an opaque background image.\n\/\/ This is needed if the image is smaller than the view, or if it has transparent pixels.\nimage = image.composited(over: self.opaqueBackground)\n\n\/\/ Start a task that renders to the texture destination.\n_ = try? self.cicontext.startTask(toRender: image, from: backBounds,\n                                  to: destination, at: CGPoint.zero)\n\n\/\/ Insert a command to present the drawable when the buffer has been scheduled for execution.\ncommandBuffer.present(drawable)\n\n\/\/ Commit the command buffer so that the GPU executes the work that the Core Image Render Task issues.\ncommandBuffer.commit()\n```\n\n### Add an EDR effect\n\nThe sample adds an EDR effect, a shiny ripple with a bright specular highlight, to the rendered checkerboard animation in three steps:\n\n1. Opt into EDR support for the view and set an accommodating color space and pixel format.\n2. Query the EDR headroom for each frame and pass `headroom` to the image provider closure for the `Renderer`.\n3. Set the peak specular highlight value to the maximum value of white with respect to the current headroom, or a reasonable default value.\n\nFor more information about adding an EDR effect, see [https:\/\/developer.apple.com\/videos\/play\/wwdc2022\/10114\/].\n\n### Configure the view for EDR support\n\nThe `MetalView` opts into EDR support setting [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer\/wantsExtendedDynamicRangeContent] to true on the backing [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer]. When enabled, the layer uses a wide gamut [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer\/colorspace] to render colors beyond SDR range. Similarly, the [doc:\/\/com.apple.documentation\/documentation\/MetalKit\/MTKView] sets a wide gamut [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAMetalLayer\/pixelFormat] to render the generated EDR image.\n\n```swift\nif let layer = view.layer as? CAMetalLayer {\n    \/\/ Enable EDR with a color space that supports values greater than SDR.\n    if #available(iOS 16.0, *) {\n        layer.wantsExtendedDynamicRangeContent = true\n    }\n    layer.colorspace = CGColorSpace(name: CGColorSpace.extendedLinearDisplayP3)\n    \/\/ Ensure the render view supports pixel values in EDR.\n    view.colorPixelFormat = MTLPixelFormat.rgba16Float\n}\n```\n\n### Query EDR headroom\n\nThe `Renderer` queries the current EDR headroom for each draw call using either [doc:\/\/com.apple.documentation\/documentation\/AppKit\/NSScreen\/maximumPotentialExtendedDynamicRangeColorComponentValue] ([doc:\/\/com.apple.documentation\/documentation\/AppKit\/NSScreen]) or [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScreen\/currentEDRHeadroom] ([doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScreen]). If EDR headroom is unavailable the sample sets `headroom` to `1.0` clamping to SDR.\n\n```swift\n                \/\/ Determine EDR headroom and fallback to SDR, as needed.\n                \/\/ Note: The headroom must be determined every frame to include changes in environmental lighting conditions.\n                let screen = view.window?.screen\n#if os(iOS)\n                var headroom = CGFloat(1.0)\n                if #available(iOS 16.0, *) {\n                    headroom = screen?.currentEDRHeadroom ?? 1.0\n                }\n#else\n                let headroom = screen?.maximumExtendedDynamicRangeColorComponentValue ?? 1.0\n#endif\n```\n\n### Leverage EDR headroom\n\nThe sample’s ripple effect takes a gradient [doc:\/\/com.apple.documentation\/documentation\/coreimage\/cirippletransition\/3228695-shadingimage] to shade the contor of the ripple so that it appears to reflect light from the upper-left corner. [doc:\/\/com.apple.documentation\/documentation\/CoreImage\/CILinearGradient] generates the gradient shading image between the current maximum RGB white, [doc:\/\/com.apple.documentation\/documentation\/coreimage\/cilineargradient\/3228542-color0], and a fully transparent clear color, [doc:\/\/com.apple.documentation\/documentation\/coreimage\/cilineargradient\/3228543-color1].\n\n```swift\n\/\/ Compute a shading image for the ripple effect below.\n\/\/ Cast light on the upper-left corner of the shading gradient image.\nlet angle = 135.0 * (.pi \/ 180.0)\nlet gradient = CIFilter.linearGradient()\n\/\/ Create a bright white color for a specular highlight with the current\n\/\/ maximum possible pixel component values within headroom\n\/\/ or a reasonable alternative.\nlet maxRGB = min(headroom, 8.0)\ngradient.color0 = CIColor(red: maxRGB, green: maxRGB, blue: maxRGB,\n                          colorSpace: CGColorSpace(name: CGColorSpace.extendedLinearSRGB)!)!\ngradient.color1 = CIColor.clear\ngradient.point0 = CGPoint(x: sin(angle) * 90.0 + 100.0,\n                          y: cos(angle) * 90.0 + 100.0)\ngradient.point1 = CGPoint(x: sin(angle) * 85.0 + 100.0,\n                          y: cos(angle) * 85.0 + 100.0)\nlet shading = gradient.outputImage?.cropped(to: CGRect(x: 0, y: 0,\n                                                       width: 200, height: 200))\n\n\/\/ Add a shiny ripple effect to the image.\nlet ripple = CIFilter.rippleTransition()\nripple.inputImage = image\nripple.targetImage = image\nripple.center = CGPoint(x: 256.0 * scaleFactor,\n                        y: 192.0 * scaleFactor)\nripple.time = Float(fmod(time * 0.25, 1.0))\nripple.shadingImage = shading\nimage = ripple.outputImage ?? CIImage()\n\nreturn image.cropped(to: CGRect(x: 0, y: 0,\n                                width: 512.0 * scaleFactor,\n                                height: 384.0 * scaleFactor))\n```\n\n## Custom Render Destination\n\n- **CIRenderDestination**: A specification for configuring all attributes of a render task’s destination and issuing asynchronous render tasks.\n- **CIRenderInfo**: An encapsulation of a render task’s timing, passes, and pixels processed.\n- **CIRenderTask**: A single render task.\n- **CIRenderDestinationAlphaMode**: Different ways of representing alpha.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A specification for configuring all attributes of a render task’s destination and issuing asynchronous render tasks.",
          "name" : "CIRenderDestination",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIRenderDestination"
        },
        {
          "description" : "An encapsulation of a render task’s timing, passes, and pixels processed.",
          "name" : "CIRenderInfo",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIRenderInfo"
        },
        {
          "description" : "A single render task.",
          "name" : "CIRenderTask",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIRenderTask"
        },
        {
          "description" : "Different ways of representing alpha.",
          "name" : "CIRenderDestinationAlphaMode",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIRenderDestinationAlphaMode"
        }
      ],
      "title" : "Custom Render Destination"
    }
  ],
  "source" : "appleJSON",
  "title" : "Generating an animation with a Core Image Render Destination",
  "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/generating-an-animation-with-a-core-image-render-destination"
}