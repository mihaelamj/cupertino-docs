{
  "abstract" : "Apply effects such as sepia tint, highlight strengthening, and scaling to images.",
  "codeExamples" : [
    {
      "code" : "CIContext* context = [CIContext context];",
      "language" : "swift"
    },
    {
      "code" : "NSURL* imageURL = [[NSBundle mainBundle] URLForResource:@\"YourImageName\" withExtension:@\"png\"];\nCIImage* originalCIImage = [CIImage imageWithContentsOfURL:imageURL];\nself.imageView.image = [UIImage imageWithCIImage:originalCIImage];",
      "language" : "swift"
    },
    {
      "code" : "- (CIImage*) sepiaFilterImage: (CIImage*)inputImage withIntensity:(CGFloat)intensity {\n    CIFilter<CISepiaTone>* sepiaFilter = CIFilter.sepiaToneFilter;\n    sepiaFilter.inputImage = inputImage;\n    sepiaFilter.intensity = intensity;\n    return sepiaFilter.outputImage;\n}",
      "language" : "swift"
    },
    {
      "code" : "CIImage* sepiaCIImage = [self sepiaFilterImage:originalCIImage withIntensity:0.9];",
      "language" : "swift"
    },
    {
      "code" : "_imageView.image = [UIImage imageWithCIImage:sepiaCIImage];",
      "language" : "swift"
    },
    {
      "code" : "- (CIImage*) bloomFilterImage: (CIImage*)inputImage withIntensity:(CGFloat)intensity radius:(CGFloat)radius {\n    CIFilter<CIBloom>* bloomFilter = CIFilter.bloomFilter;\n    bloomFilter.inputImage = inputImage;\n    bloomFilter.intensity = intensity;\n    bloomFilter.radius = radius;\n    return bloomFilter.outputImage;\n}",
      "language" : "swift"
    },
    {
      "code" : "CIImage* bloomCIImage = [self bloomFilterImage:sepiaCIImage withIntensity:1 radius:10];\n_filteredImageView.image = [UIImage imageWithCIImage:bloomCIImage];",
      "language" : "swift"
    },
    {
      "code" : "CGFloat imageWidth = originalUIImage.size.width;\nCGFloat imageHeight = originalUIImage.size.height;\nCGFloat aspectRatio = imageHeight \/ imageWidth;\nCIImage* scaledCIImage = [self scaleFilterImage:bloomCIImage withAspectRatio:aspectRatio scale:0.05];",
      "language" : "swift"
    },
    {
      "code" : "- (CIImage*) scaleFilterImage: (CIImage*)inputImage withAspectRatio:(CGFloat)aspectRatio scale:(CGFloat)scale {\n    CIFilter<CILanczosScaleTransform>* scaleFilter = CIFilter.lanczosScaleTransformFilter;\n    scaleFilter.inputImage = inputImage;\n    scaleFilter.scale = scale;\n    scaleFilter.aspectRatio = aspectRatio;\n    return scaleFilter.outputImage;\n}",
      "language" : "swift"
    },
    {
      "code" : "_imageView.image = [UIImage imageWithCIImage:scaledCIImage];",
      "language" : "swift"
    }
  ],
  "contentHash" : "8649c26013c36d1102c0cb5766a216021afe5b9df651c35983553c190a2b4bb0",
  "crawledAt" : "2025-12-03T12:48:39Z",
  "id" : "A88048EE-0680-4112-B2DC-371B2F5A9AE7",
  "kind" : "article",
  "language" : "swift",
  "module" : "Core Image",
  "overview" : "## Overview\n\nYou can add effects to images by applying Core Image filters to [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] objects. Figure 1 shows three filters chained together to achieve a cumulative effect:\n\n\n\n### Create a Context\n\n[doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] processing occurs in a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIContext] object. Creating a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIContext] is expensive, so create one during your initial setup and reuse it throughout your app.\n\n### Load an Image to Process\n\nThe next step is to load an image to process. This example loads an image from the project bundle.\n\nThe [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] object isn’t itself a displayable image, but rather image data. To display it, you must convert it to another type, such as [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage].\n\n### Apply Built-In Core Image Filters\n\nA [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class] represents a single operation or recipe for a particular effect. To process a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] object, pass it through [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class] objects. You can subclass [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class] or draw from the existing library of built-in filters.\n\n#### Tint Reddish-Brown with the Sepia Filter\n\nAlthough you can chain filters without separating them into functions, the following example shows how to configure a single [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class], the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/sepiaTone()] filter.\n\nTo pass the image through the filter, call the sepia filter function.\n\nYou can check the intermediate result at any point in the filter chain by converting from [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] to a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage]. You can then assign this [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage] to a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImageView] for display.\n\n#### Strengthen Highlights with the Bloom Filter\n\nThe bloom filter accentuates the highlights of an image. You can apply it as part of a chain without factoring it into a separate function, but this example encapsulates its functionality into a function.\n\nLike the sepia filter, the intensity of the bloom filter’s effect ranges between 0 and 1, with 1 being the most intense effect. The bloom filter has an additional r`adius` parameter to determine how much the glowing regions expand. Experiment with a range to values to fine tune the effect, or assign the input parameter to a control like a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISlider] to allow your users to tweak its values.\n\nTo display the output, convert the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] to a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage].\n\n#### Scale Image Size with the Lanczos Scale Filter\n\nApply the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/lanczosScaleTransform()] to obtain a high-quality downsampling of the image, preserving the original image’s aspect ratio through the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/lanczosScaleTransform()] filter’s parameter `aspectRatio`. For built-in Core Image filters, calculate the aspect ratio as the image’s width over height.\n\nLike other built-in filters, the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/lanczosScaleTransform()] filter also outputs its result as a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage].\n\nIn addition to trying out the built-in filters for a fixed effect, you can combine filters in certain Filter Recipes to accomplish tasks such as [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/applying-a-chroma-key-effect], [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/selectively-focusing-on-an-image], [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/customizing-image-transitions], and [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/simulating-scratchy-analog-film].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/coreimage\/processing-an-image-using-built-in-filters\ncrawled: 2025-12-03T12:48:39Z\n---\n\n# Processing an Image Using Built-in Filters\n\n**Article**\n\nApply effects such as sepia tint, highlight strengthening, and scaling to images.\n\n## Overview\n\nYou can add effects to images by applying Core Image filters to [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] objects. Figure 1 shows three filters chained together to achieve a cumulative effect:\n\n1. Apply the sepia filter to tint an image with a reddish-brown hue.\n2. Add the bloom filter to accentuate highlights.\n3. Use the Lanczos scale filter to scale an image down.\n\n\n\n### Create a Context\n\n[doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] processing occurs in a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIContext] object. Creating a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIContext] is expensive, so create one during your initial setup and reuse it throughout your app.\n\n```swift\nCIContext* context = [CIContext context];\n```\n\n### Load an Image to Process\n\nThe next step is to load an image to process. This example loads an image from the project bundle.\n\n```swift\nNSURL* imageURL = [[NSBundle mainBundle] URLForResource:@\"YourImageName\" withExtension:@\"png\"];\nCIImage* originalCIImage = [CIImage imageWithContentsOfURL:imageURL];\nself.imageView.image = [UIImage imageWithCIImage:originalCIImage];\n```\n\nThe [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] object isn’t itself a displayable image, but rather image data. To display it, you must convert it to another type, such as [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage].\n\n### Apply Built-In Core Image Filters\n\nA [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class] represents a single operation or recipe for a particular effect. To process a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] object, pass it through [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class] objects. You can subclass [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class] or draw from the existing library of built-in filters.\n\n#### Tint Reddish-Brown with the Sepia Filter\n\nAlthough you can chain filters without separating them into functions, the following example shows how to configure a single [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class], the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/sepiaTone()] filter.\n\n```swift\n- (CIImage*) sepiaFilterImage: (CIImage*)inputImage withIntensity:(CGFloat)intensity {\n    CIFilter<CISepiaTone>* sepiaFilter = CIFilter.sepiaToneFilter;\n    sepiaFilter.inputImage = inputImage;\n    sepiaFilter.intensity = intensity;\n    return sepiaFilter.outputImage;\n}\n```\n\nTo pass the image through the filter, call the sepia filter function.\n\n```swift\nCIImage* sepiaCIImage = [self sepiaFilterImage:originalCIImage withIntensity:0.9];\n```\n\nYou can check the intermediate result at any point in the filter chain by converting from [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] to a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage]. You can then assign this [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage] to a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImageView] for display.\n\n```swift\n_imageView.image = [UIImage imageWithCIImage:sepiaCIImage];\n```\n\n#### Strengthen Highlights with the Bloom Filter\n\nThe bloom filter accentuates the highlights of an image. You can apply it as part of a chain without factoring it into a separate function, but this example encapsulates its functionality into a function.\n\n```swift\n- (CIImage*) bloomFilterImage: (CIImage*)inputImage withIntensity:(CGFloat)intensity radius:(CGFloat)radius {\n    CIFilter<CIBloom>* bloomFilter = CIFilter.bloomFilter;\n    bloomFilter.inputImage = inputImage;\n    bloomFilter.intensity = intensity;\n    bloomFilter.radius = radius;\n    return bloomFilter.outputImage;\n}\n```\n\nLike the sepia filter, the intensity of the bloom filter’s effect ranges between 0 and 1, with 1 being the most intense effect. The bloom filter has an additional r`adius` parameter to determine how much the glowing regions expand. Experiment with a range to values to fine tune the effect, or assign the input parameter to a control like a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISlider] to allow your users to tweak its values.\n\n\n\nTo display the output, convert the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage] to a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIImage].\n\n```swift\nCIImage* bloomCIImage = [self bloomFilterImage:sepiaCIImage withIntensity:1 radius:10];\n_filteredImageView.image = [UIImage imageWithCIImage:bloomCIImage];\n```\n\n#### Scale Image Size with the Lanczos Scale Filter\n\nApply the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/lanczosScaleTransform()] to obtain a high-quality downsampling of the image, preserving the original image’s aspect ratio through the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/lanczosScaleTransform()] filter’s parameter `aspectRatio`. For built-in Core Image filters, calculate the aspect ratio as the image’s width over height.\n\n```swift\nCGFloat imageWidth = originalUIImage.size.width;\nCGFloat imageHeight = originalUIImage.size.height;\nCGFloat aspectRatio = imageHeight \/ imageWidth;\nCIImage* scaledCIImage = [self scaleFilterImage:bloomCIImage withAspectRatio:aspectRatio scale:0.05];\n```\n\nLike other built-in filters, the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIFilter-swift.class\/lanczosScaleTransform()] filter also outputs its result as a [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage].\n\n```swift\n- (CIImage*) scaleFilterImage: (CIImage*)inputImage withAspectRatio:(CGFloat)aspectRatio scale:(CGFloat)scale {\n    CIFilter<CILanczosScaleTransform>* scaleFilter = CIFilter.lanczosScaleTransformFilter;\n    scaleFilter.inputImage = inputImage;\n    scaleFilter.scale = scale;\n    scaleFilter.aspectRatio = aspectRatio;\n    return scaleFilter.outputImage;\n}\n```\n\n\n\n```swift\n_imageView.image = [UIImage imageWithCIImage:scaledCIImage];\n```\n\n\n\nIn addition to trying out the built-in filters for a fixed effect, you can combine filters in certain Filter Recipes to accomplish tasks such as [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/applying-a-chroma-key-effect], [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/selectively-focusing-on-an-image], [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/customizing-image-transitions], and [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/simulating-scratchy-analog-film].\n\n## Essentials\n\n- **CIContext**: The Core Image context class provides an evaluation context for Core Image processing with Metal, OpenGL, or OpenCL.\n- **CIImage**: A representation of an image to be processed or produced by Core Image filters.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The Core Image context class provides an evaluation context for Core Image processing with Metal, OpenGL, or OpenCL.",
          "name" : "CIContext",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIContext"
        },
        {
          "description" : "A representation of an image to be processed or produced by Core Image filters.",
          "name" : "CIImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage"
        }
      ],
      "title" : "Essentials"
    }
  ],
  "source" : "appleJSON",
  "title" : "Processing an Image Using Built-in Filters",
  "url" : "https:\/\/developer.apple.com\/documentation\/coreimage\/processing-an-image-using-built-in-filters"
}