{
  "abstract" : "Returns a new image created by making the pixel colors along its edges extend infinitely in all directions.",
  "codeExamples" : [

  ],
  "contentHash" : "0a00f90cda01b3ec3dec54cf36a84475cb99d8ea7272b6e5e64ad613936876fa",
  "crawledAt" : "2025-12-04T22:55:44Z",
  "declaration" : {
    "code" : "func clampedToExtent() -> CIImage",
    "language" : "swift"
  },
  "id" : "39EAD094-6758-4E03-8341-3DAAEBDC5EEB",
  "kind" : "method",
  "language" : "swift",
  "module" : "Core Image",
  "overview" : "## Return Value\n\nAn image object representing the result of the clamp operation.\n\n## Discussion\n\nCalling this method is equivalent to using the [https:\/\/developer.apple.com\/library\/archive\/documentation\/GraphicsImaging\/Reference\/CoreImageFilterReference\/index.html#\/\/apple_ref\/doc\/filter\/ci\/CIAffineClamp] filter, which creates an image of infinite extent by repeating pixel colors from the edges of the original image.\n\nThis operation can be useful when using the image as input to other filters. When an image has finite extent, Core Image treats the area outside the extent as if it were filled with empty (black, zero alpha) pixels. If you apply a filter that samples from outside the image’s extent, those empty pixels affect the result of the filter.\n\nFor example, applying the `CIGaussianBlur` filter to an image softens the edges of the blurred image, because the opaque pixels at the edges of the image blur into the transparent pixels outside the image’s extent. Applying a clamp effect before the blur filter avoids edge softening by making the original image opaque in all directions. (However, the blurred image will also have infinite extent. Use the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage\/cropped(to:)] method to return to the original image’s dimensions while retaining hard edges.)",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/clampedToExtent()\ncrawled: 2025-12-04T22:55:44Z\n---\n\n# clampedToExtent()\n\n**Instance Method**\n\nReturns a new image created by making the pixel colors along its edges extend infinitely in all directions.\n\n## Declaration\n\n```swift\nfunc clampedToExtent() -> CIImage\n```\n\n## Return Value\n\nAn image object representing the result of the clamp operation.\n\n## Discussion\n\nCalling this method is equivalent to using the [https:\/\/developer.apple.com\/library\/archive\/documentation\/GraphicsImaging\/Reference\/CoreImageFilterReference\/index.html#\/\/apple_ref\/doc\/filter\/ci\/CIAffineClamp] filter, which creates an image of infinite extent by repeating pixel colors from the edges of the original image.\n\nThis operation can be useful when using the image as input to other filters. When an image has finite extent, Core Image treats the area outside the extent as if it were filled with empty (black, zero alpha) pixels. If you apply a filter that samples from outside the image’s extent, those empty pixels affect the result of the filter.\n\nFor example, applying the `CIGaussianBlur` filter to an image softens the edges of the blurred image, because the opaque pixels at the edges of the image blur into the transparent pixels outside the image’s extent. Applying a clamp effect before the blur filter avoids edge softening by making the original image opaque in all directions. (However, the blurred image will also have infinite extent. Use the [doc:\/\/com.apple.coreimage\/documentation\/CoreImage\/CIImage\/cropped(to:)] method to return to the original image’s dimensions while retaining hard edges.)\n\n## Creating an Image by Modifying an Existing Image\n\n- **applyingFilter(_:parameters:)**: Returns a new image created by applying a filter to the original image with the specified name and parameters.\n- **applyingFilter(_:)**: Applies the filter to an image and returns the output.\n- **transformed(by:)**: Returns a new image that represents the original image after applying an affine transform.\n- **transformed(by:highQualityDownsample:)**\n- **cropped(to:)**: Returns a new image with a cropped portion of the original image.\n- **oriented(forExifOrientation:)**: Returns a new image created by transforming the original image to the specified EXIF orientation.\n- **clamped(to:)**: Returns a new image created by cropping to a specified area, then making the pixel colors along the edges of the cropped image extend infinitely in all directions.\n- **composited(over:)**: Returns a new image created by compositing the original image over the specified destination image.\n- **convertingWorkingSpaceToLab()**\n- **convertingLabToWorkingSpace()**\n- **matchedToWorkingSpace(from:)**: Returns a new image created by color matching from the specified color space to the context’s working color space.\n- **matchedFromWorkingSpace(to:)**: Returns a new image created by color matching from the context’s working color space to the specified color space.\n- **premultiplyingAlpha()**: Returns a new image created by multiplying the image’s RGB values by its alpha values.\n- **unpremultiplyingAlpha()**: Returns a new image created by dividing the image’s RGB values by its alpha values.\n- **settingAlphaOne(in:)**: Returns a new image created by setting all alpha values to 1.0 within the specified rectangle and to 0.0 outside of that area.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Returns a new image created by applying a filter to the original image with the specified name and parameters.",
          "name" : "applyingFilter(_:parameters:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/applyingFilter(_:parameters:)"
        },
        {
          "description" : "Applies the filter to an image and returns the output.",
          "name" : "applyingFilter(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/applyingFilter(_:)"
        },
        {
          "description" : "Returns a new image that represents the original image after applying an affine transform.",
          "name" : "transformed(by:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/transformed(by:)"
        },
        {
          "description" : "",
          "name" : "transformed(by:highQualityDownsample:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/transformed(by:highQualityDownsample:)"
        },
        {
          "description" : "Returns a new image with a cropped portion of the original image.",
          "name" : "cropped(to:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/cropped(to:)"
        },
        {
          "description" : "Returns a new image created by transforming the original image to the specified EXIF orientation.",
          "name" : "oriented(forExifOrientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/oriented(forExifOrientation:)"
        },
        {
          "description" : "Returns a new image created by cropping to a specified area, then making the pixel colors along the edges of the cropped image extend infinitely in all directions.",
          "name" : "clamped(to:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/clamped(to:)"
        },
        {
          "description" : "Returns a new image created by compositing the original image over the specified destination image.",
          "name" : "composited(over:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/composited(over:)"
        },
        {
          "description" : "",
          "name" : "convertingWorkingSpaceToLab()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/convertingWorkingSpaceToLab()"
        },
        {
          "description" : "",
          "name" : "convertingLabToWorkingSpace()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/convertingLabToWorkingSpace()"
        },
        {
          "description" : "Returns a new image created by color matching from the specified color space to the context’s working color space.",
          "name" : "matchedToWorkingSpace(from:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/matchedToWorkingSpace(from:)"
        },
        {
          "description" : "Returns a new image created by color matching from the context’s working color space to the specified color space.",
          "name" : "matchedFromWorkingSpace(to:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/matchedFromWorkingSpace(to:)"
        },
        {
          "description" : "Returns a new image created by multiplying the image’s RGB values by its alpha values.",
          "name" : "premultiplyingAlpha()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/premultiplyingAlpha()"
        },
        {
          "description" : "Returns a new image created by dividing the image’s RGB values by its alpha values.",
          "name" : "unpremultiplyingAlpha()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/unpremultiplyingAlpha()"
        },
        {
          "description" : "Returns a new image created by setting all alpha values to 1.0 within the specified rectangle and to 0.0 outside of that area.",
          "name" : "settingAlphaOne(in:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/settingAlphaOne(in:)"
        }
      ],
      "title" : "Creating an Image by Modifying an Existing Image"
    }
  ],
  "source" : "appleJSON",
  "title" : "clampedToExtent()",
  "url" : "https:\/\/developer.apple.com\/documentation\/CoreImage\/CIImage\/clampedToExtent()"
}