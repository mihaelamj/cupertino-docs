{
  "abstract" : "A texture that may have more than four channels for use in convolutional neural networks.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "62f288dcc15746ddc45b9a2b5e36a66e5414568b17820206edf74ee7fe3cf2e1",
  "crawledAt" : "2025-12-02T16:13:19Z",
  "declaration" : {
    "code" : "class MPSImage",
    "language" : "swift"
  },
  "id" : "D5686937-5410-4E63-9D32-AF259D043E75",
  "inheritedBy" : [
    "MPSTemporaryImage"
  ],
  "kind" : "class",
  "language" : "swift",
  "module" : "Metal Performance Shaders",
  "overview" : "## Overview\n\nSome image types, such as those found in convolutional neural networks (CNN), differ from a standard texture in that they may have more than 4 channels per pixel. While the channels could hold RGBA data, they will more commonly hold a number of structural permutations upon an RGBA image as the neural network progresses. It is not uncommon for each pixel to have 32 or 64 channels in it.\n\nSince a standard [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object cannot have more than 4 channels, the additional channels are stored in slices of a 2D texture array (i.e. a texture of type [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type2DArray]) such that 4 consecutive channels are stored in each slice of this array. If the number of feature channels is `N`, the number of array slices needed is `(N+3)\/4`. For example, a 9-channel CNN image with a width of 3 and a height of 2 will be stored as follows:\n\n\n\nThus, the width and height of the underlying 2D texture array is the same as the width and height of the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object and the array length is equal to  `(` [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/featureChannels] `+3)\/4`. (Channels marked with a `?` are just for padding and should not contain `NaN` or `INF` values.)\n\nAn [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object can contain multiple CNN images for batch processing. In order to create an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object that contains `N` images, create an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor] object with the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/numberOfImages] property set to `N`. The length of the 2D texture array (i.e. the number of slices) will be equal to `((` [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/featureChannels] `+3)\/4)*` [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/numberOfImages], where consecutive `(featureChannels+3)\/4` slices of this array represent one image.\n\nAlthough an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object can contain more than one image, the actual number of images among these processed by an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] object is controlled by the `z` dimension of the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel\/clipRect] property. (A kernel processes `n=clipRect.size.depth` images from this collection.)\n\nThe starting index of the image to process from the source [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object is given by `offset.z`. The starting index of the image in the destination [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object where this processed image is written to is given by `clipRect.origin.z`. Thus, an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] object takes the `n=clipRect.size.depth` image from the source at indices `[offset.z, offset.z+n]`, processes each independently, and stores the result in the destination at indices `[clipRect.origin.z, clipRect.origin.z+n]` respectively. Thus, `offset.z+n` should be `<=[source numberOfImages]`, `clipRect.origin.z+n` should be `<=[destination numberOfImages]`, and `offset.z` must be `>=0`.\n\nFor example, suppose an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNConvolution] object takes an input image with 16 channels and outputs an image with 32 channels. The number of slices needed in the source 2D texture array is 4 and the number of slices needed in the destination 2D texture array is 8. Suppose the source batch size is 5 and the destination batch size is 4. Thus, the number of source slices will be `4*5=20` and the number of destination slices will be `8*4=32`. If you want to process image 2 and 3 of the source and store the result at index 1 and 2 in the destination, you can achieve this by setting `offset.z=2`, `clipRect.origin.z=1`, and `clipRect.size.depth=2`. The [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNConvolution] object will take, in this case, slices 4 and 5 of the source and produce slices 4 to 7 of the destination. Similarly, slices 6 and 7 will be used to produce slices 8 to 11 of the destination.\n\nAll [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] objects process images in the batch independently. That is, calling a [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] object on a batch is formally the same as calling it on each image in the batch sequentially. Computational and GPU work submission overhead will be amortized over more work if batch processing is used. This is especially important for better performance on small images.\n\nIf `featureChannels<=4` and `numberOfImages=1` (i.e. only one slice is needed to represent the image), the underlying metal texture type is chosen to be [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type2D] rather than [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type2DArray] as explained above.\n\nThe framework also provides [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] objects, intended for very short-lived image data that is produced and consumed immediately in the same [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLCommandBuffer] object. They are a useful way to minimize CPU-side texture allocation costs and greatly reduce the amount of memory used by your image pipeline.\n\nCreation of the underlying texture may occur lazily in some cases. In general, you should avoid calling the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage\/texture] property to avoid materializing memory for longer than necessary. When possible, use the other [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] properties to get information about the object instead.\n\n### The MPSImage Class\n\n[doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLBuffer] and [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects are commonly used in Metal apps and are used directly by the Metal Performance Shaders framework when possible. In apps that use CNN, kernels may need more than the four data channels that a [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object can provide. In these cases, an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object is used instead as an abstraction layer on top of a [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object. When more than 4 channels are needed, additional textures in the 2D texture array are added to hold additional channels in sets of four. An [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object tracks this information as the number of *feature channels* in an image.\n\n### CNN Images\n\n[doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] objects operate on [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] objects. [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] objects are at their core [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects; however, whereas [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects commonly represent image or texel data, an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object is a more abstract representation of image features. The channels within an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] do not necessarily correspond to colors in a color space (although they can, if necessary). As a result, there can be many more than four of them. Having 32 or 64 channels per pixel is not uncommon in CNN. This is achieved on the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object abstraction by inserting extra RGBA pixels to handle the additional feature channels (if any) beyond 4. These extra pixels are stored as multiple slices of a 2D image array. Thus, each CNN pixel in a 32-channel image is represented as 8 array slices, with 4-channels stored per-pixel in each slice. The width and height of the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object is the same as the width and height of the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object. The number of slices in the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object is given by the number of feature channels rounded up to a multiple of 4.\n\n[doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] objects can be created from existing [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects. They may also be created anew from an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor] and backed with either standard texture memory, or as [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] objects using memory drawn from the framework’s internal cached texture backing store. [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] objects can provide great memory usage and CPU time savings, but come with significant restrictions that should be understood before using them. For example, their contents are only valid during the GPU-side execution of a single [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLCommandBuffer] object and can not be read from or written to by the CPU. They are provided as an efficient way to hold CNN computations that are used immediately within the scope of the same [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLCommandBuffer] object and then discarded. Concatenation is also supported by allowing you to define from which destination feature channel to start writing the output of the current layer. In this way, your app can make a large [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] or [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] object and fill in parts of it with multiple layers (as long as the destination feature channel offset is a multiple of 4).\n\n### Supported Pixel Formats\n\nThe following table shows pixel formats supported by [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage].",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\ncrawled: 2025-12-02T16:13:19Z\n---\n\n# MPSImage\n\n**Class**\n\nA texture that may have more than four channels for use in convolutional neural networks.\n\n## Declaration\n\n```swift\nclass MPSImage\n```\n\n## Overview\n\nSome image types, such as those found in convolutional neural networks (CNN), differ from a standard texture in that they may have more than 4 channels per pixel. While the channels could hold RGBA data, they will more commonly hold a number of structural permutations upon an RGBA image as the neural network progresses. It is not uncommon for each pixel to have 32 or 64 channels in it.\n\nSince a standard [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object cannot have more than 4 channels, the additional channels are stored in slices of a 2D texture array (i.e. a texture of type [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type2DArray]) such that 4 consecutive channels are stored in each slice of this array. If the number of feature channels is `N`, the number of array slices needed is `(N+3)\/4`. For example, a 9-channel CNN image with a width of 3 and a height of 2 will be stored as follows:\n\n\n\nThus, the width and height of the underlying 2D texture array is the same as the width and height of the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object and the array length is equal to  `(` [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/featureChannels] `+3)\/4`. (Channels marked with a `?` are just for padding and should not contain `NaN` or `INF` values.)\n\nAn [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object can contain multiple CNN images for batch processing. In order to create an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object that contains `N` images, create an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor] object with the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/numberOfImages] property set to `N`. The length of the 2D texture array (i.e. the number of slices) will be equal to `((` [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/featureChannels] `+3)\/4)*` [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor\/numberOfImages], where consecutive `(featureChannels+3)\/4` slices of this array represent one image.\n\nAlthough an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object can contain more than one image, the actual number of images among these processed by an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] object is controlled by the `z` dimension of the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel\/clipRect] property. (A kernel processes `n=clipRect.size.depth` images from this collection.)\n\nThe starting index of the image to process from the source [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object is given by `offset.z`. The starting index of the image in the destination [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object where this processed image is written to is given by `clipRect.origin.z`. Thus, an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] object takes the `n=clipRect.size.depth` image from the source at indices `[offset.z, offset.z+n]`, processes each independently, and stores the result in the destination at indices `[clipRect.origin.z, clipRect.origin.z+n]` respectively. Thus, `offset.z+n` should be `<=[source numberOfImages]`, `clipRect.origin.z+n` should be `<=[destination numberOfImages]`, and `offset.z` must be `>=0`.\n\nFor example, suppose an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNConvolution] object takes an input image with 16 channels and outputs an image with 32 channels. The number of slices needed in the source 2D texture array is 4 and the number of slices needed in the destination 2D texture array is 8. Suppose the source batch size is 5 and the destination batch size is 4. Thus, the number of source slices will be `4*5=20` and the number of destination slices will be `8*4=32`. If you want to process image 2 and 3 of the source and store the result at index 1 and 2 in the destination, you can achieve this by setting `offset.z=2`, `clipRect.origin.z=1`, and `clipRect.size.depth=2`. The [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNConvolution] object will take, in this case, slices 4 and 5 of the source and produce slices 4 to 7 of the destination. Similarly, slices 6 and 7 will be used to produce slices 8 to 11 of the destination.\n\nAll [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] objects process images in the batch independently. That is, calling a [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] object on a batch is formally the same as calling it on each image in the batch sequentially. Computational and GPU work submission overhead will be amortized over more work if batch processing is used. This is especially important for better performance on small images.\n\nIf `featureChannels<=4` and `numberOfImages=1` (i.e. only one slice is needed to represent the image), the underlying metal texture type is chosen to be [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type2D] rather than [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTextureType\/type2DArray] as explained above.\n\nThe framework also provides [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] objects, intended for very short-lived image data that is produced and consumed immediately in the same [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLCommandBuffer] object. They are a useful way to minimize CPU-side texture allocation costs and greatly reduce the amount of memory used by your image pipeline.\n\nCreation of the underlying texture may occur lazily in some cases. In general, you should avoid calling the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage\/texture] property to avoid materializing memory for longer than necessary. When possible, use the other [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] properties to get information about the object instead.\n\n### The MPSImage Class\n\n[doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLBuffer] and [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects are commonly used in Metal apps and are used directly by the Metal Performance Shaders framework when possible. In apps that use CNN, kernels may need more than the four data channels that a [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object can provide. In these cases, an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object is used instead as an abstraction layer on top of a [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object. When more than 4 channels are needed, additional textures in the 2D texture array are added to hold additional channels in sets of four. An [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object tracks this information as the number of *feature channels* in an image.\n\n### CNN Images\n\n[doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSCNNKernel] objects operate on [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] objects. [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] objects are at their core [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects; however, whereas [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects commonly represent image or texel data, an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object is a more abstract representation of image features. The channels within an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] do not necessarily correspond to colors in a color space (although they can, if necessary). As a result, there can be many more than four of them. Having 32 or 64 channels per pixel is not uncommon in CNN. This is achieved on the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object abstraction by inserting extra RGBA pixels to handle the additional feature channels (if any) beyond 4. These extra pixels are stored as multiple slices of a 2D image array. Thus, each CNN pixel in a 32-channel image is represented as 8 array slices, with 4-channels stored per-pixel in each slice. The width and height of the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object is the same as the width and height of the [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] object. The number of slices in the [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] object is given by the number of feature channels rounded up to a multiple of 4.\n\n[doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] objects can be created from existing [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLTexture] objects. They may also be created anew from an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor] and backed with either standard texture memory, or as [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] objects using memory drawn from the framework’s internal cached texture backing store. [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] objects can provide great memory usage and CPU time savings, but come with significant restrictions that should be understood before using them. For example, their contents are only valid during the GPU-side execution of a single [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLCommandBuffer] object and can not be read from or written to by the CPU. They are provided as an efficient way to hold CNN computations that are used immediately within the scope of the same [doc:\/\/com.apple.documentation\/documentation\/Metal\/MTLCommandBuffer] object and then discarded. Concatenation is also supported by allowing you to define from which destination feature channel to start writing the output of the current layer. In this way, your app can make a large [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage] or [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage] object and fill in parts of it with multiple layers (as long as the destination feature channel offset is a multiple of 4).\n\n### Supported Pixel Formats\n\nThe following table shows pixel formats supported by [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage].\n\n\n\n## Initializers\n\n- **init(device:imageDescriptor:)**: Initializes an empty image.\n- **MPSImageDescriptor**: A description of the attributes used to create an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage].\n- **init(texture:featureChannels:)**: Initializes an image from a texture. The user-allocated texture has been created for a specific number of feature channels and number of images.\n- **init(parentImage:sliceRange:featureChannels:)**\n\n## Methods\n\n- **setPurgeableState(_:)**: Set (or query) the purgeable state of the image’s underlying texture.\n- **MPSPurgeableState**: The purgeable state of an image’s underlying texture.\n\n## Methods to Read and Write Raw Data\n\n- **readBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:)**\n- **readBytes(_:dataLayout:imageIndex:)**\n- **writeBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:)**\n- **writeBytes(_:dataLayout:imageIndex:)**\n- **MPSImageReadWriteParams**: Parameters that control reading and writing of a particular set of feature channels.\n- **MPSDataLayout**: Options that define how buffer data is arranged.\n\n## Methods to Get an Image Allocator\n\n- **defaultAllocator()**\n- **MPSImageAllocator**\n\n## Properties\n\n- **device**: The device on which the image will be used.\n- **width**: The formal width of the image, in pixels.\n- **height**: The formal height of the image, in pixels.\n- **featureChannels**: The number of feature channels per pixel.\n- **numberOfImages**: The number of images for batch processing.\n- **textureType**: The type of the underlying texture.\n- **MTLTextureType**: The dimension of each image, including whether multiple images are arranged into an array or a cube.\n- **pixelFormat**: The pixel format of the underlying texture.\n- **MTLPixelFormat**: The data formats that describe the organization and characteristics of individual pixels in a texture.\n- **precision**: The number of bits of numeric precision available for each feature channel.\n- **usage**: The intended usage of the underlying texture.\n- **MTLTextureUsage**: An enumeration for the various options that determine how you can use a texture.\n- **pixelSize**: The number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)\n- **texture**: The underlying texture.\n- **MTLTexture**: A resource that holds formatted image data.\n- **label**: A string to help identify this object.\n\n## Instance Properties\n\n- **featureChannelFormat**\n- **parent**\n\n## Instance Methods\n\n- **batchRepresentation()**\n- **batchRepresentation(withSubRange:)**\n- **readBytes(_:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)**\n- **resourceSize()**\n- **subImage(withFeatureChannelRange:)**\n- **synchronize(on:)**\n- **writeBytes(_:dataLayout:bytesPerColumn:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)**\n- **writeBytes(_:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)**\n\n## Neural Networks\n\n- **Training a Neural Network with Metal Performance Shaders**: Use an MPS neural network graph to train a simple neural network digit classifier.\n- **MPSTemporaryImage**: A texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.\n- **Objects that Simplify the Creation of Neural Networks**: Simplify the creation of neural networks using networks of filter, image, and state nodes.\n- **Convolutional Neural Network Kernels**: Build neural networks with layers.\n- **Recurrent Neural Networks**: Create recurrent neural networks.\n\n## Inherits From\n\n- NSObject\n\n## Inherited By\n\n- MPSTemporaryImage\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Initializes an empty image.",
          "name" : "init(device:imageDescriptor:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/init(device:imageDescriptor:)"
        },
        {
          "description" : "A description of the attributes used to create an [doc:\/\/com.apple.metalperformanceshaders\/documentation\/MetalPerformanceShaders\/MPSImage].",
          "name" : "MPSImageDescriptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImageDescriptor"
        },
        {
          "description" : "Initializes an image from a texture. The user-allocated texture has been created for a specific number of feature channels and number of images.",
          "name" : "init(texture:featureChannels:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/init(texture:featureChannels:)"
        },
        {
          "description" : "",
          "name" : "init(parentImage:sliceRange:featureChannels:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/init(parentImage:sliceRange:featureChannels:)"
        }
      ],
      "title" : "Initializers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Set (or query) the purgeable state of the image’s underlying texture.",
          "name" : "setPurgeableState(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/setPurgeableState(_:)"
        },
        {
          "description" : "The purgeable state of an image’s underlying texture.",
          "name" : "MPSPurgeableState",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSPurgeableState"
        }
      ],
      "title" : "Methods"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "readBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/readBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:)"
        },
        {
          "description" : "",
          "name" : "readBytes(_:dataLayout:imageIndex:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/readBytes(_:dataLayout:imageIndex:)"
        },
        {
          "description" : "",
          "name" : "writeBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/writeBytes(_:dataLayout:bytesPerRow:region:featureChannelInfo:imageIndex:)"
        },
        {
          "description" : "",
          "name" : "writeBytes(_:dataLayout:imageIndex:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/writeBytes(_:dataLayout:imageIndex:)"
        },
        {
          "description" : "Parameters that control reading and writing of a particular set of feature channels.",
          "name" : "MPSImageReadWriteParams",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImageReadWriteParams"
        },
        {
          "description" : "Options that define how buffer data is arranged.",
          "name" : "MPSDataLayout",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSDataLayout"
        }
      ],
      "title" : "Methods to Read and Write Raw Data"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "defaultAllocator()",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/defaultAllocator()"
        },
        {
          "description" : "",
          "name" : "MPSImageAllocator",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImageAllocator"
        }
      ],
      "title" : "Methods to Get an Image Allocator"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The device on which the image will be used.",
          "name" : "device",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/device"
        },
        {
          "description" : "The formal width of the image, in pixels.",
          "name" : "width",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/width"
        },
        {
          "description" : "The formal height of the image, in pixels.",
          "name" : "height",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/height"
        },
        {
          "description" : "The number of feature channels per pixel.",
          "name" : "featureChannels",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/featureChannels"
        },
        {
          "description" : "The number of images for batch processing.",
          "name" : "numberOfImages",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/numberOfImages"
        },
        {
          "description" : "The type of the underlying texture.",
          "name" : "textureType",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/textureType"
        },
        {
          "description" : "The dimension of each image, including whether multiple images are arranged into an array or a cube.",
          "name" : "MTLTextureType",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLTextureType"
        },
        {
          "description" : "The pixel format of the underlying texture.",
          "name" : "pixelFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/pixelFormat"
        },
        {
          "description" : "The data formats that describe the organization and characteristics of individual pixels in a texture.",
          "name" : "MTLPixelFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLPixelFormat"
        },
        {
          "description" : "The number of bits of numeric precision available for each feature channel.",
          "name" : "precision",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/precision"
        },
        {
          "description" : "The intended usage of the underlying texture.",
          "name" : "usage",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/usage"
        },
        {
          "description" : "An enumeration for the various options that determine how you can use a texture.",
          "name" : "MTLTextureUsage",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLTextureUsage"
        },
        {
          "description" : "The number of bytes from the first byte of one pixel to the first byte of the next pixel, in storage order. (Includes padding.)",
          "name" : "pixelSize",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/pixelSize"
        },
        {
          "description" : "The underlying texture.",
          "name" : "texture",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/texture"
        },
        {
          "description" : "A resource that holds formatted image data.",
          "name" : "MTLTexture",
          "url" : "https:\/\/developer.apple.com\/documentation\/Metal\/MTLTexture"
        },
        {
          "description" : "A string to help identify this object.",
          "name" : "label",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/label"
        }
      ],
      "title" : "Properties"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "featureChannelFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/featureChannelFormat"
        },
        {
          "description" : "",
          "name" : "parent",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/parent"
        }
      ],
      "title" : "Instance Properties"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "batchRepresentation()",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/batchRepresentation()"
        },
        {
          "description" : "",
          "name" : "batchRepresentation(withSubRange:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/batchRepresentation(withSubRange:)"
        },
        {
          "description" : "",
          "name" : "readBytes(_:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/readBytes(_:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)"
        },
        {
          "description" : "",
          "name" : "resourceSize()",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/resourceSize()"
        },
        {
          "description" : "",
          "name" : "subImage(withFeatureChannelRange:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/subImage(withFeatureChannelRange:)"
        },
        {
          "description" : "",
          "name" : "synchronize(on:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/synchronize(on:)"
        },
        {
          "description" : "",
          "name" : "writeBytes(_:dataLayout:bytesPerColumn:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/writeBytes(_:dataLayout:bytesPerColumn:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)"
        },
        {
          "description" : "",
          "name" : "writeBytes(_:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage\/writeBytes(_:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:)"
        }
      ],
      "title" : "Instance Methods"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use an MPS neural network graph to train a simple neural network digit classifier.",
          "name" : "Training a Neural Network with Metal Performance Shaders",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/training-a-neural-network-with-metal-performance-shaders"
        },
        {
          "description" : "A texture for use in convolutional neural networks that stores transient data to be used and discarded promptly.",
          "name" : "MPSTemporaryImage",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSTemporaryImage"
        },
        {
          "description" : "Simplify the creation of neural networks using networks of filter, image, and state nodes.",
          "name" : "Objects that Simplify the Creation of Neural Networks",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/objects-that-simplify-the-creation-of-neural-networks"
        },
        {
          "description" : "Build neural networks with layers.",
          "name" : "Convolutional Neural Network Kernels",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/convolutional-neural-network-kernels"
        },
        {
          "description" : "Create recurrent neural networks.",
          "name" : "Recurrent Neural Networks",
          "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/recurrent-neural-networks"
        }
      ],
      "title" : "Neural Networks"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "MPSImage",
  "url" : "https:\/\/developer.apple.com\/documentation\/MetalPerformanceShaders\/MPSImage"
}