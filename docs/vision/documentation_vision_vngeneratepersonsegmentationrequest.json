{
  "abstract" : "An object that produces a matte image for a person it finds in the input image.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol"
  ],
  "contentHash" : "beb4db9f076ab91195c5e1e5f5d976c6867f60ba134095c31e45fb3a431ddd20",
  "crawledAt" : "2025-12-04T01:02:33Z",
  "declaration" : {
    "code" : "class VNGeneratePersonSegmentationRequest",
    "language" : "swift"
  },
  "id" : "615F7040-E634-4BDE-875F-9FEE68FE4C16",
  "kind" : "class",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nPerform this request to detect and generate an image mask for a person in an image. The request returns the resulting image mask in an instance of [doc:\/\/Vision\/documentation\/Vision\/VNPixelBufferObservation].",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/vngeneratepersonsegmentationrequest\ncrawled: 2025-12-04T01:02:33Z\n---\n\n# VNGeneratePersonSegmentationRequest\n\n**Class**\n\nAn object that produces a matte image for a person it finds in the input image.\n\n## Declaration\n\n```swift\nclass VNGeneratePersonSegmentationRequest\n```\n\n## Overview\n\nPerform this request to detect and generate an image mask for a person in an image. The request returns the resulting image mask in an instance of [doc:\/\/Vision\/documentation\/Vision\/VNPixelBufferObservation].\n\n## Creating a Request\n\n- **init()**: Creates a generate person segmentation request.\n- **init(completionHandler:)**: Creates a generate person segmentation request with a completion handler.\n\n## Configuring the Request\n\n- **outputPixelFormat**: The pixel format of the output image.\n- **qualityLevel**: A value that indicates how the request balances accuracy and performance.\n- **VNGeneratePersonSegmentationRequest.QualityLevel**: Constants that define the levels of quality for a person segmentation request.\n\n## Getting the supported output pixel formats\n\n- **supportedOutputPixelFormats()**: Returns a list of output pixel formats that the request supports.\n\n## Accessing the Results\n\n- **results**: The results of the segmentation request.\n- **VNPixelBufferObservation**: An object that represents an image that an image-analysis request produces.\n\n## Identifying Request Revisions\n\n- **VNGeneratePersonSegmentationRequestRevision1**: A constant for specifying revision 1 of the person segmentation generation request.\n\n## Image sequence analysis\n\n- **Applying Matte Effects to People in Images and Video**: Generate image masks for people automatically by using semantic person-segmentation.\n- **Detecting human actions in a live video feed**: Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.\n- **Segmenting and colorizing individuals from a surrounding scene**: Use the Vision framework to isolate and apply colors to people in an image.\n- **VNStatefulRequest**: An abstract request type that builds evidence of a condition over time.\n- **VNGeneratePersonInstanceMaskRequest**: An object that produces a mask of individual people it finds in the input image.\n- **VNDetectDocumentSegmentationRequest**: An object that detects rectangular regions that contain text in the input image.\n- **VNSequenceRequestHandler**: An object that processes image-analysis requests for each frame in a sequence.\n\n## Inherits From\n\n- VNStatefulRequest\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a generate person segmentation request.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest\/init()"
        },
        {
          "description" : "Creates a generate person segmentation request with a completion handler.",
          "name" : "init(completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest\/init(completionHandler:)"
        }
      ],
      "title" : "Creating a Request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The pixel format of the output image.",
          "name" : "outputPixelFormat",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest\/outputPixelFormat"
        },
        {
          "description" : "A value that indicates how the request balances accuracy and performance.",
          "name" : "qualityLevel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest\/qualityLevel-swift.property"
        },
        {
          "description" : "Constants that define the levels of quality for a person segmentation request.",
          "name" : "VNGeneratePersonSegmentationRequest.QualityLevel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest\/QualityLevel-swift.enum"
        }
      ],
      "title" : "Configuring the Request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Returns a list of output pixel formats that the request supports.",
          "name" : "supportedOutputPixelFormats()",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest\/supportedOutputPixelFormats()"
        }
      ],
      "title" : "Getting the supported output pixel formats"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The results of the segmentation request.",
          "name" : "results",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest\/results"
        },
        {
          "description" : "An object that represents an image that an image-analysis request produces.",
          "name" : "VNPixelBufferObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNPixelBufferObservation"
        }
      ],
      "title" : "Accessing the Results"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A constant for specifying revision 1 of the person segmentation generation request.",
          "name" : "VNGeneratePersonSegmentationRequestRevision1",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequestRevision1"
        }
      ],
      "title" : "Identifying Request Revisions"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Generate image masks for people automatically by using semantic person-segmentation.",
          "name" : "Applying Matte Effects to People in Images and Video",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/applying-matte-effects-to-people-in-images-and-video"
        },
        {
          "description" : "Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.",
          "name" : "Detecting human actions in a live video feed",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/detecting-human-actions-in-a-live-video-feed"
        },
        {
          "description" : "Use the Vision framework to isolate and apply colors to people in an image.",
          "name" : "Segmenting and colorizing individuals from a surrounding scene",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/segmenting-and-colorizing-individuals-from-a-surrounding-scene"
        },
        {
          "description" : "An abstract request type that builds evidence of a condition over time.",
          "name" : "VNStatefulRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNStatefulRequest"
        },
        {
          "description" : "An object that produces a mask of individual people it finds in the input image.",
          "name" : "VNGeneratePersonInstanceMaskRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonInstanceMaskRequest"
        },
        {
          "description" : "An object that detects rectangular regions that contain text in the input image.",
          "name" : "VNDetectDocumentSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectDocumentSegmentationRequest"
        },
        {
          "description" : "An object that processes image-analysis requests for each frame in a sequence.",
          "name" : "VNSequenceRequestHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNSequenceRequestHandler"
        }
      ],
      "title" : "Image sequence analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "VNStatefulRequest"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "VNGeneratePersonSegmentationRequest",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/vngeneratepersonsegmentationrequest"
}