{
  "abstract" : "The results of the face-capture quality request.",
  "codeExamples" : [

  ],
  "contentHash" : "83344e951562f47d822246468e1e7f3a16cf0c459ab4720445b937a089ca626c",
  "crawledAt" : "2025-12-02T21:21:14Z",
  "declaration" : {
    "code" : "var results: [VNFaceObservation]? { get }",
    "language" : "swift"
  },
  "id" : "7A8C3EFC-4C93-4120-9988-18A0C235DC42",
  "kind" : "property",
  "language" : "swift",
  "module" : "Vision",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceCaptureQualityRequest\/results\ncrawled: 2025-12-02T21:21:14Z\n---\n\n# results\n\n**Instance Property**\n\nThe results of the face-capture quality request.\n\n## Declaration\n\n```swift\nvar results: [VNFaceObservation]? { get }\n```\n\n## Accessing the Results\n\n- **VNFaceObservation**: Face or facial-feature information that an image analysis request detects.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Face or facial-feature information that an image analysis request detects.",
          "name" : "VNFaceObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNFaceObservation"
        }
      ],
      "title" : "Accessing the Results"
    }
  ],
  "source" : "appleJSON",
  "title" : "results",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceCaptureQualityRequest\/results"
}