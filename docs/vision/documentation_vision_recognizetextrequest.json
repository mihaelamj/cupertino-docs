{
  "abstract" : "An image-analysis request that recognizes text in an image.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "ImageProcessingRequest",
    "Sendable",
    "SendableMetatype",
    "VisionRequest"
  ],
  "contentHash" : "747720e2b47e23518ed13ed613096de04cb0608b1d4142767c473e8092dc4724",
  "crawledAt" : "2025-12-05T06:55:44Z",
  "declaration" : {
    "code" : "struct RecognizeTextRequest",
    "language" : "swift"
  },
  "id" : "FD713F09-813D-4A87-B331-457B9ABB480C",
  "kind" : "struct",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nThis request generates a collection of [doc:\/\/Vision\/documentation\/Vision\/RecognizedTextObservation] objects that describe the text the request detects. By default, a text-recognition request first locates all possible glyphs or characters in the input image, and then analyzes each string. To specify or limit the languages to find in the request, set [doc:\/\/Vision\/documentation\/Vision\/RecognizeTextRequest\/recognitionLanguages] to an array that contains the names of the languages of text you want to recognize.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/recognizetextrequest\ncrawled: 2025-12-05T06:55:44Z\n---\n\n# RecognizeTextRequest\n\n**Structure**\n\nAn image-analysis request that recognizes text in an image.\n\n## Declaration\n\n```swift\nstruct RecognizeTextRequest\n```\n\n## Overview\n\nThis request generates a collection of [doc:\/\/Vision\/documentation\/Vision\/RecognizedTextObservation] objects that describe the text the request detects. By default, a text-recognition request first locates all possible glyphs or characters in the input image, and then analyzes each string. To specify or limit the languages to find in the request, set [doc:\/\/Vision\/documentation\/Vision\/RecognizeTextRequest\/recognitionLanguages] to an array that contains the names of the languages of text you want to recognize.\n\n## Creating a request\n\n- **init(_:)**: Creates a text-recognition request.\n\n## Performing a request\n\n- **perform(on:orientation:)**: Performs the request on an image URL and produces observations.\n- **perform(on:orientation:)**: Performs the request on image data and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Graphics image and produces observations.\n- **perform(on:orientation:)**: Performs the request on a pixel buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Media buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Image image and produces observations.\n\n## Understanding the result\n\n- **RecognizedTextObservation**: An object that contains information about both the location and content of text and glyphs that the framework recognizes in an image.\n\n## Configuring a request\n\n- **automaticallyDetectsLanguage**: A Boolean value that indicates whether to attempt detecting the language to use the appropriate model for recognition and language correction.\n- **usesLanguageCorrection**: A Boolean value that indicates whether the request applies language correction during the recognition process.\n- **supportedRecognitionLanguages**: The identifiers of the languages that the request supports.\n- **customWords**: An array of strings to supplement the recognized languages at the word-recognition stage.\n- **minimumTextHeightFraction**: The minimum height, relative to the image height, of the text to recognize.\n- **recognitionLanguages**: An array of languages to detect, in priority order.\n- **recognitionLevel**: A value that determines whether the request prioritizes accuracy or speed in text recognition.\n- **RecognizeTextRequest.RecognitionLevel**: Constants that identify the performance and accuracy of the text recognition.\n\n## Getting the revision\n\n- **revision**: The algorithm or implementation the request uses.\n- **supportedRevisions**: The collection of revisions the request supports.\n- **RecognizeTextRequest.Revision**: A type that describes the algorithm or implementation that the request performs.\n\n## Text and document analysis\n\n- **Locating and displaying recognized text**: Perform text recognition on a photo using the Vision framework’s text-recognition request.\n- **Recognizing tables within a document**: Scan a document that contains a table and extract its content in a formatted way.\n- **DetectBarcodesRequest**: A request that detects barcodes in an image.\n- **DetectDocumentSegmentationRequest**: A request that detects rectangular regions that contain text in the input image.\n- **DetectTextRectanglesRequest**: An image-analysis request that finds regions of visible text in an image.\n- **RecognizeDocumentsRequest**: An image-analysis request to scan an image of a document and provide information about its structure.\n\n## Conforms To\n\n- CustomStringConvertible\n- Equatable\n- Hashable\n- ImageProcessingRequest\n- Sendable\n- SendableMetatype\n- VisionRequest\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a text-recognition request.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/init(_:)"
        }
      ],
      "title" : "Creating a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Performs the request on an image URL and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-80bya"
        },
        {
          "description" : "Performs the request on image data and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3f3f1"
        },
        {
          "description" : "Performs the request on a Core Graphics image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-qxxx"
        },
        {
          "description" : "Performs the request on a pixel buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-xspx"
        },
        {
          "description" : "Performs the request on a Core Media buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3hddl"
        },
        {
          "description" : "Performs the request on a Core Image image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-85ex1"
        }
      ],
      "title" : "Performing a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that contains information about both the location and content of text and glyphs that the framework recognizes in an image.",
          "name" : "RecognizedTextObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation"
        }
      ],
      "title" : "Understanding the result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean value that indicates whether to attempt detecting the language to use the appropriate model for recognition and language correction.",
          "name" : "automaticallyDetectsLanguage",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/automaticallyDetectsLanguage"
        },
        {
          "description" : "A Boolean value that indicates whether the request applies language correction during the recognition process.",
          "name" : "usesLanguageCorrection",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/usesLanguageCorrection"
        },
        {
          "description" : "The identifiers of the languages that the request supports.",
          "name" : "supportedRecognitionLanguages",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/supportedRecognitionLanguages"
        },
        {
          "description" : "An array of strings to supplement the recognized languages at the word-recognition stage.",
          "name" : "customWords",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/customWords"
        },
        {
          "description" : "The minimum height, relative to the image height, of the text to recognize.",
          "name" : "minimumTextHeightFraction",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/minimumTextHeightFraction"
        },
        {
          "description" : "An array of languages to detect, in priority order.",
          "name" : "recognitionLanguages",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/recognitionLanguages"
        },
        {
          "description" : "A value that determines whether the request prioritizes accuracy or speed in text recognition.",
          "name" : "recognitionLevel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/recognitionLevel-swift.property"
        },
        {
          "description" : "Constants that identify the performance and accuracy of the text recognition.",
          "name" : "RecognizeTextRequest.RecognitionLevel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/RecognitionLevel-swift.enum"
        }
      ],
      "title" : "Configuring a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The algorithm or implementation the request uses.",
          "name" : "revision",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/revision-swift.property"
        },
        {
          "description" : "The collection of revisions the request supports.",
          "name" : "supportedRevisions",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/supportedRevisions"
        },
        {
          "description" : "A type that describes the algorithm or implementation that the request performs.",
          "name" : "RecognizeTextRequest.Revision",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest\/Revision-swift.enum"
        }
      ],
      "title" : "Getting the revision"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Perform text recognition on a photo using the Vision framework’s text-recognition request.",
          "name" : "Locating and displaying recognized text",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/locating-and-displaying-recognized-text"
        },
        {
          "description" : "Scan a document that contains a table and extract its content in a formatted way.",
          "name" : "Recognizing tables within a document",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/recognize-tables-within-a-document"
        },
        {
          "description" : "A request that detects barcodes in an image.",
          "name" : "DetectBarcodesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectBarcodesRequest"
        },
        {
          "description" : "A request that detects rectangular regions that contain text in the input image.",
          "name" : "DetectDocumentSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectDocumentSegmentationRequest"
        },
        {
          "description" : "An image-analysis request that finds regions of visible text in an image.",
          "name" : "DetectTextRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectTextRectanglesRequest"
        },
        {
          "description" : "An image-analysis request to scan an image of a document and provide information about its structure.",
          "name" : "RecognizeDocumentsRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeDocumentsRequest"
        }
      ],
      "title" : "Text and document analysis"
    }
  ],
  "source" : "appleJSON",
  "title" : "RecognizeTextRequest",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/recognizetextrequest"
}