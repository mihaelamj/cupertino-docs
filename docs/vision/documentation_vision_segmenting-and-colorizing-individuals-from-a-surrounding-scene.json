{
  "abstract" : "Use the Vision framework to isolate and apply colors to people in an image.",
  "codeExamples" : [
    {
      "code" : "\/\/ Returns the number of people in the image.\nprivate func countFaces(image: CIImage) async -> Int {\n    \/\/ Approximate the number of people in the image.\n    let request = VNDetectFaceRectanglesRequest()\n    let requestHandler = VNImageRequestHandler(ciImage: image)\n    do {\n        try requestHandler.perform([request])\n        if let results = request.results {\n            return results.count\n        }\n    } catch {\n        print(\"Unable to perform face detection: \\(error).\")\n    }\n    return 0\n}",
      "language" : "swift"
    },
    {
      "code" : "let numFaces = await countFaces(image: image)\nif numFaces <= 4 {\n    request = VNGeneratePersonInstanceMaskRequest()\n} else {\n    request = VNGeneratePersonSegmentationRequest()\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Set up and run the request.\nlet requestHandler = VNImageRequestHandler(ciImage: image)\nself.baseImage = image\ndo {\n    try requestHandler.perform([request])\n    \n    \/\/ Get the segmentation results from the request.\n    switch request.results?.first {\n    case let buffer as VNPixelBufferObservation:\n        segmentationResults = PersonSegmentationResults(results: buffer)\n        selectedSegments = [1]\n    case let instanceMask as VNInstanceMaskObservation:\n        segmentationResults = InstanceMaskResults(results: instanceMask, requestHandler: requestHandler)\n        selectedSegments = instanceMask.allInstances\n    default:\n        break\n    }",
      "language" : "swift"
    },
    {
      "code" : "let segmentedImage = await segmentationResults?.generateSegmentedImage(baseImage: image, selectedSegments: selectedSegments)\n\nTask { @MainActor in\n    \/\/ Update the UI.\n    if let results = segmentationResults {\n        self.segmentationCount = results.numSegments\n    }\n    self.segmentedImage = segmentedImage ?? UIImage(cgImage: CIContext().createCGImage(image, from: image.extent)!)\n    self.showWarning = segmentationResults is PersonSegmentationResults\n}",
      "language" : "swift"
    },
    {
      "code" : "for index in selectedSegments {\n    do {\n        let maskPixelBuffer = try instanceMasks.generateScaledMaskForImage(forInstances: [index], from: requestHandler)\n        let maskImage = CIImage(cvPixelBuffer: maskPixelBuffer)\n        image = blendImageWithMask(image: image, mask: maskImage, color: SegmentationModel.colors[index])\n    } catch {\n        print(\"Error generating mask: \\(error).\")\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "if selectedSegments.contains(1) {\n    \/\/ Foreground is selected.\n    segmentedImage = blendImageWithMask(image: baseImage, mask: maskImage, color: SegmentationModel.colors[1])\n}",
      "language" : "swift"
    },
    {
      "code" : "if selectedSegments.contains(0) {\n    \/\/ Background is selected.\n    let blendFilter = CIFilter.blendWithMask()\n    blendFilter.inputImage = baseImage\n    blendFilter.backgroundImage = CIImage(color: CIColor(color: SegmentationModel.colors[0])).cropped(to: baseImage.extent)\n    blendFilter.maskImage = maskImage\n    segmentedImage = blendFilter.outputImage!\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "35be8ed402105a6a098ca5fb4f59577003e10dde52a21c9dfbbfd6b5d2b9d759",
  "crawledAt" : "2025-12-04T01:02:31Z",
  "id" : "D4B49AC9-7033-4863-AF7C-859A8D4E5C19",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nSegmenting individuals in photos is a powerful tool that can provide more creative control for people using your app. Person segmentation enables you to provide popular features like personalized effects and filters, background replacement, and enabling photographic corrections.\n\nThis sample shows you how to generate segmented masks for up to four individuals in a scene. This sample generates one mask for everyone if more than four individuals are in the scene. Individuals in each mask are then colorized. You can then select the individuals you want to segment and colorize.\n\n\n\n### Configure the sample code project\n\nTo run this sample app, you need an iPhone or iPad with iOS 17 or iPadOS 17, respectively, or later. You need to run this sample code project on a physical device.\n\n### Determine the number of faces in a scene\n\nThe sample first determines the number of faces in the scene given the [https:\/\/developer.apple.com\/documentation\/coreimage\/ciimage] using [doc:\/\/Vision\/documentation\/Vision\/VNDetectFaceRectanglesRequest].\n\nThe number of faces determines the segmentation approach:\n\n### Generate the segmented masks\n\nThe sample sets up the image analysis requests for the image with [doc:\/\/Vision\/documentation\/Vision\/VNImageRequestHandler] and processes the request for the image. The [doc:\/\/Vision\/documentation\/Vision\/VNImageRequestHandler\/perform(_:)] method schedules the request. When the request completes, the segments are returned in `request.results`.\n\nIf there are more than four faces, the sample produces a matte image for the individual segments in the image, the resulting mask is an instance of [doc:\/\/Vision\/documentation\/Vision\/VNPixelBufferObservation]. If there are four of fewer faces, the resulting mask is an instance of [doc:\/\/Vision\/documentation\/Vision\/VNInstanceMaskObservation].\n\nThe sample then updates the image on the main thread with the colorized mask.\n\n### Colorize individual people in an image\n\nThe sample’s `InstanceMaskResults` class generates segmented images for up to four people in a scene. It conforms to the `SegmentationResults` protocol. The sample initializes the class with the [doc:\/\/Vision\/documentation\/Vision\/VNInstanceMaskObservation] results and a [doc:\/\/Vision\/documentation\/Vision\/VNImageRequestHandler].\n\nThe `generateSegmentedImage` method asynchronously generates an image with the selected segments highlighted. It scales the masks for each segment and blends them with the base image using specified colors.\n\nThe following illustration depicts the colorization when the person using this sample selects two segmentations when there are up to four people in the image. The sample masks three of the people with different, selected colors. \n\nIf the person using this sample selects all the people and the background of the image, this sample masks the background with the selected color, and masks and colorizes the people. \n\n### Colorize more than four people in an image\n\nThe sample’s `PersonSegmentationResults` class generates a segmented image for every person in a scene using [doc:\/\/Vision\/documentation\/Vision\/VNPixelBufferObservation] from [doc:\/\/Vision\/documentation\/Vision\/VNGeneratePersonSegmentationRequest]. It conforms to the `SegmentationResults` protocol. The sample’s `generateSegmentedImage` method generates the image with a mask for the foreground or the background.\n\nIf there are more than four people in the image and the person using this sample selects the mask in the foreground, `blendImageWithMask(image, mask)` applies a masks to all the detected individuals with a specific color.\n\n\n\nIf the person using the sample selects the background mask in the image, the sample masks the background of the image with a specific color, but leaves the people in the foreground of the image intact. This allows for selectively coloring the background of the image based on the segmentation mask.\n\n",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/segmenting-and-colorizing-individuals-from-a-surrounding-scene\ncrawled: 2025-12-04T01:02:31Z\n---\n\n# Segmenting and colorizing individuals from a surrounding scene\n\n**Sample Code**\n\nUse the Vision framework to isolate and apply colors to people in an image.\n\n## Overview\n\nSegmenting individuals in photos is a powerful tool that can provide more creative control for people using your app. Person segmentation enables you to provide popular features like personalized effects and filters, background replacement, and enabling photographic corrections.\n\nThis sample shows you how to generate segmented masks for up to four individuals in a scene. This sample generates one mask for everyone if more than four individuals are in the scene. Individuals in each mask are then colorized. You can then select the individuals you want to segment and colorize.\n\n\n\n### Configure the sample code project\n\nTo run this sample app, you need an iPhone or iPad with iOS 17 or iPadOS 17, respectively, or later. You need to run this sample code project on a physical device.\n\n### Determine the number of faces in a scene\n\nThe sample first determines the number of faces in the scene given the [https:\/\/developer.apple.com\/documentation\/coreimage\/ciimage] using [doc:\/\/Vision\/documentation\/Vision\/VNDetectFaceRectanglesRequest].\n\n```swift\n\/\/ Returns the number of people in the image.\nprivate func countFaces(image: CIImage) async -> Int {\n    \/\/ Approximate the number of people in the image.\n    let request = VNDetectFaceRectanglesRequest()\n    let requestHandler = VNImageRequestHandler(ciImage: image)\n    do {\n        try requestHandler.perform([request])\n        if let results = request.results {\n            return results.count\n        }\n    } catch {\n        print(\"Unable to perform face detection: \\(error).\")\n    }\n    return 0\n}\n```\n\nThe number of faces determines the segmentation approach:\n\n- If there are four or fewer faces, the sample uses [doc:\/\/Vision\/documentation\/Vision\/VNGeneratePersonInstanceMaskRequest].\n- If more than four faces are detected, the sample uses [doc:\/\/Vision\/documentation\/Vision\/VNGeneratePersonSegmentationRequest], and produces a mask for all the individuals in the image.\n\n```swift\nlet numFaces = await countFaces(image: image)\nif numFaces <= 4 {\n    request = VNGeneratePersonInstanceMaskRequest()\n} else {\n    request = VNGeneratePersonSegmentationRequest()\n}\n```\n\n### Generate the segmented masks\n\nThe sample sets up the image analysis requests for the image with [doc:\/\/Vision\/documentation\/Vision\/VNImageRequestHandler] and processes the request for the image. The [doc:\/\/Vision\/documentation\/Vision\/VNImageRequestHandler\/perform(_:)] method schedules the request. When the request completes, the segments are returned in `request.results`.\n\n```swift\n\/\/ Set up and run the request.\nlet requestHandler = VNImageRequestHandler(ciImage: image)\nself.baseImage = image\ndo {\n    try requestHandler.perform([request])\n    \n    \/\/ Get the segmentation results from the request.\n    switch request.results?.first {\n    case let buffer as VNPixelBufferObservation:\n        segmentationResults = PersonSegmentationResults(results: buffer)\n        selectedSegments = [1]\n    case let instanceMask as VNInstanceMaskObservation:\n        segmentationResults = InstanceMaskResults(results: instanceMask, requestHandler: requestHandler)\n        selectedSegments = instanceMask.allInstances\n    default:\n        break\n    }\n```\n\nIf there are more than four faces, the sample produces a matte image for the individual segments in the image, the resulting mask is an instance of [doc:\/\/Vision\/documentation\/Vision\/VNPixelBufferObservation]. If there are four of fewer faces, the resulting mask is an instance of [doc:\/\/Vision\/documentation\/Vision\/VNInstanceMaskObservation].\n\nThe sample then updates the image on the main thread with the colorized mask.\n\n```swift\nlet segmentedImage = await segmentationResults?.generateSegmentedImage(baseImage: image, selectedSegments: selectedSegments)\n\nTask { @MainActor in\n    \/\/ Update the UI.\n    if let results = segmentationResults {\n        self.segmentationCount = results.numSegments\n    }\n    self.segmentedImage = segmentedImage ?? UIImage(cgImage: CIContext().createCGImage(image, from: image.extent)!)\n    self.showWarning = segmentationResults is PersonSegmentationResults\n}\n```\n\n\n\n### Colorize individual people in an image\n\nThe sample’s `InstanceMaskResults` class generates segmented images for up to four people in a scene. It conforms to the `SegmentationResults` protocol. The sample initializes the class with the [doc:\/\/Vision\/documentation\/Vision\/VNInstanceMaskObservation] results and a [doc:\/\/Vision\/documentation\/Vision\/VNImageRequestHandler].\n\nThe `generateSegmentedImage` method asynchronously generates an image with the selected segments highlighted. It scales the masks for each segment and blends them with the base image using specified colors.\n\n```swift\nfor index in selectedSegments {\n    do {\n        let maskPixelBuffer = try instanceMasks.generateScaledMaskForImage(forInstances: [index], from: requestHandler)\n        let maskImage = CIImage(cvPixelBuffer: maskPixelBuffer)\n        image = blendImageWithMask(image: image, mask: maskImage, color: SegmentationModel.colors[index])\n    } catch {\n        print(\"Error generating mask: \\(error).\")\n    }\n}\n```\n\nThe following illustration depicts the colorization when the person using this sample selects two segmentations when there are up to four people in the image. The sample masks three of the people with different, selected colors. \n\nIf the person using this sample selects all the people and the background of the image, this sample masks the background with the selected color, and masks and colorizes the people. \n\n### Colorize more than four people in an image\n\nThe sample’s `PersonSegmentationResults` class generates a segmented image for every person in a scene using [doc:\/\/Vision\/documentation\/Vision\/VNPixelBufferObservation] from [doc:\/\/Vision\/documentation\/Vision\/VNGeneratePersonSegmentationRequest]. It conforms to the `SegmentationResults` protocol. The sample’s `generateSegmentedImage` method generates the image with a mask for the foreground or the background.\n\nIf there are more than four people in the image and the person using this sample selects the mask in the foreground, `blendImageWithMask(image, mask)` applies a masks to all the detected individuals with a specific color.\n\n```swift\nif selectedSegments.contains(1) {\n    \/\/ Foreground is selected.\n    segmentedImage = blendImageWithMask(image: baseImage, mask: maskImage, color: SegmentationModel.colors[1])\n}\n```\n\n\n\nIf the person using the sample selects the background mask in the image, the sample masks the background of the image with a specific color, but leaves the people in the foreground of the image intact. This allows for selectively coloring the background of the image based on the segmentation mask.\n\n```swift\nif selectedSegments.contains(0) {\n    \/\/ Background is selected.\n    let blendFilter = CIFilter.blendWithMask()\n    blendFilter.inputImage = baseImage\n    blendFilter.backgroundImage = CIImage(color: CIColor(color: SegmentationModel.colors[0])).cropped(to: baseImage.extent)\n    blendFilter.maskImage = maskImage\n    segmentedImage = blendFilter.outputImage!\n}\n```\n\n\n\n## Image sequence analysis\n\n- **Applying Matte Effects to People in Images and Video**: Generate image masks for people automatically by using semantic person-segmentation.\n- **Detecting human actions in a live video feed**: Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.\n- **VNStatefulRequest**: An abstract request type that builds evidence of a condition over time.\n- **VNGeneratePersonSegmentationRequest**: An object that produces a matte image for a person it finds in the input image.\n- **VNGeneratePersonInstanceMaskRequest**: An object that produces a mask of individual people it finds in the input image.\n- **VNDetectDocumentSegmentationRequest**: An object that detects rectangular regions that contain text in the input image.\n- **VNSequenceRequestHandler**: An object that processes image-analysis requests for each frame in a sequence.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Generate image masks for people automatically by using semantic person-segmentation.",
          "name" : "Applying Matte Effects to People in Images and Video",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/applying-matte-effects-to-people-in-images-and-video"
        },
        {
          "description" : "Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.",
          "name" : "Detecting human actions in a live video feed",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateML\/detecting-human-actions-in-a-live-video-feed"
        },
        {
          "description" : "An abstract request type that builds evidence of a condition over time.",
          "name" : "VNStatefulRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNStatefulRequest"
        },
        {
          "description" : "An object that produces a matte image for a person it finds in the input image.",
          "name" : "VNGeneratePersonSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonSegmentationRequest"
        },
        {
          "description" : "An object that produces a mask of individual people it finds in the input image.",
          "name" : "VNGeneratePersonInstanceMaskRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGeneratePersonInstanceMaskRequest"
        },
        {
          "description" : "An object that detects rectangular regions that contain text in the input image.",
          "name" : "VNDetectDocumentSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectDocumentSegmentationRequest"
        },
        {
          "description" : "An object that processes image-analysis requests for each frame in a sequence.",
          "name" : "VNSequenceRequestHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNSequenceRequestHandler"
        }
      ],
      "title" : "Image sequence analysis"
    }
  ],
  "source" : "appleJSON",
  "title" : "Segmenting and colorizing individuals from a surrounding scene",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/segmenting-and-colorizing-individuals-from-a-surrounding-scene"
}