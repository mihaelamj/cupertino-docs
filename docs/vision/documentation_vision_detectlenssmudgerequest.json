{
  "abstract" : "A request that detects a smudge on a lens from an image or video frame capture.",
  "codeExamples" : [
    {
      "code" : "func isGoodCapture(imageURL:URL) async throws -> Bool {\n   \n   \/\/ Set an optional threshold from 0.0 to 1.0 to flag a maximum level of smudge in your capture.\n    let smudgeThreshold: Float = 0.9;\n    let request = DetectLensSmudgeRequest(.revision1)\n    let smudgeObservation = try await request.perform(on: imageURL)\n    \n    return (smudgeObservation.confidence < smudgeThreshold)\n}",
      "language" : "swift"
    }
  ],
  "conformsTo" : [
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "ImageProcessingRequest",
    "Sendable",
    "SendableMetatype",
    "VisionRequest"
  ],
  "contentHash" : "bd2fe9f5ebcd63d5b6083374497786a54bfdf725d006ece2de126308be2ea0c6",
  "crawledAt" : "2025-12-03T19:14:08Z",
  "declaration" : {
    "code" : "struct DetectLensSmudgeRequest",
    "language" : "swift"
  },
  "id" : "41FE95F6-C98E-4D1F-B23D-E0798CA6D5E2",
  "kind" : "struct",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nUse this request to detect whether an image or video is captured with a smudged lens. A smudge is anything that obscures a lens, like a fingerprint or raindrops, resulting in a hazy or blurry capture. Use this capability to find the best frame from a video or set of images.\n\nPerform this request when detecting a smudge within an image or video frame. The request returns a [doc:\/\/Vision\/documentation\/Vision\/SmudgeObservation]. This observation contains a floating-point [doc:\/\/Vision\/documentation\/Vision\/SmudgeObservation\/confidence] value in the range of  `0.0` to `1.0` indicating the probability that a capture has an impaired or smudged lens at capture time. A score of `1.0` represents a high probability the lens is smudged at capture time.\n\nRunning [doc:\/\/Vision\/documentation\/Vision\/DetectLensSmudgeRequest] requires a device with A14 Bionic and later or device with M1 and later.\n\nTo use the properties of the request, add a [doc:\/\/Vision\/documentation\/Vision\/ImageProcessingRequest] to your chosen capture type.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/detectlenssmudgerequest\ncrawled: 2025-12-03T19:14:08Z\n---\n\n# DetectLensSmudgeRequest\n\n**Structure**\n\nA request that detects a smudge on a lens from an image or video frame capture.\n\n## Declaration\n\n```swift\nstruct DetectLensSmudgeRequest\n```\n\n## Overview\n\nUse this request to detect whether an image or video is captured with a smudged lens. A smudge is anything that obscures a lens, like a fingerprint or raindrops, resulting in a hazy or blurry capture. Use this capability to find the best frame from a video or set of images.\n\n\n\nPerform this request when detecting a smudge within an image or video frame. The request returns a [doc:\/\/Vision\/documentation\/Vision\/SmudgeObservation]. This observation contains a floating-point [doc:\/\/Vision\/documentation\/Vision\/SmudgeObservation\/confidence] value in the range of  `0.0` to `1.0` indicating the probability that a capture has an impaired or smudged lens at capture time. A score of `1.0` represents a high probability the lens is smudged at capture time.\n\nRunning [doc:\/\/Vision\/documentation\/Vision\/DetectLensSmudgeRequest] requires a device with A14 Bionic and later or device with M1 and later.\n\n\n\nTo use the properties of the request, add a [doc:\/\/Vision\/documentation\/Vision\/ImageProcessingRequest] to your chosen capture type.\n\n```swift\nfunc isGoodCapture(imageURL:URL) async throws -> Bool {\n   \n   \/\/ Set an optional threshold from 0.0 to 1.0 to flag a maximum level of smudge in your capture.\n    let smudgeThreshold: Float = 0.9;\n    let request = DetectLensSmudgeRequest(.revision1)\n    let smudgeObservation = try await request.perform(on: imageURL)\n    \n    return (smudgeObservation.confidence < smudgeThreshold)\n}\n```\n\n## Creating a request\n\n- **init(_:)**: Creates a request to detect whether the camera lens has a smudge.\n\n## Performing a request\n\n- **perform(on:orientation:)**: Performs the request on an image URL and produces observations.\n- **perform(on:orientation:)**: Performs the request on image data and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Graphics image and produces observations.\n- **perform(on:orientation:)**: Performs the request on a pixel buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Media buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Image image and produces observations.\n\n## Understanding the result\n\n- **SmudgeObservation**: An observation that provides an overall score of the presence of a smudge in an image or video frame capture.\n\n## Configuring a request\n\n- **cropAndScaleAction**: An optional setting that tells the algorithm how to scale an input image before generating the result.\n- **ImageCropAndScaleAction**: A scale to apply to an input image before performing a request.\n\n## Getting the revision\n\n- **revision**: The algorithm or implementation the request uses.\n- **supportedRevisions**: The collection of revisions the request supports.\n- **DetectLensSmudgeRequest.Revision**: A type that describes the algorithm or implementation that the request performs.\n\n## Image quality and saliency analysis\n\n- **Generating high-quality thumbnails from videos**: Identify the most visually pleasing frames in a video by using the image-aesthetics scores request.\n- **CalculateImageAestheticsScoresRequest**: A request that analyzes an image for aesthetically pleasing attributes.\n- **GenerateAttentionBasedSaliencyImageRequest**: An object that produces a heat map that identifies the parts of an image most likely to draw attention.\n- **GenerateObjectnessBasedSaliencyImageRequest**: A request that generates a heat map that identifies the parts of an image most likely to represent objects.\n\n## Conforms To\n\n- CustomStringConvertible\n- Equatable\n- Hashable\n- ImageProcessingRequest\n- Sendable\n- SendableMetatype\n- VisionRequest\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a request to detect whether the camera lens has a smudge.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectLensSmudgeRequest\/init(_:)"
        }
      ],
      "title" : "Creating a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Performs the request on an image URL and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-80bya"
        },
        {
          "description" : "Performs the request on image data and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3f3f1"
        },
        {
          "description" : "Performs the request on a Core Graphics image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-qxxx"
        },
        {
          "description" : "Performs the request on a pixel buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-xspx"
        },
        {
          "description" : "Performs the request on a Core Media buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3hddl"
        },
        {
          "description" : "Performs the request on a Core Image image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-85ex1"
        }
      ],
      "title" : "Performing a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An observation that provides an overall score of the presence of a smudge in an image or video frame capture.",
          "name" : "SmudgeObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/SmudgeObservation"
        }
      ],
      "title" : "Understanding the result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An optional setting that tells the algorithm how to scale an input image before generating the result.",
          "name" : "cropAndScaleAction",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectLensSmudgeRequest\/cropAndScaleAction"
        },
        {
          "description" : "A scale to apply to an input image before performing a request.",
          "name" : "ImageCropAndScaleAction",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageCropAndScaleAction"
        }
      ],
      "title" : "Configuring a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The algorithm or implementation the request uses.",
          "name" : "revision",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectLensSmudgeRequest\/revision-swift.property"
        },
        {
          "description" : "The collection of revisions the request supports.",
          "name" : "supportedRevisions",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectLensSmudgeRequest\/supportedRevisions"
        },
        {
          "description" : "A type that describes the algorithm or implementation that the request performs.",
          "name" : "DetectLensSmudgeRequest.Revision",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectLensSmudgeRequest\/Revision-swift.enum"
        }
      ],
      "title" : "Getting the revision"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Identify the most visually pleasing frames in a video by using the image-aesthetics scores request.",
          "name" : "Generating high-quality thumbnails from videos",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/generating-thumbnails-from-videos"
        },
        {
          "description" : "A request that analyzes an image for aesthetically pleasing attributes.",
          "name" : "CalculateImageAestheticsScoresRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CalculateImageAestheticsScoresRequest"
        },
        {
          "description" : "An object that produces a heat map that identifies the parts of an image most likely to draw attention.",
          "name" : "GenerateAttentionBasedSaliencyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateAttentionBasedSaliencyImageRequest"
        },
        {
          "description" : "A request that generates a heat map that identifies the parts of an image most likely to represent objects.",
          "name" : "GenerateObjectnessBasedSaliencyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateObjectnessBasedSaliencyImageRequest"
        }
      ],
      "title" : "Image quality and saliency analysis"
    }
  ],
  "source" : "appleJSON",
  "title" : "DetectLensSmudgeRequest",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/detectlenssmudgerequest"
}