{
  "abstract" : "A request that generates a heat map that identifies the parts of an image most likely to represent objects.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol"
  ],
  "contentHash" : "d129b8ff1488101825eda81a1d7769d201aeb3ba135be89f56c024465e21073d",
  "crawledAt" : "2025-12-04T02:34:17Z",
  "declaration" : {
    "code" : "class VNGenerateObjectnessBasedSaliencyImageRequest",
    "language" : "swift"
  },
  "id" : "49DD43B4-0303-4BE4-9609-92F68BFBFF35",
  "kind" : "class",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nThe resulting observation, [doc:\/\/Vision\/documentation\/Vision\/VNSaliencyImageObservation], encodes this data as a heat map, which you can use to highlight regions of interest.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/vngenerateobjectnessbasedsaliencyimagerequest\ncrawled: 2025-12-04T02:34:17Z\n---\n\n# VNGenerateObjectnessBasedSaliencyImageRequest\n\n**Class**\n\nA request that generates a heat map that identifies the parts of an image most likely to represent objects.\n\n## Declaration\n\n```swift\nclass VNGenerateObjectnessBasedSaliencyImageRequest\n```\n\n## Overview\n\nThe resulting observation, [doc:\/\/Vision\/documentation\/Vision\/VNSaliencyImageObservation], encodes this data as a heat map, which you can use to highlight regions of interest.\n\n## Accessing the Results\n\n- **results**: The results of the image saliency request.\n\n## Identifying Request Revisions\n\n- **VNGenerateObjectnessBasedSaliencyImageRequestRevision1**: A constant for specifying revision 1 of the image saliency request.\n\n## Saliency analysis\n\n- **Cropping Images Using Saliency**: Isolate regions in an image that are most likely to draw people’s attention.\n- **Highlighting Areas of Interest in an Image Using Saliency**: Quantify and visualize where people are likely to look in an image.\n- **VNGenerateAttentionBasedSaliencyImageRequest**: An object that produces a heat map that identifies the parts of an image most likely to draw attention.\n- **VNSaliencyImageObservation**: An observation that contains a grayscale heat map of important areas across an image.\n\n## Inherits From\n\n- VNImageBasedRequest\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "The results of the image saliency request.",
          "name" : "results",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGenerateObjectnessBasedSaliencyImageRequest\/results"
        }
      ],
      "title" : "Accessing the Results"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A constant for specifying revision 1 of the image saliency request.",
          "name" : "VNGenerateObjectnessBasedSaliencyImageRequestRevision1",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGenerateObjectnessBasedSaliencyImageRequestRevision1"
        }
      ],
      "title" : "Identifying Request Revisions"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Isolate regions in an image that are most likely to draw people’s attention.",
          "name" : "Cropping Images Using Saliency",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/cropping-images-using-saliency"
        },
        {
          "description" : "Quantify and visualize where people are likely to look in an image.",
          "name" : "Highlighting Areas of Interest in an Image Using Saliency",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/highlighting-areas-of-interest-in-an-image-using-saliency"
        },
        {
          "description" : "An object that produces a heat map that identifies the parts of an image most likely to draw attention.",
          "name" : "VNGenerateAttentionBasedSaliencyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNGenerateAttentionBasedSaliencyImageRequest"
        },
        {
          "description" : "An observation that contains a grayscale heat map of important areas across an image.",
          "name" : "VNSaliencyImageObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNSaliencyImageObservation"
        }
      ],
      "title" : "Saliency analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "VNImageBasedRequest"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "VNGenerateObjectnessBasedSaliencyImageRequest",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/vngenerateobjectnessbasedsaliencyimagerequest"
}