{
  "abstract" : "Creates a model container to use with an image analysis request based on the model you provide.",
  "codeExamples" : [

  ],
  "contentHash" : "2bb498a79e095c319cd73879046d65dc2af8c6b8cd86997a48ff34d77c47d17b",
  "crawledAt" : "2025-12-02T21:21:43Z",
  "declaration" : {
    "code" : "convenience init(model: VNCoreMLModel)",
    "language" : "swift"
  },
  "id" : "1F4CBEA5-3DB2-44EA-A890-355275EB681F",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Discussion\n\nInitialization can fail if the [doc:\/\/com.apple.documentation\/documentation\/CoreML] model you provide isn’t supported in Vision, such as if the model doesn’t accept an image as input.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:)\ncrawled: 2025-12-02T21:21:43Z\n---\n\n# init(model:)\n\n**Initializer**\n\nCreates a model container to use with an image analysis request based on the model you provide.\n\n## Declaration\n\n```swift\nconvenience init(model: VNCoreMLModel)\n```\n\n## Parameters\n\n- **model**: The [doc:\/\/com.apple.documentation\/documentation\/CoreML] model on which to base the Vision request.\n\n## Discussion\n\nInitialization can fail if the [doc:\/\/com.apple.documentation\/documentation\/CoreML] model you provide isn’t supported in Vision, such as if the model doesn’t accept an image as input.\n\n## Initializing with a Core ML Model\n\n- **init(model:completionHandler:)**: Creates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.\n- **model**: The model to base the image analysis request on.\n- **VNCoreMLModel**: A container for the model to use with Vision requests.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.",
          "name" : "init(model:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:completionHandler:)"
        },
        {
          "description" : "The model to base the image analysis request on.",
          "name" : "model",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/model"
        },
        {
          "description" : "A container for the model to use with Vision requests.",
          "name" : "VNCoreMLModel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLModel"
        }
      ],
      "title" : "Initializing with a Core ML Model"
    }
  ],
  "source" : "appleJSON",
  "title" : "init(model:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:)"
}