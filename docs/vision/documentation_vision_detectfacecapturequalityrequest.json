{
  "abstract" : "A request that produces a floating-point number that represents the capture quality of a face in a photo.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "ImageProcessingRequest",
    "Sendable",
    "SendableMetatype",
    "VisionRequest"
  ],
  "contentHash" : "8cf7458eca248a27e51832344a0208abef8eb37a9b70f10a43358b6e556e759d",
  "crawledAt" : "2025-12-02T16:20:20Z",
  "declaration" : {
    "code" : "struct DetectFaceCaptureQualityRequest",
    "language" : "swift"
  },
  "id" : "71C47735-0144-4095-BF5D-C2CC481ACA45",
  "kind" : "struct",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nThis request produces a collection of [doc:\/\/Vision\/documentation\/Vision\/FaceObservation] objects with the property `FaceObservation\/faceCaptureQuality` set to a value ranging from `0` to `1`. Faces with quality closer to `1` are better lit, sharper, and more centrally positioned than faces with quality closer to `0`.\n\nIf you don’t execute the request, or the request fails, the property `FaceObservation\/faceCaptureQuality` is `nil`.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest\ncrawled: 2025-12-02T16:20:20Z\n---\n\n# DetectFaceCaptureQualityRequest\n\n**Structure**\n\nA request that produces a floating-point number that represents the capture quality of a face in a photo.\n\n## Declaration\n\n```swift\nstruct DetectFaceCaptureQualityRequest\n```\n\n## Overview\n\nThis request produces a collection of [doc:\/\/Vision\/documentation\/Vision\/FaceObservation] objects with the property `FaceObservation\/faceCaptureQuality` set to a value ranging from `0` to `1`. Faces with quality closer to `1` are better lit, sharper, and more centrally positioned than faces with quality closer to `0`.\n\nIf you don’t execute the request, or the request fails, the property `FaceObservation\/faceCaptureQuality` is `nil`.\n\n## Creating a request\n\n- **init(_:)**: Creates a face capture quality request.\n\n## Getting the revision\n\n- **revision**: The algorithm or implementation the request uses.\n- **supportedRevisions**: The collection of revisions the request supports.\n- **DetectFaceCaptureQualityRequest.Revision**: A type that describes the algorithm or implementation that the request performs.\n\n## Inspecting a request\n\n- **inputFaceObservations**: An array of face-observation objects to process as part of the request.\n\n## Performing a request\n\n- **perform(on:orientation:)**: Performs the request on an image URL and produces observations.\n- **perform(on:orientation:)**: Performs the request on image data and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Graphics image and produces observations.\n- **perform(on:orientation:)**: Performs the request on a pixel buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Media buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Image image and produces observations.\n- **FaceObservation**: An image-analysis request that identifies facial features in an image.\n\n## Face and body detection\n\n- **Analyzing a selfie and visualizing its content**: Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.\n- **DetectFaceRectanglesRequest**: A request that finds faces within an image.\n- **DetectFaceLandmarksRequest**: An image-analysis request that finds facial features like eyes and mouth in an image.\n- **DetectHumanRectanglesRequest**: A request that finds rectangular regions that contain people in an image.\n\n## Conforms To\n\n- CustomStringConvertible\n- Equatable\n- Hashable\n- ImageProcessingRequest\n- Sendable\n- SendableMetatype\n- VisionRequest\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a face capture quality request.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest\/init(_:)"
        }
      ],
      "title" : "Creating a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The algorithm or implementation the request uses.",
          "name" : "revision",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest\/revision-swift.property"
        },
        {
          "description" : "The collection of revisions the request supports.",
          "name" : "supportedRevisions",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest\/supportedRevisions"
        },
        {
          "description" : "A type that describes the algorithm or implementation that the request performs.",
          "name" : "DetectFaceCaptureQualityRequest.Revision",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest\/Revision-swift.enum"
        }
      ],
      "title" : "Getting the revision"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An array of face-observation objects to process as part of the request.",
          "name" : "inputFaceObservations",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest\/inputFaceObservations"
        }
      ],
      "title" : "Inspecting a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Performs the request on an image URL and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-80bya"
        },
        {
          "description" : "Performs the request on image data and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3f3f1"
        },
        {
          "description" : "Performs the request on a Core Graphics image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-qxxx"
        },
        {
          "description" : "Performs the request on a pixel buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-xspx"
        },
        {
          "description" : "Performs the request on a Core Media buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3hddl"
        },
        {
          "description" : "Performs the request on a Core Image image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-85ex1"
        },
        {
          "description" : "An image-analysis request that identifies facial features in an image.",
          "name" : "FaceObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/FaceObservation"
        }
      ],
      "title" : "Performing a request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.",
          "name" : "Analyzing a selfie and visualizing its content",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/analyzing-a-selfie-and-visualizing-its-content"
        },
        {
          "description" : "A request that finds faces within an image.",
          "name" : "DetectFaceRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceRectanglesRequest"
        },
        {
          "description" : "An image-analysis request that finds facial features like eyes and mouth in an image.",
          "name" : "DetectFaceLandmarksRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceLandmarksRequest"
        },
        {
          "description" : "A request that finds rectangular regions that contain people in an image.",
          "name" : "DetectHumanRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanRectanglesRequest"
        }
      ],
      "title" : "Face and body detection"
    }
  ],
  "source" : "appleJSON",
  "title" : "DetectFaceCaptureQualityRequest",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest"
}