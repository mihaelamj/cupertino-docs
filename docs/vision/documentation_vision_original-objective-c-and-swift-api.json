{
  "codeExamples" : [

  ],
  "contentHash" : "490bf3b9931ff82087349efa0526f20fc9732f9fc2f38f72bd2f8d06ca05368e",
  "crawledAt" : "2025-12-05T12:29:27Z",
  "id" : "1E73755C-484B-44E4-AA3F-064A21498625",
  "kind" : "protocol",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/original-objective-c-and-swift-api\ncrawled: 2025-12-05T12:29:27Z\n---\n\n# Original Objective-C and Swift API | Apple Developer Documentation\n\n- [ Vision ](\/documentation\/vision)\n\n- [ Original Objective-C and Swift API ](\/documentation\/vision\/original-objective-c-and-swift-api)\n\n-  Original Objective-C and Swift API \n\nAPI Collection# Original Objective-C and Swift API\n\n## [Topics](\/documentation\/vision\/original-objective-c-and-swift-api#topics)\n\n### [Essentials](\/documentation\/vision\/original-objective-c-and-swift-api#Essentials)\n\n[Building a feature-rich app for sports analysis](\/documentation\/vision\/building-a-feature-rich-app-for-sports-analysis)Detect and classify human activity in real time using computer vision and machine learning.### [Still-image analysis](\/documentation\/vision\/original-objective-c-and-swift-api#Still-image-analysis)\n\n[Detecting Objects in Still Images](\/documentation\/vision\/detecting-objects-in-still-images)Locate and demarcate rectangles, faces, barcodes, and text in images using the Vision framework.[Classifying images for categorization and search](\/documentation\/vision\/classifying-images-for-categorization-and-search)Analyze and label images using a Vision classification request.[Analyzing Image Similarity with Feature Print](\/documentation\/vision\/analyzing-image-similarity-with-feature-print)Generate a feature print to compute distance between images.[`class VNRequest`](\/documentation\/vision\/vnrequest)The abstract superclass for analysis requests.[`class VNImageBasedRequest`](\/documentation\/vision\/vnimagebasedrequest)The abstract superclass for image-analysis requests that focus on a specific part of an image.[`class VNClassifyImageRequest`](\/documentation\/vision\/vnclassifyimagerequest)A request to classify an image.[`class VNGenerateImageFeaturePrintRequest`](\/documentation\/vision\/vngenerateimagefeatureprintrequest)An image-based request to generate feature prints from an image.[`class VNFeaturePrintObservation`](\/documentation\/vision\/vnfeatureprintobservation)An observation that provides the recognized feature print.[`class VNImageRequestHandler`](\/documentation\/vision\/vnimagerequesthandler)An object that processes one or more image-analysis request pertaining to a single image.[`class VNObservation`](\/documentation\/vision\/vnobservation)The abstract superclass for analysis results.### [Image sequence analysis](\/documentation\/vision\/original-objective-c-and-swift-api#Image-sequence-analysis)\n\n[Applying Matte Effects to People in Images and Video](\/documentation\/vision\/applying-matte-effects-to-people-in-images-and-video)Generate image masks for people automatically by using semantic person-segmentation.[Detecting human actions in a live video feed](\/documentation\/CreateML\/detecting-human-actions-in-a-live-video-feed)Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.[Segmenting and colorizing individuals from a surrounding scene](\/documentation\/vision\/segmenting-and-colorizing-individuals-from-a-surrounding-scene)Use the Vision framework to isolate and apply colors to people in an image.[`class VNStatefulRequest`](\/documentation\/vision\/vnstatefulrequest)An abstract request type that builds evidence of a condition over time.[`class VNGeneratePersonSegmentationRequest`](\/documentation\/vision\/vngeneratepersonsegmentationrequest)An object that produces a matte image for a person it finds in the input image.[`class VNGeneratePersonInstanceMaskRequest`](\/documentation\/vision\/vngeneratepersoninstancemaskrequest)An object that produces a mask of individual people it finds in the input image.[`class VNDetectDocumentSegmentationRequest`](\/documentation\/vision\/vndetectdocumentsegmentationrequest)An object that detects rectangular regions that contain text in the input image.[`class VNSequenceRequestHandler`](\/documentation\/vision\/vnsequencerequesthandler)An object that processes image-analysis requests for each frame in a sequence.### [Image aesthetics analysis](\/documentation\/vision\/original-objective-c-and-swift-api#Image-aesthetics-analysis)\n\n[`class VNCalculateImageAestheticsScoresRequest`](\/documentation\/vision\/vncalculateimageaestheticsscoresrequest)An object that analyzes an image for aesthetically pleasing attributes.### [Saliency analysis](\/documentation\/vision\/original-objective-c-and-swift-api#Saliency-analysis)\n\n[Cropping Images Using Saliency](\/documentation\/vision\/cropping-images-using-saliency)Isolate regions in an image that are most likely to draw people’s attention.[Highlighting Areas of Interest in an Image Using Saliency](\/documentation\/vision\/highlighting-areas-of-interest-in-an-image-using-saliency)Quantify and visualize where people are likely to look in an image.[`class VNGenerateAttentionBasedSaliencyImageRequest`](\/documentation\/vision\/vngenerateattentionbasedsaliencyimagerequest)An object that produces a heat map that identifies the parts of an image most likely to draw attention.[`class VNGenerateObjectnessBasedSaliencyImageRequest`](\/documentation\/vision\/vngenerateobjectnessbasedsaliencyimagerequest)A request that generates a heat map that identifies the parts of an image most likely to represent objects.[`class VNSaliencyImageObservation`](\/documentation\/vision\/vnsaliencyimageobservation)An observation that contains a grayscale heat map of important areas across an image.### [Object tracking](\/documentation\/vision\/original-objective-c-and-swift-api#Object-tracking)\n\n[Tracking the User’s Face in Real Time](\/documentation\/vision\/tracking-the-user-s-face-in-real-time)Detect and track faces from the selfie cam feed in real time.[Tracking Multiple Objects or Rectangles in Video](\/documentation\/vision\/tracking-multiple-objects-or-rectangles-in-video)Apply Vision algorithms to track objects or rectangles throughout a video.[`class VNTrackingRequest`](\/documentation\/vision\/vntrackingrequest)The abstract superclass for image-analysis requests that track unique features across multiple images or video frames.[`class VNTrackRectangleRequest`](\/documentation\/vision\/vntrackrectanglerequest)An image-analysis request that tracks movement of a previously identified rectangular object across multiple images or video frames.[`class VNTrackObjectRequest`](\/documentation\/vision\/vntrackobjectrequest)An image-analysis request that tracks the movement of a previously identified object across multiple images or video frames.[`class VNDetectedObjectObservation`](\/documentation\/vision\/vndetectedobjectobservation)An observation that provides the position and extent of an image feature that an image- analysis request detects.### [Rectangle detection](\/documentation\/vision\/original-objective-c-and-swift-api#Rectangle-detection)\n\n[`class VNDetectRectanglesRequest`](\/documentation\/vision\/vndetectrectanglesrequest)An image-analysis request that finds projected rectangular regions in an image.### [Face and body detection](\/documentation\/vision\/original-objective-c-and-swift-api#Face-and-body-detection)\n\n[Selecting a selfie based on capture quality](\/documentation\/vision\/selecting-a-selfie-based-on-capture-quality)Compare face-capture quality in a set of images by using Vision.[`class VNDetectFaceCaptureQualityRequest`](\/documentation\/vision\/vndetectfacecapturequalityrequest)A request that produces a floating-point number that represents the capture quality of a face in a photo.[`class VNDetectFaceLandmarksRequest`](\/documentation\/vision\/vndetectfacelandmarksrequest)An image-analysis request that finds facial features like eyes and mouth in an image.[`class VNDetectFaceRectanglesRequest`](\/documentation\/vision\/vndetectfacerectanglesrequest)A request that finds faces within an image.[`class VNDetectHumanRectanglesRequest`](\/documentation\/vision\/vndetecthumanrectanglesrequest)A request that finds rectangular regions that contain people in an image.[`class VNHumanObservation`](\/documentation\/vision\/vnhumanobservation)An object that represents a person that the request detects.### [Body and hand pose detection](\/documentation\/vision\/original-objective-c-and-swift-api#Body-and-hand-pose-detection)\n\n[Detecting Human Body Poses in Images](\/documentation\/vision\/detecting-human-body-poses-in-images)Add the capability to detect human body poses to your app using the Vision framework.[Detecting Hand Poses with Vision](\/documentation\/vision\/detecting-hand-poses-with-vision)Create a virtual drawing app by using Vision’s capability to detect hand poses.[`class VNDetectHumanBodyPoseRequest`](\/documentation\/vision\/vndetecthumanbodyposerequest)A request that detects a human body pose.[`class VNDetectHumanHandPoseRequest`](\/documentation\/vision\/vndetecthumanhandposerequest)A request that detects a human hand pose.[`class VNRecognizedPointsObservation`](\/documentation\/vision\/vnrecognizedpointsobservation)An observation that provides the points the analysis recognized.[`class VNHumanBodyPoseObservation`](\/documentation\/vision\/vnhumanbodyposeobservation)An observation that provides the body points the analysis recognized.[`class VNHumanHandPoseObservation`](\/documentation\/vision\/vnhumanhandposeobservation)An observation that provides the hand points the analysis recognized.[`class VNPoint`](\/documentation\/vision\/vnpoint)An immutable object that represents a single 2D point in an image.[`class VNDetectedPoint`](\/documentation\/vision\/vndetectedpoint)An object that represents a normalized point in an image, along with a confidence value.[`class VNRecognizedPoint`](\/documentation\/vision\/vnrecognizedpoint)An object that represents a normalized point in an image, along with an identifier label and a confidence value.[`struct VNRecognizedPointKey`](\/documentation\/vision\/vnrecognizedpointkey)The data type for all recognized point keys.[`struct VNRecognizedPointGroupKey`](\/documentation\/vision\/vnrecognizedpointgroupkey)The data type for all recognized-point group keys.### [3D body pose detection](\/documentation\/vision\/original-objective-c-and-swift-api#3D-body-pose-detection)\n\n[Identifying 3D human body poses in images](\/documentation\/vision\/identifying-3d-human-body-poses-in-images)Detect three-dimensional human body poses using the Vision framework.[Detecting human body poses in 3D with Vision](\/documentation\/vision\/detecting-human-body-poses-in-3d-with-vision)Render skeletons of 3D body pose points in a scene overlaying the input image.[`class VNDetectHumanBodyPose3DRequest`](\/documentation\/vision\/vndetecthumanbodypose3drequest)A request that detects points on human bodies in 3D space, relative to the camera.[`class VNHumanBodyPose3DObservation`](\/documentation\/vision\/vnhumanbodypose3dobservation)An observation that provides the 3D body points the request recognizes.[`class VNRecognizedPoints3DObservation`](\/documentation\/vision\/vnrecognizedpoints3dobservation)An observation that provides the 3D points for a request.[`class VNHumanBodyRecognizedPoint3D`](\/documentation\/vision\/vnhumanbodyrecognizedpoint3d)A recognized 3D point that includes a parent joint.[`class VNPoint3D`](\/documentation\/vision\/vnpoint3d)An object that represents a 3D point in an image.[`class VNRecognizedPoint3D`](\/documentation\/vision\/vnrecognizedpoint3d)A 3D point that includes an identifier to the point.[`struct JointName`](\/documentation\/vision\/vnhumanbodypose3dobservation\/jointname)The joint names for a 3D body pose.[`struct JointsGroupName`](\/documentation\/vision\/vnhumanbodypose3dobservation\/jointsgroupname)The joint group names for a 3D body pose.### [Animal detection](\/documentation\/vision\/original-objective-c-and-swift-api#Animal-detection)\n\n[`class VNRecognizeAnimalsRequest`](\/documentation\/vision\/vnrecognizeanimalsrequest)A request that recognizes animals in an image.### [Animal body pose detection](\/documentation\/vision\/original-objective-c-and-swift-api#Animal-body-pose-detection)\n\n[Detecting animal body poses with Vision](\/documentation\/vision\/detecting-animal-body-poses-with-vision)Draw the skeleton of an animal by using Vision’s capability to detect animal body poses.[`class VNDetectAnimalBodyPoseRequest`](\/documentation\/vision\/vndetectanimalbodyposerequest)A request that detects an animal body pose.[`class VNAnimalBodyPoseObservation`](\/documentation\/vision\/vnanimalbodyposeobservation)An observation that provides the animal body points the analysis recognizes.### [Trajectory detection](\/documentation\/vision\/original-objective-c-and-swift-api#Trajectory-detection)\n\n[Identifying Trajectories in Video](\/documentation\/vision\/identifying-trajectories-in-video)Gain new insights into your video data by using Vision to detect trajectories.[Detecting moving objects in a video](\/documentation\/vision\/detecting-moving-objects-in-a-video)Identify the trajectory of a thrown object by using Vision.[`class VNDetectTrajectoriesRequest`](\/documentation\/vision\/vndetecttrajectoriesrequest)A request that detects the trajectories of shapes moving along a parabolic path.### [Contour detection](\/documentation\/vision\/original-objective-c-and-swift-api#Contour-detection)\n\n[`class VNDetectContoursRequest`](\/documentation\/vision\/vndetectcontoursrequest)A request that detects the contours of the edges of an image.### [Optical flow](\/documentation\/vision\/original-objective-c-and-swift-api#Optical-flow)\n\n[`class VNGenerateOpticalFlowRequest`](\/documentation\/vision\/vngenerateopticalflowrequest)An object that generates directional change vectors for each pixel in the targeted image.[`class VNTrackOpticalFlowRequest`](\/documentation\/vision\/vntrackopticalflowrequest)An object that determines the direction change of vectors for each pixel from a previous to current image.### [Barcode detection](\/documentation\/vision\/original-objective-c-and-swift-api#Barcode-detection)\n\n[`class VNDetectBarcodesRequest`](\/documentation\/vision\/vndetectbarcodesrequest)A request that detects barcodes in an image.[`enum VNBarcodeCompositeType`](\/documentation\/vision\/vnbarcodecompositetype)Composite types for barcode requests.### [Text detection](\/documentation\/vision\/original-objective-c-and-swift-api#Text-detection)\n\n[`class VNDetectTextRectanglesRequest`](\/documentation\/vision\/vndetecttextrectanglesrequest)An image-analysis request that finds regions of visible text in an image.[`class VNTextObservation`](\/documentation\/vision\/vntextobservation)Information about regions of text that an image-analysis request detects.### [Text recognition](\/documentation\/vision\/original-objective-c-and-swift-api#Text-recognition)\n\n[Recognizing Text in Images](\/documentation\/vision\/recognizing-text-in-images)Add text-recognition features to your app using the Vision framework.[Structuring Recognized Text on a Document](\/documentation\/visionkit\/structuring_recognized_text_on_a_document)Detect, recognize, and structure text on a business card or receipt using Vision and VisionKit.[Extracting phone numbers from text in images](\/documentation\/vision\/extracting-phone-numbers-from-text-in-images)Analyze and filter phone numbers from text in live capture by using Vision.[Locating and displaying recognized text](\/documentation\/vision\/locating-and-displaying-recognized-text)Perform text recognition on a photo using the Vision framework’s text-recognition request.[`class VNRecognizeTextRequest`](\/documentation\/vision\/vnrecognizetextrequest)An image-analysis request that finds and recognizes text in an image.[`class VNRecognizedTextObservation`](\/documentation\/vision\/vnrecognizedtextobservation)A request that detects and recognizes regions of text in an image.### [Object recognition](\/documentation\/vision\/original-objective-c-and-swift-api#Object-recognition)\n\n[Recognizing Objects in Live Capture](\/documentation\/vision\/recognizing-objects-in-live-capture)Apply Vision algorithms to identify objects in real-time video.[Understanding a Dice Roll with Vision and Object Detection](\/documentation\/CoreML\/understanding-a-dice-roll-with-vision-and-object-detection)Detect dice position and values shown in a camera frame, and determine the end of a roll by leveraging a dice detection model.[`class VNRecognizedObjectObservation`](\/documentation\/vision\/vnrecognizedobjectobservation)A detected object observation with an array of classification labels that classify the recognized object.### [Request progress tracking](\/documentation\/vision\/original-objective-c-and-swift-api#Request-progress-tracking)\n\n[`protocol VNRequestProgressProviding`](\/documentation\/vision\/vnrequestprogressproviding)A protocol for providing progress information on long-running tasks in Vision.[`typealias VNRequestProgressHandler`](\/documentation\/vision\/vnrequestprogresshandler)A block executed at intervals during the processing of a Vision request.### [Horizon detection](\/documentation\/vision\/original-objective-c-and-swift-api#Horizon-detection)\n\n[`class VNDetectHorizonRequest`](\/documentation\/vision\/vndetecthorizonrequest)An image-analysis request that determines the horizon angle in an image.[`class VNHorizonObservation`](\/documentation\/vision\/vnhorizonobservation)The horizon angle information that an image-analysis request detects.### [Image alignment](\/documentation\/vision\/original-objective-c-and-swift-api#Image-alignment)\n\n[Aligning Similar Images](\/documentation\/vision\/aligning-similar-images)Construct a composite image from images that capture the same scene.[`class VNTargetedImageRequest`](\/documentation\/vision\/vntargetedimagerequest)The abstract superclass for image analysis requests that operate on both the processed image and a secondary image.[`class VNImageRegistrationRequest`](\/documentation\/vision\/vnimageregistrationrequest)The abstract superclass for image-analysis requests that align images according to their content.[`class VNTranslationalImageRegistrationRequest`](\/documentation\/vision\/vntranslationalimageregistrationrequest)An image-analysis request that determines the affine transform necessary to align the content of two images.[`class VNTrackTranslationalImageRegistrationRequest`](\/documentation\/vision\/vntracktranslationalimageregistrationrequest)An image-analysis request, as a stateful request you track over time, that determines the affine transform necessary to align the content of two images.[`class VNHomographicImageRegistrationRequest`](\/documentation\/vision\/vnhomographicimageregistrationrequest)An image-analysis request that determines the perspective warp matrix necessary to align the content of two images.[`class VNTrackHomographicImageRegistrationRequest`](\/documentation\/vision\/vntrackhomographicimageregistrationrequest)An image-analysis request, as a stateful request you track over time, that determines the perspective warp matrix necessary to align the content of two images.[`class VNImageAlignmentObservation`](\/documentation\/vision\/vnimagealignmentobservation)The abstract superclass for image-analysis results that describe the relative alignment of two images.[`class VNImageTranslationAlignmentObservation`](\/documentation\/vision\/vnimagetranslationalignmentobservation)Affine transform information that an image-alignment request produces.[`class VNImageHomographicAlignmentObservation`](\/documentation\/vision\/vnimagehomographicalignmentobservation)An object that represents a perspective warp transformation.### [Image background removal](\/documentation\/vision\/original-objective-c-and-swift-api#Image-background-removal)\n\n[Applying visual effects to foreground subjects](\/documentation\/vision\/applying-visual-effects-to-foreground-subjects)Segment the foreground subjects of an image and composite them to a new background with visual effects.[`class VNInstanceMaskObservation`](\/documentation\/vision\/vninstancemaskobservation)An observation that contains an instance mask that labels instances in the mask.[`class VNGenerateForegroundInstanceMaskRequest`](\/documentation\/vision\/vngenerateforegroundinstancemaskrequest)A request that generates an instance mask of noticable objects to separate from the background.[`let VNGenerateForegroundInstanceMaskRequestRevision1: Int`](\/documentation\/vision\/vngenerateforegroundinstancemaskrequestrevision1)A constant for specifying the first revision of the foreground instance mask request.### [Machine learning image analysis](\/documentation\/vision\/original-objective-c-and-swift-api#Machine-learning-image-analysis)\n\n[Classifying Images with Vision and Core ML](\/documentation\/CoreML\/classifying-images-with-vision-and-core-ml)Crop and scale photos using the Vision framework and classify them with a Core ML model.[Training a Create ML Model to Classify Flowers](\/documentation\/vision\/training-a-create-ml-model-to-classify-flowers)Train a flower classifier using Create ML in Swift Playgrounds, and apply the resulting model to real-time image classification using Vision.[`class VNCoreMLRequest`](\/documentation\/vision\/vncoremlrequest)An image-analysis request that uses a Core ML model to process images.[`class VNClassificationObservation`](\/documentation\/vision\/vnclassificationobservation)An object that represents classification information that an image-analysis request produces.[`class VNPixelBufferObservation`](\/documentation\/vision\/vnpixelbufferobservation)An object that represents an image that an image-analysis request produces.[`class VNCoreMLFeatureValueObservation`](\/documentation\/vision\/vncoremlfeaturevalueobservation)An object that represents a collection of key-value information that a Core ML image-analysis request produces.### [Coordinate conversion](\/documentation\/vision\/original-objective-c-and-swift-api#Coordinate-conversion)\n\n[`func VNImagePointForNormalizedPoint(CGPoint, Int, Int) -> CGPoint`](\/documentation\/vision\/vnimagepointfornormalizedpoint(_:_:_:))Projects a point in normalized coordinates into image coordinates.[`func VNNormalizedPointForImagePoint(CGPoint, Int, Int) -> CGPoint`](\/documentation\/vision\/vnnormalizedpointforimagepoint(_:_:_:))Projects a point from image coordinates into normalized coordinates.[`func VNImagePointForNormalizedPointUsingRegionOfInterest(CGPoint, Int, Int, CGRect) -> CGPoint`](\/documentation\/vision\/vnimagepointfornormalizedpointusingregionofinterest(_:_:_:_:))Projects a point from a region of interest within the normalized coordinates into image coordinates.[`func VNNormalizedPointForImagePointUsingRegionOfInterest(CGPoint, Int, Int, CGRect) -> CGPoint`](\/documentation\/vision\/vnnormalizedpointforimagepointusingregionofinterest(_:_:_:_:))Projects a point from a region of interest within the image coordinates into normalized coordinates.[`func VNImageRectForNormalizedRect(CGRect, Int, Int) -> CGRect`](\/documentation\/vision\/vnimagerectfornormalizedrect(_:_:_:))Projects a rectangle from normalized coordinates into image coordinates.[`func VNNormalizedRectForImageRect(CGRect, Int, Int) -> CGRect`](\/documentation\/vision\/vnnormalizedrectforimagerect(_:_:_:))Projects a rectangle from image coordinates into normalized coordinates.[`func VNImageRectForNormalizedRectUsingRegionOfInterest(CGRect, Int, Int, CGRect) -> CGRect`](\/documentation\/vision\/vnimagerectfornormalizedrectusingregionofinterest(_:_:_:_:))Projects a rectangle from a region of interest within the normalized coordinates into image coordinates.[`func VNNormalizedRectForImageRectUsingRegionOfInterest(CGRect, Int, Int, CGRect) -> CGRect`](\/documentation\/vision\/vnnormalizedrectforimagerectusingregionofinterest(_:_:_:_:))Projects a rectangle from a region of interest within the image coordinates space into normalized coordinates.[`let VNNormalizedIdentityRect: CGRect`](\/documentation\/vision\/vnnormalizedidentityrect)A normalized identity rectangle with an origin of zero and unit length and width.[`func VNNormalizedRectIsIdentityRect(CGRect) -> Bool`](\/documentation\/vision\/vnnormalizedrectisidentityrect(_:))Returns a Boolean value that indicates whether the rectangle has an origin of zero and unit length and width.[`func VNImagePointForFaceLandmarkPoint(vector_float2, CGRect, Int, Int) -> CGPoint`](\/documentation\/vision\/vnimagepointforfacelandmarkpoint(_:_:_:_:))Returns the image coordinates of a specified face landmark point.[`func VNNormalizedFaceBoundingBoxPointForLandmarkPoint(vector_float2, CGRect, Int, Int) -> CGPoint`](\/documentation\/vision\/vnnormalizedfaceboundingboxpointforlandmarkpoint(_:_:_:_:))Returns the coordinates of a specified face landmark point, in bounding box coordinates.### [Utilities](\/documentation\/vision\/original-objective-c-and-swift-api#Utilities)\n\n[`struct VNComputeStage`](\/documentation\/vision\/vncomputestage)Types that represent the compute stage.[`class VNGeometryUtils`](\/documentation\/vision\/vngeometryutils)Utility methods to determine the geometries of various Vision types.[`class VNVideoProcessor`](\/documentation\/vision\/vnvideoprocessor)An object that performs offline analysis of video content.[`struct VNVideoProcessingOption`](\/documentation\/vision\/vnvideoprocessingoption)Options to pass to the video processor when adding requests.Deprecated### [Common data types](\/documentation\/vision\/original-objective-c-and-swift-api#Common-data-types)\n\n[`class VNCircle`](\/documentation\/vision\/vncircle)An immutable 2D circle represented by its center point and radius.[`class VNVector`](\/documentation\/vision\/vnvector)An immutable 2D vector represented by its x-axis and y-axis projections.### [Errors](\/documentation\/vision\/original-objective-c-and-swift-api#Errors)\n\n[`let VNErrorDomain: String`](\/documentation\/vision\/vnerrordomain)The domain of errors that the framework generates.[`enum VNErrorCode`](\/documentation\/vision\/vnerrorcode)Constants that identify errors from the framework.### [Version and revision numbers](\/documentation\/vision\/original-objective-c-and-swift-api#Version-and-revision-numbers)\n\n[`var VNVisionVersionNumber: Double`](\/documentation\/vision\/vnvisionversionnumber)The current version number of the Vision framework.[`let VNDetectAnimalBodyPoseRequestRevision1: Int`](\/documentation\/vision\/vndetectanimalbodyposerequestrevision1)A value that indicates the first revision for an animal body-pose request.[`let VNDetectHumanBodyPose3DRequestRevision1: Int`](\/documentation\/vision\/vndetecthumanbodypose3drequestrevision1)A value that indicates the first revision for a human 3D body pose request.[`let VNTrackHomographicImageRegistrationRequestRevision1: Int`](\/documentation\/vision\/vntrackhomographicimageregistrationrequestrevision1)A value that indicates the first revision for a homographic image-registration request.[`let VNTrackTranslationalImageRegistrationRequestRevision1: Int`](\/documentation\/vision\/vntracktranslationalimageregistrationrequestrevision1)A value that indicates the first revision for a translational image-registration request.[`let VNTrackOpticalFlowRequestRevision1: Int`](\/documentation\/vision\/vntrackopticalflowrequestrevision1)A value that indicates the first revision for an optial-flow request.[`let VNClassifyImageRequestRevision1: Int`](\/documentation\/vision\/vnclassifyimagerequestrevision1)A constant for specifying the first revision of the image-classification request.[`let VNClassifyImageRequestRevision2: Int`](\/documentation\/vision\/vnclassifyimagerequestrevision2)A value that indicates the second revision for an image-classification request.[`let VNGenerateObjectnessBasedSaliencyImageRequestRevision2: Int`](\/documentation\/vision\/vngenerateobjectnessbasedsaliencyimagerequestrevision2)A value that indicates the second revision for an image-classification request.[`let VNGenerateAttentionBasedSaliencyImageRequestRevision2: Int`](\/documentation\/vision\/vngenerateattentionbasedsaliencyimagerequestrevision2)A value that indicates the second revision for an attention-saliency image request.[`let VNGenerateImageFeaturePrintRequestRevision1: Int`](\/documentation\/vision\/vngenerateimagefeatureprintrequestrevision1)A constant for specifying the first revision of the feature-print request.[`let VNGenerateImageFeaturePrintRequestRevision2: Int`](\/documentation\/vision\/vngenerateimagefeatureprintrequestrevision2)A value that indicates the second revision for a feature-print request.[`let VNDetectFaceCaptureQualityRequestRevision3: Int`](\/documentation\/vision\/vndetectfacecapturequalityrequestrevision3)A value that indicates the third revision for a face capture-quality request.[`let VNDetectBarcodesRequestRevision4: Int`](\/documentation\/vision\/vndetectbarcodesrequestrevision4)A value that indicates the fourth revision for a barcode request.[`let VNCalculateImageAestheticsScoresRequestRevision1: Int`](\/documentation\/vision\/vncalculateimageaestheticsscoresrequestrevision1)A value that indicates the first revision for an aesthetics scores request.[`let VNRequestRevisionUnspecified: Int`](\/documentation\/vision\/vnrequestrevisionunspecified)A constant for specifying an unspecified request revision.### [Macros](\/documentation\/vision\/original-objective-c-and-swift-api#Macros)\n\n[Macros](\/documentation\/vision\/vision-macros)",
  "sections" : [
    {
      "content" : "",
      "title" : "Topics"
    }
  ],
  "source" : "appleWebKit",
  "title" : "Original Objective-C and Swift API | Apple Developer Documentation",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/original-objective-c-and-swift-api"
}