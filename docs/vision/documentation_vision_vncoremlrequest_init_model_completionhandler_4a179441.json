{
  "abstract" : "Creates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.",
  "codeExamples" : [

  ],
  "contentHash" : "2c1f787c151487d190e1a4506ae082a79c50abf468f46b0d58088bc84366c56a",
  "crawledAt" : "2025-12-02T21:21:44Z",
  "declaration" : {
    "code" : "init(model: VNCoreMLModel, completionHandler: VNRequestCompletionHandler? = nil)",
    "language" : "swift"
  },
  "id" : "566FA6C1-7D32-4F3F-AD02-59A50A71B914",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Discussion\n\nInitialization can fail if the [doc:\/\/com.apple.documentation\/documentation\/CoreML] model you provide isn’t supported in Vision, such as if the model doesn’t accept an image as input.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:completionHandler:)\ncrawled: 2025-12-02T21:21:44Z\n---\n\n# init(model:completionHandler:)\n\n**Initializer**\n\nCreates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.\n\n## Declaration\n\n```swift\ninit(model: VNCoreMLModel, completionHandler: VNRequestCompletionHandler? = nil)\n```\n\n## Parameters\n\n- **model**: The [doc:\/\/com.apple.documentation\/documentation\/CoreML] model on which to base the Vision request.\n- **completionHandler**: An optional block of code to execute after model initialization.\n\n## Discussion\n\nInitialization can fail if the [doc:\/\/com.apple.documentation\/documentation\/CoreML] model you provide isn’t supported in Vision, such as if the model doesn’t accept an image as input.\n\n## Initializing with a Core ML Model\n\n- **init(model:)**: Creates a model container to use with an image analysis request based on the model you provide.\n- **model**: The model to base the image analysis request on.\n- **VNCoreMLModel**: A container for the model to use with Vision requests.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a model container to use with an image analysis request based on the model you provide.",
          "name" : "init(model:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:)"
        },
        {
          "description" : "The model to base the image analysis request on.",
          "name" : "model",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/model"
        },
        {
          "description" : "A container for the model to use with Vision requests.",
          "name" : "VNCoreMLModel",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLModel"
        }
      ],
      "title" : "Initializing with a Core ML Model"
    }
  ],
  "source" : "appleJSON",
  "title" : "init(model:completionHandler:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:completionHandler:)"
}