{
  "abstract" : "An object that represents a collection of key-value information that a Core ML image-analysis request produces.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "Copyable",
    "CustomStringConvertible",
    "Decodable",
    "Encodable",
    "Equatable",
    "Hashable",
    "Sendable",
    "SendableMetatype",
    "VisionObservation"
  ],
  "contentHash" : "6b600e4e5c5a8e9c3da05c610fddfc47a004722bc9348483afd166ec03fc9f64",
  "crawledAt" : "2025-12-02T21:19:06Z",
  "declaration" : {
    "code" : "struct CoreMLFeatureValueObservation",
    "language" : "swift"
  },
  "id" : "C757E70F-8D74-49E2-ACD5-30D701F725AC",
  "kind" : "struct",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nThis type of observation results from performing a [doc:\/\/Vision\/documentation\/Vision\/CoreMLRequest] image analysis with a [doc:\/\/com.apple.documentation\/documentation\/CoreML] model whose role is prediction rather than classification or image-to-image processing.\n\nThe framework infers that an [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel] object is a predictor model if that model predicts multiple features. You can tell that a model predicts multiple features when its [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel\/modelDescription] object has a `nil` value for its [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModelDescription\/predictedFeatureName] property, or when it inserts its output in an [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModelDescription\/outputDescriptionsByName] dictionary.\n\nThe confidence for these observations is always `1.0`.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLFeatureValueObservation\ncrawled: 2025-12-02T21:19:06Z\n---\n\n# CoreMLFeatureValueObservation\n\n**Structure**\n\nAn object that represents a collection of key-value information that a Core ML image-analysis request produces.\n\n## Declaration\n\n```swift\nstruct CoreMLFeatureValueObservation\n```\n\n## Overview\n\nThis type of observation results from performing a [doc:\/\/Vision\/documentation\/Vision\/CoreMLRequest] image analysis with a [doc:\/\/com.apple.documentation\/documentation\/CoreML] model whose role is prediction rather than classification or image-to-image processing.\n\nThe framework infers that an [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel] object is a predictor model if that model predicts multiple features. You can tell that a model predicts multiple features when its [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel\/modelDescription] object has a `nil` value for its [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModelDescription\/predictedFeatureName] property, or when it inserts its output in an [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModelDescription\/outputDescriptionsByName] dictionary.\n\nThe confidence for these observations is always `1.0`.\n\n## Creating an observation\n\n- **init(_:)**: Creates a feature value observation.\n\n## Inspecting an observation\n\n- **RequestDescriptor**: A type that describes the request and revision combination.\n\n## Getting the feature name and value\n\n- **featureName**: The name in the model description of the model that produces this observation.\n- **featureValue**: The feature result of a request that outputs neither a classification nor an image.\n\n## Machine learning image analysis\n\n- **CoreMLRequest**: An image-analysis request that uses a Core ML model to process images.\n- **ClassificationObservation**: An object that represents classification information that an image-analysis request produces.\n- **PixelBufferObservation**: An object that represents an image that an image-analysis request produces.\n\n## Conforms To\n\n- Copyable\n- CustomStringConvertible\n- Decodable\n- Encodable\n- Equatable\n- Hashable\n- Sendable\n- SendableMetatype\n- VisionObservation\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a feature value observation.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLFeatureValueObservation\/init(_:)"
        }
      ],
      "title" : "Creating an observation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A type that describes the request and revision combination.",
          "name" : "RequestDescriptor",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RequestDescriptor"
        }
      ],
      "title" : "Inspecting an observation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The name in the model description of the model that produces this observation.",
          "name" : "featureName",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLFeatureValueObservation\/featureName"
        },
        {
          "description" : "The feature result of a request that outputs neither a classification nor an image.",
          "name" : "featureValue",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLFeatureValueObservation\/featureValue"
        }
      ],
      "title" : "Getting the feature name and value"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image-analysis request that uses a Core ML model to process images.",
          "name" : "CoreMLRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLRequest"
        },
        {
          "description" : "An object that represents classification information that an image-analysis request produces.",
          "name" : "ClassificationObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ClassificationObservation"
        },
        {
          "description" : "An object that represents an image that an image-analysis request produces.",
          "name" : "PixelBufferObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/PixelBufferObservation"
        }
      ],
      "title" : "Machine learning image analysis"
    }
  ],
  "source" : "appleJSON",
  "title" : "CoreMLFeatureValueObservation",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLFeatureValueObservation"
}