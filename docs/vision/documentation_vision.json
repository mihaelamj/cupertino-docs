{
  "abstract" : "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
  "codeExamples" : [

  ],
  "contentHash" : "7ef3b85c55de86b6d5b03962c9e60480e022b5839cf178d4e9225572ddc947cc",
  "crawledAt" : "2025-12-03T19:14:03Z",
  "id" : "741888B4-FDEB-4461-B5EF-57906833CFDD",
  "kind" : "framework",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nThe Vision framework combines machine learning technologies and Swift’s concurrency features to perform computer vision tasks in your app. Use the Vision framework to analyze images for a variety of purposes:\n\n\n\nTo begin using the framework, you create a request for the type of analysis you want to do. Each request conforms to the [doc:\/\/Vision\/documentation\/Vision\/VisionRequest] protocol. You then perform the request to get an observation object — or an array of observations — with the analysis details for the request. There are more than 25 requests available to choose from. Vision also allows the use of custom Core ML models for tasks like classification or object detection.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\ncrawled: 2025-12-03T19:14:03Z\n---\n\n# Vision\n\n**Framework**\n\nApply computer vision algorithms to perform a variety of tasks on input images and videos.\n\n## Overview\n\nThe Vision framework combines machine learning technologies and Swift’s concurrency features to perform computer vision tasks in your app. Use the Vision framework to analyze images for a variety of purposes:\n\n- Tracking human and animal body poses or the trajectory of an object\n- Recognizing text in 18 different languages\n- Detecting faces and face landmarks, such as eyes, nose, and mouth\n- Performing hand tracking to enable new device interactions\n- Calculating an aesthetics score to determine how memorable a photo is\n\n\n\nTo begin using the framework, you create a request for the type of analysis you want to do. Each request conforms to the [doc:\/\/Vision\/documentation\/Vision\/VisionRequest] protocol. You then perform the request to get an observation object — or an array of observations — with the analysis details for the request. There are more than 25 requests available to choose from. Vision also allows the use of custom Core ML models for tasks like classification or object detection.\n\n\n\n## Text and document analysis\n\n- **Locating and displaying recognized text**: Perform text recognition on a photo using the Vision framework’s text-recognition request.\n- **Recognizing tables within a document**: Scan a document that contains a table and extract its content in a formatted way.\n- **DetectBarcodesRequest**: A request that detects barcodes in an image.\n- **DetectDocumentSegmentationRequest**: A request that detects rectangular regions that contain text in the input image.\n- **DetectTextRectanglesRequest**: An image-analysis request that finds regions of visible text in an image.\n- **RecognizeDocumentsRequest**: An image-analysis request to scan an image of a document and provide information about its structure.\n- **RecognizeTextRequest**: An image-analysis request that recognizes text in an image.\n\n## Facial analysis\n\n- **Analyzing a selfie and visualizing its content**: Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.\n- **DetectFaceCaptureQualityRequest**: A request that produces a floating-point number that represents the capture quality of a face in a photo.\n- **DetectFaceLandmarksRequest**: An image-analysis request that finds facial features like eyes and mouth in an image.\n- **DetectFaceRectanglesRequest**: A request that finds faces within an image.\n\n## Image segmentation and subject lifting\n\n- **GenerateForegroundInstanceMaskRequest**: A request that generates an instance mask of noticeable objects to separate from the background.\n- **GeneratePersonInstanceMaskRequest**: A request that produces a mask of individual people it finds in the input image.\n- **GeneratePersonSegmentationRequest**: A request that produces a matte image for a person it finds in the input image.\n\n## Pose analysis\n\n- **DetectAnimalBodyPoseRequest**: A request that detects an animal body pose.\n- **DetectHumanBodyPose3DRequest**: A request that detects points on human bodies in 3D space, relative to the camera.\n- **DetectHumanBodyPoseRequest**: A request that detects a human body pose.\n- **DetectHumanHandPoseRequest**: A request that detects a human hand pose.\n- **Supporting Pose Types**: Types you use when working with pose analysis.\n\n## Image classification and recognition\n\n- **Classifying images for categorization and search**: Analyze and label images using a Vision classification request.\n- **ClassifyImageRequest**: A request to classify an image.\n- **DetectHumanRectanglesRequest**: A request that finds rectangular regions that contain people in an image.\n- **RecognizeAnimalsRequest**: A request that recognizes animals in an image.\n\n## Shape and edge detection\n\n- **DetectContoursRequest**: A request that detects the contours of the edges of an image.\n- **DetectHorizonRequest**: An image-analysis request that determines the horizon angle in an image.\n- **DetectRectanglesRequest**: An image-analysis request that finds projected rectangular regions in an image.\n\n## Image quality and saliency analysis\n\n- **Generating high-quality thumbnails from videos**: Identify the most visually pleasing frames in a video by using the image-aesthetics scores request.\n- **CalculateImageAestheticsScoresRequest**: A request that analyzes an image for aesthetically pleasing attributes.\n- **DetectLensSmudgeRequest**: A request that detects a smudge on a lens from an image or video frame capture.\n- **GenerateAttentionBasedSaliencyImageRequest**: An object that produces a heat map that identifies the parts of an image most likely to draw attention.\n- **GenerateObjectnessBasedSaliencyImageRequest**: A request that generates a heat map that identifies the parts of an image most likely to represent objects.\n\n## Motion and object tracking\n\n- **DetectTrajectoriesRequest**: A request that detects the trajectories of shapes moving along a parabolic path.\n- **TrackObjectRequest**: An image-analysis request that tracks the movement of a previously identified object across multiple images or video frames.\n- **TrackOpticalFlowRequest**: A request that determines the direction change of vectors for each pixel from a previous to current image.\n- **TrackRectangleRequest**: An image-analysis request that tracks movement of a previously identified rectangular object across multiple images or video frames.\n\n## Image registration and comparison\n\n- **GenerateImageFeaturePrintRequest**: An image-based request to generate feature prints from an image.\n- **TrackHomographicImageRegistrationRequest**: An image-analysis request that you track over time to determine the perspective warp matrix necessary to align the content of two images.\n- **TrackTranslationalImageRegistrationRequest**: An image-analysis request that you track over time to determine the affine transform necessary to align the content of two images.\n\n## Custom Core ML integration\n\n- **CoreMLRequest**: An image-analysis request that uses a Core ML model to process images.\n\n## Protocols\n\n- **ImageProcessingRequest**: A type for image-analysis requests that focus on a specific part of an image.\n- **PoseProviding**: An observation that provides a collection of joints that make up a pose.\n- **StatefulRequest**: The protocol for a type that builds evidence of a condition over time.\n- **TargetedRequest**: A type for analyzing two images together.\n- **VisionObservation**: A type for objects produced by image-analysis requests.\n- **VisionRequest**: A type for image-analysis requests.\n\n## Request handlers\n\n- **ImageRequestHandler**: An object that processes one or more image-analysis requests pertaining to a single image.\n- **TargetedImageRequestHandler**: An object that performs image-analysis requests on two images.\n- **VideoProcessor**: An object that performs offline analysis of video content.\n\n## Image locations and regions\n\n- **NormalizedPoint**: A point in a 2D coordinate system.\n- **NormalizedRect**: The location and dimensions of a rectangle.\n- **NormalizedRegion**: A polygon composed of normalized points.\n- **NormalizedCircle**: The center point and radius of a 2D circle.\n- **BoundingBoxProviding**: A protocol for objects that have a bounding box.\n- **BoundingRegionProviding**: A protocol for objects that have a defined boundary in an image.\n- **QuadrilateralProviding**: A protocol for objects that have a bounding quadrilateral.\n- **CoordinateOrigin**: The origin of a coordinate system relative to an image.\n\n## Errors\n\n- **VisionError**: The errors that the framework produces.\n\n## Legacy API\n\n- **Original Objective-C and Swift API**\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Perform text recognition on a photo using the Vision framework’s text-recognition request.",
          "name" : "Locating and displaying recognized text",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/locating-and-displaying-recognized-text"
        },
        {
          "description" : "Scan a document that contains a table and extract its content in a formatted way.",
          "name" : "Recognizing tables within a document",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/recognize-tables-within-a-document"
        },
        {
          "description" : "A request that detects barcodes in an image.",
          "name" : "DetectBarcodesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectBarcodesRequest"
        },
        {
          "description" : "A request that detects rectangular regions that contain text in the input image.",
          "name" : "DetectDocumentSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectDocumentSegmentationRequest"
        },
        {
          "description" : "An image-analysis request that finds regions of visible text in an image.",
          "name" : "DetectTextRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectTextRectanglesRequest"
        },
        {
          "description" : "An image-analysis request to scan an image of a document and provide information about its structure.",
          "name" : "RecognizeDocumentsRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeDocumentsRequest"
        },
        {
          "description" : "An image-analysis request that recognizes text in an image.",
          "name" : "RecognizeTextRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest"
        }
      ],
      "title" : "Text and document analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.",
          "name" : "Analyzing a selfie and visualizing its content",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/analyzing-a-selfie-and-visualizing-its-content"
        },
        {
          "description" : "A request that produces a floating-point number that represents the capture quality of a face in a photo.",
          "name" : "DetectFaceCaptureQualityRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest"
        },
        {
          "description" : "An image-analysis request that finds facial features like eyes and mouth in an image.",
          "name" : "DetectFaceLandmarksRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceLandmarksRequest"
        },
        {
          "description" : "A request that finds faces within an image.",
          "name" : "DetectFaceRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceRectanglesRequest"
        }
      ],
      "title" : "Facial analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that generates an instance mask of noticeable objects to separate from the background.",
          "name" : "GenerateForegroundInstanceMaskRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateForegroundInstanceMaskRequest"
        },
        {
          "description" : "A request that produces a mask of individual people it finds in the input image.",
          "name" : "GeneratePersonInstanceMaskRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GeneratePersonInstanceMaskRequest"
        },
        {
          "description" : "A request that produces a matte image for a person it finds in the input image.",
          "name" : "GeneratePersonSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GeneratePersonSegmentationRequest"
        }
      ],
      "title" : "Image segmentation and subject lifting"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects an animal body pose.",
          "name" : "DetectAnimalBodyPoseRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectAnimalBodyPoseRequest"
        },
        {
          "description" : "A request that detects points on human bodies in 3D space, relative to the camera.",
          "name" : "DetectHumanBodyPose3DRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanBodyPose3DRequest"
        },
        {
          "description" : "A request that detects a human body pose.",
          "name" : "DetectHumanBodyPoseRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanBodyPoseRequest"
        },
        {
          "description" : "A request that detects a human hand pose.",
          "name" : "DetectHumanHandPoseRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanHandPoseRequest"
        },
        {
          "description" : "Types you use when working with pose analysis.",
          "name" : "Supporting Pose Types",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/supporting-pose-types"
        }
      ],
      "title" : "Pose analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Analyze and label images using a Vision classification request.",
          "name" : "Classifying images for categorization and search",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/classifying-images-for-categorization-and-search"
        },
        {
          "description" : "A request to classify an image.",
          "name" : "ClassifyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ClassifyImageRequest"
        },
        {
          "description" : "A request that finds rectangular regions that contain people in an image.",
          "name" : "DetectHumanRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanRectanglesRequest"
        },
        {
          "description" : "A request that recognizes animals in an image.",
          "name" : "RecognizeAnimalsRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeAnimalsRequest"
        }
      ],
      "title" : "Image classification and recognition"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects the contours of the edges of an image.",
          "name" : "DetectContoursRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectContoursRequest"
        },
        {
          "description" : "An image-analysis request that determines the horizon angle in an image.",
          "name" : "DetectHorizonRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHorizonRequest"
        },
        {
          "description" : "An image-analysis request that finds projected rectangular regions in an image.",
          "name" : "DetectRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectRectanglesRequest"
        }
      ],
      "title" : "Shape and edge detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Identify the most visually pleasing frames in a video by using the image-aesthetics scores request.",
          "name" : "Generating high-quality thumbnails from videos",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/generating-thumbnails-from-videos"
        },
        {
          "description" : "A request that analyzes an image for aesthetically pleasing attributes.",
          "name" : "CalculateImageAestheticsScoresRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CalculateImageAestheticsScoresRequest"
        },
        {
          "description" : "A request that detects a smudge on a lens from an image or video frame capture.",
          "name" : "DetectLensSmudgeRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectLensSmudgeRequest"
        },
        {
          "description" : "An object that produces a heat map that identifies the parts of an image most likely to draw attention.",
          "name" : "GenerateAttentionBasedSaliencyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateAttentionBasedSaliencyImageRequest"
        },
        {
          "description" : "A request that generates a heat map that identifies the parts of an image most likely to represent objects.",
          "name" : "GenerateObjectnessBasedSaliencyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateObjectnessBasedSaliencyImageRequest"
        }
      ],
      "title" : "Image quality and saliency analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects the trajectories of shapes moving along a parabolic path.",
          "name" : "DetectTrajectoriesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectTrajectoriesRequest"
        },
        {
          "description" : "An image-analysis request that tracks the movement of a previously identified object across multiple images or video frames.",
          "name" : "TrackObjectRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackObjectRequest"
        },
        {
          "description" : "A request that determines the direction change of vectors for each pixel from a previous to current image.",
          "name" : "TrackOpticalFlowRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackOpticalFlowRequest"
        },
        {
          "description" : "An image-analysis request that tracks movement of a previously identified rectangular object across multiple images or video frames.",
          "name" : "TrackRectangleRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackRectangleRequest"
        }
      ],
      "title" : "Motion and object tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image-based request to generate feature prints from an image.",
          "name" : "GenerateImageFeaturePrintRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateImageFeaturePrintRequest"
        },
        {
          "description" : "An image-analysis request that you track over time to determine the perspective warp matrix necessary to align the content of two images.",
          "name" : "TrackHomographicImageRegistrationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackHomographicImageRegistrationRequest"
        },
        {
          "description" : "An image-analysis request that you track over time to determine the affine transform necessary to align the content of two images.",
          "name" : "TrackTranslationalImageRegistrationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackTranslationalImageRegistrationRequest"
        }
      ],
      "title" : "Image registration and comparison"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image-analysis request that uses a Core ML model to process images.",
          "name" : "CoreMLRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLRequest"
        }
      ],
      "title" : "Custom Core ML integration"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A type for image-analysis requests that focus on a specific part of an image.",
          "name" : "ImageProcessingRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest"
        },
        {
          "description" : "An observation that provides a collection of joints that make up a pose.",
          "name" : "PoseProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/PoseProviding"
        },
        {
          "description" : "The protocol for a type that builds evidence of a condition over time.",
          "name" : "StatefulRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/StatefulRequest"
        },
        {
          "description" : "A type for analyzing two images together.",
          "name" : "TargetedRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TargetedRequest"
        },
        {
          "description" : "A type for objects produced by image-analysis requests.",
          "name" : "VisionObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionObservation"
        },
        {
          "description" : "A type for image-analysis requests.",
          "name" : "VisionRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionRequest"
        }
      ],
      "title" : "Protocols"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that processes one or more image-analysis requests pertaining to a single image.",
          "name" : "ImageRequestHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageRequestHandler"
        },
        {
          "description" : "An object that performs image-analysis requests on two images.",
          "name" : "TargetedImageRequestHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TargetedImageRequestHandler"
        },
        {
          "description" : "An object that performs offline analysis of video content.",
          "name" : "VideoProcessor",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VideoProcessor"
        }
      ],
      "title" : "Request handlers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A point in a 2D coordinate system.",
          "name" : "NormalizedPoint",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedPoint"
        },
        {
          "description" : "The location and dimensions of a rectangle.",
          "name" : "NormalizedRect",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedRect"
        },
        {
          "description" : "A polygon composed of normalized points.",
          "name" : "NormalizedRegion",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedRegion"
        },
        {
          "description" : "The center point and radius of a 2D circle.",
          "name" : "NormalizedCircle",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedCircle"
        },
        {
          "description" : "A protocol for objects that have a bounding box.",
          "name" : "BoundingBoxProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/BoundingBoxProviding"
        },
        {
          "description" : "A protocol for objects that have a defined boundary in an image.",
          "name" : "BoundingRegionProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/BoundingRegionProviding"
        },
        {
          "description" : "A protocol for objects that have a bounding quadrilateral.",
          "name" : "QuadrilateralProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/QuadrilateralProviding"
        },
        {
          "description" : "The origin of a coordinate system relative to an image.",
          "name" : "CoordinateOrigin",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoordinateOrigin"
        }
      ],
      "title" : "Image locations and regions"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The errors that the framework produces.",
          "name" : "VisionError",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionError"
        }
      ],
      "title" : "Errors"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "Original Objective-C and Swift API",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/original-objective-c-and-swift-api"
        }
      ],
      "title" : "Legacy API"
    }
  ],
  "source" : "appleJSON",
  "title" : "Vision",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision"
}