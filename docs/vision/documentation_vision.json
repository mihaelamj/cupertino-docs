{
  "abstract" : "Apply computer vision algorithms to perform a variety of tasks on input images and videos.",
  "codeExamples" : [

  ],
  "contentHash" : "6636959be50586e2b0ee155c1f431ca3e3576669fef3dc9c2647cc5eb0338a6e",
  "crawledAt" : "2025-12-03T18:55:10Z",
  "id" : "D36036EF-D2BF-4DE4-8265-FCBFD0A1AF19",
  "kind" : "framework",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nThe Vision framework combines machine learning technologies and Swift’s concurrency features to perform computer vision tasks in your app. Use the Vision framework to analyze images for a variety of purposes:\n\n\n\nTo begin using the framework, you create a request for the type of analysis you want to do. Each request conforms to the [doc:\/\/Vision\/documentation\/Vision\/VisionRequest] protocol. You then perform the request to get an observation object — or an array of observations — with the analysis details for the request. There are more than 25 requests available to choose from. Vision also allows the use of custom Core ML models for tasks like classification or object detection.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\ncrawled: 2025-12-03T18:55:10Z\n---\n\n# Vision\n\n**Framework**\n\nApply computer vision algorithms to perform a variety of tasks on input images and videos.\n\n## Overview\n\nThe Vision framework combines machine learning technologies and Swift’s concurrency features to perform computer vision tasks in your app. Use the Vision framework to analyze images for a variety of purposes:\n\n- Tracking human and animal body poses or the trajectory of an object\n- Recognizing text in 18 different languages\n- Detecting faces and face landmarks, such as eyes, nose, and mouth\n- Performing hand tracking to enable new device interactions\n- Calculating an aesthetics score to determine how memorable a photo is\n\n\n\nTo begin using the framework, you create a request for the type of analysis you want to do. Each request conforms to the [doc:\/\/Vision\/documentation\/Vision\/VisionRequest] protocol. You then perform the request to get an observation object — or an array of observations — with the analysis details for the request. There are more than 25 requests available to choose from. Vision also allows the use of custom Core ML models for tasks like classification or object detection.\n\n\n\n## Still-image analysis\n\n- **Classifying images for categorization and search**: Analyze and label images using a Vision classification request.\n- **ClassifyImageRequest**: A request to classify an image.\n- **ImageProcessingRequest**: A type for image-analysis requests that focus on a specific part of an image.\n- **ImageRequestHandler**: An object that processes one or more image-analysis requests pertaining to a single image.\n- **VisionRequest**: A type for image-analysis requests.\n- **VisionObservation**: A type for objects produced by image-analysis requests.\n- **DetectLensSmudgeRequest**: A request that detects a smudge on a lens from an image or video frame capture.\n- **SmudgeObservation**: An observation that provides an overall score of the presence of a smudge in an image or video frame capture.\n\n## Image sequence analysis\n\n- **GeneratePersonSegmentationRequest**: A request that produces a matte image for a person it finds in the input image.\n- **GeneratePersonInstanceMaskRequest**: A request that produces a mask of individual people it finds in the input image.\n- **DetectDocumentSegmentationRequest**: A request that detects rectangular regions that contain text in the input image.\n- **StatefulRequest**: The protocol for a type that builds evidence of a condition over time.\n\n## Image aesthetics analysis\n\n- **Generating high-quality thumbnails from videos**: Identify the most visually pleasing frames in a video by using the image-aesthetics scores request.\n- **CalculateImageAestheticsScoresRequest**: A request that analyzes an image for aesthetically pleasing attributes.\n\n## Saliency analysis\n\n- **GenerateAttentionBasedSaliencyImageRequest**: An object that produces a heat map that identifies the parts of an image most likely to draw attention.\n- **GenerateObjectnessBasedSaliencyImageRequest**: A request that generates a heat map that identifies the parts of an image most likely to represent objects.\n\n## Object tracking\n\n- **TrackObjectRequest**: An image-analysis request that tracks the movement of a previously identified object across multiple images or video frames.\n- **TrackRectangleRequest**: An image-analysis request that tracks movement of a previously identified rectangular object across multiple images or video frames.\n\n## Face and body detection\n\n- **Analyzing a selfie and visualizing its content**: Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.\n- **DetectFaceRectanglesRequest**: A request that finds faces within an image.\n- **DetectFaceLandmarksRequest**: An image-analysis request that finds facial features like eyes and mouth in an image.\n- **DetectFaceCaptureQualityRequest**: A request that produces a floating-point number that represents the capture quality of a face in a photo.\n- **DetectHumanRectanglesRequest**: A request that finds rectangular regions that contain people in an image.\n\n## Body and hand pose detection\n\n- **DetectHumanBodyPoseRequest**: A request that detects a human body pose.\n- **DetectHumanHandPoseRequest**: A request that detects a human hand pose.\n- **PoseProviding**: An observation that provides a collection of joints that make up a pose.\n- **Chirality**: The hand sidedness of a pose.\n- **Joint**: A pose joint represented as a normalized point in an image, along with a label and a confidence value.\n\n## 3D body pose detection\n\n- **DetectHumanBodyPose3DRequest**: A request that detects points on human bodies in 3D space, relative to the camera.\n- **Joint3D**: An object that represents a body pose joint in 3D space.\n\n## Text detection\n\n- **Recognizing tables within a document**: Scan a document that contains a table and extract its content in a formatted way.\n- **Locating and displaying recognized text**: Perform text recognition on a photo using the Vision framework’s text-recognition request.\n- **RecognizeDocumentsRequest**: An image-analysis request to scan an image of a document and provide information about its structure.\n- **DocumentObservation**: Information about the sections of content that an image-analysis request detects in a document.\n- **DetectTextRectanglesRequest**: An image-analysis request that finds regions of visible text in an image.\n- **RecognizeTextRequest**: An image-analysis request that recognizes text in an image.\n\n## Barcode detection\n\n- **DetectBarcodesRequest**: A request that detects barcodes in an image.\n\n## Trajectory, contour, and horizon detection\n\n- **DetectTrajectoriesRequest**: A request that detects the trajectories of shapes moving along a parabolic path.\n- **DetectContoursRequest**: A request that detects the contours of the edges of an image.\n- **DetectHorizonRequest**: An image-analysis request that determines the horizon angle in an image.\n\n## Animal detection\n\n- **DetectAnimalBodyPoseRequest**: A request that detects an animal body pose.\n- **RecognizeAnimalsRequest**: A request that recognizes animals in an image.\n\n## Optical flow and rectangle detection\n\n- **TrackOpticalFlowRequest**: A request that determines the direction change of vectors for each pixel from a previous to current image.\n- **DetectRectanglesRequest**: An image-analysis request that finds projected rectangular regions in an image.\n\n## Image alignment\n\n- **TrackTranslationalImageRegistrationRequest**: An image-analysis request that you track over time to determine the affine transform necessary to align the content of two images.\n- **TrackHomographicImageRegistrationRequest**: An image-analysis request that you track over time to determine the perspective warp matrix necessary to align the content of two images.\n- **TargetedRequest**: A type for analyzing two images together.\n\n## Image feature print and background removal\n\n- **GenerateImageFeaturePrintRequest**: An image-based request to generate feature prints from an image.\n- **GenerateForegroundInstanceMaskRequest**: A request that generates an instance mask of noticeable objects to separate from the background.\n\n## Machine learning image analysis\n\n- **CoreMLRequest**: An image-analysis request that uses a Core ML model to process images.\n- **CoreMLFeatureValueObservation**: An object that represents a collection of key-value information that a Core ML image-analysis request produces.\n- **ClassificationObservation**: An object that represents classification information that an image-analysis request produces.\n- **PixelBufferObservation**: An object that represents an image that an image-analysis request produces.\n\n## Image locations and regions\n\n- **NormalizedPoint**: A point in a 2D coordinate system.\n- **NormalizedRect**: The location and dimensions of a rectangle.\n- **NormalizedRegion**: A polygon composed of normalized points.\n- **NormalizedCircle**: The center point and radius of a 2D circle.\n- **BoundingBoxProviding**: A protocol for objects that have a bounding box.\n- **BoundingRegionProviding**: A protocol for objects that have a defined boundary in an image.\n- **QuadrilateralProviding**: A protocol for objects that have a bounding quadrilateral.\n- **CoordinateOrigin**: The origin of a coordinate system relative to an image.\n\n## Request Handlers\n\n- **ImageRequestHandler**: An object that processes one or more image-analysis requests pertaining to a single image.\n- **TargetedImageRequestHandler**: An object that performs image-analysis requests on two images.\n\n## Utilities\n\n- **ComputeStage**: Types that represent the compute stage.\n- **VideoProcessor**: An object that performs offline analysis of video content.\n\n## Errors\n\n- **VisionError**: The errors that the framework produces.\n\n## Legacy API\n\n- **Original Objective-C and Swift API**\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Analyze and label images using a Vision classification request.",
          "name" : "Classifying images for categorization and search",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/classifying-images-for-categorization-and-search"
        },
        {
          "description" : "A request to classify an image.",
          "name" : "ClassifyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ClassifyImageRequest"
        },
        {
          "description" : "A type for image-analysis requests that focus on a specific part of an image.",
          "name" : "ImageProcessingRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest"
        },
        {
          "description" : "An object that processes one or more image-analysis requests pertaining to a single image.",
          "name" : "ImageRequestHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageRequestHandler"
        },
        {
          "description" : "A type for image-analysis requests.",
          "name" : "VisionRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionRequest"
        },
        {
          "description" : "A type for objects produced by image-analysis requests.",
          "name" : "VisionObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionObservation"
        },
        {
          "description" : "A request that detects a smudge on a lens from an image or video frame capture.",
          "name" : "DetectLensSmudgeRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectLensSmudgeRequest"
        },
        {
          "description" : "An observation that provides an overall score of the presence of a smudge in an image or video frame capture.",
          "name" : "SmudgeObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/SmudgeObservation"
        }
      ],
      "title" : "Still-image analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that produces a matte image for a person it finds in the input image.",
          "name" : "GeneratePersonSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GeneratePersonSegmentationRequest"
        },
        {
          "description" : "A request that produces a mask of individual people it finds in the input image.",
          "name" : "GeneratePersonInstanceMaskRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GeneratePersonInstanceMaskRequest"
        },
        {
          "description" : "A request that detects rectangular regions that contain text in the input image.",
          "name" : "DetectDocumentSegmentationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectDocumentSegmentationRequest"
        },
        {
          "description" : "The protocol for a type that builds evidence of a condition over time.",
          "name" : "StatefulRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/StatefulRequest"
        }
      ],
      "title" : "Image sequence analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Identify the most visually pleasing frames in a video by using the image-aesthetics scores request.",
          "name" : "Generating high-quality thumbnails from videos",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/generating-thumbnails-from-videos"
        },
        {
          "description" : "A request that analyzes an image for aesthetically pleasing attributes.",
          "name" : "CalculateImageAestheticsScoresRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CalculateImageAestheticsScoresRequest"
        }
      ],
      "title" : "Image aesthetics analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that produces a heat map that identifies the parts of an image most likely to draw attention.",
          "name" : "GenerateAttentionBasedSaliencyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateAttentionBasedSaliencyImageRequest"
        },
        {
          "description" : "A request that generates a heat map that identifies the parts of an image most likely to represent objects.",
          "name" : "GenerateObjectnessBasedSaliencyImageRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateObjectnessBasedSaliencyImageRequest"
        }
      ],
      "title" : "Saliency analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image-analysis request that tracks the movement of a previously identified object across multiple images or video frames.",
          "name" : "TrackObjectRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackObjectRequest"
        },
        {
          "description" : "An image-analysis request that tracks movement of a previously identified rectangular object across multiple images or video frames.",
          "name" : "TrackRectangleRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackRectangleRequest"
        }
      ],
      "title" : "Object tracking"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.",
          "name" : "Analyzing a selfie and visualizing its content",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/analyzing-a-selfie-and-visualizing-its-content"
        },
        {
          "description" : "A request that finds faces within an image.",
          "name" : "DetectFaceRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceRectanglesRequest"
        },
        {
          "description" : "An image-analysis request that finds facial features like eyes and mouth in an image.",
          "name" : "DetectFaceLandmarksRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceLandmarksRequest"
        },
        {
          "description" : "A request that produces a floating-point number that represents the capture quality of a face in a photo.",
          "name" : "DetectFaceCaptureQualityRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectFaceCaptureQualityRequest"
        },
        {
          "description" : "A request that finds rectangular regions that contain people in an image.",
          "name" : "DetectHumanRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanRectanglesRequest"
        }
      ],
      "title" : "Face and body detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects a human body pose.",
          "name" : "DetectHumanBodyPoseRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanBodyPoseRequest"
        },
        {
          "description" : "A request that detects a human hand pose.",
          "name" : "DetectHumanHandPoseRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanHandPoseRequest"
        },
        {
          "description" : "An observation that provides a collection of joints that make up a pose.",
          "name" : "PoseProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/PoseProviding"
        },
        {
          "description" : "The hand sidedness of a pose.",
          "name" : "Chirality",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/Chirality"
        },
        {
          "description" : "A pose joint represented as a normalized point in an image, along with a label and a confidence value.",
          "name" : "Joint",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/Joint"
        }
      ],
      "title" : "Body and hand pose detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects points on human bodies in 3D space, relative to the camera.",
          "name" : "DetectHumanBodyPose3DRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHumanBodyPose3DRequest"
        },
        {
          "description" : "An object that represents a body pose joint in 3D space.",
          "name" : "Joint3D",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/Joint3D"
        }
      ],
      "title" : "3D body pose detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Scan a document that contains a table and extract its content in a formatted way.",
          "name" : "Recognizing tables within a document",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/recognize-tables-within-a-document"
        },
        {
          "description" : "Perform text recognition on a photo using the Vision framework’s text-recognition request.",
          "name" : "Locating and displaying recognized text",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/locating-and-displaying-recognized-text"
        },
        {
          "description" : "An image-analysis request to scan an image of a document and provide information about its structure.",
          "name" : "RecognizeDocumentsRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeDocumentsRequest"
        },
        {
          "description" : "Information about the sections of content that an image-analysis request detects in a document.",
          "name" : "DocumentObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DocumentObservation"
        },
        {
          "description" : "An image-analysis request that finds regions of visible text in an image.",
          "name" : "DetectTextRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectTextRectanglesRequest"
        },
        {
          "description" : "An image-analysis request that recognizes text in an image.",
          "name" : "RecognizeTextRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeTextRequest"
        }
      ],
      "title" : "Text detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects barcodes in an image.",
          "name" : "DetectBarcodesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectBarcodesRequest"
        }
      ],
      "title" : "Barcode detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects the trajectories of shapes moving along a parabolic path.",
          "name" : "DetectTrajectoriesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectTrajectoriesRequest"
        },
        {
          "description" : "A request that detects the contours of the edges of an image.",
          "name" : "DetectContoursRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectContoursRequest"
        },
        {
          "description" : "An image-analysis request that determines the horizon angle in an image.",
          "name" : "DetectHorizonRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectHorizonRequest"
        }
      ],
      "title" : "Trajectory, contour, and horizon detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that detects an animal body pose.",
          "name" : "DetectAnimalBodyPoseRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectAnimalBodyPoseRequest"
        },
        {
          "description" : "A request that recognizes animals in an image.",
          "name" : "RecognizeAnimalsRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizeAnimalsRequest"
        }
      ],
      "title" : "Animal detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A request that determines the direction change of vectors for each pixel from a previous to current image.",
          "name" : "TrackOpticalFlowRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackOpticalFlowRequest"
        },
        {
          "description" : "An image-analysis request that finds projected rectangular regions in an image.",
          "name" : "DetectRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/DetectRectanglesRequest"
        }
      ],
      "title" : "Optical flow and rectangle detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image-analysis request that you track over time to determine the affine transform necessary to align the content of two images.",
          "name" : "TrackTranslationalImageRegistrationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackTranslationalImageRegistrationRequest"
        },
        {
          "description" : "An image-analysis request that you track over time to determine the perspective warp matrix necessary to align the content of two images.",
          "name" : "TrackHomographicImageRegistrationRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TrackHomographicImageRegistrationRequest"
        },
        {
          "description" : "A type for analyzing two images together.",
          "name" : "TargetedRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TargetedRequest"
        }
      ],
      "title" : "Image alignment"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image-based request to generate feature prints from an image.",
          "name" : "GenerateImageFeaturePrintRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateImageFeaturePrintRequest"
        },
        {
          "description" : "A request that generates an instance mask of noticeable objects to separate from the background.",
          "name" : "GenerateForegroundInstanceMaskRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/GenerateForegroundInstanceMaskRequest"
        }
      ],
      "title" : "Image feature print and background removal"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image-analysis request that uses a Core ML model to process images.",
          "name" : "CoreMLRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLRequest"
        },
        {
          "description" : "An object that represents a collection of key-value information that a Core ML image-analysis request produces.",
          "name" : "CoreMLFeatureValueObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoreMLFeatureValueObservation"
        },
        {
          "description" : "An object that represents classification information that an image-analysis request produces.",
          "name" : "ClassificationObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ClassificationObservation"
        },
        {
          "description" : "An object that represents an image that an image-analysis request produces.",
          "name" : "PixelBufferObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/PixelBufferObservation"
        }
      ],
      "title" : "Machine learning image analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A point in a 2D coordinate system.",
          "name" : "NormalizedPoint",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedPoint"
        },
        {
          "description" : "The location and dimensions of a rectangle.",
          "name" : "NormalizedRect",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedRect"
        },
        {
          "description" : "A polygon composed of normalized points.",
          "name" : "NormalizedRegion",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedRegion"
        },
        {
          "description" : "The center point and radius of a 2D circle.",
          "name" : "NormalizedCircle",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/NormalizedCircle"
        },
        {
          "description" : "A protocol for objects that have a bounding box.",
          "name" : "BoundingBoxProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/BoundingBoxProviding"
        },
        {
          "description" : "A protocol for objects that have a defined boundary in an image.",
          "name" : "BoundingRegionProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/BoundingRegionProviding"
        },
        {
          "description" : "A protocol for objects that have a bounding quadrilateral.",
          "name" : "QuadrilateralProviding",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/QuadrilateralProviding"
        },
        {
          "description" : "The origin of a coordinate system relative to an image.",
          "name" : "CoordinateOrigin",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/CoordinateOrigin"
        }
      ],
      "title" : "Image locations and regions"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An object that processes one or more image-analysis requests pertaining to a single image.",
          "name" : "ImageRequestHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageRequestHandler"
        },
        {
          "description" : "An object that performs image-analysis requests on two images.",
          "name" : "TargetedImageRequestHandler",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/TargetedImageRequestHandler"
        }
      ],
      "title" : "Request Handlers"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Types that represent the compute stage.",
          "name" : "ComputeStage",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ComputeStage"
        },
        {
          "description" : "An object that performs offline analysis of video content.",
          "name" : "VideoProcessor",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VideoProcessor"
        }
      ],
      "title" : "Utilities"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The errors that the framework produces.",
          "name" : "VisionError",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionError"
        }
      ],
      "title" : "Errors"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "",
          "name" : "Original Objective-C and Swift API",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/original-objective-c-and-swift-api"
        }
      ],
      "title" : "Legacy API"
    }
  ],
  "source" : "appleJSON",
  "title" : "Vision",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision"
}