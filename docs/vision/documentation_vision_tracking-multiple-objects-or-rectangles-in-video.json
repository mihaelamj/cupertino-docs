{
  "abstract" : "Apply Vision algorithms to track objects or rectangles throughout a video.",
  "codeExamples" : [
    {
      "code" : "var inputObservations = [UUID: VNDetectedObjectObservation]()\nvar trackedObjects = [UUID: TrackedPolyRect]()\nswitch type {\ncase .object:\n    for rect in self.objectsToTrack {\n        let inputObservation = VNDetectedObjectObservation(boundingBox: rect.boundingBox)\n        inputObservations[inputObservation.uuid] = inputObservation\n        trackedObjects[inputObservation.uuid] = rect\n    }\ncase .rectangle:\n    for rectangleObservation in initialRectObservations {\n        inputObservations[rectangleObservation.uuid] = rectangleObservation\n        let rectColor = TrackedObjectsPalette.color(atIndex: trackedObjects.count)\n        trackedObjects[rectangleObservation.uuid] = TrackedPolyRect(observation: rectangleObservation, color: rectColor)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "let request: VNTrackingRequest!\nswitch type {\ncase .object:\n    request = VNTrackObjectRequest(detectedObjectObservation: inputObservation.value)\ncase .rectangle:\n    guard let rectObservation = inputObservation.value as? VNRectangleObservation else {\n        continue\n    }\n    request = VNTrackRectangleRequest(rectangleObservation: rectObservation)\n}\nrequest.trackingLevel = trackingLevel\n\ntrackingRequests.append(request)",
      "language" : "swift"
    },
    {
      "code" : "try requestHandler.perform(trackingRequests, on: frame, orientation: videoReader.orientation)",
      "language" : "swift"
    },
    {
      "code" : "guard let results = processedRequest.results else {\n    continue\n}\nguard let observation = results.first as? VNDetectedObjectObservation else {\n    continue\n}\n\/\/ Assume threshold = 0.5f\nlet rectStyle: TrackedPolyRectStyle = observation.confidence > 0.5 ? .solid : .dashed\nlet knownRect = trackedObjects[observation.uuid]!\nswitch type {\ncase .object:\n    rects.append(TrackedPolyRect(observation: observation, color: knownRect.color, style: rectStyle))\ncase .rectangle:\n    guard let rectObservation = observation as? VNRectangleObservation else {\n        break\n    }\n    rects.append(TrackedPolyRect(observation: rectObservation, color: knownRect.color, style: rectStyle))\n}",
      "language" : "swift"
    },
    {
      "code" : "inputObservations[observation.uuid] = observation",
      "language" : "swift"
    }
  ],
  "contentHash" : "9c3e560b96604b68245ee673b1a06c1e162b449f1ba9c2edb81e573a675ecf3a",
  "crawledAt" : "2025-12-04T02:34:20Z",
  "id" : "7A65A4F8-96B7-4370-95C9-D0E813919A22",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nWith the [https:\/\/developer.apple.com\/documentation\/vision] framework, you can detect and track objects or rectangles through a sequence of frames coming from video, live capture, or other sources.\n\nThis sample app shows you how to pick an initial object to track, how to create Vision tracking requests to follow that object, and how to parse results from the object or rectangle tracker.\n\n### Preview the Sample App\n\nTo see this sample app in action, build and run the project in Xcode, then choose a video from your photo library.  Once the video is loaded from your photo library, choose to track either objects or rectangles.\n\n### Nominate Objects or Rectangles to Track\n\nTo track rectangles, select Rectangles.  The app runs the rectangle detector and shows rectangles it finds in a preview of the scene.\n\nOtherwise, to track objects, select Objects.  Then nominate objects to track by touching them in the preview and dragging boxes around them.  You can select multiple objects; the app identifies them by their [https:\/\/developer.apple.com\/documentation\/foundation\/uuid], using differently colored rectangles.\n\nThe [https:\/\/developer.apple.com\/documentation\/vision\/vntrackobjectrequest] class requires a detected object observation to initialize.  The sample provides this observation by running [https:\/\/developer.apple.com\/documentation\/vision\/vndetectrectanglesrequest], or by creating one from the bounding box you drew in the preview.  It tracks multiple objects by iterating through each observation and creating a [https:\/\/developer.apple.com\/documentation\/vision\/vndetectedobjectobservation] from its bounding box.\n\nIn your own app, if you prefer to nominate objects programmatically, you can use observations returned from Vision’s own object detection algorithms.  For example, the Vision framework’s [https:\/\/developer.apple.com\/documentation\/vision\/vnimagerequesthandler] accepts face detection, text detection, and barcode detection requests, and those requests return their results in subclasses of [https:\/\/developer.apple.com\/documentation\/vision\/vnobservation].  You can pass these observations directly into [https:\/\/developer.apple.com\/documentation\/vision\/vntrackobjectrequest].\n\nSelecting a salient object heavily influences the performance of the tracking algorithm; provide the best initial bounding box segmentation of your object that you can.\n\n### Track Objects or Rectangles with a Request Handler\n\nThe Vision framework handles tracking requests through a [https:\/\/developer.apple.com\/documentation\/vision\/vnsequencerequesthandler].  Whereas the [https:\/\/developer.apple.com\/documentation\/vision\/vnimagerequesthandler] handles object detection requests on a still image, the [https:\/\/developer.apple.com\/documentation\/vision\/vnsequencerequesthandler] handles tracking requests.\n\nCreate a tracking request for each rectangle or object you’d like to track.  Seed each tracking request with the observation created during nomination.\n\nFor each such request, call the sequence request handler’s [https:\/\/developer.apple.com\/documentation\/vision\/vnsequencerequesthandler\/2880308-perform] method, making sure to pass in the video reader’s orientation to ensure upright tracking. This method runs synchronously; use a background queue, such as `workQueue` in the sample code, so that the main queue isn’t blocked while your requests execute.\n\nBy iterating through each selected object or rectangle, creating a tracking request from it, and calling `perform` on the request handler, Vision follows the object or rectangle over the image sequence and returns results through its `results` property.\n\n### Interpret Tracking Results\n\nAccess tracking results through the request’s `results` property or its completion handler.  A single tracking request represents a single tracked object in a one-to-one relationship.  If a tracking request succeeds, its [https:\/\/developer.apple.com\/documentation\/vision\/vnrequest\/2867238-results] property contains [https:\/\/developer.apple.com\/documentation\/vision\/vndetectedobjectobservation] objects describing the tracked object’s new location in the frame.\n\nUse the observation’s [https:\/\/developer.apple.com\/documentation\/vision\/vndetectedobjectobservation\/2867227-boundingbox] to determine its location, so you can update your app or UI with the tracked object’s new location.  Also use it to seed the next round of tracking.\n\nIn practice, you should periodically run a new tracking request with an updated set of input observations  to capture objects that weren’t present in your initial nomination frame. For instance, you could create a new [https:\/\/developer.apple.com\/documentation\/vision\/vntrackobjectrequest] every ten frames.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/tracking-multiple-objects-or-rectangles-in-video\ncrawled: 2025-12-04T02:34:20Z\n---\n\n# Tracking Multiple Objects or Rectangles in Video\n\n**Sample Code**\n\nApply Vision algorithms to track objects or rectangles throughout a video.\n\n## Overview\n\nWith the [https:\/\/developer.apple.com\/documentation\/vision] framework, you can detect and track objects or rectangles through a sequence of frames coming from video, live capture, or other sources.\n\nThis sample app shows you how to pick an initial object to track, how to create Vision tracking requests to follow that object, and how to parse results from the object or rectangle tracker.\n\n### Preview the Sample App\n\nTo see this sample app in action, build and run the project in Xcode, then choose a video from your photo library.  Once the video is loaded from your photo library, choose to track either objects or rectangles.\n\n### Nominate Objects or Rectangles to Track\n\nTo track rectangles, select Rectangles.  The app runs the rectangle detector and shows rectangles it finds in a preview of the scene.\n\nOtherwise, to track objects, select Objects.  Then nominate objects to track by touching them in the preview and dragging boxes around them.  You can select multiple objects; the app identifies them by their [https:\/\/developer.apple.com\/documentation\/foundation\/uuid], using differently colored rectangles.\n\nThe [https:\/\/developer.apple.com\/documentation\/vision\/vntrackobjectrequest] class requires a detected object observation to initialize.  The sample provides this observation by running [https:\/\/developer.apple.com\/documentation\/vision\/vndetectrectanglesrequest], or by creating one from the bounding box you drew in the preview.  It tracks multiple objects by iterating through each observation and creating a [https:\/\/developer.apple.com\/documentation\/vision\/vndetectedobjectobservation] from its bounding box.\n\n```swift\nvar inputObservations = [UUID: VNDetectedObjectObservation]()\nvar trackedObjects = [UUID: TrackedPolyRect]()\nswitch type {\ncase .object:\n    for rect in self.objectsToTrack {\n        let inputObservation = VNDetectedObjectObservation(boundingBox: rect.boundingBox)\n        inputObservations[inputObservation.uuid] = inputObservation\n        trackedObjects[inputObservation.uuid] = rect\n    }\ncase .rectangle:\n    for rectangleObservation in initialRectObservations {\n        inputObservations[rectangleObservation.uuid] = rectangleObservation\n        let rectColor = TrackedObjectsPalette.color(atIndex: trackedObjects.count)\n        trackedObjects[rectangleObservation.uuid] = TrackedPolyRect(observation: rectangleObservation, color: rectColor)\n    }\n}\n```\n\nIn your own app, if you prefer to nominate objects programmatically, you can use observations returned from Vision’s own object detection algorithms.  For example, the Vision framework’s [https:\/\/developer.apple.com\/documentation\/vision\/vnimagerequesthandler] accepts face detection, text detection, and barcode detection requests, and those requests return their results in subclasses of [https:\/\/developer.apple.com\/documentation\/vision\/vnobservation].  You can pass these observations directly into [https:\/\/developer.apple.com\/documentation\/vision\/vntrackobjectrequest].\n\nSelecting a salient object heavily influences the performance of the tracking algorithm; provide the best initial bounding box segmentation of your object that you can.\n\n### Track Objects or Rectangles with a Request Handler\n\nThe Vision framework handles tracking requests through a [https:\/\/developer.apple.com\/documentation\/vision\/vnsequencerequesthandler].  Whereas the [https:\/\/developer.apple.com\/documentation\/vision\/vnimagerequesthandler] handles object detection requests on a still image, the [https:\/\/developer.apple.com\/documentation\/vision\/vnsequencerequesthandler] handles tracking requests.\n\nCreate a tracking request for each rectangle or object you’d like to track.  Seed each tracking request with the observation created during nomination.\n\n```swift\nlet request: VNTrackingRequest!\nswitch type {\ncase .object:\n    request = VNTrackObjectRequest(detectedObjectObservation: inputObservation.value)\ncase .rectangle:\n    guard let rectObservation = inputObservation.value as? VNRectangleObservation else {\n        continue\n    }\n    request = VNTrackRectangleRequest(rectangleObservation: rectObservation)\n}\nrequest.trackingLevel = trackingLevel\n\ntrackingRequests.append(request)\n```\n\nFor each such request, call the sequence request handler’s [https:\/\/developer.apple.com\/documentation\/vision\/vnsequencerequesthandler\/2880308-perform] method, making sure to pass in the video reader’s orientation to ensure upright tracking. This method runs synchronously; use a background queue, such as `workQueue` in the sample code, so that the main queue isn’t blocked while your requests execute.\n\n```swift\ntry requestHandler.perform(trackingRequests, on: frame, orientation: videoReader.orientation)\n```\n\nBy iterating through each selected object or rectangle, creating a tracking request from it, and calling `perform` on the request handler, Vision follows the object or rectangle over the image sequence and returns results through its `results` property.\n\n### Interpret Tracking Results\n\nAccess tracking results through the request’s `results` property or its completion handler.  A single tracking request represents a single tracked object in a one-to-one relationship.  If a tracking request succeeds, its [https:\/\/developer.apple.com\/documentation\/vision\/vnrequest\/2867238-results] property contains [https:\/\/developer.apple.com\/documentation\/vision\/vndetectedobjectobservation] objects describing the tracked object’s new location in the frame.\n\n```swift\nguard let results = processedRequest.results else {\n    continue\n}\nguard let observation = results.first as? VNDetectedObjectObservation else {\n    continue\n}\n\/\/ Assume threshold = 0.5f\nlet rectStyle: TrackedPolyRectStyle = observation.confidence > 0.5 ? .solid : .dashed\nlet knownRect = trackedObjects[observation.uuid]!\nswitch type {\ncase .object:\n    rects.append(TrackedPolyRect(observation: observation, color: knownRect.color, style: rectStyle))\ncase .rectangle:\n    guard let rectObservation = observation as? VNRectangleObservation else {\n        break\n    }\n    rects.append(TrackedPolyRect(observation: rectObservation, color: knownRect.color, style: rectStyle))\n}\n```\n\nUse the observation’s [https:\/\/developer.apple.com\/documentation\/vision\/vndetectedobjectobservation\/2867227-boundingbox] to determine its location, so you can update your app or UI with the tracked object’s new location.  Also use it to seed the next round of tracking.\n\n```swift\ninputObservations[observation.uuid] = observation\n```\n\nIn practice, you should periodically run a new tracking request with an updated set of input observations  to capture objects that weren’t present in your initial nomination frame. For instance, you could create a new [https:\/\/developer.apple.com\/documentation\/vision\/vntrackobjectrequest] every ten frames.\n\n## Object tracking\n\n- **Tracking the User’s Face in Real Time**: Detect and track faces from the selfie cam feed in real time.\n- **VNTrackingRequest**: The abstract superclass for image-analysis requests that track unique features across multiple images or video frames.\n- **VNTrackRectangleRequest**: An image-analysis request that tracks movement of a previously identified rectangular object across multiple images or video frames.\n- **VNTrackObjectRequest**: An image-analysis request that tracks the movement of a previously identified object across multiple images or video frames.\n- **VNDetectedObjectObservation**: An observation that provides the position and extent of an image feature that an image- analysis request detects.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Detect and track faces from the selfie cam feed in real time.",
          "name" : "Tracking the User’s Face in Real Time",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/tracking-the-user-s-face-in-real-time"
        },
        {
          "description" : "The abstract superclass for image-analysis requests that track unique features across multiple images or video frames.",
          "name" : "VNTrackingRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNTrackingRequest"
        },
        {
          "description" : "An image-analysis request that tracks movement of a previously identified rectangular object across multiple images or video frames.",
          "name" : "VNTrackRectangleRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNTrackRectangleRequest"
        },
        {
          "description" : "An image-analysis request that tracks the movement of a previously identified object across multiple images or video frames.",
          "name" : "VNTrackObjectRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNTrackObjectRequest"
        },
        {
          "description" : "An observation that provides the position and extent of an image feature that an image- analysis request detects.",
          "name" : "VNDetectedObjectObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectedObjectObservation"
        }
      ],
      "title" : "Object tracking"
    }
  ],
  "source" : "appleJSON",
  "title" : "Tracking Multiple Objects or Rectangles in Video",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/tracking-multiple-objects-or-rectangles-in-video"
}