{
  "abstract" : "The result the framework produces by performing a request.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "Copyable",
    "CustomStringConvertible",
    "Equatable",
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "ffb715bf45d14ff4f3d6904dfad7d928a38654e9bf5b8c1bbcd727f94a48a8a3",
  "crawledAt" : "2025-12-05T05:28:17Z",
  "declaration" : {
    "code" : "enum VisionResult",
    "language" : "swift"
  },
  "id" : "678AD771-FF7F-4750-A79A-6ADB6AB5D8D7",
  "kind" : "enum",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nEach result contains the original [doc:\/\/Vision\/documentation\/Vision\/VisionRequest], along with any observations produced.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/visionresult\ncrawled: 2025-12-05T05:28:17Z\n---\n\n# VisionResult\n\n**Enumeration**\n\nThe result the framework produces by performing a request.\n\n## Declaration\n\n```swift\nenum VisionResult\n```\n\n## Overview\n\nEach result contains the original [doc:\/\/Vision\/documentation\/Vision\/VisionRequest], along with any observations produced.\n\n## Getting the still-image result\n\n- **VisionResult.classifyImage(_:_:)**: A result from performing a classify image request.\n\n## Getting the image sequence result\n\n- **VisionResult.generatePersonInstanceMask(_:_:)**: A result from performing a generate person instance mask request.\n- **VisionResult.generatePersonSegmentation(_:_:)**: A result from performing a generate person segmentation request.\n- **VisionResult.detectDocumentSegmentation(_:_:)**: A result from performing a detect document segmentation request.\n- **VisionResult.recognizeDocuments(_:_:)**\n\n## Getting the image aesthetics and lens smudge result\n\n- **VisionResult.calculateImageAestheticsScores(_:_:)**: A result from performing a calculate image aesthetics scores request.\n- **VisionResult.detectLensSmudge(_:_:)**\n\n## Getting the saliency result\n\n- **VisionResult.generateObjectnessBasedSaliencyImage(_:_:)**: A result from performing a generate objectness based saliency image request.\n- **VisionResult.generateAttentionBasedSaliencyImage(_:_:)**: A result from performing a generate attention based saliency image request.\n\n## Getting the object-tracking result\n\n- **VisionResult.trackRectangle(_:_:)**: A result from performing a track rectangle request.\n- **VisionResult.trackObject(_:_:)**: A result from performing a track object request.\n\n## Getting the face and body detection result\n\n- **VisionResult.detectFaceCaptureQuality(_:_:)**: A result from performing a detect face capture quality request.\n- **VisionResult.detectFaceLandmarks(_:_:)**: A result from performing a detect face landmarks request.\n- **VisionResult.detectFaceRectangles(_:_:)**: A result from performing a detect face rectangles request.\n- **VisionResult.detectHumanRectangles(_:_:)**: A result from performing a detect human rectangles request.\n\n## Getting the body and hand pose detection result\n\n- **VisionResult.detectHumanBodyPose(_:_:)**: A result from performing a detect human body pose request.\n- **VisionResult.detectHumanHandPose(_:_:)**: A result from performing a detect human hand pose request.\n- **VisionResult.detectHumanBodyPose3D(_:_:)**: A result from performing a 3D detect human body pose request.\n\n## Getting the animal detection result\n\n- **VisionResult.recognizeAnimals(_:_:)**: A result from performing a recognize animals request.\n- **VisionResult.detectAnimalBodyPose(_:_:)**: A result from performing a detect animal body pose request.\n\n## Getting the text result\n\n- **VisionResult.detectTextRectangles(_:_:)**: A result from performing a detect text rectangles request.\n- **VisionResult.recognizeText(_:_:)**: A result from performing a recognize text request.\n\n## Getting the image alignment, feature print, and background removal result\n\n- **VisionResult.trackTranslationalImageRegistration(_:_:)**: A result from performing a track translational image request.\n- **VisionResult.trackHomographicImageRegistration(_:_:)**: A result from performing a track homographic image request.\n- **VisionResult.generateForegroundInstanceMask(_:_:)**: A result from performing a generate foreground instance mask request.\n- **VisionResult.generateImageFeaturePrint(_:_:)**: A result from performing a generate image feature print request.\n\n## Getting the trajectory, contour, and horizon detection result\n\n- **VisionResult.detectTrajectories(_:_:)**: A result from performing a detect trajectories request.\n- **VisionResult.detectContours(_:_:)**: A result from performing a detect contours request.\n- **VisionResult.detectHorizon(_:_:)**: A result from performing a detect horizon request.\n\n## Getting the optical flow, rectangle and barcode detection result\n\n- **VisionResult.trackOpticalFlow(_:_:)**: A result from performing a track optical flow request.\n- **VisionResult.detectRectangles(_:_:)**: A result from performing a detect rectangles request.\n- **VisionResult.detectBarcodes(_:_:)**: A result from performing a detect barcodes request.\n\n## Getting the machine learning image-analysis result\n\n- **VisionResult.coreML(_:_:)**: A result from performing a Core ML request.\n\n## Getting the error result\n\n- **VisionResult.error(_:_:)**: A result from encountering a framework error.\n\n## Performing the request\n\n- **Result**: An associated type that represents the result.\n\n## Conforms To\n\n- Copyable\n- CustomStringConvertible\n- Equatable\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a classify image request.",
          "name" : "VisionResult.classifyImage(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/classifyImage(_:_:)"
        }
      ],
      "title" : "Getting the still-image result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a generate person instance mask request.",
          "name" : "VisionResult.generatePersonInstanceMask(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/generatePersonInstanceMask(_:_:)"
        },
        {
          "description" : "A result from performing a generate person segmentation request.",
          "name" : "VisionResult.generatePersonSegmentation(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/generatePersonSegmentation(_:_:)"
        },
        {
          "description" : "A result from performing a detect document segmentation request.",
          "name" : "VisionResult.detectDocumentSegmentation(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectDocumentSegmentation(_:_:)"
        },
        {
          "description" : "",
          "name" : "VisionResult.recognizeDocuments(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/recognizeDocuments(_:_:)"
        }
      ],
      "title" : "Getting the image sequence result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a calculate image aesthetics scores request.",
          "name" : "VisionResult.calculateImageAestheticsScores(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/calculateImageAestheticsScores(_:_:)"
        },
        {
          "description" : "",
          "name" : "VisionResult.detectLensSmudge(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectLensSmudge(_:_:)"
        }
      ],
      "title" : "Getting the image aesthetics and lens smudge result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a generate objectness based saliency image request.",
          "name" : "VisionResult.generateObjectnessBasedSaliencyImage(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/generateObjectnessBasedSaliencyImage(_:_:)"
        },
        {
          "description" : "A result from performing a generate attention based saliency image request.",
          "name" : "VisionResult.generateAttentionBasedSaliencyImage(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/generateAttentionBasedSaliencyImage(_:_:)"
        }
      ],
      "title" : "Getting the saliency result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a track rectangle request.",
          "name" : "VisionResult.trackRectangle(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/trackRectangle(_:_:)"
        },
        {
          "description" : "A result from performing a track object request.",
          "name" : "VisionResult.trackObject(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/trackObject(_:_:)"
        }
      ],
      "title" : "Getting the object-tracking result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a detect face capture quality request.",
          "name" : "VisionResult.detectFaceCaptureQuality(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectFaceCaptureQuality(_:_:)"
        },
        {
          "description" : "A result from performing a detect face landmarks request.",
          "name" : "VisionResult.detectFaceLandmarks(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectFaceLandmarks(_:_:)"
        },
        {
          "description" : "A result from performing a detect face rectangles request.",
          "name" : "VisionResult.detectFaceRectangles(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectFaceRectangles(_:_:)"
        },
        {
          "description" : "A result from performing a detect human rectangles request.",
          "name" : "VisionResult.detectHumanRectangles(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectHumanRectangles(_:_:)"
        }
      ],
      "title" : "Getting the face and body detection result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a detect human body pose request.",
          "name" : "VisionResult.detectHumanBodyPose(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectHumanBodyPose(_:_:)"
        },
        {
          "description" : "A result from performing a detect human hand pose request.",
          "name" : "VisionResult.detectHumanHandPose(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectHumanHandPose(_:_:)"
        },
        {
          "description" : "A result from performing a 3D detect human body pose request.",
          "name" : "VisionResult.detectHumanBodyPose3D(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectHumanBodyPose3D(_:_:)"
        }
      ],
      "title" : "Getting the body and hand pose detection result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a recognize animals request.",
          "name" : "VisionResult.recognizeAnimals(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/recognizeAnimals(_:_:)"
        },
        {
          "description" : "A result from performing a detect animal body pose request.",
          "name" : "VisionResult.detectAnimalBodyPose(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectAnimalBodyPose(_:_:)"
        }
      ],
      "title" : "Getting the animal detection result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a detect text rectangles request.",
          "name" : "VisionResult.detectTextRectangles(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectTextRectangles(_:_:)"
        },
        {
          "description" : "A result from performing a recognize text request.",
          "name" : "VisionResult.recognizeText(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/recognizeText(_:_:)"
        }
      ],
      "title" : "Getting the text result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a track translational image request.",
          "name" : "VisionResult.trackTranslationalImageRegistration(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/trackTranslationalImageRegistration(_:_:)"
        },
        {
          "description" : "A result from performing a track homographic image request.",
          "name" : "VisionResult.trackHomographicImageRegistration(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/trackHomographicImageRegistration(_:_:)"
        },
        {
          "description" : "A result from performing a generate foreground instance mask request.",
          "name" : "VisionResult.generateForegroundInstanceMask(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/generateForegroundInstanceMask(_:_:)"
        },
        {
          "description" : "A result from performing a generate image feature print request.",
          "name" : "VisionResult.generateImageFeaturePrint(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/generateImageFeaturePrint(_:_:)"
        }
      ],
      "title" : "Getting the image alignment, feature print, and background removal result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a detect trajectories request.",
          "name" : "VisionResult.detectTrajectories(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectTrajectories(_:_:)"
        },
        {
          "description" : "A result from performing a detect contours request.",
          "name" : "VisionResult.detectContours(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectContours(_:_:)"
        },
        {
          "description" : "A result from performing a detect horizon request.",
          "name" : "VisionResult.detectHorizon(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectHorizon(_:_:)"
        }
      ],
      "title" : "Getting the trajectory, contour, and horizon detection result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a track optical flow request.",
          "name" : "VisionResult.trackOpticalFlow(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/trackOpticalFlow(_:_:)"
        },
        {
          "description" : "A result from performing a detect rectangles request.",
          "name" : "VisionResult.detectRectangles(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectRectangles(_:_:)"
        },
        {
          "description" : "A result from performing a detect barcodes request.",
          "name" : "VisionResult.detectBarcodes(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/detectBarcodes(_:_:)"
        }
      ],
      "title" : "Getting the optical flow, rectangle and barcode detection result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from performing a Core ML request.",
          "name" : "VisionResult.coreML(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/coreML(_:_:)"
        }
      ],
      "title" : "Getting the machine learning image-analysis result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A result from encountering a framework error.",
          "name" : "VisionResult.error(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionResult\/error(_:_:)"
        }
      ],
      "title" : "Getting the error result"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An associated type that represents the result.",
          "name" : "Result",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VisionRequest\/Result"
        }
      ],
      "title" : "Performing the request"
    }
  ],
  "source" : "appleJSON",
  "title" : "VisionResult",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/visionresult"
}