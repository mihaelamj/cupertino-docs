{
  "abstract" : "Begins analyzing video frames.",
  "codeExamples" : [

  ],
  "contentHash" : "8f410ef19ba9646057bdf7479e0727cf8fc5525f61a15ae405490309b821ca66",
  "crawledAt" : "2025-12-04T01:01:59Z",
  "declaration" : {
    "code" : "final func startAnalysis(of timeRange: CMTimeRange? = nil)",
    "language" : "swift"
  },
  "id" : "455CAC26-D3D0-4AB0-A645-31B4B89E5512",
  "kind" : "method",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Discussion\n\nBy default the framework processes the entire video.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/VideoProcessor\/startAnalysis(of:)\ncrawled: 2025-12-04T01:01:59Z\n---\n\n# startAnalysis(of:)\n\n**Instance Method**\n\nBegins analyzing video frames.\n\n## Declaration\n\n```swift\nfinal func startAnalysis(of timeRange: CMTimeRange? = nil)\n```\n\n## Parameters\n\n- **timeRange**: The range of video timestamps to process.\n\n## Discussion\n\nBy default the framework processes the entire video.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "startAnalysis(of:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VideoProcessor\/startAnalysis(of:)"
}