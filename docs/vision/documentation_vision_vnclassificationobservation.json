{
  "abstract" : "An object that represents classification information that an image-analysis request produces.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCoding",
    "NSCopying",
    "NSObjectProtocol",
    "NSSecureCoding",
    "VNRequestRevisionProviding"
  ],
  "contentHash" : "a7c93ff75efc39f180be87272f7f498bea2106571c1f1214162509265d79c9ff",
  "crawledAt" : "2025-12-04T01:03:39Z",
  "declaration" : {
    "code" : "class VNClassificationObservation",
    "language" : "swift"
  },
  "id" : "98426B3F-3864-4C86-BCC1-F777207E6726",
  "kind" : "class",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nThis type of observation results from performing a [doc:\/\/Vision\/documentation\/Vision\/VNCoreMLRequest] image analysis with a Core ML model whose role is classification (rather than prediction or image-to-image processing). Vision infers that an [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel] object is a classifier model if that model predicts a single feature. That is, the model’s [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel\/modelDescription] object has a non-`nil` value for its [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModelDescription\/predictedFeatureName] property.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/vision\/vnclassificationobservation\ncrawled: 2025-12-04T01:03:39Z\n---\n\n# VNClassificationObservation\n\n**Class**\n\nAn object that represents classification information that an image-analysis request produces.\n\n## Declaration\n\n```swift\nclass VNClassificationObservation\n```\n\n## Overview\n\nThis type of observation results from performing a [doc:\/\/Vision\/documentation\/Vision\/VNCoreMLRequest] image analysis with a Core ML model whose role is classification (rather than prediction or image-to-image processing). Vision infers that an [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel] object is a classifier model if that model predicts a single feature. That is, the model’s [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModel\/modelDescription] object has a non-`nil` value for its [doc:\/\/com.apple.documentation\/documentation\/CoreML\/MLModelDescription\/predictedFeatureName] property.\n\n## Determining Classification\n\n- **identifier**: Classification label identifying the type of observation.\n\n## Measuring Confidence and Precision\n\n- **hasPrecisionRecallCurve**: A Boolean variable indicating whether the observation contains precision and recall curves.\n- **hasMinimumPrecision(_:forRecall:)**: Determines whether the observation for a specific recall has a minimum precision value.\n- **hasMinimumRecall(_:forPrecision:)**: Determines whether the observation for a specific precision has a minimum recall value.\n\n## Machine learning image analysis\n\n- **Classifying Images with Vision and Core ML**: Crop and scale photos using the Vision framework and classify them with a Core ML model.\n- **Training a Create ML Model to Classify Flowers**: Train a flower classifier using Create ML in Swift Playgrounds, and apply the resulting model to real-time image classification using Vision.\n- **VNCoreMLRequest**: An image-analysis request that uses a Core ML model to process images.\n- **VNPixelBufferObservation**: An object that represents an image that an image-analysis request produces.\n- **VNCoreMLFeatureValueObservation**: An object that represents a collection of key-value information that a Core ML image-analysis request produces.\n\n## Inherits From\n\n- VNObservation\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCoding\n- NSCopying\n- NSObjectProtocol\n- NSSecureCoding\n- VNRequestRevisionProviding\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Classification label identifying the type of observation.",
          "name" : "identifier",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNClassificationObservation\/identifier"
        }
      ],
      "title" : "Determining Classification"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A Boolean variable indicating whether the observation contains precision and recall curves.",
          "name" : "hasPrecisionRecallCurve",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNClassificationObservation\/hasPrecisionRecallCurve"
        },
        {
          "description" : "Determines whether the observation for a specific recall has a minimum precision value.",
          "name" : "hasMinimumPrecision(_:forRecall:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNClassificationObservation\/hasMinimumPrecision(_:forRecall:)"
        },
        {
          "description" : "Determines whether the observation for a specific precision has a minimum recall value.",
          "name" : "hasMinimumRecall(_:forPrecision:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNClassificationObservation\/hasMinimumRecall(_:forPrecision:)"
        }
      ],
      "title" : "Measuring Confidence and Precision"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Crop and scale photos using the Vision framework and classify them with a Core ML model.",
          "name" : "Classifying Images with Vision and Core ML",
          "url" : "https:\/\/developer.apple.com\/documentation\/CoreML\/classifying-images-with-vision-and-core-ml"
        },
        {
          "description" : "Train a flower classifier using Create ML in Swift Playgrounds, and apply the resulting model to real-time image classification using Vision.",
          "name" : "Training a Create ML Model to Classify Flowers",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/training-a-create-ml-model-to-classify-flowers"
        },
        {
          "description" : "An image-analysis request that uses a Core ML model to process images.",
          "name" : "VNCoreMLRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest"
        },
        {
          "description" : "An object that represents an image that an image-analysis request produces.",
          "name" : "VNPixelBufferObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNPixelBufferObservation"
        },
        {
          "description" : "An object that represents a collection of key-value information that a Core ML image-analysis request produces.",
          "name" : "VNCoreMLFeatureValueObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLFeatureValueObservation"
        }
      ],
      "title" : "Machine learning image analysis"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "VNObservation"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "VNClassificationObservation",
  "url" : "https:\/\/developer.apple.com\/documentation\/vision\/vnclassificationobservation"
}