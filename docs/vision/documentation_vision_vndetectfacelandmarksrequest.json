{
  "abstract" : "An image-analysis request that finds facial features like eyes and mouth in an image.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSCopying",
    "NSObjectProtocol",
    "VNFaceObservationAccepting"
  ],
  "contentHash" : "592d48e30e2fd15b656e82704019fef4d75ebe4e54997022de2d224fbaa55c4f",
  "crawledAt" : "2025-12-02T16:21:07Z",
  "declaration" : {
    "code" : "class VNDetectFaceLandmarksRequest",
    "language" : "swift"
  },
  "id" : "45E1356B-895C-4489-BA8E-81686699D973",
  "kind" : "class",
  "language" : "swift",
  "module" : "Vision",
  "overview" : "## Overview\n\nBy default, a face landmarks request first locates all faces in the input image, then analyzes each to detect facial features.\n\nIf you’ve already located all the faces in an image, or want to detect landmarks in only a subset of the faces in the image, set the [doc:\/\/Vision\/documentation\/Vision\/VNFaceObservationAccepting\/inputFaceObservations] property to an array of [doc:\/\/Vision\/documentation\/Vision\/VNFaceObservation] objects representing the faces you want to analyze. You can either use face observations output by a [doc:\/\/Vision\/documentation\/Vision\/VNDetectFaceRectanglesRequest] or manually create [doc:\/\/Vision\/documentation\/Vision\/VNFaceObservation] instances with the bounding boxes of the faces you want to analyze.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequest\ncrawled: 2025-12-02T16:21:07Z\n---\n\n# VNDetectFaceLandmarksRequest\n\n**Class**\n\nAn image-analysis request that finds facial features like eyes and mouth in an image.\n\n## Declaration\n\n```swift\nclass VNDetectFaceLandmarksRequest\n```\n\n## Overview\n\nBy default, a face landmarks request first locates all faces in the input image, then analyzes each to detect facial features.\n\nIf you’ve already located all the faces in an image, or want to detect landmarks in only a subset of the faces in the image, set the [doc:\/\/Vision\/documentation\/Vision\/VNFaceObservationAccepting\/inputFaceObservations] property to an array of [doc:\/\/Vision\/documentation\/Vision\/VNFaceObservation] objects representing the faces you want to analyze. You can either use face observations output by a [doc:\/\/Vision\/documentation\/Vision\/VNDetectFaceRectanglesRequest] or manually create [doc:\/\/Vision\/documentation\/Vision\/VNFaceObservation] instances with the bounding boxes of the faces you want to analyze.\n\n## Configuring a Face Landmarks Request\n\n- **VNFaceObservationAccepting**: An image analysis request that operates on face observations.\n\n## Accessing the Results\n\n- **results**: The results of the face landmarks request.\n- **VNFaceObservation**: Face or facial-feature information that an image analysis request detects.\n\n## Locating Face Landmarks\n\n- **constellation**: A variable that describes how a face landmarks request orders or enumerates the resulting features.\n- **VNRequestFaceLandmarksConstellation**: An enumeration of face landmarks in a constellation object.\n\n## Identifying Request Revisions\n\n- **revision(_:supportsConstellation:)**: Returns a Boolean value that indicates whether a revision supports a constellation.\n- **VNDetectFaceLandmarksRequestRevision3**: A constant for specifying revision 3 of the face landmarks detection request.\n- **VNDetectFaceLandmarksRequestRevision2**: A constant for specifying revision 2 of the face landmarks detection request.\n- **VNDetectFaceLandmarksRequestRevision1**: A constant for specifying revision 1 of the face landmarks detection request.\n\n## Face and body detection\n\n- **Selecting a selfie based on capture quality**: Compare face-capture quality in a set of images by using Vision.\n- **VNDetectFaceCaptureQualityRequest**: A request that produces a floating-point number that represents the capture quality of a face in a photo.\n- **VNDetectFaceRectanglesRequest**: A request that finds faces within an image.\n- **VNDetectHumanRectanglesRequest**: A request that finds rectangular regions that contain people in an image.\n- **VNHumanObservation**: An object that represents a person that the request detects.\n\n## Inherits From\n\n- VNImageBasedRequest\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSCopying\n- NSObjectProtocol\n- VNFaceObservationAccepting\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "An image analysis request that operates on face observations.",
          "name" : "VNFaceObservationAccepting",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNFaceObservationAccepting"
        }
      ],
      "title" : "Configuring a Face Landmarks Request"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The results of the face landmarks request.",
          "name" : "results",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequest\/results"
        },
        {
          "description" : "Face or facial-feature information that an image analysis request detects.",
          "name" : "VNFaceObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNFaceObservation"
        }
      ],
      "title" : "Accessing the Results"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "A variable that describes how a face landmarks request orders or enumerates the resulting features.",
          "name" : "constellation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequest\/constellation"
        },
        {
          "description" : "An enumeration of face landmarks in a constellation object.",
          "name" : "VNRequestFaceLandmarksConstellation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNRequestFaceLandmarksConstellation"
        }
      ],
      "title" : "Locating Face Landmarks"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Returns a Boolean value that indicates whether a revision supports a constellation.",
          "name" : "revision(_:supportsConstellation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequest\/revision(_:supportsConstellation:)"
        },
        {
          "description" : "A constant for specifying revision 3 of the face landmarks detection request.",
          "name" : "VNDetectFaceLandmarksRequestRevision3",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequestRevision3"
        },
        {
          "description" : "A constant for specifying revision 2 of the face landmarks detection request.",
          "name" : "VNDetectFaceLandmarksRequestRevision2",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequestRevision2"
        },
        {
          "description" : "A constant for specifying revision 1 of the face landmarks detection request.",
          "name" : "VNDetectFaceLandmarksRequestRevision1",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequestRevision1"
        }
      ],
      "title" : "Identifying Request Revisions"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Compare face-capture quality in a set of images by using Vision.",
          "name" : "Selecting a selfie based on capture quality",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/selecting-a-selfie-based-on-capture-quality"
        },
        {
          "description" : "A request that produces a floating-point number that represents the capture quality of a face in a photo.",
          "name" : "VNDetectFaceCaptureQualityRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceCaptureQualityRequest"
        },
        {
          "description" : "A request that finds faces within an image.",
          "name" : "VNDetectFaceRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceRectanglesRequest"
        },
        {
          "description" : "A request that finds rectangular regions that contain people in an image.",
          "name" : "VNDetectHumanRectanglesRequest",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectHumanRectanglesRequest"
        },
        {
          "description" : "An object that represents a person that the request detects.",
          "name" : "VNHumanObservation",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNHumanObservation"
        }
      ],
      "title" : "Face and body detection"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "VNImageBasedRequest"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "VNDetectFaceLandmarksRequest",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNDetectFaceLandmarksRequest"
}