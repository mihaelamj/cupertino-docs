{
  "abstract" : "A container for the model to use with Vision requests.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "CVarArg",
    "CustomDebugStringConvertible",
    "CustomStringConvertible",
    "Equatable",
    "Hashable",
    "NSObjectProtocol"
  ],
  "contentHash" : "b96beb1f997b122f7d17407adaff8f4f40b71211a3f898e702eac334acb15ecc",
  "crawledAt" : "2025-12-01T02:31:47Z",
  "declaration" : {
    "code" : "class VNCoreMLModel",
    "language" : "swift"
  },
  "id" : "E3528E07-5583-407A-B7D3-305932CF7D2B",
  "kind" : "class",
  "module" : "Vision",
  "overview" : "## Overview\n\nA [doc:\/\/com.apple.documentation\/documentation\/CoreML] model encapsulates the information trained from a data set used to drive Vision recognition requests. See [doc:\/\/com.apple.documentation\/documentation\/CoreML\/getting-a-core-ml-model] for instructions on training your own model. Once you train the model, use this class to initialize a [doc:\/\/Vision\/documentation\/Vision\/VNCoreMLRequest] for identification.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLModel\ncrawled: 2025-12-01T02:31:47Z\n---\n\n# VNCoreMLModel\n\n**Class**\n\nA container for the model to use with Vision requests.\n\n## Declaration\n\n```swift\nclass VNCoreMLModel\n```\n\n## Overview\n\nA [doc:\/\/com.apple.documentation\/documentation\/CoreML] model encapsulates the information trained from a data set used to drive Vision recognition requests. See [doc:\/\/com.apple.documentation\/documentation\/CoreML\/getting-a-core-ml-model] for instructions on training your own model. Once you train the model, use this class to initialize a [doc:\/\/Vision\/documentation\/Vision\/VNCoreMLRequest] for identification.\n\n## Initializing a Model\n\n- **init(for:)**: Creates a model container to use with a Core ML request.\n\n## Providing Features\n\n- **featureProvider**: An optional object to support inputs outside Vision.\n- **inputImageFeatureName**: The name of the feature value that Vision sets from the request handler.\n\n## Initializing with a Core ML Model\n\n- **init(model:)**: Creates a model container to use with an image analysis request based on the model you provide.\n- **init(model:completionHandler:)**: Creates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.\n- **model**: The model to base the image analysis request on.\n\n## Inherits From\n\n- NSObject\n\n## Conforms To\n\n- CVarArg\n- CustomDebugStringConvertible\n- CustomStringConvertible\n- Equatable\n- Hashable\n- NSObjectProtocol\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a model container to use with a Core ML request.",
          "name" : "init(for:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLModel\/init(for:)"
        }
      ],
      "title" : "Initializing a Model"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An optional object to support inputs outside Vision.",
          "name" : "featureProvider",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLModel\/featureProvider"
        },
        {
          "description" : "The name of the feature value that Vision sets from the request handler.",
          "name" : "inputImageFeatureName",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLModel\/inputImageFeatureName"
        }
      ],
      "title" : "Providing Features"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a model container to use with an image analysis request based on the model you provide.",
          "name" : "init(model:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:)"
        },
        {
          "description" : "Creates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.",
          "name" : "init(model:completionHandler:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/init(model:completionHandler:)"
        },
        {
          "description" : "The model to base the image analysis request on.",
          "name" : "model",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLRequest\/model"
        }
      ],
      "title" : "Initializing with a Core ML Model"
    },
    {
      "content" : "",
      "items" : [
        {
          "name" : "NSObject"
        }
      ],
      "title" : "Inherits From"
    }
  ],
  "source" : "appleJSON",
  "title" : "VNCoreMLModel",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/VNCoreMLModel"
}