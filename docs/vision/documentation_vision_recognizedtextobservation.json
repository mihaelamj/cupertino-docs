{
  "abstract" : "An object that contains information about both the location and content of text and glyphs that the framework recognizes in an image.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "BoundingBoxProviding",
    "Copyable",
    "CustomStringConvertible",
    "Decodable",
    "Encodable",
    "Equatable",
    "Hashable",
    "QuadrilateralProviding",
    "Sendable",
    "SendableMetatype",
    "VisionObservation"
  ],
  "contentHash" : "b2aba74184058b9f637fbe99b5f08d704ceb2c2ed2024e82b028360a34cee5d2",
  "crawledAt" : "2025-12-02T18:15:00Z",
  "declaration" : {
    "code" : "struct RecognizedTextObservation",
    "language" : "swift"
  },
  "id" : "D0BA78F5-8418-4FBB-AF01-53162C780DDA",
  "kind" : "struct",
  "language" : "swift",
  "module" : "Vision",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\ncrawled: 2025-12-02T18:15:00Z\n---\n\n# RecognizedTextObservation\n\n**Structure**\n\nAn object that contains information about both the location and content of text and glyphs that the framework recognizes in an image.\n\n## Declaration\n\n```swift\nstruct RecognizedTextObservation\n```\n\n## Creating an observation\n\n- **init(_:)**: Creates a recognized text observation.\n\n## Inspecting an observation\n\n- **boundingRegion**: The bounding region of the text.\n- **isTitle**: Whether this text is the title of the document.\n- **recognitionLanguages**: The languages in which the recognized text was written.\n- **shouldWrapToNextLine**: Whether the text continues on the next line.\n- **textDirection**\n- **RecognizedTextObservation.Direction**: An enum representing which direction the text is read.\n- **transcript**: The top text candidate as a string.\n\n## Getting the recognized text\n\n- **topCandidates(_:)**: Requests the top candidates for a recognized text string.\n- **RecognizedText**: Text recognized in an image through a text recognition request.\n\n## Performing a request\n\n- **perform(on:orientation:)**: Performs the request on an image URL and produces observations.\n- **perform(on:orientation:)**: Performs the request on image data and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Graphics image and produces observations.\n- **perform(on:orientation:)**: Performs the request on a pixel buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Media buffer and produces observations.\n- **perform(on:orientation:)**: Performs the request on a Core Image image and produces observations.\n\n## Conforms To\n\n- BoundingBoxProviding\n- Copyable\n- CustomStringConvertible\n- Decodable\n- Encodable\n- Equatable\n- Hashable\n- QuadrilateralProviding\n- Sendable\n- SendableMetatype\n- VisionObservation\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates a recognized text observation.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/init(_:)"
        }
      ],
      "title" : "Creating an observation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The bounding region of the text.",
          "name" : "boundingRegion",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/boundingRegion"
        },
        {
          "description" : "Whether this text is the title of the document.",
          "name" : "isTitle",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/isTitle"
        },
        {
          "description" : "The languages in which the recognized text was written.",
          "name" : "recognitionLanguages",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/recognitionLanguages"
        },
        {
          "description" : "Whether the text continues on the next line.",
          "name" : "shouldWrapToNextLine",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/shouldWrapToNextLine"
        },
        {
          "description" : "",
          "name" : "textDirection",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/textDirection"
        },
        {
          "description" : "An enum representing which direction the text is read.",
          "name" : "RecognizedTextObservation.Direction",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/Direction"
        },
        {
          "description" : "The top text candidate as a string.",
          "name" : "transcript",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/transcript"
        }
      ],
      "title" : "Inspecting an observation"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Requests the top candidates for a recognized text string.",
          "name" : "topCandidates(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation\/topCandidates(_:)"
        },
        {
          "description" : "Text recognized in an image through a text recognition request.",
          "name" : "RecognizedText",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedText"
        }
      ],
      "title" : "Getting the recognized text"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Performs the request on an image URL and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-80bya"
        },
        {
          "description" : "Performs the request on image data and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3f3f1"
        },
        {
          "description" : "Performs the request on a Core Graphics image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-qxxx"
        },
        {
          "description" : "Performs the request on a pixel buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-xspx"
        },
        {
          "description" : "Performs the request on a Core Media buffer and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-3hddl"
        },
        {
          "description" : "Performs the request on a Core Image image and produces observations.",
          "name" : "perform(on:orientation:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/ImageProcessingRequest\/perform(on:orientation:)-85ex1"
        }
      ],
      "title" : "Performing a request"
    }
  ],
  "source" : "appleJSON",
  "title" : "RecognizedTextObservation",
  "url" : "https:\/\/developer.apple.com\/documentation\/Vision\/RecognizedTextObservation"
}