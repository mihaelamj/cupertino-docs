{
  "abstract" : "Eliminate issues in your audio-specific code when running on Apple silicon Mac computers.",
  "codeExamples" : [

  ],
  "contentHash" : "81fc2f311086c136ec07fc48ad3e1d416cc55d166290ad2f37eb921d65cafcc9",
  "crawledAt" : "2025-12-03T10:26:41Z",
  "id" : "C521BA82-83F6-4636-B9DF-65521C014B7C",
  "kind" : "article",
  "language" : "swift",
  "overview" : "## Overview\n\nInclude time in your porting plans to migrate code that uses the Core Audio family of frameworks. In particular, update your Audio Units to support Apple silicon, and optimize any real-time code to run efficiently on all Mac computers.\n\n### Create Universal Versions of Your Host App and Audio Units\n\nAlways create universal versions of your audio host app and Audio Unit plug-ins. Universal binaries ensure that your code runs natively on all platforms, which gives you the opportunity to optimize your code for each platform.\n\nBecause the host app controls the execution environment, providing universal Audio Units is particularly important. If your Audio Unit contains code for both `arm64` and `x86_64` architectures, a host app can load your Audio Unit either in-process or out-of-process. The ability to load Audio Units in-process is still important for some apps, such as those that require minimal latency.\n\nTo learn how to create a universal binary, see [doc:\/\/com.apple.Apple-Silicon\/documentation\/Apple-Silicon\/building-a-universal-macos-binary].\n\n### Support the Modern Audio Component Architecture\n\nFor the `arm64` architecture, always use the Audio Component API to load Audio Units, codecs, and other code modules into your app. The Audio Component API is the modern way to search for loadable code modules, and it’s available in macOS 10.6 and later. Apps that target the `arm64` architecture or link against the macOS 11 SDK cannot use the legacy Carbon Component Manager API to open Audio Units. If your app uses the Carbon Component Manager, plan to migrate off of it when porting your app.\n\nIf you develop Audio Units or codecs, update your code to support the Audio Component or Audio Unit Extension APIs if you haven’t already done so. When you link an Audio Unit or codec against the macOS 11 (or later) SDK, use one of these modern APIs instead of the Carbon Component API.\n\nFor information about the Audio Component API, see the [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox] framework.\n\n### Prioritize Realtime Threads Using Workgroups\n\nApps that perform realtime audio processing need to ensure that their threads run at regular intervals. In some cases, your app or Audio Unit may also need to coordinate with threads from the audio server or a host app to ensure timely processing of audio. For both of these situations, use workgroups to communicate the scheduling needs of your realtime threads to the system.\n\nEach Core Audio device provides a workgroup that other realtime threads can join using the `os_workgroup_join_self` function. Joining the audio device workgroup tells the system that your app’s realtime threads are working toward the same deadline as the device’s thread. You access the workgroup associated with a device in one of several ways:\n\nIf your Audio Unit creates its own realtime audio processing threads for rendering, coordinate the activity of those threads with the host app by joining the threads to the host app’s workgroup. To obtain the host app’s workgroup, return an [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AURenderContextObserver] block from the [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/auaudiounit\/3579515-rendercontextobserver] property of your [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AUAudioUnit] object. (For v2 Audio Units, return the [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AURenderContextObserver] block as the data for your Audio Unit’s [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/1534199-general_audio_unit_properties\/kaudiounitproperty_rendercontextobserver] property.) When the system executes your block, retrieve the host app’s workgroup from the provided [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AudioUnitRenderContext] object. The host’s workgroup may change between rendering calls. If it does, update your realtime audio threads to join the workgroup that the system passes to your block, and to leave their previous workgroup.\n\nIf your realtime audio threads operate on different deadlines than Core Audio threads, create your own interval workgroup using the [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/3547073-audioworkintervalcreate] function. For workgroups you create, join your threads to the workgroup and call the [doc:\/\/com.apple.documentation\/documentation\/os\/3548458-os_workgroup_interval_start] function from one thread. When you call that function, specify the time at which you expected your thread to wake up and process the audio. Upon completion of the work, call the [doc:\/\/com.apple.documentation\/documentation\/os\/3548457-os_workgroup_interval_finish] function to tell the system that you finished the work associated with the current deadline.\n\nFor information about the Core Audio workgroups, see the reference for [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/apple-silicon\/porting-your-audio-code-to-apple-silicon\ncrawled: 2025-12-03T10:26:41Z\n---\n\n# Porting your audio code to Apple silicon\n\n**Article**\n\nEliminate issues in your audio-specific code when running on Apple silicon Mac computers.\n\n## Overview\n\nInclude time in your porting plans to migrate code that uses the Core Audio family of frameworks. In particular, update your Audio Units to support Apple silicon, and optimize any real-time code to run efficiently on all Mac computers.\n\n### Create Universal Versions of Your Host App and Audio Units\n\nAlways create universal versions of your audio host app and Audio Unit plug-ins. Universal binaries ensure that your code runs natively on all platforms, which gives you the opportunity to optimize your code for each platform.\n\nBecause the host app controls the execution environment, providing universal Audio Units is particularly important. If your Audio Unit contains code for both `arm64` and `x86_64` architectures, a host app can load your Audio Unit either in-process or out-of-process. The ability to load Audio Units in-process is still important for some apps, such as those that require minimal latency.\n\nTo learn how to create a universal binary, see [doc:\/\/com.apple.Apple-Silicon\/documentation\/Apple-Silicon\/building-a-universal-macos-binary].\n\n### Support the Modern Audio Component Architecture\n\nFor the `arm64` architecture, always use the Audio Component API to load Audio Units, codecs, and other code modules into your app. The Audio Component API is the modern way to search for loadable code modules, and it’s available in macOS 10.6 and later. Apps that target the `arm64` architecture or link against the macOS 11 SDK cannot use the legacy Carbon Component Manager API to open Audio Units. If your app uses the Carbon Component Manager, plan to migrate off of it when porting your app.\n\nIf you develop Audio Units or codecs, update your code to support the Audio Component or Audio Unit Extension APIs if you haven’t already done so. When you link an Audio Unit or codec against the macOS 11 (or later) SDK, use one of these modern APIs instead of the Carbon Component API.\n\n\n\nFor information about the Audio Component API, see the [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox] framework.\n\n### Prioritize Realtime Threads Using Workgroups\n\nApps that perform realtime audio processing need to ensure that their threads run at regular intervals. In some cases, your app or Audio Unit may also need to coordinate with threads from the audio server or a host app to ensure timely processing of audio. For both of these situations, use workgroups to communicate the scheduling needs of your realtime threads to the system.\n\nEach Core Audio device provides a workgroup that other realtime threads can join using the `os_workgroup_join_self` function. Joining the audio device workgroup tells the system that your app’s realtime threads are working toward the same deadline as the device’s thread. You access the workgroup associated with a device in one of several ways:\n\n- Fetch the [doc:\/\/com.apple.documentation\/documentation\/CoreAudio\/kAudioDevicePropertyIOThreadOSWorkgroup] property of the device.\n- Fetch the [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/1534116-i_o_audio_unit_properties\/kaudiooutputunitproperty_osworkgroup] property of an audio I\/O unit (AUHAL or AURemoteIO).\n- Get it from the [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/auaudiounit\/3547046-osworkgroup] property of an [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AUAudioUnit] object that acts as an input\/output unit.\n\nIf your Audio Unit creates its own realtime audio processing threads for rendering, coordinate the activity of those threads with the host app by joining the threads to the host app’s workgroup. To obtain the host app’s workgroup, return an [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AURenderContextObserver] block from the [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/auaudiounit\/3579515-rendercontextobserver] property of your [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AUAudioUnit] object. (For v2 Audio Units, return the [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AURenderContextObserver] block as the data for your Audio Unit’s [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/1534199-general_audio_unit_properties\/kaudiounitproperty_rendercontextobserver] property.) When the system executes your block, retrieve the host app’s workgroup from the provided [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AudioUnitRenderContext] object. The host’s workgroup may change between rendering calls. If it does, update your realtime audio threads to join the workgroup that the system passes to your block, and to leave their previous workgroup.\n\nIf your realtime audio threads operate on different deadlines than Core Audio threads, create your own interval workgroup using the [doc:\/\/com.apple.documentation\/documentation\/audiotoolbox\/3547073-audioworkintervalcreate] function. For workgroups you create, join your threads to the workgroup and call the [doc:\/\/com.apple.documentation\/documentation\/os\/3548458-os_workgroup_interval_start] function from one thread. When you call that function, specify the time at which you expected your thread to wake up and process the audio. Upon completion of the work, call the [doc:\/\/com.apple.documentation\/documentation\/os\/3548457-os_workgroup_interval_finish] function to tell the system that you finished the work associated with the current deadline.\n\nFor information about the Core Audio workgroups, see the reference for [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox].\n\n## General porting tips\n\n- **Addressing architectural differences in your macOS code**: Fix problems that stem from architectural differences between Apple silicon and Intel-based Mac computers.\n- **Porting just-in-time compilers to Apple silicon**: Update your just-in-time (JIT) compiler to work with the Hardened Runtime capability, and with Apple silicon.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Fix problems that stem from architectural differences between Apple silicon and Intel-based Mac computers.",
          "name" : "Addressing architectural differences in your macOS code",
          "url" : "https:\/\/developer.apple.com\/documentation\/Apple-Silicon\/addressing-architectural-differences-in-your-macos-code"
        },
        {
          "description" : "Update your just-in-time (JIT) compiler to work with the Hardened Runtime capability, and with Apple silicon.",
          "name" : "Porting just-in-time compilers to Apple silicon",
          "url" : "https:\/\/developer.apple.com\/documentation\/Apple-Silicon\/porting-just-in-time-compilers-to-apple-silicon"
        }
      ],
      "title" : "General porting tips"
    }
  ],
  "source" : "appleJSON",
  "title" : "Porting your audio code to Apple silicon",
  "url" : "https:\/\/developer.apple.com\/documentation\/apple-silicon\/porting-your-audio-code-to-apple-silicon"
}