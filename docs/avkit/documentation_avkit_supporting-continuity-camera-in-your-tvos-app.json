{
  "abstract" : "Capture high-quality photos, video, and audio in your Apple TV app by connecting an iPhone or iPad as a continuity device.",
  "codeExamples" : [
    {
      "code" : ".continuityDevicePicker(isPresented: $showContinuityDevicePicker,\n                        onDidConnect: handleNewConnectionForDevice)\n.task {\n    \/\/ Shows the picker when app has no continuity device at launch.\n    if !captureManager.activateDefaultContinuityCameraDevice() {\n        showContinuityDevicePicker = true\n    }",
      "language" : "swift"
    },
    {
      "code" : "func handleNewConnectionForDevice(_ device: AVContinuityDevice?) {\n    guard let device else {\n        print(\"The Continuity Device Picker didn't connect a device.\")\n        return\n    }\n\n    guard let firstCamera = device.videoDevices.first else {\n        print(\"The Continuity Device Picker doesn't have any cameras.\")\n        return\n    }\n\n    captureManager.setActiveVideoInput(firstCamera,\n                                       isUserPreferredCamera: true)\n}",
      "language" : "swift"
    },
    {
      "code" : "let name = camera.localizedName\nprint(\"Setting video input to: \\(name).\")\n\n\/\/ Creates a video input with the camera.\nguard let videoInput = try? AVCaptureDeviceInput(device: camera) else {\n    print(\"Couldn't make an input from: \\(name).\")\n    return false\n}\n\n\/\/ Checks whether the capture session accepts the new camera as an input.\nguard session.canAddInput(videoInput) else {\n    print(\"Capture session rejected '\\(name)' as an input.\")\n    return false\n}\n\n\/\/ Adds the new camera input to the capture session.\nactiveInput = videoInput",
      "language" : "swift"
    },
    {
      "code" : "internal var activeInput: AVCaptureDeviceInput? {\n    willSet {\n        if let oldInput = activeInput {\n            session.removeInput(oldInput)\n        }\n    }\n    didSet {\n        if let newInput = activeInput {\n            session.addInput(newInput)\n        }\n        isActive = (activeInput != nil)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "func observeCamera(_ camera: AVCaptureDevice) {\n    \/\/ Tells the observer to watch the new camera's properties.\n    videoEffectsObvserver.observeCamera(camera)\n\n    \/\/ Tells the notification observer to monitor camera-related events.\n    notificationObserver.observeCamera(camera,\n                                       with: notification(_:for:))\n}",
      "language" : "swift"
    },
    {
      "code" : "private static let inputAvailableKeyPath = \"isInputAvailable\"\n\nfunc registerForInputAvailabilityUpdates(on session: AVAudioSession) {\n    session.addObserver(self,\n                        forKeyPath: Self.inputAvailableKeyPath,\n                        options: [.new],\n                        context: nil)\n}",
      "language" : "swift"
    },
    {
      "code" : "func setupAndStartAudioSession() {\n    configureAudioOutput()\n    enableVoiceProcessing(true)\n    configureAudioSessionForVoiceChat()\n    startAudioEngine()\n}",
      "language" : "swift"
    },
    {
      "code" : "try avAudioSession.setCategory(.playAndRecord,\n                               mode: .voiceChat,\n                               options: [])",
      "language" : "swift"
    },
    {
      "code" : "public func bypassVoiceProcessing(_ bypass: Bool) {\n    \/\/ If true, temporarily disables echo cancelation.\n    avAudioEngine.inputNode.isVoiceProcessingBypassed = bypass\n\n    DispatchQueue.main.async {\n        self.isVoiceProcessingBypassed = bypass\n    }\n\n    var message = \"Audio engine's voice processing: \"\n    message += bypass ? \"bypassed\" : \"normal\"\n    print(message)\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "511eb07096af010e5426d472bb8f3958bbc82504051684229d2e5030f3cb77e2",
  "crawledAt" : "2025-12-02T15:51:56Z",
  "id" : "B529EB7A-90CA-47BD-A525-E034554D6BD5",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "AVKit",
  "overview" : "## Overview\n\nContinuity Camera brings the power of the cameras and microphones from an iOS or iPadOS device to Apple TV, including advanced features like Center Stage and Portrait mode.\n\nThis sample project provides an example implementation that accesses a camera and microphone from a nearby iPhone or iPad in an Apple TV app. It builds on a similar sample, [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/supporting-continuity-camera-in-your-macos-app], and shares some of its functionality, including automatic camera selection and observing the state of video effects. The following sections focus on the aspects specific to tvOS.\n\n### Configure the sample code project\n\nTo run this sample app, you need the following:\n\nYou need to run this sample code project on physical devices, because Simulator doesn’t include the components to support cameras.\n\nContinuity Camera works with all iPhone and iPad models that support video effects in Control Center. You need to sign in with an Apple ID that uses two-factor authentication for the Apple TV and the device with a camera. You can use a separate Apple ID for each device or the same Apple ID for both.\n\nThe first time you run the app on an Apple TV, the system prompts you for permission to access to the camera and microphone. The app needs these permissions to function correctly.\n\n### Present the continuity device picker\n\nWhen the app launches, it immediately presents a continuity device picker by calling the [doc:\/\/com.apple.documentation\/documentation\/AVKit\/VideoPlayer\/continuityDevicePicker(isPresented:onDidConnect:)] modifier in its SwiftUI implementation.\n\nThe picker only appears if the `isPresented` parameter — which is a Boolean [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Binding] — is `true`. The picker calls the closure the app passes to the `onDidConnect` parameter when a person selects a device and the system successfully connects to it.\n\nThe handling closure’s [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVContinuityDevice] parameter represents the device that a person selects on their Apple TV. Each continuity device has a [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVContinuityDevice\/videoDevices] property, which is an array of [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDevice] instances.\n\nThe app’s `handleNewConnectionForDevice(_:)` method is a minimal implementation that selects the first video device in the array. Apps typically compare all the video device elements and select one that’s appropriate for their needs.\n\n### Connect a video device to a capture session\n\nThe app’s `CaptureManager` class creates and maintains an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureSession] instance for the app’s lifetime. The capture manager’s `setActiveVideoInput(_:)` method creates an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDeviceInput] instance from the video device, and then tests to see whether it’s an acceptable input for the capture session.\n\nIf the new device is an acceptable input, the method assigns it to the app’s `activeInput` property. The property updates the capture session with its `willSet` and `didSet` property observers.\n\nThe `willSet` observer removes the capture session’s current input, if applicable. The `didSet` observer adds the new input to the capture session. The `didSet` observer also updates the `isActive` Boolean property, which can cause the app to change its behavior and UI.\n\n### Register for capture device updates\n\nThe app receives various updates related to its capture device by registering with [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NotificationCenter] and with key-value observation (KVO). See [doc:\/\/com.apple.documentation\/documentation\/Swift\/using-key-value-observing-in-swift] and [doc:\/\/com.apple.documentation\/documentation\/ObjectiveC\/nskeyvalueobserving] for more information.\n\nThe app specifically registers for the following events:\n\nThe sample’s implementation that monitors the video effects and system changes is similar to the macOS equivalent of this sample, [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/supporting-continuity-camera-in-your-macos-app]. The sample also monitors Notification Center events related to the camera. The app’s capture manager responds when a capture device disconnects by registering with Notification Center for the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDevice\/wasConnectedNotification] event.\n\nThe app’s `CaptureDeviceNotificationObserver` structure listens for the these events on behalf of the capture manager and calls the manager’s `notification(_:for:)` method for each event it gets from Notification Center.\n\n### Configure the audio engine with an audio input device\n\nAt launch, the app creates an `AudioCapturer` instance, which checks for audio inputs (microphones). It does this by inspecting the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/availableInputs] property of the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession] type’s shared instance, and then monitoring the property for updates.\n\nThe app monitors for new microphones — similar to how the app’s capture manager monitors for new cameras — by observing the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/isInputAvailable] property of the `AVAudioSession` type’s shared instance.\n\nWhen the app has access to a microphone, it configures an [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioEngine] instance in the audio capturer’s `setupAndStartAudioSession()` method.\n\nThe method configures the audio engine for a conference call scenario when the app gains access to a microphone — at launch or later — with the following steps:\n\n### Configure the audio engine for a call\n\nThe third step is important for conferencing apps that use Voice over IP (VoIP). The `configureAudioSessionForVoiceChat` method configures the audio session by passing the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/Mode-swift.struct\/voiceChat] mode to the audio session’s [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/setCategory(_:options:)] method.\n\nThe app gains access to additional audio features and microphone modes, including automatic gain correction, voice processing, and muting, by configuring the audio session for VoIP.\n\nThe app’s audio interface has a button that lets a person temporarily disable microphone processing, including echo cancellation, by bypassing the audio engine’s voice processing. Each time a person toggles the button, the app calls audio capturer’s `bypassVoiceProcessing(_:)` method.\n\nThe app can temporarily disable voice processing by setting the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioInputNode\/isVoiceProcessingBypassed] property of the audio engine’s [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioEngine\/inputNode] to `true`. This gives the app all the incoming audio from the microphone without any adjustments from the system.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AVKit\/supporting-continuity-camera-in-your-tvos-app\ncrawled: 2025-12-02T15:51:56Z\n---\n\n# Supporting Continuity Camera in your tvOS app\n\n**Sample Code**\n\nCapture high-quality photos, video, and audio in your Apple TV app by connecting an iPhone or iPad as a continuity device.\n\n## Overview\n\nContinuity Camera brings the power of the cameras and microphones from an iOS or iPadOS device to Apple TV, including advanced features like Center Stage and Portrait mode.\n\nThis sample project provides an example implementation that accesses a camera and microphone from a nearby iPhone or iPad in an Apple TV app. It builds on a similar sample, [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/supporting-continuity-camera-in-your-macos-app], and shares some of its functionality, including automatic camera selection and observing the state of video effects. The following sections focus on the aspects specific to tvOS.\n\n\n\n### Configure the sample code project\n\nTo run this sample app, you need the following:\n\n- An Apple TV 4k (2nd generation) or later with tvOS 17 or later.\n- An iPhone or iPad with iOS 17 or iPadOS 17, respectively, or later.\n\nYou need to run this sample code project on physical devices, because Simulator doesn’t include the components to support cameras.\n\nContinuity Camera works with all iPhone and iPad models that support video effects in Control Center. You need to sign in with an Apple ID that uses two-factor authentication for the Apple TV and the device with a camera. You can use a separate Apple ID for each device or the same Apple ID for both.\n\nThe first time you run the app on an Apple TV, the system prompts you for permission to access to the camera and microphone. The app needs these permissions to function correctly.\n\n### Present the continuity device picker\n\nWhen the app launches, it immediately presents a continuity device picker by calling the [doc:\/\/com.apple.documentation\/documentation\/AVKit\/VideoPlayer\/continuityDevicePicker(isPresented:onDidConnect:)] modifier in its SwiftUI implementation.\n\n```swift\n.continuityDevicePicker(isPresented: $showContinuityDevicePicker,\n                        onDidConnect: handleNewConnectionForDevice)\n.task {\n    \/\/ Shows the picker when app has no continuity device at launch.\n    if !captureManager.activateDefaultContinuityCameraDevice() {\n        showContinuityDevicePicker = true\n    }\n```\n\nThe picker only appears if the `isPresented` parameter — which is a Boolean [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/Binding] — is `true`. The picker calls the closure the app passes to the `onDidConnect` parameter when a person selects a device and the system successfully connects to it.\n\n```swift\nfunc handleNewConnectionForDevice(_ device: AVContinuityDevice?) {\n    guard let device else {\n        print(\"The Continuity Device Picker didn't connect a device.\")\n        return\n    }\n\n    guard let firstCamera = device.videoDevices.first else {\n        print(\"The Continuity Device Picker doesn't have any cameras.\")\n        return\n    }\n\n    captureManager.setActiveVideoInput(firstCamera,\n                                       isUserPreferredCamera: true)\n}\n```\n\nThe handling closure’s [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVContinuityDevice] parameter represents the device that a person selects on their Apple TV. Each continuity device has a [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVContinuityDevice\/videoDevices] property, which is an array of [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDevice] instances.\n\nThe app’s `handleNewConnectionForDevice(_:)` method is a minimal implementation that selects the first video device in the array. Apps typically compare all the video device elements and select one that’s appropriate for their needs.\n\n\n\n### Connect a video device to a capture session\n\nThe app’s `CaptureManager` class creates and maintains an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureSession] instance for the app’s lifetime. The capture manager’s `setActiveVideoInput(_:)` method creates an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDeviceInput] instance from the video device, and then tests to see whether it’s an acceptable input for the capture session.\n\n```swift\nlet name = camera.localizedName\nprint(\"Setting video input to: \\(name).\")\n\n\/\/ Creates a video input with the camera.\nguard let videoInput = try? AVCaptureDeviceInput(device: camera) else {\n    print(\"Couldn't make an input from: \\(name).\")\n    return false\n}\n\n\/\/ Checks whether the capture session accepts the new camera as an input.\nguard session.canAddInput(videoInput) else {\n    print(\"Capture session rejected '\\(name)' as an input.\")\n    return false\n}\n\n\/\/ Adds the new camera input to the capture session.\nactiveInput = videoInput\n```\n\nIf the new device is an acceptable input, the method assigns it to the app’s `activeInput` property. The property updates the capture session with its `willSet` and `didSet` property observers.\n\n```swift\ninternal var activeInput: AVCaptureDeviceInput? {\n    willSet {\n        if let oldInput = activeInput {\n            session.removeInput(oldInput)\n        }\n    }\n    didSet {\n        if let newInput = activeInput {\n            session.addInput(newInput)\n        }\n        isActive = (activeInput != nil)\n    }\n}\n```\n\nThe `willSet` observer removes the capture session’s current input, if applicable. The `didSet` observer adds the new input to the capture session. The `didSet` observer also updates the `isActive` Boolean property, which can cause the app to change its behavior and UI.\n\n### Register for capture device updates\n\nThe app receives various updates related to its capture device by registering with [doc:\/\/com.apple.documentation\/documentation\/Foundation\/NotificationCenter] and with key-value observation (KVO). See [doc:\/\/com.apple.documentation\/documentation\/Swift\/using-key-value-observing-in-swift] and [doc:\/\/com.apple.documentation\/documentation\/ObjectiveC\/nskeyvalueobserving] for more information.\n\nThe app specifically registers for the following events:\n\n- A specific video effect, such as Center Stage, changes its active state.\n- The system changes the capture device it prefers.\n- The active capture device disconnects from the system.\n\n\n\nThe sample’s implementation that monitors the video effects and system changes is similar to the macOS equivalent of this sample, [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/supporting-continuity-camera-in-your-macos-app]. The sample also monitors Notification Center events related to the camera. The app’s capture manager responds when a capture device disconnects by registering with Notification Center for the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVCaptureDevice\/wasConnectedNotification] event.\n\n```swift\nfunc observeCamera(_ camera: AVCaptureDevice) {\n    \/\/ Tells the observer to watch the new camera's properties.\n    videoEffectsObvserver.observeCamera(camera)\n\n    \/\/ Tells the notification observer to monitor camera-related events.\n    notificationObserver.observeCamera(camera,\n                                       with: notification(_:for:))\n}\n```\n\nThe app’s `CaptureDeviceNotificationObserver` structure listens for the these events on behalf of the capture manager and calls the manager’s `notification(_:for:)` method for each event it gets from Notification Center.\n\n### Configure the audio engine with an audio input device\n\nAt launch, the app creates an `AudioCapturer` instance, which checks for audio inputs (microphones). It does this by inspecting the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/availableInputs] property of the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession] type’s shared instance, and then monitoring the property for updates.\n\nThe app monitors for new microphones — similar to how the app’s capture manager monitors for new cameras — by observing the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/isInputAvailable] property of the `AVAudioSession` type’s shared instance.\n\n```swift\nprivate static let inputAvailableKeyPath = \"isInputAvailable\"\n\nfunc registerForInputAvailabilityUpdates(on session: AVAudioSession) {\n    session.addObserver(self,\n                        forKeyPath: Self.inputAvailableKeyPath,\n                        options: [.new],\n                        context: nil)\n}\n```\n\nWhen the app has access to a microphone, it configures an [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioEngine] instance in the audio capturer’s `setupAndStartAudioSession()` method.\n\n```swift\nfunc setupAndStartAudioSession() {\n    configureAudioOutput()\n    enableVoiceProcessing(true)\n    configureAudioSessionForVoiceChat()\n    startAudioEngine()\n}\n```\n\nThe method configures the audio engine for a conference call scenario when the app gains access to a microphone — at launch or later — with the following steps:\n\n1. Configures the audio engine to produce sound from the system’s first audio output.\n2. Enables voice processing on the audio engine’s input node.\n3. Configures the audio engine for conversational audio.\n4. Starts the audio engine.\n\n### Configure the audio engine for a call\n\nThe third step is important for conferencing apps that use Voice over IP (VoIP). The `configureAudioSessionForVoiceChat` method configures the audio session by passing the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/Mode-swift.struct\/voiceChat] mode to the audio session’s [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioSession\/setCategory(_:options:)] method.\n\n```swift\ntry avAudioSession.setCategory(.playAndRecord,\n                               mode: .voiceChat,\n                               options: [])\n```\n\nThe app gains access to additional audio features and microphone modes, including automatic gain correction, voice processing, and muting, by configuring the audio session for VoIP.\n\nThe app’s audio interface has a button that lets a person temporarily disable microphone processing, including echo cancellation, by bypassing the audio engine’s voice processing. Each time a person toggles the button, the app calls audio capturer’s `bypassVoiceProcessing(_:)` method.\n\n```swift\npublic func bypassVoiceProcessing(_ bypass: Bool) {\n    \/\/ If true, temporarily disables echo cancelation.\n    avAudioEngine.inputNode.isVoiceProcessingBypassed = bypass\n\n    DispatchQueue.main.async {\n        self.isVoiceProcessingBypassed = bypass\n    }\n\n    var message = \"Audio engine's voice processing: \"\n    message += bypass ? \"bypassed\" : \"normal\"\n    print(message)\n}\n```\n\nThe app can temporarily disable voice processing by setting the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioInputNode\/isVoiceProcessingBypassed] property of the audio engine’s [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioEngine\/inputNode] to `true`. This gives the app all the incoming audio from the microphone without any adjustments from the system.\n\n\n\n## tvOS playback and capture\n\n- **Customizing the tvOS Playback Experience**: Adopt the latest features of the redesigned tvOS player user interface to provide a more streamlined way to watch your content.\n- **Presenting Navigation Markers**: Present navigation markers in the Chapters panel to help users quickly navigate your content.\n- **Working with Interstitial Content**: Present additional content alongside your main media presentation using HTTP Live Streaming support.\n- **Presenting Content Proposals in tvOS**: Display a preview of an upcoming media item at the conclusion of the currently playing media item.\n- **Working with Overlays and Parental Controls in tvOS**: Add interactive overlays, parental controls, and livestream channel flipping using a player view controller.\n- **AVPlayerViewController**: A view controller that displays content from a player and presents a native user interface to control playback.\n- **AVPlayerViewControllerDelegate**: A protocol that defines the methods to implement to respond to player view controller events.\n- **AVInterstitialTimeRange**: A time range in an audiovisual presentation for content with an interstitial designation, such as advertisements or legal notices.\n- **AVNavigationMarkersGroup**: A set of markers for navigating playback of an audiovisual presentation.\n- **AVContentProposalViewController**: A view controller that proposes content to watch next.\n- **AVDisplayManager**: A tvOS management object that controls whether a TV switches modes to match the video’s native mode.\n- **AVContinuityDevicePickerViewController**: A view controller that provides an interface to a person so they can select and connect a continuity device to the system.\n- **AVContinuityDevicePickerViewControllerDelegate**: An interface that responds to events from a continuity device picker view controller.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Adopt the latest features of the redesigned tvOS player user interface to provide a more streamlined way to watch your content.",
          "name" : "Customizing the tvOS Playback Experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/customizing-the-tvos-playback-experience"
        },
        {
          "description" : "Present navigation markers in the Chapters panel to help users quickly navigate your content.",
          "name" : "Presenting Navigation Markers",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/presenting-navigation-markers"
        },
        {
          "description" : "Present additional content alongside your main media presentation using HTTP Live Streaming support.",
          "name" : "Working with Interstitial Content",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/working-with-interstitial-content"
        },
        {
          "description" : "Display a preview of an upcoming media item at the conclusion of the currently playing media item.",
          "name" : "Presenting Content Proposals in tvOS",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/presenting-content-proposals-in-tvos"
        },
        {
          "description" : "Add interactive overlays, parental controls, and livestream channel flipping using a player view controller.",
          "name" : "Working with Overlays and Parental Controls in tvOS",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/working-with-overlays-and-parental-controls-in-tvos"
        },
        {
          "description" : "A view controller that displays content from a player and presents a native user interface to control playback.",
          "name" : "AVPlayerViewController",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVPlayerViewController"
        },
        {
          "description" : "A protocol that defines the methods to implement to respond to player view controller events.",
          "name" : "AVPlayerViewControllerDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVPlayerViewControllerDelegate"
        },
        {
          "description" : "A time range in an audiovisual presentation for content with an interstitial designation, such as advertisements or legal notices.",
          "name" : "AVInterstitialTimeRange",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVInterstitialTimeRange"
        },
        {
          "description" : "A set of markers for navigating playback of an audiovisual presentation.",
          "name" : "AVNavigationMarkersGroup",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVNavigationMarkersGroup"
        },
        {
          "description" : "A view controller that proposes content to watch next.",
          "name" : "AVContentProposalViewController",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVContentProposalViewController"
        },
        {
          "description" : "A tvOS management object that controls whether a TV switches modes to match the video’s native mode.",
          "name" : "AVDisplayManager",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVDisplayManager"
        },
        {
          "description" : "A view controller that provides an interface to a person so they can select and connect a continuity device to the system.",
          "name" : "AVContinuityDevicePickerViewController",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVContinuityDevicePickerViewController"
        },
        {
          "description" : "An interface that responds to events from a continuity device picker view controller.",
          "name" : "AVContinuityDevicePickerViewControllerDelegate",
          "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/AVContinuityDevicePickerViewControllerDelegate"
        }
      ],
      "title" : "tvOS playback and capture"
    }
  ],
  "source" : "appleJSON",
  "title" : "Supporting Continuity Camera in your tvOS app",
  "url" : "https:\/\/developer.apple.com\/documentation\/AVKit\/supporting-continuity-camera-in-your-tvos-app"
}