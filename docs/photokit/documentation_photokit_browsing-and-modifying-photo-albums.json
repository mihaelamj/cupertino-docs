{
  "abstract" : "Help users organize their photos into albums and browse photo collections in a grid-based layout using PhotoKit.",
  "codeExamples" : [
    {
      "code" : "PHPhotoLibrary.shared().register(self)",
      "language" : "swift"
    },
    {
      "code" : "let allPhotosOptions = PHFetchOptions()\nallPhotosOptions.sortDescriptors = [NSSortDescriptor(key: \"creationDate\", ascending: true)]\nallPhotos = PHAsset.fetchAssets(with: allPhotosOptions)\nsmartAlbums = PHAssetCollection.fetchAssetCollections(with: .smartAlbum, subtype: .albumRegular, options: nil)\nuserCollections = PHCollectionList.fetchTopLevelUserCollections(with: nil)",
      "language" : "swift"
    },
    {
      "code" : "let (addedRects, removedRects) = differencesBetweenRects(previousPreheatRect, preheatRect)\nlet addedAssets = addedRects\n    .flatMap { rect in collectionView!.indexPathsForElements(in: rect) }\n    .map { indexPath in fetchResult.object(at: indexPath.item) }\nlet removedAssets = removedRects\n    .flatMap { rect in collectionView!.indexPathsForElements(in: rect) }\n    .map { indexPath in fetchResult.object(at: indexPath.item) }\n\n\/\/ Update the assets the PHCachingImageManager is caching.\nimageManager.startCachingImages(for: addedAssets,\n                                targetSize: thumbnailSize, contentMode: .aspectFill, options: nil)\nimageManager.stopCachingImages(for: removedAssets,\n                               targetSize: thumbnailSize, contentMode: .aspectFill, options: nil)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Dequeue a GridViewCell.\nguard let cell = collectionView.dequeueReusableCell(withReuseIdentifier: \"GridViewCell\", for: indexPath) as? GridViewCell\n    else { fatalError(\"Unexpected cell in collection view\") }\n\n\/\/ Add a badge to the cell if the PHAsset represents a Live Photo.\nif asset.mediaSubtypes.contains(.photoLive) {\n    cell.livePhotoBadgeImage = PHLivePhotoView.livePhotoBadgeImage(options: .overContent)\n}\n\n\/\/ Request an image for the asset from the PHCachingImageManager.\ncell.representedAssetIdentifier = asset.localIdentifier\nimageManager.requestImage(for: asset, targetSize: thumbnailSize, contentMode: .aspectFill, options: nil, resultHandler: { image, _ in\n    \/\/ UIKit may have recycled this cell by the handler's activation time.\n    \/\/ Set the cell's thumbnail image only if it's still showing the same asset.\n    if cell.representedAssetIdentifier == asset.localIdentifier {\n        cell.thumbnailImage = image\n    }\n})",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Set the appropriate toolbar items based on the media type of the asset.\n#if os(iOS)\nnavigationController?.isToolbarHidden = false\nnavigationController?.hidesBarsOnTap = true\nif asset.mediaType == .video {\n    toolbarItems = [favoriteButton, space, playButton, space, trashButton]\n} else {\n    \/\/ In iOS, present both stills and Live Photos the same way, because\n    \/\/ PHLivePhotoView provides the same gesture-based UI as in the Photos app.\n    toolbarItems = [favoriteButton, space, trashButton]\n}\n#elseif os(tvOS)\nif asset.mediaType == .video {\n    navigationItem.leftBarButtonItems = [playButton, favoriteButton, trashButton]\n} else {\n    \/\/ In tvOS, PHLivePhotoView doesn't support playback gestures,\n    \/\/ so add a play button for Live Photos.\n    if asset.mediaSubtypes.contains(.photoLive) {\n        navigationItem.leftBarButtonItems = [favoriteButton, trashButton]\n    } else {\n        navigationItem.leftBarButtonItems = [livePhotoPlayButton, favoriteButton, trashButton]\n    }\n}\n#endif",
      "language" : "swift"
    },
    {
      "code" : "#if os(tvOS)\n@IBAction func playLivePhoto(_ sender: Any) {\n    livePhotoView.startPlayback(with: .full)\n}\n#endif",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Request an AVPlayerItem for the displayed PHAsset.\n\/\/ Then configure a layer for playing it.\nPHImageManager.default().requestPlayerItem(forVideo: asset, options: options, resultHandler: { playerItem, info in\n    DispatchQueue.main.sync {\n        guard self.playerLayer == nil else { return }\n        \n        \/\/ Create an AVPlayer and AVPlayerLayer with the AVPlayerItem.\n        let player = AVPlayer(playerItem: playerItem)\n        let playerLayer = AVPlayerLayer(player: player)\n        \n        \/\/ Configure the AVPlayerLayer and add it to the view.\n        playerLayer.videoGravity = AVLayerVideoGravity.resizeAspect\n        playerLayer.frame = self.view.layer.bounds\n        self.view.layer.addSublayer(playerLayer)\n        \n        player.play()\n        \n        \/\/ Cache the player layer by reference, so you can remove it later.\n        self.playerLayer = playerLayer\n    }\n})",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Allow editing only if the PHAsset supports edit operations.\nif asset.canPerform(.content) {\n    \/\/ Add actions for some canned filters.\n    alertController.addAction(UIAlertAction(title: NSLocalizedString(\"Sepia Tone\", comment: \"\"),\n                                            style: .default, handler: getFilter(\"CISepiaTone\")))\n    alertController.addAction(UIAlertAction(title: NSLocalizedString(\"Chrome\", comment: \"\"),\n                                            style: .default, handler: getFilter(\"CIPhotoEffectChrome\")))\n    \n    \/\/ Add actions to revert any edits that have been made to the PHAsset.\n    alertController.addAction(UIAlertAction(title: NSLocalizedString(\"Revert\", comment: \"\"),\n                                            style: .default, handler: revertAsset))\n}\n\/\/ Present the UIAlertController.\npresent(alertController, animated: true)",
      "language" : "swift"
    },
    {
      "code" : "DispatchQueue.global(qos: .userInitiated).async {\n    \n    \/\/ Create adjustment data describing the edit.\n    let adjustmentData = PHAdjustmentData(formatIdentifier: self.formatIdentifier,\n                                          formatVersion: self.formatVersion,\n                                          data: filterName.data(using: .utf8)!)\n    \n    \/\/ Create content editing output, write the adjustment data.\n    let output = PHContentEditingOutput(contentEditingInput: input)\n    output.adjustmentData = adjustmentData\n    \n    \/\/ Select a filtering function for the asset's media type.\n    let applyFunc: (String, PHContentEditingInput, PHContentEditingOutput, @escaping () -> Void) -> Void\n    if self.asset.mediaSubtypes.contains(.photoLive) {\n        applyFunc = self.applyLivePhotoFilter\n    } else if self.asset.mediaType == .image {\n        applyFunc = self.applyPhotoFilter\n    } else {\n        applyFunc = self.applyVideoFilter\n    }\n    \n    \/\/ Apply the filter.\n    applyFunc(filterName, input, output, {\n        \/\/ When the app finishes rendering the filtered result, commit the edit to the photo library.\n        PHPhotoLibrary.shared().performChanges({\n            let request = PHAssetChangeRequest(for: self.asset)\n            request.contentEditingOutput = output\n        }, completionHandler: { success, error in\n            if !success { print(\"Can't edit the asset: \\(String(describing: error))\") }\n        })\n    })\n}",
      "language" : "swift"
    },
    {
      "code" : "PHPhotoLibrary.shared().performChanges({\n    PHAssetCollectionChangeRequest.creationRequestForAssetCollection(withTitle: title)\n}, completionHandler: { success, error in\n    if !success { print(\"Error creating album: \\(String(describing: error)).\") }\n})",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Add the asset to the photo library.\nPHPhotoLibrary.shared().performChanges({\n    let creationRequest = PHAssetChangeRequest.creationRequestForAsset(from: image)\n    if let assetCollection = self.assetCollection {\n        let addAssetRequest = PHAssetCollectionChangeRequest(for: assetCollection)\n        addAssetRequest?.addAssets([creationRequest.placeholderForCreatedAsset!] as NSArray)\n    }\n}, completionHandler: {success, error in\n    if !success { print(\"Error creating the asset: \\(String(describing: error))\") }\n})",
      "language" : "swift"
    },
    {
      "code" : "if assetCollection != nil {\n    \/\/ Remove the asset from the selected album.\n    PHPhotoLibrary.shared().performChanges({\n        let request = PHAssetCollectionChangeRequest(for: self.assetCollection)!\n        request.removeAssets([self.asset as Any] as NSArray)\n    }, completionHandler: completion)\n} else {\n    \/\/ Delete the asset from the photo library.\n    PHPhotoLibrary.shared().performChanges({\n        PHAssetChangeRequest.deleteAssets([self.asset as Any] as NSArray)\n    }, completionHandler: completion)\n}",
      "language" : "swift"
    },
    {
      "code" : "PHPhotoLibrary.shared().performChanges({\n    let request = PHAssetChangeRequest(for: self.asset)\n    request.isFavorite = !self.asset.isFavorite\n}, completionHandler: { success, error in\n    if success {\n        DispatchQueue.main.sync {\n            sender.title = self.asset.isFavorite ? \"♥︎\" : \"♡\"\n        }\n    } else {\n        print(\"Can't mark the asset as a Favorite: \\(String(describing: error))\")\n    }\n})",
      "language" : "swift"
    },
    {
      "code" : "if let changeDetails = changeInstance.changeDetails(for: allPhotos) {\n    \/\/ Update the cached fetch result.\n    allPhotos = changeDetails.fetchResultAfterChanges\n    \/\/ Don't update the table row that always reads \"All Photos.\"\n}\n\n\/\/ Update the cached fetch results, and reload the table sections to match.\nif let changeDetails = changeInstance.changeDetails(for: smartAlbums) {\n    smartAlbums = changeDetails.fetchResultAfterChanges\n    tableView.reloadSections(IndexSet(integer: Section.smartAlbums.rawValue), with: .automatic)\n}\nif let changeDetails = changeInstance.changeDetails(for: userCollections) {\n    userCollections = changeDetails.fetchResultAfterChanges\n    tableView.reloadSections(IndexSet(integer: Section.userCollections.rawValue), with: .automatic)\n}",
      "language" : "swift"
    },
    {
      "code" : "PHPhotoLibrary.shared().unregisterChangeObserver(self)",
      "language" : "swift"
    }
  ],
  "contentHash" : "78aae4c40d0408c849c7bf1fafb6b63206de7df5c9c7cea937e64922eb854b60",
  "crawledAt" : "2025-12-02T15:31:46Z",
  "id" : "A5DAD132-A15C-435E-A07A-8068F656F197",
  "kind" : "unknown",
  "language" : "swift",
  "overview" : "## Overview\n\nThe Photos app on iOS displays assets in a thumbnail grid. This sample demonstrates how to achieve a similar layout with a custom [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UICollectionViewController]. It fetches asset thumbnails using PhotoKit, then displays them as a single photo, video, or Live Photo asset.\n\nThe sample app, PhotoBrowse, also demonstrates how to organize the user’s photos into albums and built-in collections, such as Recently Added and Favorites. It supports album creation, deletion, modification, as well as the editing and favoriting of individual assets.\n\n### Getting Started\n\nThe sample app, PhotoBrowse, runs on iOS and tvOS and requires the following:\n\nIf you build and run the project in Xcode, you may also add photos to the app in Simulator.\n\n### List Albums and Built-in Collections\n\nWhen the app first launches, it fetches all of the user’s photo assets. All requests for asset data—single photos, albums, and user collections—go through PhotoKit’s shared [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHPhotoLibrary] object, so the app registers the main view controller once its view loads:\n\nTo list all the user’s albums and collections, the app creates a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHFetchOptions] object and dispatches several fetch requests:\n\nThe resulting [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHFetchResult] informs the app about the structure of the user’s photo library, allowing the user interface to show the number of photos in each album.\n\n### Display Assets in a Thumbnail Grid\n\nThe sample app implements thumbnail grid browsing by subclassing `UICollectionViewController` in `AssetGridViewController`.\n\nAfter the grid view controller loads, it updates the image cache, which allows thumbnails to load quickly as the user scrolls:\n\nImplement the `UICollectionView` delegate method [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UICollectionView\/cellForItem(at:)] to use thumbnails instead of full assets. PhotoKit allows you to request assets directly, and even badge Live Photos to set them apart:\n\n### Show a Single Photo, Video, or Live Photo\n\n`AssetViewController` implements the view of a single asset. If the asset is a video or Live Photo, the view controller also supports playback through a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIBarButtonItem]:\n\nOn tvOS, PhotoKit supports Live Photo playback:\n\nThe view controller supports playback by creating an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer] and layering it on top of the item once the [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHImageManager] fetches a video:\n\n### Apply Canned Filters in an Editing Interface\n\nThe `AssetViewController` view allows the user to edit the photo and save changes back to the photo library. It uses an alert controller to display a list of preset editing options, including sepia tone, chrome, and revert.\n\nEach option creates an edit request and prepares a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHContentEditingOutput] to encapsulate edit results as data. A [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAssetChangeRequest] object communicates the edit back to the user’s photo library.\n\nAfter the user picks a filter, the app applies it and outputs the saved asset immediately. There’s no UI state for having chosen—but not yet committed—an edit. As such, there’s no role for reading adjustment data to resume in-progress edits, since PhotoBrowse has no notion of *in-progress*. However, it’s still good practice to write adjustment data so that potential future versions of the app—or other apps that understand your adjustment data format—could make use of it.\n\n### Create a New Album\n\nAn alert controller allows the user to add a new album:\n\n### Add an Asset to a Collection\n\nWhen the user chooses to add an asset by tapping the Add button (+) in the navigation bar, PhotoBrowse creates a mock photo from a random color at a random orientation. Like other changes to a user’s photo library, adding an asset requires the app to wrap the addition inside a `PHAssetChangeRequest` as follows:\n\n### Delete Assets and Albums\n\nThe user can delete an asset through the trash can button at the lower-right corner of `AssetViewController`. For removal from an album, PhotoBrowse wraps the deletion operation inside a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAssetCollectionChangeRequest] object. For  removal from the entire photo library, PhotoBrowse wraps the deletion operation inside a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAssetChangeRequest] object:\n\n### Favorite an Asset\n\nUsers can favorite an asset by toggling the [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAsset] parameter [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAsset\/isFavorite]:\n\n### Observe and Respond to Changes\n\nRegister your main view controller—and any view that shows the user  assets—to observe changes to the photo library, so your app can receive and respond to notifications as assets change. These changes may not necessarily occur inside your app’s functionality; they could originate from other apps, other devices, iCloud Photos, or Shared Albums:\n\nBe sure to unregister your change observer after the app’s main view controller goes away.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/PhotoKit\/browsing-and-modifying-photo-albums\ncrawled: 2025-12-02T15:31:46Z\n---\n\n# Browsing and Modifying Photo Albums\n\n**Sample Code**\n\nHelp users organize their photos into albums and browse photo collections in a grid-based layout using PhotoKit.\n\n## Overview\n\nThe Photos app on iOS displays assets in a thumbnail grid. This sample demonstrates how to achieve a similar layout with a custom [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UICollectionViewController]. It fetches asset thumbnails using PhotoKit, then displays them as a single photo, video, or Live Photo asset.\n\nThe sample app, PhotoBrowse, also demonstrates how to organize the user’s photos into albums and built-in collections, such as Recently Added and Favorites. It supports album creation, deletion, modification, as well as the editing and favoriting of individual assets.\n\n### Getting Started\n\nThe sample app, PhotoBrowse, runs on iOS and tvOS and requires the following:\n\n- iOS 12 or later.\n- tvOS 12 or later.\n\nIf you build and run the project in Xcode, you may also add photos to the app in Simulator.\n\n### List Albums and Built-in Collections\n\nWhen the app first launches, it fetches all of the user’s photo assets. All requests for asset data—single photos, albums, and user collections—go through PhotoKit’s shared [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHPhotoLibrary] object, so the app registers the main view controller once its view loads:\n\n```swift\nPHPhotoLibrary.shared().register(self)\n```\n\nTo list all the user’s albums and collections, the app creates a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHFetchOptions] object and dispatches several fetch requests:\n\n```swift\nlet allPhotosOptions = PHFetchOptions()\nallPhotosOptions.sortDescriptors = [NSSortDescriptor(key: \"creationDate\", ascending: true)]\nallPhotos = PHAsset.fetchAssets(with: allPhotosOptions)\nsmartAlbums = PHAssetCollection.fetchAssetCollections(with: .smartAlbum, subtype: .albumRegular, options: nil)\nuserCollections = PHCollectionList.fetchTopLevelUserCollections(with: nil)\n```\n\nThe resulting [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHFetchResult] informs the app about the structure of the user’s photo library, allowing the user interface to show the number of photos in each album.\n\n### Display Assets in a Thumbnail Grid\n\nThe sample app implements thumbnail grid browsing by subclassing `UICollectionViewController` in `AssetGridViewController`.\n\nAfter the grid view controller loads, it updates the image cache, which allows thumbnails to load quickly as the user scrolls:\n\n```swift\nlet (addedRects, removedRects) = differencesBetweenRects(previousPreheatRect, preheatRect)\nlet addedAssets = addedRects\n    .flatMap { rect in collectionView!.indexPathsForElements(in: rect) }\n    .map { indexPath in fetchResult.object(at: indexPath.item) }\nlet removedAssets = removedRects\n    .flatMap { rect in collectionView!.indexPathsForElements(in: rect) }\n    .map { indexPath in fetchResult.object(at: indexPath.item) }\n\n\/\/ Update the assets the PHCachingImageManager is caching.\nimageManager.startCachingImages(for: addedAssets,\n                                targetSize: thumbnailSize, contentMode: .aspectFill, options: nil)\nimageManager.stopCachingImages(for: removedAssets,\n                               targetSize: thumbnailSize, contentMode: .aspectFill, options: nil)\n```\n\nImplement the `UICollectionView` delegate method [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UICollectionView\/cellForItem(at:)] to use thumbnails instead of full assets. PhotoKit allows you to request assets directly, and even badge Live Photos to set them apart:\n\n```swift\n\/\/ Dequeue a GridViewCell.\nguard let cell = collectionView.dequeueReusableCell(withReuseIdentifier: \"GridViewCell\", for: indexPath) as? GridViewCell\n    else { fatalError(\"Unexpected cell in collection view\") }\n\n\/\/ Add a badge to the cell if the PHAsset represents a Live Photo.\nif asset.mediaSubtypes.contains(.photoLive) {\n    cell.livePhotoBadgeImage = PHLivePhotoView.livePhotoBadgeImage(options: .overContent)\n}\n\n\/\/ Request an image for the asset from the PHCachingImageManager.\ncell.representedAssetIdentifier = asset.localIdentifier\nimageManager.requestImage(for: asset, targetSize: thumbnailSize, contentMode: .aspectFill, options: nil, resultHandler: { image, _ in\n    \/\/ UIKit may have recycled this cell by the handler's activation time.\n    \/\/ Set the cell's thumbnail image only if it's still showing the same asset.\n    if cell.representedAssetIdentifier == asset.localIdentifier {\n        cell.thumbnailImage = image\n    }\n})\n```\n\n### Show a Single Photo, Video, or Live Photo\n\n`AssetViewController` implements the view of a single asset. If the asset is a video or Live Photo, the view controller also supports playback through a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIBarButtonItem]:\n\n```swift\n\/\/ Set the appropriate toolbar items based on the media type of the asset.\n#if os(iOS)\nnavigationController?.isToolbarHidden = false\nnavigationController?.hidesBarsOnTap = true\nif asset.mediaType == .video {\n    toolbarItems = [favoriteButton, space, playButton, space, trashButton]\n} else {\n    \/\/ In iOS, present both stills and Live Photos the same way, because\n    \/\/ PHLivePhotoView provides the same gesture-based UI as in the Photos app.\n    toolbarItems = [favoriteButton, space, trashButton]\n}\n#elseif os(tvOS)\nif asset.mediaType == .video {\n    navigationItem.leftBarButtonItems = [playButton, favoriteButton, trashButton]\n} else {\n    \/\/ In tvOS, PHLivePhotoView doesn't support playback gestures,\n    \/\/ so add a play button for Live Photos.\n    if asset.mediaSubtypes.contains(.photoLive) {\n        navigationItem.leftBarButtonItems = [favoriteButton, trashButton]\n    } else {\n        navigationItem.leftBarButtonItems = [livePhotoPlayButton, favoriteButton, trashButton]\n    }\n}\n#endif\n```\n\nOn tvOS, PhotoKit supports Live Photo playback:\n\n```swift\n#if os(tvOS)\n@IBAction func playLivePhoto(_ sender: Any) {\n    livePhotoView.startPlayback(with: .full)\n}\n#endif\n```\n\nThe view controller supports playback by creating an [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer] and layering it on top of the item once the [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHImageManager] fetches a video:\n\n```swift\n\/\/ Request an AVPlayerItem for the displayed PHAsset.\n\/\/ Then configure a layer for playing it.\nPHImageManager.default().requestPlayerItem(forVideo: asset, options: options, resultHandler: { playerItem, info in\n    DispatchQueue.main.sync {\n        guard self.playerLayer == nil else { return }\n        \n        \/\/ Create an AVPlayer and AVPlayerLayer with the AVPlayerItem.\n        let player = AVPlayer(playerItem: playerItem)\n        let playerLayer = AVPlayerLayer(player: player)\n        \n        \/\/ Configure the AVPlayerLayer and add it to the view.\n        playerLayer.videoGravity = AVLayerVideoGravity.resizeAspect\n        playerLayer.frame = self.view.layer.bounds\n        self.view.layer.addSublayer(playerLayer)\n        \n        player.play()\n        \n        \/\/ Cache the player layer by reference, so you can remove it later.\n        self.playerLayer = playerLayer\n    }\n})\n```\n\n### Apply Canned Filters in an Editing Interface\n\nThe `AssetViewController` view allows the user to edit the photo and save changes back to the photo library. It uses an alert controller to display a list of preset editing options, including sepia tone, chrome, and revert.\n\n```swift\n\/\/ Allow editing only if the PHAsset supports edit operations.\nif asset.canPerform(.content) {\n    \/\/ Add actions for some canned filters.\n    alertController.addAction(UIAlertAction(title: NSLocalizedString(\"Sepia Tone\", comment: \"\"),\n                                            style: .default, handler: getFilter(\"CISepiaTone\")))\n    alertController.addAction(UIAlertAction(title: NSLocalizedString(\"Chrome\", comment: \"\"),\n                                            style: .default, handler: getFilter(\"CIPhotoEffectChrome\")))\n    \n    \/\/ Add actions to revert any edits that have been made to the PHAsset.\n    alertController.addAction(UIAlertAction(title: NSLocalizedString(\"Revert\", comment: \"\"),\n                                            style: .default, handler: revertAsset))\n}\n\/\/ Present the UIAlertController.\npresent(alertController, animated: true)\n```\n\nEach option creates an edit request and prepares a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHContentEditingOutput] to encapsulate edit results as data. A [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAssetChangeRequest] object communicates the edit back to the user’s photo library.\n\n```swift\nDispatchQueue.global(qos: .userInitiated).async {\n    \n    \/\/ Create adjustment data describing the edit.\n    let adjustmentData = PHAdjustmentData(formatIdentifier: self.formatIdentifier,\n                                          formatVersion: self.formatVersion,\n                                          data: filterName.data(using: .utf8)!)\n    \n    \/\/ Create content editing output, write the adjustment data.\n    let output = PHContentEditingOutput(contentEditingInput: input)\n    output.adjustmentData = adjustmentData\n    \n    \/\/ Select a filtering function for the asset's media type.\n    let applyFunc: (String, PHContentEditingInput, PHContentEditingOutput, @escaping () -> Void) -> Void\n    if self.asset.mediaSubtypes.contains(.photoLive) {\n        applyFunc = self.applyLivePhotoFilter\n    } else if self.asset.mediaType == .image {\n        applyFunc = self.applyPhotoFilter\n    } else {\n        applyFunc = self.applyVideoFilter\n    }\n    \n    \/\/ Apply the filter.\n    applyFunc(filterName, input, output, {\n        \/\/ When the app finishes rendering the filtered result, commit the edit to the photo library.\n        PHPhotoLibrary.shared().performChanges({\n            let request = PHAssetChangeRequest(for: self.asset)\n            request.contentEditingOutput = output\n        }, completionHandler: { success, error in\n            if !success { print(\"Can't edit the asset: \\(String(describing: error))\") }\n        })\n    })\n}\n```\n\nAfter the user picks a filter, the app applies it and outputs the saved asset immediately. There’s no UI state for having chosen—but not yet committed—an edit. As such, there’s no role for reading adjustment data to resume in-progress edits, since PhotoBrowse has no notion of *in-progress*. However, it’s still good practice to write adjustment data so that potential future versions of the app—or other apps that understand your adjustment data format—could make use of it.\n\n### Create a New Album\n\nAn alert controller allows the user to add a new album:\n\n```swift\nPHPhotoLibrary.shared().performChanges({\n    PHAssetCollectionChangeRequest.creationRequestForAssetCollection(withTitle: title)\n}, completionHandler: { success, error in\n    if !success { print(\"Error creating album: \\(String(describing: error)).\") }\n})\n```\n\n### Add an Asset to a Collection\n\nWhen the user chooses to add an asset by tapping the Add button (+) in the navigation bar, PhotoBrowse creates a mock photo from a random color at a random orientation. Like other changes to a user’s photo library, adding an asset requires the app to wrap the addition inside a `PHAssetChangeRequest` as follows:\n\n```swift\n\/\/ Add the asset to the photo library.\nPHPhotoLibrary.shared().performChanges({\n    let creationRequest = PHAssetChangeRequest.creationRequestForAsset(from: image)\n    if let assetCollection = self.assetCollection {\n        let addAssetRequest = PHAssetCollectionChangeRequest(for: assetCollection)\n        addAssetRequest?.addAssets([creationRequest.placeholderForCreatedAsset!] as NSArray)\n    }\n}, completionHandler: {success, error in\n    if !success { print(\"Error creating the asset: \\(String(describing: error))\") }\n})\n```\n\n### Delete Assets and Albums\n\nThe user can delete an asset through the trash can button at the lower-right corner of `AssetViewController`. For removal from an album, PhotoBrowse wraps the deletion operation inside a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAssetCollectionChangeRequest] object. For  removal from the entire photo library, PhotoBrowse wraps the deletion operation inside a [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAssetChangeRequest] object:\n\n```swift\nif assetCollection != nil {\n    \/\/ Remove the asset from the selected album.\n    PHPhotoLibrary.shared().performChanges({\n        let request = PHAssetCollectionChangeRequest(for: self.assetCollection)!\n        request.removeAssets([self.asset as Any] as NSArray)\n    }, completionHandler: completion)\n} else {\n    \/\/ Delete the asset from the photo library.\n    PHPhotoLibrary.shared().performChanges({\n        PHAssetChangeRequest.deleteAssets([self.asset as Any] as NSArray)\n    }, completionHandler: completion)\n}\n```\n\n### Favorite an Asset\n\nUsers can favorite an asset by toggling the [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAsset] parameter [doc:\/\/com.apple.photokit\/documentation\/Photos\/PHAsset\/isFavorite]:\n\n```swift\nPHPhotoLibrary.shared().performChanges({\n    let request = PHAssetChangeRequest(for: self.asset)\n    request.isFavorite = !self.asset.isFavorite\n}, completionHandler: { success, error in\n    if success {\n        DispatchQueue.main.sync {\n            sender.title = self.asset.isFavorite ? \"♥︎\" : \"♡\"\n        }\n    } else {\n        print(\"Can't mark the asset as a Favorite: \\(String(describing: error))\")\n    }\n})\n```\n\n### Observe and Respond to Changes\n\nRegister your main view controller—and any view that shows the user  assets—to observe changes to the photo library, so your app can receive and respond to notifications as assets change. These changes may not necessarily occur inside your app’s functionality; they could originate from other apps, other devices, iCloud Photos, or Shared Albums:\n\n```swift\nif let changeDetails = changeInstance.changeDetails(for: allPhotos) {\n    \/\/ Update the cached fetch result.\n    allPhotos = changeDetails.fetchResultAfterChanges\n    \/\/ Don't update the table row that always reads \"All Photos.\"\n}\n\n\/\/ Update the cached fetch results, and reload the table sections to match.\nif let changeDetails = changeInstance.changeDetails(for: smartAlbums) {\n    smartAlbums = changeDetails.fetchResultAfterChanges\n    tableView.reloadSections(IndexSet(integer: Section.smartAlbums.rawValue), with: .automatic)\n}\nif let changeDetails = changeInstance.changeDetails(for: userCollections) {\n    userCollections = changeDetails.fetchResultAfterChanges\n    tableView.reloadSections(IndexSet(integer: Section.userCollections.rawValue), with: .automatic)\n}\n```\n\nBe sure to unregister your change observer after the app’s main view controller goes away.\n\n```swift\nPHPhotoLibrary.shared().unregisterChangeObserver(self)\n```\n\n## Sample code\n\n- **Selecting Photos and Videos in iOS**: Improve the user experience of finding and selecting assets by using the Photos picker.\n- **Bringing Photos picker to your SwiftUI app**: Select media assets by using a Photos picker view that SwiftUI provides.\n- **Implementing an inline Photos picker**: Embed a system-provided, half-height Photos picker into your app’s view.\n- **Creating a Slideshow Project Extension for Photos**: Augment the macOS Photos app with extensions that support project creation.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Improve the user experience of finding and selecting assets by using the Photos picker.",
          "name" : "Selecting Photos and Videos in iOS",
          "url" : "https:\/\/developer.apple.com\/documentation\/PhotoKit\/selecting-photos-and-videos-in-ios"
        },
        {
          "description" : "Select media assets by using a Photos picker view that SwiftUI provides.",
          "name" : "Bringing Photos picker to your SwiftUI app",
          "url" : "https:\/\/developer.apple.com\/documentation\/PhotoKit\/bringing-photos-picker-to-your-swiftui-app"
        },
        {
          "description" : "Embed a system-provided, half-height Photos picker into your app’s view.",
          "name" : "Implementing an inline Photos picker",
          "url" : "https:\/\/developer.apple.com\/documentation\/PhotoKit\/implementing-an-inline-photos-picker"
        },
        {
          "description" : "Augment the macOS Photos app with extensions that support project creation.",
          "name" : "Creating a Slideshow Project Extension for Photos",
          "url" : "https:\/\/developer.apple.com\/documentation\/PhotoKit\/creating-a-slideshow-project-extension-for-photos"
        }
      ],
      "title" : "Sample code"
    }
  ],
  "source" : "appleJSON",
  "title" : "Browsing and Modifying Photo Albums",
  "url" : "https:\/\/developer.apple.com\/documentation\/PhotoKit\/browsing-and-modifying-photo-albums"
}