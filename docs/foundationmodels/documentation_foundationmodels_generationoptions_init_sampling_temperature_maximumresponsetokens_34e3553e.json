{
  "abstract" : "Creates generation options that control token sampling behavior.",
  "codeExamples" : [

  ],
  "contentHash" : "ff42498018834b5aa019e4d4f21458127e4f24f360971a2af9421ca182a75ae2",
  "crawledAt" : "2025-12-02T16:54:52Z",
  "declaration" : {
    "code" : "init(sampling: GenerationOptions.SamplingMode? = nil, temperature: Double? = nil, maximumResponseTokens: Int? = nil)",
    "language" : "swift"
  },
  "id" : "A0FF86D4-4A70-4EE6-A31B-39E27065CC6A",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "Foundation Models",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/FoundationModels\/GenerationOptions\/init(sampling:temperature:maximumResponseTokens:)\ncrawled: 2025-12-02T16:54:52Z\n---\n\n# init(sampling:temperature:maximumResponseTokens:)\n\n**Initializer**\n\nCreates generation options that control token sampling behavior.\n\n## Declaration\n\n```swift\ninit(sampling: GenerationOptions.SamplingMode? = nil, temperature: Double? = nil, maximumResponseTokens: Int? = nil)\n```\n\n## Parameters\n\n- **sampling**: A strategy to use for sampling from a distribution.\n- **temperature**: Increasing temperature makes it possible for the model to produce less likely responses. Must be between `0` and `1`, inclusive.\n- **maximumResponseTokens**: The maximum number of tokens the model is allowed to produce before being artificially halted. Must be positive.\n\n",
  "sections" : [

  ],
  "source" : "appleJSON",
  "title" : "init(sampling:temperature:maximumResponseTokens:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/FoundationModels\/GenerationOptions\/init(sampling:temperature:maximumResponseTokens:)"
}