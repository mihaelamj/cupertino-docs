{
  "abstract" : "Enhance the experience in your app by prompting an on-device large language model.",
  "codeExamples" : [
    {
      "code" : "struct GenerativeView: View {\n    \/\/ Create a reference to the system language model.\n    private var model = SystemLanguageModel.default\n\n    var body: some View {\n        switch model.availability {\n        case .available:\n            \/\/ Show your intelligence UI.\n        case .unavailable(.deviceNotEligible):\n            \/\/ Show an alternative UI.\n        case .unavailable(.appleIntelligenceNotEnabled):\n            \/\/ Ask the person to turn on Apple Intelligence.\n        case .unavailable(.modelNotReady):\n            \/\/ The model isn't ready because it's downloading or because of other system reasons.\n        case .unavailable(let other):\n            \/\/ The model is unavailable for an unknown reason.\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Create a session with the system model.\nlet session = LanguageModelSession()",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Generate a longer response for a specific command.\nlet simple = \"Write me a story about pears.\"\n\n\/\/ Quickly generate a concise response.\nlet quick = \"Write the profile for the dog breed Siberian Husky using three sentences.\"",
      "language" : "swift"
    },
    {
      "code" : "let instructions = \"\"\"\n    Suggest five related topics. Keep them concise (three to seven words) and make sure they \\\n    build naturally from the person's topic.\n    \"\"\"\n\nlet session = LanguageModelSession(instructions: instructions)\n\nlet prompt = \"Making homemade bread\"\nlet response = try await session.respond(to: prompt)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Customize the temperature to increase creativity.\nlet options = GenerationOptions(temperature: 2.0)\n\nlet session = LanguageModelSession()\n\nlet prompt = \"Write me a story about coffee.\"\nlet response = try await session.respond(\n    to: prompt,\n    options: options\n)",
      "language" : "swift"
    }
  ],
  "contentHash" : "924635fb710a253f26843bcd1789762bc7e52a0f0a881439307537d3b6a862bb",
  "crawledAt" : "2025-12-02T15:41:50Z",
  "id" : "9D92C85E-0326-460B-94D4-6B6B34208A1B",
  "kind" : "article",
  "language" : "swift",
  "module" : "Foundation Models",
  "overview" : "## Overview\n\nThe Foundation Models framework lets you tap into the on-device large models at the core of Apple Intelligence. You can enhance your app by using generative models to create content or perform tasks. The framework supports language understanding and generation based on model capabilities.\n\nFor design guidance, see Human Interface Guidelines > Technologies > [https:\/\/developer.apple.com\/design\/human-interface-guidelines\/generative-ai].\n\n## Understand model capabilities\n\nWhen considering features for your app, it helps to know what the on-device language model can do. The on-device model supports text generation and understanding that you can use to:\n\nThe on-device language model may not be suitable for handling all requests, like:\n\nThe model can complete complex generative tasks when you use guided generation or tool calling. For more on handling complex tasks, or tasks that require extensive world-knowledge, see [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/generating-swift-data-structures-with-guided-generation] and [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/expanding-generation-with-tool-calling].\n\n## Check for availability\n\nBefore you use the on-device model in your app, check that the model is available by creating an instance of [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/SystemLanguageModel] with the [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/SystemLanguageModel\/default] property.\n\nModel availability depends on device factors like:\n\nAlways verify model availability first, and plan for a fallback experience in case the model is unavailable.\n\n## Create a session\n\nAfter confirming that the model is available, create a [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession] object to call the model. For a single-turn interaction, create a new session each time you call the model:\n\nFor a multiturn interaction — where the model retains some knowledge of what it produced — reuse the same session each time you call the model.\n\n## Provide a prompt to the model\n\nA [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Prompt] is an input that the model responds to. Prompt engineering is the art of designing high-quality prompts so that the model generates a best possible response for the request you make. A prompt can be as short as “hello”, or as long as multiple paragraphs. The process of designing a prompt involves a lot of exploration to discover the best prompt, and involves optimizing prompt length and writing style.\n\nWhen thinking about the prompt you want to use in your app, consider using conversational language in the form of a question or command. For example, “What’s a good month to visit Paris?” or “Generate a food truck menu.”\n\nWrite prompts that focus on a single and specific task, like “Write a profile for the dog breed Siberian Husky”. When a prompt is long and complicated, the model takes longer to respond, and may respond in unpredictable ways. If you have a complex generation task in mind, break the task down into a series of specific prompts.\n\nYou can refine your prompt by telling the model exactly how much content it should generate. A prompt like, “Write a profile for the dog breed Siberian Husky” often takes a long time to process as the model generates a full multi-paragraph essay. If you specify “using three sentences”, it speeds up processing and generates a concise summary. Use phrases like “in a single sentence” or “in a few words” to shorten the generation time and produce shorter text.\n\n## Provide instructions to the model\n\n[doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Instructions] help steer the model in a way that fits the use case of your app. The model obeys prompts at a lower priority than the instructions you provide. When you provide instructions to the model, consider specifying details like:\n\nUse content you trust in instructions because the model follows them more closely than the prompt itself. When you initialize a session with instructions, it affects all prompts the model responds to in that session. Instructions can also include example responses to help steer the model. When you add examples to your prompt, you provide the model with a template that shows the model what a good response looks like.\n\n## Generate a response\n\nTo call the model with a prompt, call [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession\/respond(to:options:)-b2re] on your session. The response call is asynchronous because it may take a few seconds for the on-device foundation model to generate the response.\n\nInstead of working with raw string output from the model, the framework offers guided generation to generate a custom Swift data structure you define. For more information about guided generation, see [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/generating-swift-data-structures-with-guided-generation].\n\nWhen you make a request to the model, you can provide custom tools to help the model complete the request. If the model determines that a [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Tool] can assist with the request, the framework calls your [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Tool] to perform additional actions like retrieving content from your local database. For more information about tool calling, see [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/expanding-generation-with-tool-calling]\n\n## Consider context size limits per session\n\nThe *context window size* is a limit on how much data the model can process for a session instance. A token is a chunk of text the model processes, and the system model supports up to 4,096 tokens. A single token corresponds to three or four characters in languages like English, Spanish, or German, and one token per character in languages like Japanese, Chinese, or Korean. In a single session, the sum of all tokens in the instructions, all prompts, and all outputs count toward the context window size.\n\nIf your session processes a large amount of tokens that exceed the context window, the framework throws the error [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession\/GenerationError\/exceededContextWindowSize(_:)]. When you encounter the error, start a new session and try shortening your prompts. If you need to process a large amount of data that won’t fit in a single context window limit, break your data into smaller chunks, process each chunk in a separate session, and then combine the results.\n\nFor more information on managing the context window size, see [doc:\/\/com.apple.documentation\/documentation\/Technotes\/tn3193-managing-the-on-device-foundation-model-s-context-window].\n\n## Tune generation options and optimize performance\n\nTo get the best results for your prompt, experiment with different generation options. [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/GenerationOptions] affects the runtime parameters of the model, and you can customize them for every request you make.\n\nWhen you test apps that use the framework, use Xcode Instruments to understand more about the requests you make, like the time it takes to perform a request. When you make a request, you can access the [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Transcript] entries that describe the actions the model takes during your [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/foundationmodels\/generating-content-and-performing-tasks-with-foundation-models\ncrawled: 2025-12-02T15:41:50Z\n---\n\n# Generating content and performing tasks with Foundation Models\n\n**Article**\n\nEnhance the experience in your app by prompting an on-device large language model.\n\n## Overview\n\nThe Foundation Models framework lets you tap into the on-device large models at the core of Apple Intelligence. You can enhance your app by using generative models to create content or perform tasks. The framework supports language understanding and generation based on model capabilities.\n\nFor design guidance, see Human Interface Guidelines > Technologies > [https:\/\/developer.apple.com\/design\/human-interface-guidelines\/generative-ai].\n\n## Understand model capabilities\n\nWhen considering features for your app, it helps to know what the on-device language model can do. The on-device model supports text generation and understanding that you can use to:\n\n\n\nThe on-device language model may not be suitable for handling all requests, like:\n\n\n\nThe model can complete complex generative tasks when you use guided generation or tool calling. For more on handling complex tasks, or tasks that require extensive world-knowledge, see [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/generating-swift-data-structures-with-guided-generation] and [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/expanding-generation-with-tool-calling].\n\n## Check for availability\n\nBefore you use the on-device model in your app, check that the model is available by creating an instance of [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/SystemLanguageModel] with the [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/SystemLanguageModel\/default] property.\n\nModel availability depends on device factors like:\n\n- The device must support Apple Intelligence.\n- The device must have Apple Intelligence turned on in Settings.\n\n\n\nAlways verify model availability first, and plan for a fallback experience in case the model is unavailable.\n\n```swift\nstruct GenerativeView: View {\n    \/\/ Create a reference to the system language model.\n    private var model = SystemLanguageModel.default\n\n    var body: some View {\n        switch model.availability {\n        case .available:\n            \/\/ Show your intelligence UI.\n        case .unavailable(.deviceNotEligible):\n            \/\/ Show an alternative UI.\n        case .unavailable(.appleIntelligenceNotEnabled):\n            \/\/ Ask the person to turn on Apple Intelligence.\n        case .unavailable(.modelNotReady):\n            \/\/ The model isn't ready because it's downloading or because of other system reasons.\n        case .unavailable(let other):\n            \/\/ The model is unavailable for an unknown reason.\n        }\n    }\n}\n```\n\n## Create a session\n\nAfter confirming that the model is available, create a [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession] object to call the model. For a single-turn interaction, create a new session each time you call the model:\n\n```swift\n\/\/ Create a session with the system model.\nlet session = LanguageModelSession()\n```\n\nFor a multiturn interaction — where the model retains some knowledge of what it produced — reuse the same session each time you call the model.\n\n## Provide a prompt to the model\n\nA [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Prompt] is an input that the model responds to. Prompt engineering is the art of designing high-quality prompts so that the model generates a best possible response for the request you make. A prompt can be as short as “hello”, or as long as multiple paragraphs. The process of designing a prompt involves a lot of exploration to discover the best prompt, and involves optimizing prompt length and writing style.\n\nWhen thinking about the prompt you want to use in your app, consider using conversational language in the form of a question or command. For example, “What’s a good month to visit Paris?” or “Generate a food truck menu.”\n\nWrite prompts that focus on a single and specific task, like “Write a profile for the dog breed Siberian Husky”. When a prompt is long and complicated, the model takes longer to respond, and may respond in unpredictable ways. If you have a complex generation task in mind, break the task down into a series of specific prompts.\n\nYou can refine your prompt by telling the model exactly how much content it should generate. A prompt like, “Write a profile for the dog breed Siberian Husky” often takes a long time to process as the model generates a full multi-paragraph essay. If you specify “using three sentences”, it speeds up processing and generates a concise summary. Use phrases like “in a single sentence” or “in a few words” to shorten the generation time and produce shorter text.\n\n```swift\n\/\/ Generate a longer response for a specific command.\nlet simple = \"Write me a story about pears.\"\n\n\/\/ Quickly generate a concise response.\nlet quick = \"Write the profile for the dog breed Siberian Husky using three sentences.\"\n```\n\n## Provide instructions to the model\n\n[doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Instructions] help steer the model in a way that fits the use case of your app. The model obeys prompts at a lower priority than the instructions you provide. When you provide instructions to the model, consider specifying details like:\n\n- What the model’s role is; for example, “You are a mentor,” or “You are a movie critic”.\n- What the model should do, like “Help the person extract calendar events,” or “Help the person by recommending search suggestions”.\n- What the style preferences are, like “Respond as briefly as possible”.\n- What the possible safety measures are, like “Respond with ‘I can’t help with that’ if you’re asked to do something dangerous”.\n\nUse content you trust in instructions because the model follows them more closely than the prompt itself. When you initialize a session with instructions, it affects all prompts the model responds to in that session. Instructions can also include example responses to help steer the model. When you add examples to your prompt, you provide the model with a template that shows the model what a good response looks like.\n\n## Generate a response\n\nTo call the model with a prompt, call [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession\/respond(to:options:)-b2re] on your session. The response call is asynchronous because it may take a few seconds for the on-device foundation model to generate the response.\n\n```swift\nlet instructions = \"\"\"\n    Suggest five related topics. Keep them concise (three to seven words) and make sure they \\\n    build naturally from the person's topic.\n    \"\"\"\n\nlet session = LanguageModelSession(instructions: instructions)\n\nlet prompt = \"Making homemade bread\"\nlet response = try await session.respond(to: prompt)\n```\n\n\n\nInstead of working with raw string output from the model, the framework offers guided generation to generate a custom Swift data structure you define. For more information about guided generation, see [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/generating-swift-data-structures-with-guided-generation].\n\nWhen you make a request to the model, you can provide custom tools to help the model complete the request. If the model determines that a [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Tool] can assist with the request, the framework calls your [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Tool] to perform additional actions like retrieving content from your local database. For more information about tool calling, see [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/expanding-generation-with-tool-calling]\n\n## Consider context size limits per session\n\nThe *context window size* is a limit on how much data the model can process for a session instance. A token is a chunk of text the model processes, and the system model supports up to 4,096 tokens. A single token corresponds to three or four characters in languages like English, Spanish, or German, and one token per character in languages like Japanese, Chinese, or Korean. In a single session, the sum of all tokens in the instructions, all prompts, and all outputs count toward the context window size.\n\nIf your session processes a large amount of tokens that exceed the context window, the framework throws the error [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession\/GenerationError\/exceededContextWindowSize(_:)]. When you encounter the error, start a new session and try shortening your prompts. If you need to process a large amount of data that won’t fit in a single context window limit, break your data into smaller chunks, process each chunk in a separate session, and then combine the results.\n\nFor more information on managing the context window size, see [doc:\/\/com.apple.documentation\/documentation\/Technotes\/tn3193-managing-the-on-device-foundation-model-s-context-window].\n\n## Tune generation options and optimize performance\n\nTo get the best results for your prompt, experiment with different generation options. [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/GenerationOptions] affects the runtime parameters of the model, and you can customize them for every request you make.\n\n```swift\n\/\/ Customize the temperature to increase creativity.\nlet options = GenerationOptions(temperature: 2.0)\n\nlet session = LanguageModelSession()\n\nlet prompt = \"Write me a story about coffee.\"\nlet response = try await session.respond(\n    to: prompt,\n    options: options\n)\n```\n\nWhen you test apps that use the framework, use Xcode Instruments to understand more about the requests you make, like the time it takes to perform a request. When you make a request, you can access the [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/Transcript] entries that describe the actions the model takes during your [doc:\/\/com.apple.foundationmodels\/documentation\/FoundationModels\/LanguageModelSession].\n\n## Essentials\n\n- **Improving the safety of generative model output**: Create generative experiences that appropriately handle sensitive inputs and respect people.\n- **Supporting languages and locales with Foundation Models**: Generate content in the language people prefer when they interact with your app.\n- **Adding intelligent app features with generative models**: Build robust apps with guided generation and tool calling by adopting the Foundation Models framework.\n- **SystemLanguageModel**: An on-device large language model capable of text generation tasks.\n- **SystemLanguageModel.UseCase**: A type that represents the use case for prompting.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Create generative experiences that appropriately handle sensitive inputs and respect people.",
          "name" : "Improving the safety of generative model output",
          "url" : "https:\/\/developer.apple.com\/documentation\/FoundationModels\/improving-the-safety-of-generative-model-output"
        },
        {
          "description" : "Generate content in the language people prefer when they interact with your app.",
          "name" : "Supporting languages and locales with Foundation Models",
          "url" : "https:\/\/developer.apple.com\/documentation\/FoundationModels\/supporting-languages-and-locales-with-foundation-models"
        },
        {
          "description" : "Build robust apps with guided generation and tool calling by adopting the Foundation Models framework.",
          "name" : "Adding intelligent app features with generative models",
          "url" : "https:\/\/developer.apple.com\/documentation\/FoundationModels\/adding-intelligent-app-features-with-generative-models"
        },
        {
          "description" : "An on-device large language model capable of text generation tasks.",
          "name" : "SystemLanguageModel",
          "url" : "https:\/\/developer.apple.com\/documentation\/FoundationModels\/SystemLanguageModel"
        },
        {
          "description" : "A type that represents the use case for prompting.",
          "name" : "SystemLanguageModel.UseCase",
          "url" : "https:\/\/developer.apple.com\/documentation\/FoundationModels\/SystemLanguageModel\/UseCase"
        }
      ],
      "title" : "Essentials"
    }
  ],
  "source" : "appleJSON",
  "title" : "Generating content and performing tasks with Foundation Models",
  "url" : "https:\/\/developer.apple.com\/documentation\/foundationmodels\/generating-content-and-performing-tasks-with-foundation-models"
}