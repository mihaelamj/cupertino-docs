{
  "abstract" : "Classification metrics.",
  "codeExamples" : [

  ],
  "conformsTo" : [
    "Sendable",
    "SendableMetatype"
  ],
  "contentHash" : "ba113a28d64e99a2e39485bfc0aa75e84e09591fbf7897f0889a411cb72bb763",
  "crawledAt" : "2025-12-03T04:27:50Z",
  "declaration" : {
    "code" : "struct ClassificationMetrics<Label> where Label : Hashable",
    "language" : "swift"
  },
  "id" : "0C4C9602-25D3-4767-A4B3-42E527AE6203",
  "kind" : "struct",
  "language" : "swift",
  "module" : "Create ML Components",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\ncrawled: 2025-12-03T04:27:50Z\n---\n\n# ClassificationMetrics\n\n**Structure**\n\nClassification metrics.\n\n## Declaration\n\n```swift\nstruct ClassificationMetrics<Label> where Label : Hashable\n```\n\n## Creating the distribution\n\n- **init(_:_:)**: Creates classification metrics for predicted and ground truth labels.\n- **init()**: Creates empty classification metrics.\n- **init(_:)**: Creates classification metrics for a sequence of predicted and ground truth label pairs.\n- **init(_:labels:)**: Creates classification metrics for a sequence of predicted and ground truth label pairs.\n- **init(predicted:groundTruth:labels:)**: Creates classification metrics for predicted and ground truth labels.\n\n## Getting the properties\n\n- **accuracy**: The number of correctly classified examples out of the total number of examples.\n- **exampleCount**: The number of examples used to compute the metrics.\n- **labels**: The set of labels.\n- **restrictToKnownLabels**: A Boolean value indicating whether to restrict metrics to labels in the labels set.\n\n## Computing and scoring\n\n- **makeConfusionMatrix()**: Computes the confusion matrix.\n- **precisionScore(label:)**: Computes the precision score for a class label.\n- **recallScore(label:)**: Computes the recall score for a class label.\n- **count(label:)**: Returns the number of times a label appeared in the ground truth collection.\n- **count(predicted:)**: Returns the number of times a label appeared in the predicted collection.\n- **count(predicted:label:)**: Returns the number of times a predicted, true label pair appeared in the label collections.\n- **trueNegativeCount(of:)**: Returns the number of times a label was not in the predicted or ground truth collections.\n- **truePositiveCount(of:)**: Returns the number of times the predicted label matched the true label.\n- **falseNegativeCount(of:)**: Returns the number of times a true label was not predicted.\n- **falsePositiveCount(of:)**: Returns the number of times the predicted label did not match the true label.\n- **f1Score(label:)**: Computes the F1 score for a class label.\n- **mapLabels(_:)**: Returns new classification metrics where the labels are the result of applying a transformation.\n\n## Updating the metrics\n\n- **add(_:)**: Updates the metrics with more predicted and ground truth label pairs.\n- **add(predicted:groundTruth:)**: Updates the metrics with more predicted and ground truth labels.\n\n## Metrics\n\n- **Classification**: An item in a classification result.\n- **ClassificationDistribution**: A classification distribution that contains a probability for each classification label.\n- **MultiLabelClassificationMetrics**: Multi-label classification metrics.\n- **rootMeanSquaredError(_:)**: Computes the root mean squared error between predicted and ground truth values.\n- **rootMeanSquaredError(_:_:)**: Computes the root mean squared error between predicted and ground truth values.\n- **maximumAbsoluteError(_:)**: Computes the maximum absolute error between predicted and ground truth values.\n- **maximumAbsoluteError(_:_:)**: Computes the maximum absolute error between predicted and ground truth values.\n- **meanAbsoluteError(_:)**: Computes the mean absolute error between predicted and ground truth values.\n- **meanAbsoluteError(_:_:)**: Computes the mean absolute error between predicted and ground truth values.\n- **meanAbsolutePercentageError(_:)**: Computes the mean absolute percentage error between predicted and ground truth values.\n- **meanSquaredError(_:)**: Computes the root mean squared error between predicted and ground truth values.\n- **meanSquaredError(_:_:)**: Computes the mean squared error between predicted and ground truth values.\n\n## Conforms To\n\n- Sendable\n- SendableMetatype\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Creates classification metrics for predicted and ground truth labels.",
          "name" : "init(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/init(_:_:)"
        },
        {
          "description" : "Creates empty classification metrics.",
          "name" : "init()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/init()"
        },
        {
          "description" : "Creates classification metrics for a sequence of predicted and ground truth label pairs.",
          "name" : "init(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/init(_:)"
        },
        {
          "description" : "Creates classification metrics for a sequence of predicted and ground truth label pairs.",
          "name" : "init(_:labels:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/init(_:labels:)"
        },
        {
          "description" : "Creates classification metrics for predicted and ground truth labels.",
          "name" : "init(predicted:groundTruth:labels:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/init(predicted:groundTruth:labels:)"
        }
      ],
      "title" : "Creating the distribution"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "The number of correctly classified examples out of the total number of examples.",
          "name" : "accuracy",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/accuracy"
        },
        {
          "description" : "The number of examples used to compute the metrics.",
          "name" : "exampleCount",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/exampleCount"
        },
        {
          "description" : "The set of labels.",
          "name" : "labels",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/labels"
        },
        {
          "description" : "A Boolean value indicating whether to restrict metrics to labels in the labels set.",
          "name" : "restrictToKnownLabels",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/restrictToKnownLabels"
        }
      ],
      "title" : "Getting the properties"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Computes the confusion matrix.",
          "name" : "makeConfusionMatrix()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/makeConfusionMatrix()"
        },
        {
          "description" : "Computes the precision score for a class label.",
          "name" : "precisionScore(label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/precisionScore(label:)"
        },
        {
          "description" : "Computes the recall score for a class label.",
          "name" : "recallScore(label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/recallScore(label:)"
        },
        {
          "description" : "Returns the number of times a label appeared in the ground truth collection.",
          "name" : "count(label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/count(label:)"
        },
        {
          "description" : "Returns the number of times a label appeared in the predicted collection.",
          "name" : "count(predicted:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/count(predicted:)"
        },
        {
          "description" : "Returns the number of times a predicted, true label pair appeared in the label collections.",
          "name" : "count(predicted:label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/count(predicted:label:)"
        },
        {
          "description" : "Returns the number of times a label was not in the predicted or ground truth collections.",
          "name" : "trueNegativeCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/trueNegativeCount(of:)"
        },
        {
          "description" : "Returns the number of times the predicted label matched the true label.",
          "name" : "truePositiveCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/truePositiveCount(of:)"
        },
        {
          "description" : "Returns the number of times a true label was not predicted.",
          "name" : "falseNegativeCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/falseNegativeCount(of:)"
        },
        {
          "description" : "Returns the number of times the predicted label did not match the true label.",
          "name" : "falsePositiveCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/falsePositiveCount(of:)"
        },
        {
          "description" : "Computes the F1 score for a class label.",
          "name" : "f1Score(label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/f1Score(label:)"
        },
        {
          "description" : "Returns new classification metrics where the labels are the result of applying a transformation.",
          "name" : "mapLabels(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/mapLabels(_:)"
        }
      ],
      "title" : "Computing and scoring"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "Updates the metrics with more predicted and ground truth label pairs.",
          "name" : "add(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/add(_:)"
        },
        {
          "description" : "Updates the metrics with more predicted and ground truth labels.",
          "name" : "add(predicted:groundTruth:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/add(predicted:groundTruth:)"
        }
      ],
      "title" : "Updating the metrics"
    },
    {
      "content" : "",
      "items" : [
        {
          "description" : "An item in a classification result.",
          "name" : "Classification",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/Classification"
        },
        {
          "description" : "A classification distribution that contains a probability for each classification label.",
          "name" : "ClassificationDistribution",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationDistribution"
        },
        {
          "description" : "Multi-label classification metrics.",
          "name" : "MultiLabelClassificationMetrics",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/MultiLabelClassificationMetrics"
        },
        {
          "description" : "Computes the root mean squared error between predicted and ground truth values.",
          "name" : "rootMeanSquaredError(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/rootMeanSquaredError(_:)"
        },
        {
          "description" : "Computes the root mean squared error between predicted and ground truth values.",
          "name" : "rootMeanSquaredError(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/rootMeanSquaredError(_:_:)"
        },
        {
          "description" : "Computes the maximum absolute error between predicted and ground truth values.",
          "name" : "maximumAbsoluteError(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/maximumAbsoluteError(_:)"
        },
        {
          "description" : "Computes the maximum absolute error between predicted and ground truth values.",
          "name" : "maximumAbsoluteError(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/maximumAbsoluteError(_:_:)"
        },
        {
          "description" : "Computes the mean absolute error between predicted and ground truth values.",
          "name" : "meanAbsoluteError(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/meanAbsoluteError(_:)"
        },
        {
          "description" : "Computes the mean absolute error between predicted and ground truth values.",
          "name" : "meanAbsoluteError(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/meanAbsoluteError(_:_:)"
        },
        {
          "description" : "Computes the mean absolute percentage error between predicted and ground truth values.",
          "name" : "meanAbsolutePercentageError(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/meanAbsolutePercentageError(_:)"
        },
        {
          "description" : "Computes the root mean squared error between predicted and ground truth values.",
          "name" : "meanSquaredError(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/meanSquaredError(_:)"
        },
        {
          "description" : "Computes the mean squared error between predicted and ground truth values.",
          "name" : "meanSquaredError(_:_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/meanSquaredError(_:_:)"
        }
      ],
      "title" : "Metrics"
    }
  ],
  "source" : "appleJSON",
  "title" : "ClassificationMetrics",
  "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics"
}