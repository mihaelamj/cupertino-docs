{
  "abstract" : "Computes the recall score for a class label.",
  "codeExamples" : [

  ],
  "contentHash" : "bfcb0b8ef3f04ccaa9c1e7562e3914d00ccb89e30349a96fd3e3df268b35dfd7",
  "crawledAt" : "2025-12-04T05:05:39Z",
  "declaration" : {
    "code" : "func recallScore(label: Label) -> Double",
    "language" : "swift"
  },
  "id" : "879D2CCB-EC98-4616-A10B-970F3C731A2C",
  "kind" : "method",
  "language" : "swift",
  "module" : "Create ML Components",
  "overview" : "## Return Value\n\nThe recall score for the given label.\n\n## Discussion\n\nPrecision score is computed as the ratio `tp \/ (tp + fn)` where `tp` is the number of true positives and `fn` is the number of false negatives.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS",
    "watchOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/recallScore(label:)\ncrawled: 2025-12-04T05:05:39Z\n---\n\n# recallScore(label:)\n\n**Instance Method**\n\nComputes the recall score for a class label.\n\n## Declaration\n\n```swift\nfunc recallScore(label: Label) -> Double\n```\n\n## Parameters\n\n- **label**: The label to use as true positive.\n\n## Return Value\n\nThe recall score for the given label.\n\n## Discussion\n\nPrecision score is computed as the ratio `tp \/ (tp + fn)` where `tp` is the number of true positives and `fn` is the number of false negatives.\n\n## Computing and scoring\n\n- **makeConfusionMatrix()**: Computes the confusion matrix.\n- **precisionScore(label:)**: Computes the precision score for a class label.\n- **count(label:)**: Returns the number of times a label appeared in the ground truth collection.\n- **count(predicted:)**: Returns the number of times a label appeared in the predicted collection.\n- **count(predicted:label:)**: Returns the number of times a predicted, true label pair appeared in the label collections.\n- **trueNegativeCount(of:)**: Returns the number of times a label was not in the predicted or ground truth collections.\n- **truePositiveCount(of:)**: Returns the number of times the predicted label matched the true label.\n- **falseNegativeCount(of:)**: Returns the number of times a true label was not predicted.\n- **falsePositiveCount(of:)**: Returns the number of times the predicted label did not match the true label.\n- **f1Score(label:)**: Computes the F1 score for a class label.\n- **mapLabels(_:)**: Returns new classification metrics where the labels are the result of applying a transformation.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Computes the confusion matrix.",
          "name" : "makeConfusionMatrix()",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/makeConfusionMatrix()"
        },
        {
          "description" : "Computes the precision score for a class label.",
          "name" : "precisionScore(label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/precisionScore(label:)"
        },
        {
          "description" : "Returns the number of times a label appeared in the ground truth collection.",
          "name" : "count(label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/count(label:)"
        },
        {
          "description" : "Returns the number of times a label appeared in the predicted collection.",
          "name" : "count(predicted:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/count(predicted:)"
        },
        {
          "description" : "Returns the number of times a predicted, true label pair appeared in the label collections.",
          "name" : "count(predicted:label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/count(predicted:label:)"
        },
        {
          "description" : "Returns the number of times a label was not in the predicted or ground truth collections.",
          "name" : "trueNegativeCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/trueNegativeCount(of:)"
        },
        {
          "description" : "Returns the number of times the predicted label matched the true label.",
          "name" : "truePositiveCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/truePositiveCount(of:)"
        },
        {
          "description" : "Returns the number of times a true label was not predicted.",
          "name" : "falseNegativeCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/falseNegativeCount(of:)"
        },
        {
          "description" : "Returns the number of times the predicted label did not match the true label.",
          "name" : "falsePositiveCount(of:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/falsePositiveCount(of:)"
        },
        {
          "description" : "Computes the F1 score for a class label.",
          "name" : "f1Score(label:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/f1Score(label:)"
        },
        {
          "description" : "Returns new classification metrics where the labels are the result of applying a transformation.",
          "name" : "mapLabels(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/mapLabels(_:)"
        }
      ],
      "title" : "Computing and scoring"
    }
  ],
  "source" : "appleJSON",
  "title" : "recallScore(label:)",
  "url" : "https:\/\/developer.apple.com\/documentation\/CreateMLComponents\/ClassificationMetrics\/recallScore(label:)"
}