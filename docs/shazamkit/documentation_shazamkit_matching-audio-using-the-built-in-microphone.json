{
  "abstract" : "Use the audio stream from the microphone as the source for a ShazamKit session.",
  "codeExamples" : [
    {
      "code" : "let audioEngine = AVAudioEngine()\nlet mixerNode = AVAudioMixerNode()\n\n\/\/ The session for the active ShazamKit match request.\nlet session: SHSession?",
      "language" : "swift"
    },
    {
      "code" : "func addAudio(buffer: AVAudioPCMBuffer, audioTime: AVAudioTime) {\n    \/\/ Add the audio to the current match request.\n    session?.matchStreamingBuffer(buffer, at: audioTime)\n}",
      "language" : "swift"
    },
    {
      "code" : "func configureAudioEngine() {\n    \/\/ Get the native audio format of the engine's input bus.\n    let inputFormat = audioEngine.inputNode.inputFormat(forBus: 0)\n    \n    \/\/ Set an output format compatible with ShazamKit.\n    let outputFormat = AVAudioFormat(standardFormatWithSampleRate: 48000, channels: 1)\n    \n    \/\/ Create a mixer node to convert the input.\n    audioEngine.attach(mixerNode)\n\n    \/\/ Attach the mixer to the microphone input and the output of the audio engine.\n    audioEngine.connect(audioEngine.inputNode, to: mixerNode, format: inputFormat)\n    audioEngine.connect(mixerNode, to: audioEngine.outputNode, format: outputFormat)\n        \n    \/\/ Install a tap on the mixer node to capture the microphone audio.\n    mixerNode.installTap(onBus: 0,\n                         bufferSize: 8192,\n                         format: outputFormat) { buffer, audioTime in\n        \/\/ Add captured audio to the buffer used for making a match.\n        self.addAudio(buffer: buffer, audioTime: audioTime)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "func startListening() throws {\n    \/\/ Throw an error if the audio engine is already running.\n    guard !audioEngine.isRunning else { return }\n    let audioSession = AVAudioSession.sharedInstance()\n    \n    \/\/ Ask the user for permission to use the mic if required then start the engine.\n    try audioSession.setCategory(.playAndRecord)\n    audioSession.requestRecordPermission { [weak self] success in\n        guard success, let self = self else { return }\n        try? self.audioEngine.start()\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "func stopListening() {\n    \/\/ Check if the audio engine is already recording.\n    if audioEngine.isRunning {\n        audioEngine.stop()\n    }\n}\n",
      "language" : "swift"
    },
    {
      "code" : "func match(_ catalog: SHCustomCatalog) throws {\n    \/\/ Create a session if one doesn't already exist.\n    if (session == nil) {\n        session = SHSession(catalog: catalog)\n        session?.delegate = self\n    }\n    \n    \/\/ Start listening to the audio to find a match.\n    try startListening()\n}",
      "language" : "swift"
    },
    {
      "code" : "func match(_ catalog: SHCustomCatalog) throws {\n    \/\/ Create a new session if there's an existing session with a different catalog.\n    if session?.catalog != catalog {\n        \/\/ Stop any active match request.\n        stopListening()\n        \n        session = SHSession(catalog: catalog)\n        session?.delegate = self\n    }\n    try startListening()\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "e5c58690f8dccbfd69db9a9eae87db2525441225d4d36c745f700a5abfbb0203",
  "crawledAt" : "2025-12-04T02:48:18Z",
  "id" : "44D9C3CC-3439-40BA-9A57-17EBF9DED068",
  "kind" : "article",
  "language" : "swift",
  "module" : "ShazamKit",
  "overview" : "## Overview\n\nUse an audio engine with a mixer node to connect to the microphone and convert the audio format into one that’s compatible with ShazamKit. You’ll also need to add a description of the intended use of the microphone.\n\n### Add a microphone use description\n\nThe microphone is a protected resource and requires permission from the user. Your app must provide a description of the intended use by adding a `Privacy - Microphone Usage Description` key to App Info. For more information on accessing protected resources, see [doc:\/\/com.apple.documentation\/documentation\/UIKit\/requesting-access-to-protected-resources].\n\n### Configure an audio mixer and install a tap\n\nAccess the microphone using [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioEngine] and an [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioMixerNode] to convert the sound into one that’s compatible with ShazamKit.\n\nStart by adding properties to your matcher class for the audio engine and mixer node. Then add a property for the active ShazamKit session.\n\nAdd a function that appends an audio buffer to the buffer used for matching. The audio engine calls this function when new audio is available.\n\nNext, add a method that configures the audio engine and mixer, and installs the tap that calls your add audio function. A tap provides access to the input of the audio engine. Call this function from the initialization code for your object because you only need to set up the engine once.\n\n### Start and stop the audio engine\n\nAdd a function to start listening to the microphone using the tap on the mixer node. You must request access to the microphone.\n\nThe category uses [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioRoutingArbiter\/Category\/playAndRecord] because the input of the mixer records the mic and the output plays the result. The tap captures the audio buffers from the output of the mixer.\n\nAdd another function to stop listening to the microphone. Call this function when you no longer need information about the matched item, such as the [doc:\/\/com.apple.shazamkit\/documentation\/ShazamKit\/SHMatchedMediaItem\/predictedCurrentMatchOffset]. Also call this function when there’s a value for error in [doc:\/\/com.apple.shazamkit\/documentation\/ShazamKit\/SHSessionDelegate\/session(_:didNotFindMatchFor:error:)].\n\nYou can also [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer\/pause()] the engine instead of stopping it.\n\n### Check for a match in a catalog\n\nCheck for a match by creating an [doc:\/\/com.apple.shazamkit\/documentation\/ShazamKit\/SHSession] object for a catalog and starting the audio engine. The following function demonstrates this:\n\nIf your matcher uses multiple catalogs, you must create a new session when the catalog changes. The following function shows an example of this:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/ShazamKit\/matching-audio-using-the-built-in-microphone\ncrawled: 2025-12-04T02:48:18Z\n---\n\n# Matching audio using the built-in microphone\n\n**Article**\n\nUse the audio stream from the microphone as the source for a ShazamKit session.\n\n## Overview\n\nUse an audio engine with a mixer node to connect to the microphone and convert the audio format into one that’s compatible with ShazamKit. You’ll also need to add a description of the intended use of the microphone.\n\n### Add a microphone use description\n\nThe microphone is a protected resource and requires permission from the user. Your app must provide a description of the intended use by adding a `Privacy - Microphone Usage Description` key to App Info. For more information on accessing protected resources, see [doc:\/\/com.apple.documentation\/documentation\/UIKit\/requesting-access-to-protected-resources].\n\n### Configure an audio mixer and install a tap\n\nAccess the microphone using [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioEngine] and an [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioMixerNode] to convert the sound into one that’s compatible with ShazamKit.\n\nStart by adding properties to your matcher class for the audio engine and mixer node. Then add a property for the active ShazamKit session.\n\n```swift\nlet audioEngine = AVAudioEngine()\nlet mixerNode = AVAudioMixerNode()\n\n\/\/ The session for the active ShazamKit match request.\nlet session: SHSession?\n```\n\nAdd a function that appends an audio buffer to the buffer used for matching. The audio engine calls this function when new audio is available.\n\n```swift\nfunc addAudio(buffer: AVAudioPCMBuffer, audioTime: AVAudioTime) {\n    \/\/ Add the audio to the current match request.\n    session?.matchStreamingBuffer(buffer, at: audioTime)\n}\n```\n\nNext, add a method that configures the audio engine and mixer, and installs the tap that calls your add audio function. A tap provides access to the input of the audio engine. Call this function from the initialization code for your object because you only need to set up the engine once.\n\n```swift\nfunc configureAudioEngine() {\n    \/\/ Get the native audio format of the engine's input bus.\n    let inputFormat = audioEngine.inputNode.inputFormat(forBus: 0)\n    \n    \/\/ Set an output format compatible with ShazamKit.\n    let outputFormat = AVAudioFormat(standardFormatWithSampleRate: 48000, channels: 1)\n    \n    \/\/ Create a mixer node to convert the input.\n    audioEngine.attach(mixerNode)\n\n    \/\/ Attach the mixer to the microphone input and the output of the audio engine.\n    audioEngine.connect(audioEngine.inputNode, to: mixerNode, format: inputFormat)\n    audioEngine.connect(mixerNode, to: audioEngine.outputNode, format: outputFormat)\n        \n    \/\/ Install a tap on the mixer node to capture the microphone audio.\n    mixerNode.installTap(onBus: 0,\n                         bufferSize: 8192,\n                         format: outputFormat) { buffer, audioTime in\n        \/\/ Add captured audio to the buffer used for making a match.\n        self.addAudio(buffer: buffer, audioTime: audioTime)\n    }\n}\n```\n\n\n\n### Start and stop the audio engine\n\nAdd a function to start listening to the microphone using the tap on the mixer node. You must request access to the microphone.\n\n```swift\nfunc startListening() throws {\n    \/\/ Throw an error if the audio engine is already running.\n    guard !audioEngine.isRunning else { return }\n    let audioSession = AVAudioSession.sharedInstance()\n    \n    \/\/ Ask the user for permission to use the mic if required then start the engine.\n    try audioSession.setCategory(.playAndRecord)\n    audioSession.requestRecordPermission { [weak self] success in\n        guard success, let self = self else { return }\n        try? self.audioEngine.start()\n    }\n}\n```\n\nThe category uses [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioRoutingArbiter\/Category\/playAndRecord] because the input of the mixer records the mic and the output plays the result. The tap captures the audio buffers from the output of the mixer.\n\nAdd another function to stop listening to the microphone. Call this function when you no longer need information about the matched item, such as the [doc:\/\/com.apple.shazamkit\/documentation\/ShazamKit\/SHMatchedMediaItem\/predictedCurrentMatchOffset]. Also call this function when there’s a value for error in [doc:\/\/com.apple.shazamkit\/documentation\/ShazamKit\/SHSessionDelegate\/session(_:didNotFindMatchFor:error:)].\n\n```swift\nfunc stopListening() {\n    \/\/ Check if the audio engine is already recording.\n    if audioEngine.isRunning {\n        audioEngine.stop()\n    }\n}\n\n```\n\nYou can also [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer\/pause()] the engine instead of stopping it.\n\n### Check for a match in a catalog\n\nCheck for a match by creating an [doc:\/\/com.apple.shazamkit\/documentation\/ShazamKit\/SHSession] object for a catalog and starting the audio engine. The following function demonstrates this:\n\n```swift\nfunc match(_ catalog: SHCustomCatalog) throws {\n    \/\/ Create a session if one doesn't already exist.\n    if (session == nil) {\n        session = SHSession(catalog: catalog)\n        session?.delegate = self\n    }\n    \n    \/\/ Start listening to the audio to find a match.\n    try startListening()\n}\n```\n\nIf your matcher uses multiple catalogs, you must create a new session when the catalog changes. The following function shows an example of this:\n\n```swift\nfunc match(_ catalog: SHCustomCatalog) throws {\n    \/\/ Create a new session if there's an existing session with a different catalog.\n    if session?.catalog != catalog {\n        \/\/ Stop any active match request.\n        stopListening()\n        \n        session = SHSession(catalog: catalog)\n        session?.delegate = self\n    }\n    try startListening()\n}\n```\n\n## Making a match\n\n- **match(_:)**: Searches for the query signature in the reference signatures that the session catalog contains.\n- **matchStreamingBuffer(_:at:)**: Converts the audio in the buffer to a signature, and searches the reference signatures in the session catalog.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Searches for the query signature in the reference signatures that the session catalog contains.",
          "name" : "match(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ShazamKit\/SHSession\/match(_:)"
        },
        {
          "description" : "Converts the audio in the buffer to a signature, and searches the reference signatures in the session catalog.",
          "name" : "matchStreamingBuffer(_:at:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/ShazamKit\/SHSession\/matchStreamingBuffer(_:at:)"
        }
      ],
      "title" : "Making a match"
    }
  ],
  "source" : "appleJSON",
  "title" : "Matching audio using the built-in microphone",
  "url" : "https:\/\/developer.apple.com\/documentation\/ShazamKit\/matching-audio-using-the-built-in-microphone"
}