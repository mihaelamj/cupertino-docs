{
  "codeExamples" : [

  ],
  "contentHash" : "a4ceb9bb2544fbadfe66b13416e1349f970be145a19b9fd2fd5ae65b4eb391e4",
  "crawledAt" : "2025-12-02T19:04:34Z",
  "declaration" : {
    "code" : "struct ScheduledAudioFileRegion",
    "language" : "swift"
  },
  "id" : "E34AB17F-1807-47E2-92C3-1FC14F80CE0D",
  "kind" : "unknown",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AudioToolbox\/ScheduledAudioFileRegion\ncrawled: 2025-12-02T19:04:34Z\n---\n\n# ScheduledAudioFileRegion | Apple Developer Documentation\n\n- [ Audio Toolbox ](\/documentation\/audiotoolbox)\n\n- [ ScheduledAudioFileRegion ](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion)\n\n-  ScheduledAudioFileRegion \n\nStructure# ScheduledAudioFileRegion\n\niOSiPadOSMac CatalystmacOStvOSvisionOS\n\n```\nstruct ScheduledAudioFileRegion\n```\n\n## [Topics](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion#topics)\n\n### [Initializers](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion#Initializers)\n\n[`init(mTimeStamp: AudioTimeStamp, mCompletionProc: ScheduledAudioFileRegionCompletionProc?, mCompletionProcUserData: UnsafeMutableRawPointer?, mAudioFile: OpaquePointer, mLoopCount: UInt32, mStartFrame: Int64, mFramesToPlay: UInt32)`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/init(mtimestamp:mcompletionproc:mcompletionprocuserdata:maudiofile:mloopcount:mstartframe:mframestoplay:))### [Instance Properties](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion#Instance-Properties)\n\n[`var mAudioFile: OpaquePointer`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/maudiofile)Must be a valid and already-open audio file object (of type `AudioFileID`), as declared in `AudioToolbox\/AudioFile.h`.[`var mCompletionProc: ScheduledAudioFileRegionCompletionProc?`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/mcompletionproc)may be `NULL`[`var mCompletionProcUserData: UnsafeMutableRawPointer?`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/mcompletionprocuserdata)[`var mFramesToPlay: UInt32`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/mframestoplay)The number of frames to play.[`var mLoopCount: UInt32`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/mloopcount)`0` = do not loop[`var mStartFrame: Int64`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/mstartframe)The frame offset into the file.[`var mTimeStamp: AudioTimeStamp`](\/documentation\/audiotoolbox\/scheduledaudiofileregion\/mtimestamp)## [Relationships](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion#relationships)\n\n### [Conforms To](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion#conforms-to)\n\n- [`BitwiseCopyable`](\/documentation\/Swift\/BitwiseCopyable)\n\n## [See Also](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion#see-also)\n\n### [Audio Unit Types](\/documentation\/AudioToolbox\/ScheduledAudioFileRegion#Audio-Unit-Types)\n\n[`struct ScheduledAudioSlice`](\/documentation\/audiotoolbox\/scheduledaudioslice)[`typealias ScheduledAudioFileRegionCompletionProc`](\/documentation\/audiotoolbox\/scheduledaudiofileregioncompletionproc)[`typealias ScheduledAudioSliceCompletionProc`](\/documentation\/audiotoolbox\/scheduledaudioslicecompletionproc)[`typealias MIDIChannelNumber`](\/documentation\/audiotoolbox\/midichannelnumber)MIDI Channel, 0~15 (channels 1 through 16, respectively).[`typealias AUAudioObjectID`](\/documentation\/audiotoolbox\/auaudioobjectid)[`typealias AUMIDICIProfileChangedBlock`](\/documentation\/audiotoolbox\/aumidiciprofilechangedblock)[`typealias AUAudioChannelCount`](\/documentation\/audiotoolbox\/auaudiochannelcount)A number of audio channels.[`typealias AUAudioFrameCount`](\/documentation\/audiotoolbox\/auaudioframecount)A number of audio sample frames.[`typealias AUAudioUnitStatus`](\/documentation\/audiotoolbox\/auaudiounitstatus)A result code returned from an audio unit’s render function.[`typealias AUEventListenerProc`](\/documentation\/audiotoolbox\/aueventlistenerproc)[`typealias AUEventListenerRef`](\/documentation\/audiotoolbox\/aueventlistenerref)[`typealias AUEventSampleTime`](\/documentation\/audiotoolbox\/aueventsampletime)Expresses time as a sample count.[`typealias AUImplementorValueObserver`](\/documentation\/audiotoolbox\/auimplementorvalueobserver)A block called to notify the audio unit implementation of changes to a parameter value.[`typealias AUImplementorValueProvider`](\/documentation\/audiotoolbox\/auimplementorvalueprovider)A block called to fetch a parameter’s current value from the audio unit implementation.[`typealias AUInputHandler`](\/documentation\/audiotoolbox\/auinputhandler)A block to notify the host of an I\/O unit that an input is available.",
  "sections" : [
    {
      "content" : "",
      "title" : "Topics"
    },
    {
      "content" : "",
      "title" : "Relationships"
    },
    {
      "content" : "",
      "title" : "See Also"
    }
  ],
  "source" : "appleWebKit",
  "title" : "ScheduledAudioFileRegion | Apple Developer Documentation",
  "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/ScheduledAudioFileRegion"
}