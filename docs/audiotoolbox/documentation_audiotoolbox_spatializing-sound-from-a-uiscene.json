{
  "abstract" : "Provide unique app experiences by attaching sounds to windows and volumes in 3D space.",
  "codeExamples" : [
    {
      "code" : "import SwiftUI \n\n@main\nstruct MyApplication: App {\n    @UIApplicationDelegateAdaptor var delegate: MyAppDelegate\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n        }\n    }\n}\n\nclass MyAppDelegate: NSObject, UIApplicationDelegate, ObservableObject {\n    func application(_ application: UIApplication,\n                     configurationForConnecting connectingSceneSession: UISceneSession,\n                     options: UIScene.ConnectionOptions) -> UISceneConfiguration {\n        let sceneConfig = UISceneConfiguration(name: nil, sessionRole: connectingSceneSession.role)\n        sceneConfig.delegateClass = MySceneDelegate.self\n        return sceneConfig\n    }\n}\n\nclass MySceneDelegate: NSObject, UISceneDelegate, ObservableObject {\n    var sceneIdentifier: String?\n\n    func scene(_ scene: UIScene, willConnectTo session: UISceneSession, options connectionOptions: UIScene.ConnectionOptions) {\n        sceneIdentifier = session.persistentIdentifier\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import SwiftUI\n\nstruct ContentView: View {\n    @EnvironmentObject var sceneDelegate: MySceneDelegate\n\n    var body: some View {\n        Text(\"\\(String(describing: sceneDelegate.sceneIdentifier))\")\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import SwiftUI\nimport AVFAudio\n\nstruct ContentView: View {\n    @EnvironmentObject var sceneDelegate: MySceneDelegate\n    \n    @State var player: AVAudioPlayer? = {\n        guard let url = Bundle.main.url(forResource: \"my_sound\", withExtension: \"wav\") else {\n            return nil\n        }\n        return try? AVAudioPlayer(contentsOf: url)\n    }()\n\n    var body: some View {\n        Text(\"Hello, Sound!\")\n    }\n    .onAppear {\n        guard let player = self.player, let sceneID = self.sceneDelegate.sceneIdentifier else {\n            return\n        }\n        \n        player.intendedSpatialExperience = .headTracked(.scene(identifier: sceneID))\n        player.play()\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "4acf31e0582c0502194bff32ce201c3f8886f57204598acc0ddd2ac09d9c9a84",
  "crawledAt" : "2025-12-02T17:01:43Z",
  "id" : "8ADDDA69-F3B0-4196-BF4C-0D4411F0C722",
  "kind" : "article",
  "language" : "swift",
  "module" : "Audio Toolbox",
  "overview" : "## Overview\n\nMany audio playback APIs have a property to configure their 3D spatial rendering using the [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/SpatialAudioExperience] type [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/HeadTrackedSpatialAudio]. This article shows how to take advantage of [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/HeadTrackedSpatialAudio] to place each sound at the center of its intended [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] in your multiwindow or multivolume application.\n\n\n\n## Get the scene’s identifier\n\nPlacing a sound on a specific [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] requires knowledge of the target scene’s [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISceneSession\/persistentIdentifier]. In a SwiftUI application, that means adding both a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIApplicationDelegate] and [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISceneDelegate] to your SwiftUI App:\n\nThe following code makes the identifier for each [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] accessible from any SwiftUI [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/View] using your [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISceneDelegate] as an [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/EnvironmentObject]:\n\n## Anchor the sound to the scene\n\nWith a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] identifier in-hand, configure each sound using a [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/HeadTrackedSpatialAudio] structure.\n\nBesides just [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioPlayer], you can also use [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/SpatialAudioExperience] types with the other playback APIs listed below.\n\n## Spatialize system and alert sounds\n\nConfigure the spatial audio experience of your system and alert sounds using:\n\n## Spatialize audio-only playback APIs\n\nConfigure the spatial audio experience of audio-only playback APIs using the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioPlayer\/intendedSpatialExperience-27klj] property on:\n\n## Spatialize audio playback APIs that also have video\n\nSetting a scene identifier on playback APIs that have video content isn’t always necessary as their sound automatically anchors to its visual counterpart. However, if there is no video or if you prefer something besides the automatic behavior, configure the spatial audio experience of these playback APIs using the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer\/intendedSpatialAudioExperience-1bd87] property on:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AudioToolbox\/spatializing-sound-from-a-uiscene\ncrawled: 2025-12-02T17:01:43Z\n---\n\n# Anchoring sound to a window or volume\n\n**Article**\n\nProvide unique app experiences by attaching sounds to windows and volumes in 3D space.\n\n## Overview\n\nMany audio playback APIs have a property to configure their 3D spatial rendering using the [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/SpatialAudioExperience] type [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/HeadTrackedSpatialAudio]. This article shows how to take advantage of [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/HeadTrackedSpatialAudio] to place each sound at the center of its intended [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] in your multiwindow or multivolume application.\n\n\n\n## Get the scene’s identifier\n\nPlacing a sound on a specific [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] requires knowledge of the target scene’s [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISceneSession\/persistentIdentifier]. In a SwiftUI application, that means adding both a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIApplicationDelegate] and [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISceneDelegate] to your SwiftUI App:\n\n```swift\nimport SwiftUI \n\n@main\nstruct MyApplication: App {\n    @UIApplicationDelegateAdaptor var delegate: MyAppDelegate\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n        }\n    }\n}\n\nclass MyAppDelegate: NSObject, UIApplicationDelegate, ObservableObject {\n    func application(_ application: UIApplication,\n                     configurationForConnecting connectingSceneSession: UISceneSession,\n                     options: UIScene.ConnectionOptions) -> UISceneConfiguration {\n        let sceneConfig = UISceneConfiguration(name: nil, sessionRole: connectingSceneSession.role)\n        sceneConfig.delegateClass = MySceneDelegate.self\n        return sceneConfig\n    }\n}\n\nclass MySceneDelegate: NSObject, UISceneDelegate, ObservableObject {\n    var sceneIdentifier: String?\n\n    func scene(_ scene: UIScene, willConnectTo session: UISceneSession, options connectionOptions: UIScene.ConnectionOptions) {\n        sceneIdentifier = session.persistentIdentifier\n    }\n}\n```\n\nThe following code makes the identifier for each [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] accessible from any SwiftUI [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/View] using your [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UISceneDelegate] as an [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/EnvironmentObject]:\n\n```swift\nimport SwiftUI\n\nstruct ContentView: View {\n    @EnvironmentObject var sceneDelegate: MySceneDelegate\n\n    var body: some View {\n        Text(\"\\(String(describing: sceneDelegate.sceneIdentifier))\")\n    }\n}\n```\n\n## Anchor the sound to the scene\n\nWith a [doc:\/\/com.apple.documentation\/documentation\/UIKit\/UIScene] identifier in-hand, configure each sound using a [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/HeadTrackedSpatialAudio] structure.\n\n```swift\nimport SwiftUI\nimport AVFAudio\n\nstruct ContentView: View {\n    @EnvironmentObject var sceneDelegate: MySceneDelegate\n    \n    @State var player: AVAudioPlayer? = {\n        guard let url = Bundle.main.url(forResource: \"my_sound\", withExtension: \"wav\") else {\n            return nil\n        }\n        return try? AVAudioPlayer(contentsOf: url)\n    }()\n\n    var body: some View {\n        Text(\"Hello, Sound!\")\n    }\n    .onAppear {\n        guard let player = self.player, let sceneID = self.sceneDelegate.sceneIdentifier else {\n            return\n        }\n        \n        player.intendedSpatialExperience = .headTracked(.scene(identifier: sceneID))\n        player.play()\n    }\n}\n```\n\nBesides just [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioPlayer], you can also use [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/SpatialAudioExperience] types with the other playback APIs listed below.\n\n## Spatialize system and alert sounds\n\nConfigure the spatial audio experience of your system and alert sounds using:\n\n- [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AudioServicesPlaySystemSound(_:spatialExperience:)]\n- [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AudioServicesPlayAlertSound(_:spatialExperience:)]\n\n## Spatialize audio-only playback APIs\n\nConfigure the spatial audio experience of audio-only playback APIs using the [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioPlayer\/intendedSpatialExperience-27klj] property on:\n\n- [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioPlayer\/intendedSpatialExperience-27klj]\n- [doc:\/\/com.apple.documentation\/documentation\/AVFAudio\/AVAudioOutputNode\/intendedSpatialExperience-3ts59]\n- [doc:\/\/com.apple.documentation\/documentation\/AudioToolbox\/AUAudioUnit\/intendedSpatialExperience-7uqrm]\n- [doc:\/\/com.apple.documentation\/documentation\/CoreHaptics\/CHHapticEngine\/intendedSpatialExperience-55ca0]\n\n## Spatialize audio playback APIs that also have video\n\nSetting a scene identifier on playback APIs that have video content isn’t always necessary as their sound automatically anchors to its visual counterpart. However, if there is no video or if you prefer something besides the automatic behavior, configure the spatial audio experience of these playback APIs using the [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer\/intendedSpatialAudioExperience-1bd87] property on:\n\n- [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVPlayer\/intendedSpatialAudioExperience-1bd87]\n- [doc:\/\/com.apple.documentation\/documentation\/AVFoundation\/AVSampleBufferRenderSynchronizer\/intendedSpatialAudioExperience-3z7d3]\n\n## Playback and Recording\n\n- **Audio Queue Services**: Connect to audio hardware and manage the recording or playback process.\n- **Audio Services**: Play short sounds or trigger a vibration effect on iOS devices with the appropriate hardware.\n- **Music Player**: Create and play a sequence of tracks, and manage aspects of playback in response to standard events.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Connect to audio hardware and manage the recording or playback process.",
          "name" : "Audio Queue Services",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/audio-queue-services"
        },
        {
          "description" : "Play short sounds or trigger a vibration effect on iOS devices with the appropriate hardware.",
          "name" : "Audio Services",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/audio-services"
        },
        {
          "description" : "Create and play a sequence of tracks, and manage aspects of playback in response to standard events.",
          "name" : "Music Player",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/music-player"
        }
      ],
      "title" : "Playback and Recording"
    }
  ],
  "source" : "appleJSON",
  "title" : "Anchoring sound to a window or volume",
  "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/spatializing-sound-from-a-uiscene"
}