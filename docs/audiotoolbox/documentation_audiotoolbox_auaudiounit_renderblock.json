{
  "abstract" : "The block that hosts use to ask the audio unit to render audio.",
  "codeExamples" : [

  ],
  "contentHash" : "2f6ff74472774402676e953e93f35181eff24a2de23fcebe2893d3028cb533dd",
  "crawledAt" : "2025-12-02T19:17:39Z",
  "declaration" : {
    "code" : "var renderBlock: AURenderBlock { get }",
    "language" : "swift"
  },
  "id" : "2DF1EF51-4951-42A7-B99B-24A6AF5E6EF2",
  "kind" : "property",
  "language" : "swift",
  "module" : "Audio Toolbox",
  "overview" : "## Discussion\n\nBefore invoking an audio unit’s rendering functionality, a host should fetch this block and cache the result. The block can then be called from a realtime context without the possibility of blocking and causing an overload at the Core Audio HAL level.\n\nThis block will call a subclass’s [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AUAudioUnit\/internalRenderBlock] implementation, providing all realtime events scheduled for the current render time interval, bracketed by calls to any render observers. Subclasses should override their [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AUAudioUnit\/internalRenderBlock] implementation, not this property.\n\nThis version 3 property is bridged to the version 2 [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AudioUnitRender(_:_:_:_:_:_:)] API.",
  "platforms" : [
    "iOS",
    "iPadOS",
    "Mac Catalyst",
    "macOS",
    "tvOS",
    "visionOS"
  ],
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/renderBlock\ncrawled: 2025-12-02T19:17:39Z\n---\n\n# renderBlock\n\n**Instance Property**\n\nThe block that hosts use to ask the audio unit to render audio.\n\n## Declaration\n\n```swift\nvar renderBlock: AURenderBlock { get }\n```\n\n## Discussion\n\nBefore invoking an audio unit’s rendering functionality, a host should fetch this block and cache the result. The block can then be called from a realtime context without the possibility of blocking and causing an overload at the Core Audio HAL level.\n\nThis block will call a subclass’s [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AUAudioUnit\/internalRenderBlock] implementation, providing all realtime events scheduled for the current render time interval, bracketed by calls to any render observers. Subclasses should override their [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AUAudioUnit\/internalRenderBlock] implementation, not this property.\n\nThis version 3 property is bridged to the version 2 [doc:\/\/com.apple.audiotoolbox\/documentation\/AudioToolbox\/AudioUnitRender(_:_:_:_:_:_:)] API.\n\n## Managing the Render Cycle\n\n- **allocateRenderResources()**: Allocates resources required to render audio.\n- **deallocateRenderResources()**: Deallocates resources required to render audio.\n- **reset()**: Resets transitory rendering state to its initial state.\n- **renderResourcesAllocated**: Determines whether the audio unit has allocated render resources.\n- **scheduleParameterBlock**: The block that hosts use to schedule parameters.\n- **maximumFramesToRender**: The maximum number of frames that the audio unit can render at once.\n- **token(byAddingRenderObserver:)**: Adds a block to be called on each render cycle.\n- **removeRenderObserver(_:)**: Removes an observer block previously added to the render cycle.\n- **AURenderObserver**: A block called when an audio unit renders audio.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Allocates resources required to render audio.",
          "name" : "allocateRenderResources()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/allocateRenderResources()"
        },
        {
          "description" : "Deallocates resources required to render audio.",
          "name" : "deallocateRenderResources()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/deallocateRenderResources()"
        },
        {
          "description" : "Resets transitory rendering state to its initial state.",
          "name" : "reset()",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/reset()"
        },
        {
          "description" : "Determines whether the audio unit has allocated render resources.",
          "name" : "renderResourcesAllocated",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/renderResourcesAllocated"
        },
        {
          "description" : "The block that hosts use to schedule parameters.",
          "name" : "scheduleParameterBlock",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/scheduleParameterBlock"
        },
        {
          "description" : "The maximum number of frames that the audio unit can render at once.",
          "name" : "maximumFramesToRender",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/maximumFramesToRender"
        },
        {
          "description" : "Adds a block to be called on each render cycle.",
          "name" : "token(byAddingRenderObserver:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/token(byAddingRenderObserver:)"
        },
        {
          "description" : "Removes an observer block previously added to the render cycle.",
          "name" : "removeRenderObserver(_:)",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/removeRenderObserver(_:)"
        },
        {
          "description" : "A block called when an audio unit renders audio.",
          "name" : "AURenderObserver",
          "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AURenderObserver"
        }
      ],
      "title" : "Managing the Render Cycle"
    }
  ],
  "source" : "appleJSON",
  "title" : "renderBlock",
  "url" : "https:\/\/developer.apple.com\/documentation\/AudioToolbox\/AUAudioUnit\/renderBlock"
}