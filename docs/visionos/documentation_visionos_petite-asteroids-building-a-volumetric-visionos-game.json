{
  "abstract" : "Use the latest RealityKit APIs to create a beautiful video game for visionOS.",
  "codeExamples" : [
    {
      "code" : "struct SingleInputJumpGesture: Gesture {\n    @Environment(AppModel.self) private var appModel\n    \n    var body: some Gesture {\n        SpatialTapGesture()\n            \/\/ Only target this gesture to entities with the custom component.\n            .targetedToEntity(where: .has(LevelInputTargetComponent.self))\n             \/\/ The character jumps when the gesture ends.\n            .onEnded() { event in\n                \/\/ Guard for the character's container entity.\n                guard let containerEntity = appModel.character.parent else { return }\n                \n                \/\/ Convert the tap position to scene space.\n                var targetPosition = event.convert(event.location3D, from: .local, to: .scene)\n                \n                \/\/ Next, convert the scene-space position to one in the character's container entity space.\n                targetPosition = containerEntity.convert(position: targetPosition, from: nil)\n\n                \/\/ Pass the jump target position to a custom component for this game.\n                appModel.character.components[CharacterMovementComponent.self]?.targetJumpPosition = targetPosition\n                \n                \/\/ Reset the jump buffer timer, which helps the game feel more responsive when players try to jump a few frames before hitting the\n                \/\/ ground.\n                appModel.character.components[CharacterMovementComponent.self]?.jumpBufferTimer = GameSettings.jumpBufferTime\n            }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "struct SingleInputDragGesture: Gesture {\n    @Environment(AppModel.self) private var appModel\n    \n    var isDragActive: GestureState<Bool>\n    @State private var dragStartPosition: SIMD3<Float> = .zero\n    @State private var isDragging = false\n    \n    var body: some Gesture {\n        DragGesture(minimumDistance: CGFloat(GameSettings.dragMinimumDistance), coordinateSpace: .local)\n            .targetedToAnyEntity()\n            .updating(isDragActive) { value, state, transaction in\n                state = true\n            }\n            .onChanged() { event in\n                \/\/ Guard for the nearest physics simulation entity.\n                guard let physicsRoot = PhysicsSimulationComponent.nearestSimulationEntity(for: appModel.character) else { return }\n                \n                \/\/ Get the drag position in scene space.\n                let dragPosition = event.convert(event.location3D, from: .local, to: .scene)\n                        \n                \/\/ Start the drag if the player isn't already dragging.\n                if !isDragging {\n                    dragStartPosition = dragPosition\n                    isDragging = true\n                }\n\n                \/\/ Update the scene-space, drag-start position.\n                dragStartPosition = updateDragStartPosition(\n                    dragStartPosition: dragStartPosition,\n                    dragPosition: dragPosition,\n                    physicsRoot: physicsRoot,\n                    useRelativeDragInput: appModel.rollInputMode == .relative\n                )\n                \n                let sceneDragDelta = dragPosition - dragStartPosition\n                \/\/ Normalize the scene-space drag translation and pass it to the character movement component.\n                let normalizedSceneDragDelta = sceneDragDelta == .zero ? .zero : simd_normalize(sceneDragDelta)\n                let inputDirection = normalizedSceneDragDelta * (min(length(sceneDragDelta), GameSettings.dragRadius) \/ GameSettings.dragRadius)\n                appModel.character.components[CharacterMovementComponent.self]?.inputMoveDirection = inputDirection\n                appModel.character.components[CharacterMovementComponent.self]?.dragDelta = sceneDragDelta\n            }\n            .onEnded() { event in\n                isDragging = false\n            }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "func updateDragStartPosition(dragStartPosition: SIMD3<Float>,\n                             dragPosition: SIMD3<Float>,\n                             physicsRoot: Entity,\n                             useRelativeDragInput: Bool) -> SIMD3<Float> {\n    \/\/ Convert the drag start and current position to the local space of the physics root.\n    let dragPositionInPhysicsSpace = physicsRoot.convert(position: dragPosition, from: nil)\n    var dragStartPositionInPhysicsSpace = physicsRoot.convert(position: dragStartPosition, from: nil)\n    \/\/ Project the drag start position to an XZ-plane that's parallel to the current drag position.\n    dragStartPositionInPhysicsSpace.y = dragPositionInPhysicsSpace.y\n    \/\/ Get the drag translation in the XZ-plane of the local space of the physics root.\n    let dragDelta = (dragPositionInPhysicsSpace - dragStartPositionInPhysicsSpace)\n\n    \/\/ When `useRelativeDragInput` is true, the drag start point will follow behind the current drag position.\n    let dragDistance = length(dragDelta)\n    let dragRadius = GameSettings.dragRadius \/ GameSettings.scale\n    if useRelativeDragInput && dragDistance > dragRadius {\n        \/\/ Move the drag start position so that it follows behind the current drag position so the player doesn't have to move their\n        \/\/ input device all the way back to change direction.\n        let normalizedDragDelta = dragDelta \/ dragDistance\n        dragStartPositionInPhysicsSpace = dragPositionInPhysicsSpace - normalizedDragDelta * dragRadius\n    }\n\n    \/\/ Update the scene-space, drag-start position.\n    return physicsRoot.convert(position: dragStartPositionInPhysicsSpace, to: nil)\n}",
      "language" : "swift"
    },
    {
      "code" : "struct DualInputGesture: Gesture {\n    enum SpatialEventClassification {\n        case pinch\n        case drag\n        case unresolved\n    }\n\n    struct SpatialEventState {\n        var classification: SpatialEventClassification = .unresolved\n        var chirality: Chirality\n        var startPosition: SIMD3<Float>\n        var translation: SIMD3<Float> = .zero\n        var startTime: TimeInterval\n        var duration: TimeInterval = 0\n    }\n\n    @Environment(AppModel.self) private var appModel\n\n    var isDragActive: GestureState<Bool>\n    @State var activeSpatialEvents: [SpatialEventCollection.Event.ID: SpatialEventState] = [:]\n\n    private func handleSpatialEventEnded(spatialEvent: SpatialEventState?) {\n        if spatialEvent?.classification == .unresolved {\n            appModel.character.components[CharacterMovementComponent.self]?.jumpBufferTimer = GameSettings.jumpBufferTime\n        }\n    }\n\n    \/\/ ...\n\n    var body: some Gesture {\n        SpatialEventGesture()\n            .targetedToAnyEntity()\n            .updating(isDragActive) { value, state, transaction in\n                state = activeSpatialEvents.values.contains(where: { $0.classification == .drag })\n            }\n            .onChanged() { event in\n                \/\/ Update the active spatial events.\n                updateActiveSpatialEvents(event: event)\n                \n                \/\/ Classify unresolved spatial events.\n                classifyUnresolvedSpatialEvents()\n                \n                \/\/ Respond to the active spatial events.\n                respondToActiveSpatialEvents()\n            }.onEnded() { event in\n                \/\/ Handle and remove any events that ended.\n                for value in event.gestureValue {\n                    if value.phase == .ended {\n                        handleSpatialEventEnded(spatialEvent: activeSpatialEvents[value.id])\n                    }\n                    activeSpatialEvents[value.id] = nil\n                }\n            }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "private func updateActiveSpatialEvents(event: EntityTargetValue<SpatialEventGesture.Value>) {\n    \/\/ Guard for the nearest physics simulation entity.\n    guard let physicsRoot = PhysicsSimulationComponent.nearestSimulationEntity(for: appModel.character) else { return }\n\n    for value in event.gestureValue {\n        \/\/ Skip spatial events without chirality.\n        guard let chirality = value.chirality else {\n            continue\n        }\n        \n        \/\/ Get the event position in scene space.\n        let spatialEventPosition = event.convert(value.location3D, from: .local, to: .scene)\n        \n        \/\/ Handle and remove the event if it ended.\n        if value.phase == .ended {\n            handleSpatialEventEnded(spatialEvent: activeSpatialEvents[value.id])\n            activeSpatialEvents[value.id] = nil\n        \/\/ Update the event state if it's already active.\n        } else if var activeSpatialEvent = activeSpatialEvents[value.id] {\n            \/\/ Update the scene-space, event-start position.\n            activeSpatialEvent.startPosition = updateDragStartPosition(\n                dragStartPosition: activeSpatialEvent.startPosition,\n                dragPosition: spatialEventPosition,\n                physicsRoot: physicsRoot,\n                useRelativeDragInput: appModel.rollInputMode == .relative\n            )\n            \/\/ Update the scene-space event translation.\n            activeSpatialEvent.translation = spatialEventPosition - activeSpatialEvent.startPosition\n            activeSpatialEvent.duration = value.timestamp - activeSpatialEvent.startTime\n            activeSpatialEvents[value.id] = activeSpatialEvent\n        \/\/ Otherwise, create a new state structure to track this event.\n        } else {\n            \/\/ Add the event to the dictionary of active spatial events.\n            let spatialEventState = SpatialEventState(chirality: chirality,\n                                                      startPosition: spatialEventPosition,\n                                                      startTime: value.timestamp)\n            activeSpatialEvents[value.id] = spatialEventState\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "private func classifyUnresolvedSpatialEvents() {\n    for (spatialEventId, spatialEvent) in activeSpatialEvents where spatialEvent.classification == .unresolved {\n        \/\/ Classify the event as a pinch if there's already an active drag event.\n        if activeSpatialEvents.values.contains(where: { $0.classification == .drag }) {\n            activeSpatialEvents[spatialEventId]?.classification = .pinch\n        \/\/ Classify the event as a drag if there's already an active pinch event\n        \/\/ or the length of event's translation is larger than the drag minimum distance.\n        } else if activeSpatialEvents.values.contains(where: { $0.classification == .pinch }) ||\n                    length_squared(spatialEvent.translation) > GameSettings.dragMinimumDistance {\n            activeSpatialEvents[spatialEventId]?.classification = .drag\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "private func respondToActiveSpatialEvents() {\n    for spatialEvent in activeSpatialEvents.values {\n        switch spatialEvent.classification {\n            case .drag:\n                \/\/ Move the character in the direction of the spatial event translation.\n                var inputDirection = spatialEvent.translation \/ GameSettings.dragRadius\n                let inputDirectionMagnitude = length(inputDirection)\n                if inputDirectionMagnitude > 1 {\n                    inputDirection \/= inputDirectionMagnitude\n                }\n                appModel.character\n                    .components[CharacterMovementComponent.self]?.inputMoveDirection = inputDirection\n                appModel.character\n                    .components[CharacterMovementComponent.self]?.dragDelta = spatialEvent.translation\n            case .pinch:\n                \/\/ Make the character jump if the player pinched this frame.\n                if spatialEvent.duration == 0 {\n                    appModel.character.components[CharacterMovementComponent.self]?.jumpBufferTimer = GameSettings.jumpBufferTime\n                }\n            default:\n                break\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "private func dampingFactor(smoothing: Float, deltaTime: Float) -> Float {\n    smoothing == 0 ? 0 : 1 - exp2(-deltaTime \/ smoothing)\n}\n\npublic extension Float {\n    \/\/\/ Perform a damped interpolation between the current value and a target value.\n    mutating func lerpTo(_ targetFloat: Float, smoothing: Float, deltaTime: Float) {\n        self = simd_mix(self, targetFloat, dampingFactor(smoothing: smoothing, deltaTime: deltaTime))\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "public func angleBetween(from fromVector: SIMD3<Float>, to toVector: SIMD3<Float>) -> Float {\n    acos(simd_clamp(dot(normalize(fromVector), normalize(toVector)), -1, 1))\n}\n\npublic func signedAngleBetween(from fromVector: SIMD3<Float>, to toVector: SIMD3<Float>, axis: SIMD3<Float>) -> Float {\n    let sign: Float = dot(cross(fromVector, toVector), axis) > 0 ? 1 : -1\n    let angleBetween = angleBetween(from: fromVector, to: toVector)\n    return angleBetween * sign\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Get the direction to the follow target entity.\nvar toFollowTarget = rotationComponent.followTarget.position(relativeTo: rotationEntity)\ntoFollowTarget.y = 0\n\n\/\/ Calculate the angle between the follow target and the forward direction.\nvar forwardDirection = rotationEntity.convert(direction: .forward, from: nil)\nforwardDirection.y = 0\nlet angleBetweenForward = signedAngleBetween(from: toFollowTarget, to: forwardDirection, axis: [0, 1, 0])\nlet isOutsideThreshold = abs(angleBetweenForward) > rotationComponent.rotationThreshold\n\n\/\/ Determine whether the target entity is in the camera rotation deadzone.\nlet distance = length(SIMD3<Float>(rotationComponent.followTarget.position.x, 0, rotationComponent.followTarget.position.z))\nlet isInHorizontalDeadzone = distance <= rotationComponent.deadZoneRadiusAndHeight.radius\nlet height = rotationComponent.followTarget.position.y\nlet isInDeadzone = (isInHorizontalDeadzone && height >= rotationComponent.deadZoneRadiusAndHeight.height)\n    || height >= rotationComponent.deadzoneMinHeight\n\n\/\/ When outside the threshold, calculate a new rotation for the butte that brings the player back within the threshold.\nif isOutsideThreshold && isInDeadzone == false {\n    let angleDifference = if angleBetweenForward > 0 {\n        angleBetweenForward - rotationComponent.rotationThreshold\n    } else {\n        angleBetweenForward + rotationComponent.rotationThreshold\n    }\n    rotationComponent.targetAngle = rotationComponent.angle + angleDifference\n}\n\n\/\/ Increase the rotation smoothing when inside the deadzone, and decrease it back to its normal value when outside.\nif isInDeadzone {\n    rotationComponent.dyanamicRotationSmoothing.lerpTo(1, smoothing: 1, deltaTime: deltaTime)\n} else {\n    rotationComponent.dyanamicRotationSmoothing.lerpTo(rotationComponent.rotationSmoothing, smoothing: 1.5, deltaTime: deltaTime)\n}\n\n\/\/ Rotate the camera rotation angle toward the target rotation angle.\nrotationComponent.angle\n    .lerpTo(rotationComponent.targetAngle, smoothing: rotationComponent.dyanamicRotationSmoothing, deltaTime: deltaTime)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ Store subscriptions in a list.\nvar subscriptions: [AnyCancellable] = .init()\n\nrequired init (scene: Scene ) {\n    \/\/ Register the `onDidAddCompoundCollisionMarker` callback when adding a custom component to an `Entity`.\n    \/\/ The callback runs on the scene load.\n    scene.subscribe(to: ComponentEvents.DidAdd.self, componentType: CompoundCollisionMarkerComponent.self) {\n        self.onDidAddCompoundCollisionMarker(event: $0)\n    }.store(in: &subscriptions)\n}",
      "language" : "swift"
    },
    {
      "code" : "\/\/\/ A recursive search of all descendants with a specific component.\npublic func forEachDescendant<T: Component>(withComponent componentClass: T.Type, _ closure: (Entity, T) -> Void) {\n    for descendant in children {\n        \n        \/\/ Run the closure using the subentity and its component as parameters.\n        if let component = descendant.components[componentClass] {\n            closure(descendant, component)\n        }\n        \n        \/\/ Call this same function for each descendant entity.\n        descendant.forEachDescendant(withComponent: componentClass, closure)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "var meshes = [(entity: Entity, mesh: MeshResource)]()\ncollisionRoot.forEachDescendant(withComponent: ModelComponent.self) {\n    (entity, modelComponent) in\n    \n    \/\/ Skip descendant entities that you don't want to become part of the collision shape.\n    guard entity.components.has(IgnoreCompoundCollisionMarkerComponent.self) == false else { return }\n    \n    meshes.append((entity: entity, mesh: modelComponent.mesh))\n    \n    \/\/ Optionally, delete the source model component if you're no longer using it.\n    if deleteModel {\n        entity.components.remove(ModelComponent.self)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "for (entity, mesh) in meshes {\n    \/\/ Generate the shape from the mesh data.\n    guard var shape = if isStatic {\n        try? await ShapeResource.generateStaticMesh(from: mesh)\n    } else {\n        try? await ShapeResource.generateConvex(from: mesh)\n    } else {\n        continue\n    }\n    \n    \/\/ Offset the shape by its translation and orientation relative to the collision root.\n    shape = shape.offsetBy(rotation: entity.orientation(relativeTo: collisionRoot), translation: entity.position(relativeTo: collisionRoot))\n    shapes.append(shape)\n}",
      "language" : "swift"
    },
    {
      "code" : "let collision = CollisionComponent(shapes: shapes, mode: collisionMode)\ncollisionRoot.components.set(collision)",
      "language" : "swift"
    },
    {
      "code" : "func calculateParametersForShadow(_ entity: Entity, _ physicsRoot: Entity)\n    -> (characterPosition: SIMD3<Float>, shadowYPosition: Float)? {\n    \/\/ Get the origin relative to the physics root entity.\n    let origin = entity.position(relativeTo: physicsRoot)\n    \n    \/\/ Perform a ray cast against the scene downward from the origin.\n    return if let hit = entity.scene?.raycast(\n        origin: origin,\n        direction: [0, -1, 0],\n        query: .nearest,\n        \/\/ Use a mask to make sure you're only performing a ray cast against entities in the shadow receiver group.\n        mask: GameCollisionGroup.shadowReceiver.collisionGroup,\n        relativeTo: physicsRoot\n    ).first {\n        \/\/ Return a tuple when the ray cast is successful.\n        (origin, hit.position.y)\n    } else {\n        nil\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "func update(context: SceneUpdateContext) {\n        \/\/ Guard for the physics root and the character entity.\n        guard let physicsRoot = context.first(withComponent: PhysicsSimulationComponent.self)?.entity,\n                let character = context.first(withComponent: CharacterMovementComponent.self)?.entity else { return }\n        \n        \/\/ Get the matrix that transforms from world space to level space.\n        let worldToLevelMatrix = physicsRoot.transformMatrix(relativeTo: nil).inverse\n        \n        \/\/ Ray cast downward to determine where the character's shadow lands.\n        if let (characterPosition, characterShadowYPosition) = calculateParametersForShadow(character, physicsRoot) {\n            \n            \/\/ Ray cast downward for each rock friend to determine where their shadows land.\n            var rockFriendPositions = [(position: SIMD3<Float>, shadowYPosition: Float)]()\n            for rockFriend in context.entities(matching: rockFriendQuery, updatingSystemWhen: .rendering) {\n                if let (friendPosition, friendShadowYPosition) = calculateParametersForShadow(rockFriend, physicsRoot) {\n                    rockFriendPositions.append((friendPosition, friendShadowYPosition))\n                }\n            }\n            \n            \/\/ Dispatch a compute shader to write the shadow positions to the low-level texture.\n            \/\/ ...\n            \n            \/\/ Send the shadow parameters to the shader.\n            for dropShadowReceiver in context.entities(matching: dropShadowReceiverQuery, updatingSystemWhen: .rendering) {\n                setShadowShaderParameters(entity: dropShadowReceiver, worldToLevelMatrix: worldToLevelMatrix)\n            }\n        }\n    }",
      "language" : "swift"
    },
    {
      "code" : "func setShadowShaderParameters (entity: Entity, worldToLevelMatrix: simd_float4x4) {\n    if let dropShadowReceiverModelComponent = entity.components[DropShadowReceiverModelComponent.self] {\n        \/\/ Iterate through each shadow material on this model and apply the shadow shader parameters.\n        for materialIndex in dropShadowReceiverModelComponent.shadowMaterialIndices {\n            guard var shaderGraphMaterial = entity.components[ModelComponent.self]?.materials[materialIndex] as? ShaderGraphMaterial else {\n                continue\n            }\n\n            try? shaderGraphMaterial.setParameter(handle: dropShadowReceiverModelComponent.worldToLevelMatrixParameterHandle,\n                                                  value: .float4x4(worldToLevelMatrix))\n\n            entity.components[ModelComponent.self]?.materials[materialIndex] = shaderGraphMaterial\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import RealityKit\n\nclass GameMovementSystem: System {\n    var subscriptions: [AnyCancellable] = .init()\n\n    required init(scene: RealityKit.Scene) {\n    \/\/ Subscribe to the CollisionEvents and connect to class methods.\n    scene.subscribe(to: CollisionEvents.Began.self, componentType: GameMovementComponent.self, onCollisionBegan).store(in: &subscriptions)\n    scene.subscribe(to: CollisionEvents.Updated.self,\n                    componentType: CharacterMovementComponent.self,\n                    onCollisionUpdated).store(in: &subscriptions)\n    scene.subscribe(to: CollisionEvents.Ended.self, componentType: GameMovementComponent.self, onCollisionEnded).store(in: &subscriptions)\n    }\n\n    @MainActor\n    func onCollisionBegan(event: CollisionEvents.Began) {\n        let gameEntity = event.entityA\n        let collisionEntity = event.entityB\n\n        updateCollisionClassification(entityA: event.entityA, entityB: event.entityB, contacts: event.contacts)\n\n        event.entityA.components[GameMovementComponent.self].currentlyTrackedCollisionEntity = event.entityB\n\n        if let collisionClassification = event.entityA.components[GameMovementComponent.self].trackedCollisionEntities[event.entityB] {\n            \/\/ If collision impulse reaches over a specific threshold, play a sound.\n            if event.impulse > GameSettings.collisionImpulseThreshold {\n                let audioEvent = AudioEventComponent(resourceName: \"CollisionSound\")\n                gameEntity.components.set(audioEvent)\n            }\n        }\n    }\n\n    @MainActor\n    func onCollisionUpdated(event: CollisionEvents.Updated) {\n        updateCollisionClassification(entityA: event.entityA, entityB: event.entityB, contacts: event.contacts)\n    }\n\n    @MainActor\n    func onCollisionEnded(event: CollisionEvents.Ended) {\n        \/\/ Stop tracking.\n        event.entityA.components[GameMovementComponent.self]?.trackedCollisionEntities[event.entityB] = nil\n\n        if event.entityB == event.entityA.components[GameMovementComponent.self]?.currentlyTrackedCollisionEntity {\n            event.entityA.components[GameMovementComponent.self]?.currentlyTrackedCollisionEntity = nil\n    }\n\n\n    private func updateCollisionClassification(entityA: Entity, entityB: Entity, contacts: [Contact]) {\n        guard var collisionNormal = contacts.first?.normal else { return }\n\n        collisionNormal = normalize(collisionNormal)\n\n        let collisionDot = dot(collisionNormal, [0, 1, 0])\n        let classification: CollisionClassification = if collisionDot < -GameSettings.floorThreshold {\n            .top \n        } else if collisionDot == GameSettings.floorThreshold {\n            .floor(normal: collisionNormal)\n        }  else {\n           .inTheAir(normal: collisionNormal) \n        }\n\n        entityA.components[GameMovementComponent.self].trackedCollisionEntities[entityB] = classification\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "c9aa606d68ab9fcba8141590b8a8ef22401d391847ec9ee0f1e91f16debd2616",
  "crawledAt" : "2025-12-02T17:51:55Z",
  "id" : "51EBC244-A905-4E69-899F-C9B4199C3C22",
  "kind" : "unknown",
  "language" : "swift",
  "overview" : "## Overview\n\nThis sample code project uses RealityKit for visionOS to create a video game that tells the story of a lost chondrite as she collects her missing rock friends in a beautifully rendered environment.\n\n\n\nThe sample shows you how to use native APIs to leverage the full power of Apple Vision Pro in a real-world scenario. Its code and assets provide examples and inspiration so that you can create your own spectacular apps and games for Apple Vision Pro. The game supports two input modes for jumping: single input look-based jumping, and dual input pinch-based jumping.\n\n## Climb the butte with single input gestures\n\nAfter our hero crash-lands on Earth, you begin controlling her movement using spatial gestures. By pinching and dragging, you can guide the character toward her destination.\n\nWhen the single input mode is active, the player looks and taps a target destination and the character leaps into the air toward it, allowing her to begin the treacherous journey up the rocky landmark.\n\nA [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/SpatialTapGesture] handles look-based jumping.\n\nA separate [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/DragGesture] handles rolling the character on the ground.\n\nThe `updateDragStartPosition` method updates the drag start position so that it remains coplanar with the current drag position. When the `useRelativeDragInput` parameter is true, the method also updates the drag start position to follow behind the current drag position when the player drags beyond a specific radius, which improves the input experience for some players.\n\n## Climb the butte with dual input gestures\n\nIn the dual input mode, a custom [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/SpatialEventGesture] allows the player to move the character and jump at the same time by tracking the state of two spatial events simultaneously.\n\nThe `updateActiveSpatialEvents` method updates the `SpatialEventState` of all active spatial events by tracking their chirality, position, translation, and duration.\n\nThe `classifyUnresolvedSpatialEvents` method classifies any `.unresolved` spatial events as either a `.pinch` or a `.drag`.\n\nFinally, the `respondToActiveSpatialEvents` uses the classification of each active spatial event along with their state data to move the character and make the character jump.\n\n## Rotate the world in a mixed space\n\nIn this game, the world itself rotates as the character circles the butte. All physics entities in this sample app are descendants of a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/PhysicsSimulationComponent] entity. When you translate, rotate, or scale this entity, the entire physics world transforms with it. The physics simulation component entity serves as the root entity for the physics world, and you can move it like a camera inside custom systems (although the transformations are inverted). For more information, see [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/handling-different-sized-objects-in-physics-simulations].\n\nBefore animating the physics root, create an extension method to interpolate floating-point values using a damping function. This makes animations feel less abrupt.\n\nAdditionally, to perform the necessary calculations to determine which direction the butte rotates, the sample uses helper functions to derive the signed angle between two directions.\n\nThere is no camera entity in this sample code project. Instead, the butte itself rotates as the character progresses through the level. When the character moves outside a threshold, the sample calculates the angle necessary to rotate the butte so the character is always visible to the player.\n\n## Prepare assets for gameplay\n\nUsing third-party digital content creation (DCC) tools to create the visual assets for this sample app, you can export those assets as USD files, and then import and arrange them inside Reality Composer Pro. Then you can apply custom components to the entities in a Reality Composer Pro scene, and custom systems can look for those components to process entities for gameplay. For more information, see [doc:\/\/com.apple.documentation\/documentation\/RealityComposerPro\/Adding-assets-into-your-Reality-Composer-Pro-scene].\n\nTo generate the collision component that uses the shape of the butte, you first use a DCC to generate a model that matches the shape of the butte and platforms, but that contains fewer vertices. In Reality Composer Pro, you apply a custom component to the model entity. The custom system looks for that component by subscribing to the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ComponentEvents\/DidAdd] event for a custom type in the initializer for a custom system.\n\nOn the first scene load, RealityKit adds the component to an entity. The custom system searches for model components that descend from that entity. The system then creates a collision component on the entity using all the shapes that the mesh data generates.\n\nTo perform a recursive operation on each descendant entity, the sample uses an extension method for [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity].\n\nYou can then use this extension method to generate the shape data for every descendant model component.\n\nNext, use [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ShapeResource\/generateStaticMesh(from:)] to create a shape from each discovered mesh resource, and then offset that shape relative to the collision root entity (the original entity with the custom component).\n\nFinally, the sample initializes the collision component with the array of shapes and then adds it to the collision root:\n\nThe sample also loads and configures audio assets in code. In this sample, a custom system accumulates collision sounds into a Swift list, and then passes the sounds into the initializer, [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AudioFileGroupResource\/init(_:)], for an `AudioFileGroupResource`. On startup, the app loads audio files into the scene using the `AudioResourcesComponent`. This componentʼs load function then caches the `AudioResource` using an `AudioLibraryComponent` for retrieval by name later in the app code. The app also adds other sounds, such as music and environmental ambiences, into the `AudioResourcesComponent`, in addition to the collision sounds, for later use.\n\n## Structure your project for development\n\nDuring development, many people with a diverse set of expertise work on the same Xcode project and in the same Reality Composer Pro scenes. It’s important to think strategically about your project structure to avoid cumbersome merge conflicts or accidentally undoing someone else’s changes.\n\nWithin Reality Composer Pro, USD references allow you to isolate your work to individual files. The same asset becomes available for reference multiple times throughout a Reality Composer Pro project.\n\nAs an example, in this sample code project, the original materials are in a separate scene. Additionally, the main materials scene instances and reuses custom node graphs in other materials. One example is `DropShadow`, the node graph for rendering drop shadows.\n\n\n\nFor USD assets, the source models are in their own folder. These assets don’t have applied materials, and don’t contain any configuration data necessary for gameplay.\n\n\n\nIn the `GameAssets` folder, create game assets by configuring source assets with materials and any custom component data necessary. Those game assets are then ready for a designer to assemble into levels.\n\n\n\nFinally, assemble the game assets in the completed game level scene.\n\n\n\n## Create effects with the shader graph\n\nAdopting a variety of techniques, including making custom materials with [https:\/\/developer.apple.com\/documentation\/shadergraph\/] in Reality Composer Pro, promotes efficient rendering of the towering landmark at the center of the hero’s journey. A combination of baked light maps, which you generate in an external DCC, and clever lighting techniques come together to make the player’s experience smooth and rewarding.\n\nUnlit materials are very performant because they don’t require lighting calculations from the GPU to determine their color. The materials for the butte use textures you create in an external DCC, allowing you to calculate shadows from the sun ahead of time, and preventing real-time lights from casting shadows onto the butte.\n\nTo achieve effective grounding shadows beneath the character, perform a ray cast downward from her position and check for collisions with geometry. `calculateParametersForShadow` implements the check and returns shader parameters in a tuple.\n\nOn each frame, the CPU calculates the shader parameters and passes them to a GPU compute shader which writes them into a texture. This happens in the update function of a custom system.\n\nSee the `DropShadowComputeShader.metal` file in the sample project for the full compute shader implementation.\n\nInside `setShadowShaderParameters`, the sample sets the properties on the custom material by getting a reference to the `ShaderGraphMaterial` on the entity’s [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ModelComponent]. The sample then applies the modified shader graph material back to the shadow receiver entity directly.\n\n## Understand how collision audio works\n\nIn Petite Asteroids, the audio system has multiple types of collision sounds. These sounds play depending on the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/CollisionEvents] of their respective component. These events govern when and how to play the audio accordingly. The information that the system receives from the physics and collision events determines the loudness of the audio playback.\n\nThe physics event calculates the velocity of the character or whether the character stops jumping, which changes the nature of the audio playback. The collision event provides information on the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/CollisionEvents\/Began\/impulse], which is directly proportional to the loudness of the audio playback. When the character jumps or falls off the butte, she lands on a virtual surface. The app plays a sound whenever the character collides with a virtual surface.\n\nThe sample shows how to handle collision events, play a sound upon collision, and track the collision entity throughout events:\n\nThe collision sounds in Petite Asteroids are usually one-shot collision sounds, which the app plays using [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity\/playAudio(_:)]. For other collision sounds, the app groups a set of similar sounds together using an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AudioFileGroupResource] to play nonrepeating random sounds for audio playback.\n\n## Design dynamic sounds\n\nIn this game, the Audio [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity] uses an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AmbientAudioComponent] for ambient audio. The system plays two audio files using [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AudioPlaybackController] for the environment audio of the game. The character starts at the bottom of the butte with a calmer environment. As she reaches higher parts of the butte, the calmer environment cross-fades with the windier environment. The system blends these two files according to how high the character ascends. If she falls, the windier environment fades gracefully by interpolating values over a number of seconds.\n\nThe soundstage design intentionally utilizes stereo music with spread and width (decorrelated content), so any spatial sound effects in the game play closer to the center of the view. This way, the music doesn’t distract from the overall game experience, and improves the sense of immersion. To accomplish this effect, the app uses psychoacoustic and filtering techniques:\n\nAn audio cue subsystem in Petite Asteroids’ audio system controls playback of the app’s music. The sound effects of the game differ, depending on the scenes of the game. In the Fiery Descent sequence, the app plays back two layers simultaneously:\n\nThe design of the music scoring separates linear and nonlinear categories. The linear music at the end of the game triggers a cut scene and the app plays a linear music sequence. The nonlinear music scores make the sound nonrepetitive. This design means the app can cut the score into segments that it can loop infinitely and cleanly, while also allowing the audio to start playback at any randomized time. The `gameplayMusic`, `tutorialMusic`, and `menuMusic` all fall under this category.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionos\/petite-asteroids-building-a-volumetric-visionos-game\ncrawled: 2025-12-02T17:51:55Z\n---\n\n# Petite Asteroids: Building a volumetric visionOS game\n\n**Sample Code**\n\nUse the latest RealityKit APIs to create a beautiful video game for visionOS.\n\n## Overview\n\nThis sample code project uses RealityKit for visionOS to create a video game that tells the story of a lost chondrite as she collects her missing rock friends in a beautifully rendered environment.\n\n\n\nThe sample shows you how to use native APIs to leverage the full power of Apple Vision Pro in a real-world scenario. Its code and assets provide examples and inspiration so that you can create your own spectacular apps and games for Apple Vision Pro. The game supports two input modes for jumping: single input look-based jumping, and dual input pinch-based jumping.\n\n## Climb the butte with single input gestures\n\nAfter our hero crash-lands on Earth, you begin controlling her movement using spatial gestures. By pinching and dragging, you can guide the character toward her destination.\n\nWhen the single input mode is active, the player looks and taps a target destination and the character leaps into the air toward it, allowing her to begin the treacherous journey up the rocky landmark.\n\nA [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/SpatialTapGesture] handles look-based jumping.\n\n```swift\nstruct SingleInputJumpGesture: Gesture {\n    @Environment(AppModel.self) private var appModel\n    \n    var body: some Gesture {\n        SpatialTapGesture()\n            \/\/ Only target this gesture to entities with the custom component.\n            .targetedToEntity(where: .has(LevelInputTargetComponent.self))\n             \/\/ The character jumps when the gesture ends.\n            .onEnded() { event in\n                \/\/ Guard for the character's container entity.\n                guard let containerEntity = appModel.character.parent else { return }\n                \n                \/\/ Convert the tap position to scene space.\n                var targetPosition = event.convert(event.location3D, from: .local, to: .scene)\n                \n                \/\/ Next, convert the scene-space position to one in the character's container entity space.\n                targetPosition = containerEntity.convert(position: targetPosition, from: nil)\n\n                \/\/ Pass the jump target position to a custom component for this game.\n                appModel.character.components[CharacterMovementComponent.self]?.targetJumpPosition = targetPosition\n                \n                \/\/ Reset the jump buffer timer, which helps the game feel more responsive when players try to jump a few frames before hitting the\n                \/\/ ground.\n                appModel.character.components[CharacterMovementComponent.self]?.jumpBufferTimer = GameSettings.jumpBufferTime\n            }\n    }\n}\n```\n\nA separate [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/DragGesture] handles rolling the character on the ground.\n\n```swift\nstruct SingleInputDragGesture: Gesture {\n    @Environment(AppModel.self) private var appModel\n    \n    var isDragActive: GestureState<Bool>\n    @State private var dragStartPosition: SIMD3<Float> = .zero\n    @State private var isDragging = false\n    \n    var body: some Gesture {\n        DragGesture(minimumDistance: CGFloat(GameSettings.dragMinimumDistance), coordinateSpace: .local)\n            .targetedToAnyEntity()\n            .updating(isDragActive) { value, state, transaction in\n                state = true\n            }\n            .onChanged() { event in\n                \/\/ Guard for the nearest physics simulation entity.\n                guard let physicsRoot = PhysicsSimulationComponent.nearestSimulationEntity(for: appModel.character) else { return }\n                \n                \/\/ Get the drag position in scene space.\n                let dragPosition = event.convert(event.location3D, from: .local, to: .scene)\n                        \n                \/\/ Start the drag if the player isn't already dragging.\n                if !isDragging {\n                    dragStartPosition = dragPosition\n                    isDragging = true\n                }\n\n                \/\/ Update the scene-space, drag-start position.\n                dragStartPosition = updateDragStartPosition(\n                    dragStartPosition: dragStartPosition,\n                    dragPosition: dragPosition,\n                    physicsRoot: physicsRoot,\n                    useRelativeDragInput: appModel.rollInputMode == .relative\n                )\n                \n                let sceneDragDelta = dragPosition - dragStartPosition\n                \/\/ Normalize the scene-space drag translation and pass it to the character movement component.\n                let normalizedSceneDragDelta = sceneDragDelta == .zero ? .zero : simd_normalize(sceneDragDelta)\n                let inputDirection = normalizedSceneDragDelta * (min(length(sceneDragDelta), GameSettings.dragRadius) \/ GameSettings.dragRadius)\n                appModel.character.components[CharacterMovementComponent.self]?.inputMoveDirection = inputDirection\n                appModel.character.components[CharacterMovementComponent.self]?.dragDelta = sceneDragDelta\n            }\n            .onEnded() { event in\n                isDragging = false\n            }\n    }\n}\n```\n\nThe `updateDragStartPosition` method updates the drag start position so that it remains coplanar with the current drag position. When the `useRelativeDragInput` parameter is true, the method also updates the drag start position to follow behind the current drag position when the player drags beyond a specific radius, which improves the input experience for some players.\n\n```swift\nfunc updateDragStartPosition(dragStartPosition: SIMD3<Float>,\n                             dragPosition: SIMD3<Float>,\n                             physicsRoot: Entity,\n                             useRelativeDragInput: Bool) -> SIMD3<Float> {\n    \/\/ Convert the drag start and current position to the local space of the physics root.\n    let dragPositionInPhysicsSpace = physicsRoot.convert(position: dragPosition, from: nil)\n    var dragStartPositionInPhysicsSpace = physicsRoot.convert(position: dragStartPosition, from: nil)\n    \/\/ Project the drag start position to an XZ-plane that's parallel to the current drag position.\n    dragStartPositionInPhysicsSpace.y = dragPositionInPhysicsSpace.y\n    \/\/ Get the drag translation in the XZ-plane of the local space of the physics root.\n    let dragDelta = (dragPositionInPhysicsSpace - dragStartPositionInPhysicsSpace)\n\n    \/\/ When `useRelativeDragInput` is true, the drag start point will follow behind the current drag position.\n    let dragDistance = length(dragDelta)\n    let dragRadius = GameSettings.dragRadius \/ GameSettings.scale\n    if useRelativeDragInput && dragDistance > dragRadius {\n        \/\/ Move the drag start position so that it follows behind the current drag position so the player doesn't have to move their\n        \/\/ input device all the way back to change direction.\n        let normalizedDragDelta = dragDelta \/ dragDistance\n        dragStartPositionInPhysicsSpace = dragPositionInPhysicsSpace - normalizedDragDelta * dragRadius\n    }\n\n    \/\/ Update the scene-space, drag-start position.\n    return physicsRoot.convert(position: dragStartPositionInPhysicsSpace, to: nil)\n}\n```\n\n\n\n## Climb the butte with dual input gestures\n\nIn the dual input mode, a custom [doc:\/\/com.apple.documentation\/documentation\/SwiftUI\/SpatialEventGesture] allows the player to move the character and jump at the same time by tracking the state of two spatial events simultaneously.\n\n```swift\nstruct DualInputGesture: Gesture {\n    enum SpatialEventClassification {\n        case pinch\n        case drag\n        case unresolved\n    }\n\n    struct SpatialEventState {\n        var classification: SpatialEventClassification = .unresolved\n        var chirality: Chirality\n        var startPosition: SIMD3<Float>\n        var translation: SIMD3<Float> = .zero\n        var startTime: TimeInterval\n        var duration: TimeInterval = 0\n    }\n\n    @Environment(AppModel.self) private var appModel\n\n    var isDragActive: GestureState<Bool>\n    @State var activeSpatialEvents: [SpatialEventCollection.Event.ID: SpatialEventState] = [:]\n\n    private func handleSpatialEventEnded(spatialEvent: SpatialEventState?) {\n        if spatialEvent?.classification == .unresolved {\n            appModel.character.components[CharacterMovementComponent.self]?.jumpBufferTimer = GameSettings.jumpBufferTime\n        }\n    }\n\n    \/\/ ...\n\n    var body: some Gesture {\n        SpatialEventGesture()\n            .targetedToAnyEntity()\n            .updating(isDragActive) { value, state, transaction in\n                state = activeSpatialEvents.values.contains(where: { $0.classification == .drag })\n            }\n            .onChanged() { event in\n                \/\/ Update the active spatial events.\n                updateActiveSpatialEvents(event: event)\n                \n                \/\/ Classify unresolved spatial events.\n                classifyUnresolvedSpatialEvents()\n                \n                \/\/ Respond to the active spatial events.\n                respondToActiveSpatialEvents()\n            }.onEnded() { event in\n                \/\/ Handle and remove any events that ended.\n                for value in event.gestureValue {\n                    if value.phase == .ended {\n                        handleSpatialEventEnded(spatialEvent: activeSpatialEvents[value.id])\n                    }\n                    activeSpatialEvents[value.id] = nil\n                }\n            }\n    }\n}\n```\n\nThe `updateActiveSpatialEvents` method updates the `SpatialEventState` of all active spatial events by tracking their chirality, position, translation, and duration.\n\n```swift\nprivate func updateActiveSpatialEvents(event: EntityTargetValue<SpatialEventGesture.Value>) {\n    \/\/ Guard for the nearest physics simulation entity.\n    guard let physicsRoot = PhysicsSimulationComponent.nearestSimulationEntity(for: appModel.character) else { return }\n\n    for value in event.gestureValue {\n        \/\/ Skip spatial events without chirality.\n        guard let chirality = value.chirality else {\n            continue\n        }\n        \n        \/\/ Get the event position in scene space.\n        let spatialEventPosition = event.convert(value.location3D, from: .local, to: .scene)\n        \n        \/\/ Handle and remove the event if it ended.\n        if value.phase == .ended {\n            handleSpatialEventEnded(spatialEvent: activeSpatialEvents[value.id])\n            activeSpatialEvents[value.id] = nil\n        \/\/ Update the event state if it's already active.\n        } else if var activeSpatialEvent = activeSpatialEvents[value.id] {\n            \/\/ Update the scene-space, event-start position.\n            activeSpatialEvent.startPosition = updateDragStartPosition(\n                dragStartPosition: activeSpatialEvent.startPosition,\n                dragPosition: spatialEventPosition,\n                physicsRoot: physicsRoot,\n                useRelativeDragInput: appModel.rollInputMode == .relative\n            )\n            \/\/ Update the scene-space event translation.\n            activeSpatialEvent.translation = spatialEventPosition - activeSpatialEvent.startPosition\n            activeSpatialEvent.duration = value.timestamp - activeSpatialEvent.startTime\n            activeSpatialEvents[value.id] = activeSpatialEvent\n        \/\/ Otherwise, create a new state structure to track this event.\n        } else {\n            \/\/ Add the event to the dictionary of active spatial events.\n            let spatialEventState = SpatialEventState(chirality: chirality,\n                                                      startPosition: spatialEventPosition,\n                                                      startTime: value.timestamp)\n            activeSpatialEvents[value.id] = spatialEventState\n        }\n    }\n}\n```\n\nThe `classifyUnresolvedSpatialEvents` method classifies any `.unresolved` spatial events as either a `.pinch` or a `.drag`.\n\n```swift\nprivate func classifyUnresolvedSpatialEvents() {\n    for (spatialEventId, spatialEvent) in activeSpatialEvents where spatialEvent.classification == .unresolved {\n        \/\/ Classify the event as a pinch if there's already an active drag event.\n        if activeSpatialEvents.values.contains(where: { $0.classification == .drag }) {\n            activeSpatialEvents[spatialEventId]?.classification = .pinch\n        \/\/ Classify the event as a drag if there's already an active pinch event\n        \/\/ or the length of event's translation is larger than the drag minimum distance.\n        } else if activeSpatialEvents.values.contains(where: { $0.classification == .pinch }) ||\n                    length_squared(spatialEvent.translation) > GameSettings.dragMinimumDistance {\n            activeSpatialEvents[spatialEventId]?.classification = .drag\n        }\n    }\n}\n```\n\nFinally, the `respondToActiveSpatialEvents` uses the classification of each active spatial event along with their state data to move the character and make the character jump.\n\n```swift\nprivate func respondToActiveSpatialEvents() {\n    for spatialEvent in activeSpatialEvents.values {\n        switch spatialEvent.classification {\n            case .drag:\n                \/\/ Move the character in the direction of the spatial event translation.\n                var inputDirection = spatialEvent.translation \/ GameSettings.dragRadius\n                let inputDirectionMagnitude = length(inputDirection)\n                if inputDirectionMagnitude > 1 {\n                    inputDirection \/= inputDirectionMagnitude\n                }\n                appModel.character\n                    .components[CharacterMovementComponent.self]?.inputMoveDirection = inputDirection\n                appModel.character\n                    .components[CharacterMovementComponent.self]?.dragDelta = spatialEvent.translation\n            case .pinch:\n                \/\/ Make the character jump if the player pinched this frame.\n                if spatialEvent.duration == 0 {\n                    appModel.character.components[CharacterMovementComponent.self]?.jumpBufferTimer = GameSettings.jumpBufferTime\n                }\n            default:\n                break\n        }\n    }\n}\n```\n\n## Rotate the world in a mixed space\n\nIn this game, the world itself rotates as the character circles the butte. All physics entities in this sample app are descendants of a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/PhysicsSimulationComponent] entity. When you translate, rotate, or scale this entity, the entire physics world transforms with it. The physics simulation component entity serves as the root entity for the physics world, and you can move it like a camera inside custom systems (although the transformations are inverted). For more information, see [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/handling-different-sized-objects-in-physics-simulations].\n\nBefore animating the physics root, create an extension method to interpolate floating-point values using a damping function. This makes animations feel less abrupt.\n\n```swift\nprivate func dampingFactor(smoothing: Float, deltaTime: Float) -> Float {\n    smoothing == 0 ? 0 : 1 - exp2(-deltaTime \/ smoothing)\n}\n\npublic extension Float {\n    \/\/\/ Perform a damped interpolation between the current value and a target value.\n    mutating func lerpTo(_ targetFloat: Float, smoothing: Float, deltaTime: Float) {\n        self = simd_mix(self, targetFloat, dampingFactor(smoothing: smoothing, deltaTime: deltaTime))\n    }\n}\n```\n\nAdditionally, to perform the necessary calculations to determine which direction the butte rotates, the sample uses helper functions to derive the signed angle between two directions.\n\n```swift\npublic func angleBetween(from fromVector: SIMD3<Float>, to toVector: SIMD3<Float>) -> Float {\n    acos(simd_clamp(dot(normalize(fromVector), normalize(toVector)), -1, 1))\n}\n\npublic func signedAngleBetween(from fromVector: SIMD3<Float>, to toVector: SIMD3<Float>, axis: SIMD3<Float>) -> Float {\n    let sign: Float = dot(cross(fromVector, toVector), axis) > 0 ? 1 : -1\n    let angleBetween = angleBetween(from: fromVector, to: toVector)\n    return angleBetween * sign\n}\n```\n\nThere is no camera entity in this sample code project. Instead, the butte itself rotates as the character progresses through the level. When the character moves outside a threshold, the sample calculates the angle necessary to rotate the butte so the character is always visible to the player.\n\n```swift\n\/\/ Get the direction to the follow target entity.\nvar toFollowTarget = rotationComponent.followTarget.position(relativeTo: rotationEntity)\ntoFollowTarget.y = 0\n\n\/\/ Calculate the angle between the follow target and the forward direction.\nvar forwardDirection = rotationEntity.convert(direction: .forward, from: nil)\nforwardDirection.y = 0\nlet angleBetweenForward = signedAngleBetween(from: toFollowTarget, to: forwardDirection, axis: [0, 1, 0])\nlet isOutsideThreshold = abs(angleBetweenForward) > rotationComponent.rotationThreshold\n\n\/\/ Determine whether the target entity is in the camera rotation deadzone.\nlet distance = length(SIMD3<Float>(rotationComponent.followTarget.position.x, 0, rotationComponent.followTarget.position.z))\nlet isInHorizontalDeadzone = distance <= rotationComponent.deadZoneRadiusAndHeight.radius\nlet height = rotationComponent.followTarget.position.y\nlet isInDeadzone = (isInHorizontalDeadzone && height >= rotationComponent.deadZoneRadiusAndHeight.height)\n    || height >= rotationComponent.deadzoneMinHeight\n\n\/\/ When outside the threshold, calculate a new rotation for the butte that brings the player back within the threshold.\nif isOutsideThreshold && isInDeadzone == false {\n    let angleDifference = if angleBetweenForward > 0 {\n        angleBetweenForward - rotationComponent.rotationThreshold\n    } else {\n        angleBetweenForward + rotationComponent.rotationThreshold\n    }\n    rotationComponent.targetAngle = rotationComponent.angle + angleDifference\n}\n\n\/\/ Increase the rotation smoothing when inside the deadzone, and decrease it back to its normal value when outside.\nif isInDeadzone {\n    rotationComponent.dyanamicRotationSmoothing.lerpTo(1, smoothing: 1, deltaTime: deltaTime)\n} else {\n    rotationComponent.dyanamicRotationSmoothing.lerpTo(rotationComponent.rotationSmoothing, smoothing: 1.5, deltaTime: deltaTime)\n}\n\n\/\/ Rotate the camera rotation angle toward the target rotation angle.\nrotationComponent.angle\n    .lerpTo(rotationComponent.targetAngle, smoothing: rotationComponent.dyanamicRotationSmoothing, deltaTime: deltaTime)\n```\n\n## Prepare assets for gameplay\n\nUsing third-party digital content creation (DCC) tools to create the visual assets for this sample app, you can export those assets as USD files, and then import and arrange them inside Reality Composer Pro. Then you can apply custom components to the entities in a Reality Composer Pro scene, and custom systems can look for those components to process entities for gameplay. For more information, see [doc:\/\/com.apple.documentation\/documentation\/RealityComposerPro\/Adding-assets-into-your-Reality-Composer-Pro-scene].\n\nTo generate the collision component that uses the shape of the butte, you first use a DCC to generate a model that matches the shape of the butte and platforms, but that contains fewer vertices. In Reality Composer Pro, you apply a custom component to the model entity. The custom system looks for that component by subscribing to the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ComponentEvents\/DidAdd] event for a custom type in the initializer for a custom system.\n\n```swift\n\/\/ Store subscriptions in a list.\nvar subscriptions: [AnyCancellable] = .init()\n\nrequired init (scene: Scene ) {\n    \/\/ Register the `onDidAddCompoundCollisionMarker` callback when adding a custom component to an `Entity`.\n    \/\/ The callback runs on the scene load.\n    scene.subscribe(to: ComponentEvents.DidAdd.self, componentType: CompoundCollisionMarkerComponent.self) {\n        self.onDidAddCompoundCollisionMarker(event: $0)\n    }.store(in: &subscriptions)\n}\n```\n\nOn the first scene load, RealityKit adds the component to an entity. The custom system searches for model components that descend from that entity. The system then creates a collision component on the entity using all the shapes that the mesh data generates.\n\nTo perform a recursive operation on each descendant entity, the sample uses an extension method for [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity].\n\n```swift\n\/\/\/ A recursive search of all descendants with a specific component.\npublic func forEachDescendant<T: Component>(withComponent componentClass: T.Type, _ closure: (Entity, T) -> Void) {\n    for descendant in children {\n        \n        \/\/ Run the closure using the subentity and its component as parameters.\n        if let component = descendant.components[componentClass] {\n            closure(descendant, component)\n        }\n        \n        \/\/ Call this same function for each descendant entity.\n        descendant.forEachDescendant(withComponent: componentClass, closure)\n    }\n}\n```\n\nYou can then use this extension method to generate the shape data for every descendant model component.\n\n```swift\nvar meshes = [(entity: Entity, mesh: MeshResource)]()\ncollisionRoot.forEachDescendant(withComponent: ModelComponent.self) {\n    (entity, modelComponent) in\n    \n    \/\/ Skip descendant entities that you don't want to become part of the collision shape.\n    guard entity.components.has(IgnoreCompoundCollisionMarkerComponent.self) == false else { return }\n    \n    meshes.append((entity: entity, mesh: modelComponent.mesh))\n    \n    \/\/ Optionally, delete the source model component if you're no longer using it.\n    if deleteModel {\n        entity.components.remove(ModelComponent.self)\n    }\n}\n```\n\nNext, use [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ShapeResource\/generateStaticMesh(from:)] to create a shape from each discovered mesh resource, and then offset that shape relative to the collision root entity (the original entity with the custom component).\n\n```swift\nfor (entity, mesh) in meshes {\n    \/\/ Generate the shape from the mesh data.\n    guard var shape = if isStatic {\n        try? await ShapeResource.generateStaticMesh(from: mesh)\n    } else {\n        try? await ShapeResource.generateConvex(from: mesh)\n    } else {\n        continue\n    }\n    \n    \/\/ Offset the shape by its translation and orientation relative to the collision root.\n    shape = shape.offsetBy(rotation: entity.orientation(relativeTo: collisionRoot), translation: entity.position(relativeTo: collisionRoot))\n    shapes.append(shape)\n}\n```\n\nFinally, the sample initializes the collision component with the array of shapes and then adds it to the collision root:\n\n```swift\nlet collision = CollisionComponent(shapes: shapes, mode: collisionMode)\ncollisionRoot.components.set(collision)\n```\n\nThe sample also loads and configures audio assets in code. In this sample, a custom system accumulates collision sounds into a Swift list, and then passes the sounds into the initializer, [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AudioFileGroupResource\/init(_:)], for an `AudioFileGroupResource`. On startup, the app loads audio files into the scene using the `AudioResourcesComponent`. This componentʼs load function then caches the `AudioResource` using an `AudioLibraryComponent` for retrieval by name later in the app code. The app also adds other sounds, such as music and environmental ambiences, into the `AudioResourcesComponent`, in addition to the collision sounds, for later use.\n\n## Structure your project for development\n\nDuring development, many people with a diverse set of expertise work on the same Xcode project and in the same Reality Composer Pro scenes. It’s important to think strategically about your project structure to avoid cumbersome merge conflicts or accidentally undoing someone else’s changes.\n\nWithin Reality Composer Pro, USD references allow you to isolate your work to individual files. The same asset becomes available for reference multiple times throughout a Reality Composer Pro project.\n\nAs an example, in this sample code project, the original materials are in a separate scene. Additionally, the main materials scene instances and reuses custom node graphs in other materials. One example is `DropShadow`, the node graph for rendering drop shadows.\n\n\n\nFor USD assets, the source models are in their own folder. These assets don’t have applied materials, and don’t contain any configuration data necessary for gameplay.\n\n\n\n\n\nIn the `GameAssets` folder, create game assets by configuring source assets with materials and any custom component data necessary. Those game assets are then ready for a designer to assemble into levels.\n\n\n\nFinally, assemble the game assets in the completed game level scene.\n\n\n\n## Create effects with the shader graph\n\nAdopting a variety of techniques, including making custom materials with [https:\/\/developer.apple.com\/documentation\/shadergraph\/] in Reality Composer Pro, promotes efficient rendering of the towering landmark at the center of the hero’s journey. A combination of baked light maps, which you generate in an external DCC, and clever lighting techniques come together to make the player’s experience smooth and rewarding.\n\nUnlit materials are very performant because they don’t require lighting calculations from the GPU to determine their color. The materials for the butte use textures you create in an external DCC, allowing you to calculate shadows from the sun ahead of time, and preventing real-time lights from casting shadows onto the butte.\n\nTo achieve effective grounding shadows beneath the character, perform a ray cast downward from her position and check for collisions with geometry. `calculateParametersForShadow` implements the check and returns shader parameters in a tuple.\n\n```swift\nfunc calculateParametersForShadow(_ entity: Entity, _ physicsRoot: Entity)\n    -> (characterPosition: SIMD3<Float>, shadowYPosition: Float)? {\n    \/\/ Get the origin relative to the physics root entity.\n    let origin = entity.position(relativeTo: physicsRoot)\n    \n    \/\/ Perform a ray cast against the scene downward from the origin.\n    return if let hit = entity.scene?.raycast(\n        origin: origin,\n        direction: [0, -1, 0],\n        query: .nearest,\n        \/\/ Use a mask to make sure you're only performing a ray cast against entities in the shadow receiver group.\n        mask: GameCollisionGroup.shadowReceiver.collisionGroup,\n        relativeTo: physicsRoot\n    ).first {\n        \/\/ Return a tuple when the ray cast is successful.\n        (origin, hit.position.y)\n    } else {\n        nil\n    }\n}\n```\n\nOn each frame, the CPU calculates the shader parameters and passes them to a GPU compute shader which writes them into a texture. This happens in the update function of a custom system.\n\n```swift\nfunc update(context: SceneUpdateContext) {\n        \/\/ Guard for the physics root and the character entity.\n        guard let physicsRoot = context.first(withComponent: PhysicsSimulationComponent.self)?.entity,\n                let character = context.first(withComponent: CharacterMovementComponent.self)?.entity else { return }\n        \n        \/\/ Get the matrix that transforms from world space to level space.\n        let worldToLevelMatrix = physicsRoot.transformMatrix(relativeTo: nil).inverse\n        \n        \/\/ Ray cast downward to determine where the character's shadow lands.\n        if let (characterPosition, characterShadowYPosition) = calculateParametersForShadow(character, physicsRoot) {\n            \n            \/\/ Ray cast downward for each rock friend to determine where their shadows land.\n            var rockFriendPositions = [(position: SIMD3<Float>, shadowYPosition: Float)]()\n            for rockFriend in context.entities(matching: rockFriendQuery, updatingSystemWhen: .rendering) {\n                if let (friendPosition, friendShadowYPosition) = calculateParametersForShadow(rockFriend, physicsRoot) {\n                    rockFriendPositions.append((friendPosition, friendShadowYPosition))\n                }\n            }\n            \n            \/\/ Dispatch a compute shader to write the shadow positions to the low-level texture.\n            \/\/ ...\n            \n            \/\/ Send the shadow parameters to the shader.\n            for dropShadowReceiver in context.entities(matching: dropShadowReceiverQuery, updatingSystemWhen: .rendering) {\n                setShadowShaderParameters(entity: dropShadowReceiver, worldToLevelMatrix: worldToLevelMatrix)\n            }\n        }\n    }\n```\n\nSee the `DropShadowComputeShader.metal` file in the sample project for the full compute shader implementation.\n\nInside `setShadowShaderParameters`, the sample sets the properties on the custom material by getting a reference to the `ShaderGraphMaterial` on the entity’s [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/ModelComponent]. The sample then applies the modified shader graph material back to the shadow receiver entity directly.\n\n```swift\nfunc setShadowShaderParameters (entity: Entity, worldToLevelMatrix: simd_float4x4) {\n    if let dropShadowReceiverModelComponent = entity.components[DropShadowReceiverModelComponent.self] {\n        \/\/ Iterate through each shadow material on this model and apply the shadow shader parameters.\n        for materialIndex in dropShadowReceiverModelComponent.shadowMaterialIndices {\n            guard var shaderGraphMaterial = entity.components[ModelComponent.self]?.materials[materialIndex] as? ShaderGraphMaterial else {\n                continue\n            }\n\n            try? shaderGraphMaterial.setParameter(handle: dropShadowReceiverModelComponent.worldToLevelMatrixParameterHandle,\n                                                  value: .float4x4(worldToLevelMatrix))\n\n            entity.components[ModelComponent.self]?.materials[materialIndex] = shaderGraphMaterial\n        }\n    }\n}\n```\n\n\n\n## Understand how collision audio works\n\nIn Petite Asteroids, the audio system has multiple types of collision sounds. These sounds play depending on the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/CollisionEvents] of their respective component. These events govern when and how to play the audio accordingly. The information that the system receives from the physics and collision events determines the loudness of the audio playback.\n\nThe physics event calculates the velocity of the character or whether the character stops jumping, which changes the nature of the audio playback. The collision event provides information on the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/CollisionEvents\/Began\/impulse], which is directly proportional to the loudness of the audio playback. When the character jumps or falls off the butte, she lands on a virtual surface. The app plays a sound whenever the character collides with a virtual surface.\n\nThe sample shows how to handle collision events, play a sound upon collision, and track the collision entity throughout events:\n\n```swift\nimport RealityKit\n\nclass GameMovementSystem: System {\n    var subscriptions: [AnyCancellable] = .init()\n\n    required init(scene: RealityKit.Scene) {\n    \/\/ Subscribe to the CollisionEvents and connect to class methods.\n    scene.subscribe(to: CollisionEvents.Began.self, componentType: GameMovementComponent.self, onCollisionBegan).store(in: &subscriptions)\n    scene.subscribe(to: CollisionEvents.Updated.self,\n                    componentType: CharacterMovementComponent.self,\n                    onCollisionUpdated).store(in: &subscriptions)\n    scene.subscribe(to: CollisionEvents.Ended.self, componentType: GameMovementComponent.self, onCollisionEnded).store(in: &subscriptions)\n    }\n\n    @MainActor\n    func onCollisionBegan(event: CollisionEvents.Began) {\n        let gameEntity = event.entityA\n        let collisionEntity = event.entityB\n\n        updateCollisionClassification(entityA: event.entityA, entityB: event.entityB, contacts: event.contacts)\n\n        event.entityA.components[GameMovementComponent.self].currentlyTrackedCollisionEntity = event.entityB\n\n        if let collisionClassification = event.entityA.components[GameMovementComponent.self].trackedCollisionEntities[event.entityB] {\n            \/\/ If collision impulse reaches over a specific threshold, play a sound.\n            if event.impulse > GameSettings.collisionImpulseThreshold {\n                let audioEvent = AudioEventComponent(resourceName: \"CollisionSound\")\n                gameEntity.components.set(audioEvent)\n            }\n        }\n    }\n\n    @MainActor\n    func onCollisionUpdated(event: CollisionEvents.Updated) {\n        updateCollisionClassification(entityA: event.entityA, entityB: event.entityB, contacts: event.contacts)\n    }\n\n    @MainActor\n    func onCollisionEnded(event: CollisionEvents.Ended) {\n        \/\/ Stop tracking.\n        event.entityA.components[GameMovementComponent.self]?.trackedCollisionEntities[event.entityB] = nil\n\n        if event.entityB == event.entityA.components[GameMovementComponent.self]?.currentlyTrackedCollisionEntity {\n            event.entityA.components[GameMovementComponent.self]?.currentlyTrackedCollisionEntity = nil\n    }\n\n\n    private func updateCollisionClassification(entityA: Entity, entityB: Entity, contacts: [Contact]) {\n        guard var collisionNormal = contacts.first?.normal else { return }\n\n        collisionNormal = normalize(collisionNormal)\n\n        let collisionDot = dot(collisionNormal, [0, 1, 0])\n        let classification: CollisionClassification = if collisionDot < -GameSettings.floorThreshold {\n            .top \n        } else if collisionDot == GameSettings.floorThreshold {\n            .floor(normal: collisionNormal)\n        }  else {\n           .inTheAir(normal: collisionNormal) \n        }\n\n        entityA.components[GameMovementComponent.self].trackedCollisionEntities[entityB] = classification\n    }\n}\n```\n\nThe collision sounds in Petite Asteroids are usually one-shot collision sounds, which the app plays using [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity\/playAudio(_:)]. For other collision sounds, the app groups a set of similar sounds together using an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AudioFileGroupResource] to play nonrepeating random sounds for audio playback.\n\n## Design dynamic sounds\n\nIn this game, the Audio [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity] uses an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AmbientAudioComponent] for ambient audio. The system plays two audio files using [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/AudioPlaybackController] for the environment audio of the game. The character starts at the bottom of the butte with a calmer environment. As she reaches higher parts of the butte, the calmer environment cross-fades with the windier environment. The system blends these two files according to how high the character ascends. If she falls, the windier environment fades gracefully by interpolating values over a number of seconds.\n\nThe soundstage design intentionally utilizes stereo music with spread and width (decorrelated content), so any spatial sound effects in the game play closer to the center of the view. This way, the music doesn’t distract from the overall game experience, and improves the sense of immersion. To accomplish this effect, the app uses psychoacoustic and filtering techniques:\n\n- At the bottom of the butte, the app uses a stereo recording asset, anchored to the volume.\n- As you reposition the volume, the stereo recording follows it, so you can localize the app.\n- The top of the butte has a quadraphonic (may be cube) surround layout recording, so as the character ascends the butte, the audio experience becomes increasingly immersive.\n\nAn audio cue subsystem in Petite Asteroids’ audio system controls playback of the app’s music. The sound effects of the game differ, depending on the scenes of the game. In the Fiery Descent sequence, the app plays back two layers simultaneously:\n\n\n\nThe design of the music scoring separates linear and nonlinear categories. The linear music at the end of the game triggers a cut scene and the app plays a linear music sequence. The nonlinear music scores make the sound nonrepetitive. This design means the app can cut the score into segments that it can loop infinitely and cleanly, while also allowing the audio to start playback at any randomized time. The `gameplayMusic`, `tutorialMusic`, and `menuMusic` all fall under this category.\n\n\n\n## RealityKit and Reality Composer Pro\n\n- **Reality Composer Pro**: Build, create, and design 3D content for your RealityKit apps.\n- **BOT-anist**: Build a multiplatform app that uses windows, volumes, and animations to create a robot botanist’s greenhouse.\n- **Swift Splash**: Use RealityKit to create an interactive ride in visionOS.\n- **Diorama**: Design scenes for your visionOS app using Reality Composer Pro.\n- **Building an immersive media viewing experience**: Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.\n- **Enabling video reflections in an immersive environment**: Create a more immersive experience by adding video reflections in a custom environment.\n- **Combining 2D and 3D views in an immersive app**: Use attachments to place 2D content relative to 3D content in your visionOS app.\n- **Understanding the modular architecture of RealityKit**: Learn how everything fits together in RealityKit.\n- **Using transforms to move, scale, and rotate entities**: Learn how to use Transforms to move, scale, and rotate entities in RealityKit.\n- **Capturing screenshots and video from Apple Vision Pro for 2D viewing**: Create screenshots and record high-quality video of your visionOS app and its surroundings for app previews.\n- **Implementing object tracking in your visionOS app**: Create engaging interactions by training models to recognize and track real-world objects in your app.\n- **Placing entities using head and device transform**: Query and react to changes in the position and rotation of Apple Vision Pro.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Build, create, and design 3D content for your RealityKit apps.",
          "name" : "Reality Composer Pro",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityComposerPro"
        },
        {
          "description" : "Build a multiplatform app that uses windows, volumes, and animations to create a robot botanist’s greenhouse.",
          "name" : "BOT-anist",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/BOT-anist"
        },
        {
          "description" : "Use RealityKit to create an interactive ride in visionOS.",
          "name" : "Swift Splash",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/swift-splash"
        },
        {
          "description" : "Design scenes for your visionOS app using Reality Composer Pro.",
          "name" : "Diorama",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/diorama"
        },
        {
          "description" : "Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.",
          "name" : "Building an immersive media viewing experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/building-an-immersive-media-viewing-experience"
        },
        {
          "description" : "Create a more immersive experience by adding video reflections in a custom environment.",
          "name" : "Enabling video reflections in an immersive environment",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/enabling-video-reflections-in-an-immersive-environment"
        },
        {
          "description" : "Use attachments to place 2D content relative to 3D content in your visionOS app.",
          "name" : "Combining 2D and 3D views in an immersive app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/combining-2d-and-3d-views-in-an-immersive-app"
        },
        {
          "description" : "Learn how everything fits together in RealityKit.",
          "name" : "Understanding the modular architecture of RealityKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/understanding-the-realitykit-modular-architecture"
        },
        {
          "description" : "Learn how to use Transforms to move, scale, and rotate entities in RealityKit.",
          "name" : "Using transforms to move, scale, and rotate entities",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/understanding-transforms"
        },
        {
          "description" : "Create screenshots and record high-quality video of your visionOS app and its surroundings for app previews.",
          "name" : "Capturing screenshots and video from Apple Vision Pro for 2D viewing",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/capturing-screenshots-and-video-from-your-apple-vision-pro-for-2d-viewing"
        },
        {
          "description" : "Create engaging interactions by training models to recognize and track real-world objects in your app.",
          "name" : "Implementing object tracking in your visionOS app",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/implementing-object-tracking-in-your-visionOS-app"
        },
        {
          "description" : "Query and react to changes in the position and rotation of Apple Vision Pro.",
          "name" : "Placing entities using head and device transform",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/placing-entities-using-head-and-device-transform"
        }
      ],
      "title" : "RealityKit and Reality Composer Pro"
    }
  ],
  "source" : "appleJSON",
  "title" : "Petite Asteroids: Building a volumetric visionOS game",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionos\/petite-asteroids-building-a-volumetric-visionos-game"
}