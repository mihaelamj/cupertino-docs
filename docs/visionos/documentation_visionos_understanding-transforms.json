{
  "abstract" : "Learn how to use Transforms to move, scale, and rotate entities in RealityKit.",
  "codeExamples" : [
    {
      "code" : "RealityView { content in\n  let a = ModelEntity(mesh: .generateBox(size: 0.05), materials: [SimpleMaterial(color: .orange, isMetallic: false)])\n  a.name = \"A\"\n  a.transform = Transform(translation: SIMD3<Float>(0.05, 0.0, 0.0))\n  content.add(a)\n\n  let b = ModelEntity(mesh: .generateBox(size: 0.05), materials: [SimpleMaterial(color: .purple, isMetallic: false)])\n  b.name = \"B\"\n  b.transform = Transform(translation: SIMD3<Float>(0.1, 0.0, 0.0))\n\n  a.addChild(b)\n}",
      "language" : "swift"
    },
    {
      "code" : "func createCube() -> ModelEntity? {\n  let material = SimpleMaterial(color: .blue, isMetallic: false)\n  var descriptor = MeshDescriptor(name: \"Simple Cube\")\n  let allVerts: Array<SIMD3<Float>> = [[0.05,  0.05, -0.05], \/\/ Right-top-back vertex\n                                       [-0.05,  0.05, -0.05], \/\/ Left-top-back vertex\n                                       [-0.05,  0.05,  0.05], \/\/ Left-top-front vertex\n                                       [0.05,  0.05,  0.05], \/\/ Right-top-front vertex\n                                       [0.05, -0.05, -0.05], \/\/ Right-bottom-back vertex\n                                       [-0.05, -0.05, -0.05], \/\/ Left-bottom-back vertex\n                                       [-0.05, -0.05,  0.05], \/\/ Left-bottom-front vertex\n                                       [0.05, -0.05,  0.05]] \/\/ Right-bottom-front vertex\n  let allTris: Array<UInt32> = [\n    \/\/ Index into the vertex array for the top triangles.\n    0, 1, 2,\n    0, 2, 3,\n    \/\/ Index into the vertex array for the bottom triangles.\n    4, 6, 5,\n    4, 7, 6,\n    \/\/ Index into the vertex array for the right triangles.\n    0, 3, 7,\n    7, 4, 0,\n    \/\/ Index into the vertex array for the back triangles.\n    0, 4, 1,\n    4, 5, 1,\n    \/\/ Index into the vertex array for the left triangles.\n    2, 1, 5,\n    5, 6, 2,\n    \/\/ Index into the vertex array for the front triangles.\n    3, 2, 6,\n    6, 7, 3\n  ]\n  descriptor.positions = MeshBuffer(allVerts)\n  descriptor.primitives = .triangles(allTris)\n\n  if let resource = try? MeshResource.generate(from: [descriptor]) {\n     return ModelEntity(mesh: resource, materials: [material])\n  }\n  return nil\n}",
      "language" : "swift"
    },
    {
      "code" : "RealityView { content in\n  if let cube = createCube() {\n    content.add(cube)\n  }\n}",
      "language" : "swift"
    },
    {
      "code" : "    cube.transform = Transform(translation: SIMD3<Float>(0.1, 0.0, 0.0))",
      "language" : "swift"
    },
    {
      "code" : "  cube?.transform = Transform(scale: SIMD3<Float>(2.0, 2.0, 2.0))",
      "language" : "swift"
    },
    {
      "code" : "  cube?.transform = Transform(scale: SIMD3<Float>(2.0, 2.0, 2.0), translation: SIMD3<Float>(0.1, 0.0, 0.0))",
      "language" : "swift"
    },
    {
      "code" : "RealityView { content in\n  if let cube {\n    content.add(cube)\n  }\n  cube?.transform = Transform(rotation: simd_quatf(angle: .pi\/4, axis: SIMD3<Float>(1.0, 0.0, 0.0)))\n }",
      "language" : "swift"
    },
    {
      "code" : "  cube?.transform = Transform(rotation: simd_quatf(angle: .pi\/4, axis: normalize(SIMD3<Float>(1.0, 1.0, 1.0))))",
      "language" : "swift"
    },
    {
      "code" : "  cube?.transform = Transform(scale: SIMD3<Float>(2.0, 2.0, 2.0),\n                              rotation: simd_quatf(angle: .pi\/4, axis: normalize(SIMD3<Float>(1.0, 1.0, 1.0))),\n                              translation: SIMD3<Float>(0.1, 0.0, 0.0))\n",
      "language" : "swift"
    }
  ],
  "contentHash" : "c3adeff2eaf30228b3321b6a6c137a91825a62b434fef4330d3890fc8349aa47",
  "crawledAt" : "2025-12-02T17:51:56Z",
  "id" : "6CE935C9-0595-4E50-8A8F-6FFCCCAB86C6",
  "kind" : "article",
  "language" : "swift",
  "overview" : "## Overview\n\nRealityKit [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity] objects exist in a tree, and each entity can have any number of subentities. (The entities themselves can standalone, or can be in a single container.) Every entity in the tree stores its own transform component. The transform contains the `translation`, `scale`, and `orientation` relative to its container entity. The *root* of each tree is an entity without a container entity.\n\nEach entity exists in its own coordinate system that defines the origin and orientation of the three ordinal directions (the x, y, and z axes). The coordinate system is relative to its container coordinate system and is defined by its transform.\n\n## Arrange entities with transforms\n\nA root entity has no parent entity. Its location in the scene is either controlled by SwiftUI or placed via a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/SpatialTrackingSession]. SwiftUI provides a root entity for the volume defined by the `RealityView`. The root entity defines the root coordinate system.\n\nEach entity added to the tree adds a new coordinate system defined by its [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/HasTransform\/transform] and is relative to its container entity. Each of the coordinate systems relate to each other by the hierarchy of entities and their transforms. For example a hierarchy of entities built with this code:\n\nThis reality view has three entities `B`, `A`, and the root entity. These three entities form a tree, with one root entity at the center of the reality view’s volume. Entity A is a subentity of the root, and B is a subentity of A.\n\n\n\nThe reality view provides the root entity, which is located at the center of a volumetric window or near the floor in an immersive space. Use the [https:\/\/developer.apple.com\/documentation\/realitykit\/realityviewcontentprotocol\/add(_:)]  method on the `content` supplied by the reality view to add entities as subentites of that root entity. The coordinate system defined by `B` is `0.1` units along the `x-axis` of the coordinate system defined by `A`. The coordinate system defined by `A` is `0.05` units along the `x-axis` defined by the root. With three entities there are three coordinate systems.\n\n\n\nIn this example there are two cubes. Each cube has eight corners, and each corner is `0.025` units away from the origin. The cubes appear in different locations in the scene because the system applies the `transform` to each corner of the cubes moving them from the local coordinate system (also called *model space*) to the world coordinate system. For example, the top, right, forward corner of the cube is at `{0.025, 0.025, 0.025}` in `model space`. The entity is translated by `{0.05, 0.0, 0.0}` The top-right-forward corner is then at `{0.075, 0.025, 0.025}`.\n\n## Build a simple entity to experiment with\n\nTo be visible, an entity must have a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/MeshDescriptor] and a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Material]. A `MeshDescriptor` contains the description of a mesh. In this case, the mesh contains all of the vertices and how they connect into triangles. A Material specifies the color and appearance of the entity.\n\nThe previous example used [https:\/\/developer.apple.com\/documentation\/realitykit\/meshresource\/generatebox(size:cornerradius:)-2ovma] to generate the mesh. This convenience obscures what the transform does. The remaining examples use a mesh built from scratch.\n\nAll entities have a coordinate space, often called *model space*. This coordinate system determines the location of the *vertices*.\n\nThe code below builds an entity with the following properties:\n\n## Add the cube entity to a reality view\n\nYou add the `cube` entity to the volumetric window via SwiftUI like this:\n\nThe cube entity appears at the center of the volume, the origin of the volume’s root entity.\n\n## Move the cube with a transform\n\nTo move the cube use the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Transform] component with the `translation` argument:\n\nApplying this `Transform` to the cube moves all eight vertices in the `x` direction by `0.1`.\n\nThe system moves the entity from its ‘model space’ origin to the location in world space. To achieve that effect, RealityKit performs some linear algebra behind the scenes to ‘transform’ the points into world space. The left matrix is the `Transform` converted to a matrix. The right vertex is the list of vertices. Here is the full multiplication for the transform and the first vertex.\n\n                                       \n\n\n\nThe left matrix is a direct representation of the `Transform` you made earlier and applied to the `cube`. The right matrix is the first vertex from the cube represented by a vector with `1.0` in the last position. Performing that multiplication (the [doc:\/\/com.apple.documentation\/documentation\/simd\/dot(_:_:)-4gb9g] product of each row of the matrix with the vertex) yields:\n\n\n\nThe net effect is that the new vertices have `0.1` added to their `x` component. This approach generalizes to all other forms of transformation that you use to manipulate entities in RealityKit:\n\n## Scale the cube with a transform\n\nTo scale an entity use the `transform` property. To apply a uniform scale of 2 to the entity change the code, like this:\n\nThat yields a matrix multiplication that looks like this:\n\n\n\nAfter the multiplication yields a transformed vertex like this:\n\n\n\nAfter multiplying all of the vertices by the scale matrix, the cube is twice as large in each direction (`0.2` versus `0.1`):\n\n## Combine transforms\n\nThese two operations combine into a single operation with the `Transform` type like this:\n\nThat transform yields a matrix multiplication for all the vertices, laid out as column vectors. The multiplication looks like this:\n\n\n\nThe order is important: scale first then translate.\n\nMultiplying these two transformation matrices in the order shown above yields this result:\n\n\n\nThe result scales the model by `2` uniformly and translates the model by `0.1` in the `x` direction:\n\nSwitching that order yields a different matrix:\n\n\n\nThis resulting matrix yields a similar uniform scale of `2`, but the translation is scaled by `2` as well. The net result of this matrix is to scale the model uniformly by `2` and move it in the positive `x` direction by `0.2`:\n\nMultiply the `scale` matrix by the `translation` matrix to get the combined `transform` matrix. RealityKit then applies the combined matrix to the vertices:\n\n\n\nWhich yields a matrix like this:\n\n\n\nThe scaled and translated vertices yield a cube that is twice as large in each direction and moved `0.1` units to the right.\n\n## Rotate entities\n\nTo rotate the cube 45° (π\/4 radians), use the `Transform` type with the `rotation` argument like this:\n\nThis causes the cube to rotate 45° around its origin along the `x-axis`. The matrix for this rotation looks like this:\n\nRotation around any other axis is achieved in the same way. For example, to rotate 45° around the axis through the top-right corner of the cube you could use:\n\nThat code performs a rotation that looks like this:\n\nApplying this transformation matrix to the full set of vertices yields this new set of transformed vertices:\n\n\n\nNotice that the fourth and sixth vertex didn’t change. The axis of rotation goes through those two vertices so nothing changes on that axis.\n\n## Combine rotation, translation, and scale in one transform\n\nRotation combined with other transforms might yield unexpected results depending on the order of the application. You can combine all three transformations in the `Transform` initializer like this:\n\nThe order of these transforms is `translation` followed by `rotation` then `scale`.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionos\/understanding-transforms\ncrawled: 2025-12-02T17:51:56Z\n---\n\n# Using transforms to move, scale, and rotate entities\n\n**Article**\n\nLearn how to use Transforms to move, scale, and rotate entities in RealityKit.\n\n## Overview\n\nRealityKit [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Entity] objects exist in a tree, and each entity can have any number of subentities. (The entities themselves can standalone, or can be in a single container.) Every entity in the tree stores its own transform component. The transform contains the `translation`, `scale`, and `orientation` relative to its container entity. The *root* of each tree is an entity without a container entity.\n\nEach entity exists in its own coordinate system that defines the origin and orientation of the three ordinal directions (the x, y, and z axes). The coordinate system is relative to its container coordinate system and is defined by its transform.\n\n## Arrange entities with transforms\n\nA root entity has no parent entity. Its location in the scene is either controlled by SwiftUI or placed via a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/SpatialTrackingSession]. SwiftUI provides a root entity for the volume defined by the `RealityView`. The root entity defines the root coordinate system.\n\n\n\nEach entity added to the tree adds a new coordinate system defined by its [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/HasTransform\/transform] and is relative to its container entity. Each of the coordinate systems relate to each other by the hierarchy of entities and their transforms. For example a hierarchy of entities built with this code:\n\n```swift\nRealityView { content in\n  let a = ModelEntity(mesh: .generateBox(size: 0.05), materials: [SimpleMaterial(color: .orange, isMetallic: false)])\n  a.name = \"A\"\n  a.transform = Transform(translation: SIMD3<Float>(0.05, 0.0, 0.0))\n  content.add(a)\n\n  let b = ModelEntity(mesh: .generateBox(size: 0.05), materials: [SimpleMaterial(color: .purple, isMetallic: false)])\n  b.name = \"B\"\n  b.transform = Transform(translation: SIMD3<Float>(0.1, 0.0, 0.0))\n\n  a.addChild(b)\n}\n```\n\nThis reality view has three entities `B`, `A`, and the root entity. These three entities form a tree, with one root entity at the center of the reality view’s volume. Entity A is a subentity of the root, and B is a subentity of A.\n\n\n\nThe reality view provides the root entity, which is located at the center of a volumetric window or near the floor in an immersive space. Use the [https:\/\/developer.apple.com\/documentation\/realitykit\/realityviewcontentprotocol\/add(_:)]  method on the `content` supplied by the reality view to add entities as subentites of that root entity. The coordinate system defined by `B` is `0.1` units along the `x-axis` of the coordinate system defined by `A`. The coordinate system defined by `A` is `0.05` units along the `x-axis` defined by the root. With three entities there are three coordinate systems.\n\n\n\nIn this example there are two cubes. Each cube has eight corners, and each corner is `0.025` units away from the origin. The cubes appear in different locations in the scene because the system applies the `transform` to each corner of the cubes moving them from the local coordinate system (also called *model space*) to the world coordinate system. For example, the top, right, forward corner of the cube is at `{0.025, 0.025, 0.025}` in `model space`. The entity is translated by `{0.05, 0.0, 0.0}` The top-right-forward corner is then at `{0.075, 0.025, 0.025}`.\n\n## Build a simple entity to experiment with\n\nTo be visible, an entity must have a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/MeshDescriptor] and a [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Material]. A `MeshDescriptor` contains the description of a mesh. In this case, the mesh contains all of the vertices and how they connect into triangles. A Material specifies the color and appearance of the entity.\n\nThe previous example used [https:\/\/developer.apple.com\/documentation\/realitykit\/meshresource\/generatebox(size:cornerradius:)-2ovma] to generate the mesh. This convenience obscures what the transform does. The remaining examples use a mesh built from scratch.\n\nAll entities have a coordinate space, often called *model space*. This coordinate system determines the location of the *vertices*.\n\nThe code below builds an entity with the following properties:\n\n- The entity has one material.\n- The mesh has 8 vertices and 12 triangles. Each vertex is one corner of the cube. Each triangle is one half of each side and involves three of the vertices. There are six sides, with two triangles each, for a total of 12 triangles. These vertices are in the model space coordinate system. This function builds the entity.\n\n```swift\nfunc createCube() -> ModelEntity? {\n  let material = SimpleMaterial(color: .blue, isMetallic: false)\n  var descriptor = MeshDescriptor(name: \"Simple Cube\")\n  let allVerts: Array<SIMD3<Float>> = [[0.05,  0.05, -0.05], \/\/ Right-top-back vertex\n                                       [-0.05,  0.05, -0.05], \/\/ Left-top-back vertex\n                                       [-0.05,  0.05,  0.05], \/\/ Left-top-front vertex\n                                       [0.05,  0.05,  0.05], \/\/ Right-top-front vertex\n                                       [0.05, -0.05, -0.05], \/\/ Right-bottom-back vertex\n                                       [-0.05, -0.05, -0.05], \/\/ Left-bottom-back vertex\n                                       [-0.05, -0.05,  0.05], \/\/ Left-bottom-front vertex\n                                       [0.05, -0.05,  0.05]] \/\/ Right-bottom-front vertex\n  let allTris: Array<UInt32> = [\n    \/\/ Index into the vertex array for the top triangles.\n    0, 1, 2,\n    0, 2, 3,\n    \/\/ Index into the vertex array for the bottom triangles.\n    4, 6, 5,\n    4, 7, 6,\n    \/\/ Index into the vertex array for the right triangles.\n    0, 3, 7,\n    7, 4, 0,\n    \/\/ Index into the vertex array for the back triangles.\n    0, 4, 1,\n    4, 5, 1,\n    \/\/ Index into the vertex array for the left triangles.\n    2, 1, 5,\n    5, 6, 2,\n    \/\/ Index into the vertex array for the front triangles.\n    3, 2, 6,\n    6, 7, 3\n  ]\n  descriptor.positions = MeshBuffer(allVerts)\n  descriptor.primitives = .triangles(allTris)\n\n  if let resource = try? MeshResource.generate(from: [descriptor]) {\n     return ModelEntity(mesh: resource, materials: [material])\n  }\n  return nil\n}\n```\n\n\n\n\n\n## Add the cube entity to a reality view\n\nYou add the `cube` entity to the volumetric window via SwiftUI like this:\n\n```swift\nRealityView { content in\n  if let cube = createCube() {\n    content.add(cube)\n  }\n}\n```\n\nThe cube entity appears at the center of the volume, the origin of the volume’s root entity.\n\n## Move the cube with a transform\n\nTo move the cube use the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/Transform] component with the `translation` argument:\n\n```swift\n    cube.transform = Transform(translation: SIMD3<Float>(0.1, 0.0, 0.0))\n```\n\nApplying this `Transform` to the cube moves all eight vertices in the `x` direction by `0.1`.\n\nThe system moves the entity from its ‘model space’ origin to the location in world space. To achieve that effect, RealityKit performs some linear algebra behind the scenes to ‘transform’ the points into world space. The left matrix is the `Transform` converted to a matrix. The right vertex is the list of vertices. Here is the full multiplication for the transform and the first vertex.\n\n                                       \n\n\n\nThe left matrix is a direct representation of the `Transform` you made earlier and applied to the `cube`. The right matrix is the first vertex from the cube represented by a vector with `1.0` in the last position. Performing that multiplication (the [doc:\/\/com.apple.documentation\/documentation\/simd\/dot(_:_:)-4gb9g] product of each row of the matrix with the vertex) yields:\n\n\n\nThe net effect is that the new vertices have `0.1` added to their `x` component. This approach generalizes to all other forms of transformation that you use to manipulate entities in RealityKit:\n\n\n\n## Scale the cube with a transform\n\nTo scale an entity use the `transform` property. To apply a uniform scale of 2 to the entity change the code, like this:\n\n```swift\n  cube?.transform = Transform(scale: SIMD3<Float>(2.0, 2.0, 2.0))\n```\n\nThat yields a matrix multiplication that looks like this:\n\n\n\nAfter the multiplication yields a transformed vertex like this:\n\n\n\nAfter multiplying all of the vertices by the scale matrix, the cube is twice as large in each direction (`0.2` versus `0.1`):\n\n\n\n## Combine transforms\n\nThese two operations combine into a single operation with the `Transform` type like this:\n\n```swift\n  cube?.transform = Transform(scale: SIMD3<Float>(2.0, 2.0, 2.0), translation: SIMD3<Float>(0.1, 0.0, 0.0))\n```\n\nThat transform yields a matrix multiplication for all the vertices, laid out as column vectors. The multiplication looks like this:\n\n\n\nThe order is important: scale first then translate.\n\n\n\nMultiplying these two transformation matrices in the order shown above yields this result:\n\n\n\nThe result scales the model by `2` uniformly and translates the model by `0.1` in the `x` direction:\n\n\n\nSwitching that order yields a different matrix:\n\n\n\nThis resulting matrix yields a similar uniform scale of `2`, but the translation is scaled by `2` as well. The net result of this matrix is to scale the model uniformly by `2` and move it in the positive `x` direction by `0.2`:\n\n\n\n\n\nMultiply the `scale` matrix by the `translation` matrix to get the combined `transform` matrix. RealityKit then applies the combined matrix to the vertices:\n\n\n\nWhich yields a matrix like this:\n\n\n\nThe scaled and translated vertices yield a cube that is twice as large in each direction and moved `0.1` units to the right.\n\n## Rotate entities\n\nTo rotate the cube 45° (π\/4 radians), use the `Transform` type with the `rotation` argument like this:\n\n```swift\nRealityView { content in\n  if let cube {\n    content.add(cube)\n  }\n  cube?.transform = Transform(rotation: simd_quatf(angle: .pi\/4, axis: SIMD3<Float>(1.0, 0.0, 0.0)))\n }\n```\n\nThis causes the cube to rotate 45° around its origin along the `x-axis`. The matrix for this rotation looks like this:\n\n\n\nRotation around any other axis is achieved in the same way. For example, to rotate 45° around the axis through the top-right corner of the cube you could use:\n\n```swift\n  cube?.transform = Transform(rotation: simd_quatf(angle: .pi\/4, axis: normalize(SIMD3<Float>(1.0, 1.0, 1.0))))\n```\n\n\n\nThat code performs a rotation that looks like this:\n\n\n\nApplying this transformation matrix to the full set of vertices yields this new set of transformed vertices:\n\n\n\nNotice that the fourth and sixth vertex didn’t change. The axis of rotation goes through those two vertices so nothing changes on that axis.\n\n## Combine rotation, translation, and scale in one transform\n\nRotation combined with other transforms might yield unexpected results depending on the order of the application. You can combine all three transformations in the `Transform` initializer like this:\n\n```swift\n  cube?.transform = Transform(scale: SIMD3<Float>(2.0, 2.0, 2.0),\n                              rotation: simd_quatf(angle: .pi\/4, axis: normalize(SIMD3<Float>(1.0, 1.0, 1.0))),\n                              translation: SIMD3<Float>(0.1, 0.0, 0.0))\n\n```\n\nThe order of these transforms is `translation` followed by `rotation` then `scale`.\n\n## RealityKit and Reality Composer Pro\n\n- **Reality Composer Pro**: Build, create, and design 3D content for your RealityKit apps.\n- **Petite Asteroids: Building a volumetric visionOS game**: Use the latest RealityKit APIs to create a beautiful video game for visionOS.\n- **BOT-anist**: Build a multiplatform app that uses windows, volumes, and animations to create a robot botanist’s greenhouse.\n- **Swift Splash**: Use RealityKit to create an interactive ride in visionOS.\n- **Diorama**: Design scenes for your visionOS app using Reality Composer Pro.\n- **Building an immersive media viewing experience**: Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.\n- **Enabling video reflections in an immersive environment**: Create a more immersive experience by adding video reflections in a custom environment.\n- **Combining 2D and 3D views in an immersive app**: Use attachments to place 2D content relative to 3D content in your visionOS app.\n- **Understanding the modular architecture of RealityKit**: Learn how everything fits together in RealityKit.\n- **Capturing screenshots and video from Apple Vision Pro for 2D viewing**: Create screenshots and record high-quality video of your visionOS app and its surroundings for app previews.\n- **Implementing object tracking in your visionOS app**: Create engaging interactions by training models to recognize and track real-world objects in your app.\n- **Placing entities using head and device transform**: Query and react to changes in the position and rotation of Apple Vision Pro.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Build, create, and design 3D content for your RealityKit apps.",
          "name" : "Reality Composer Pro",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityComposerPro"
        },
        {
          "description" : "Use the latest RealityKit APIs to create a beautiful video game for visionOS.",
          "name" : "Petite Asteroids: Building a volumetric visionOS game",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/petite-asteroids-building-a-volumetric-visionos-game"
        },
        {
          "description" : "Build a multiplatform app that uses windows, volumes, and animations to create a robot botanist’s greenhouse.",
          "name" : "BOT-anist",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/BOT-anist"
        },
        {
          "description" : "Use RealityKit to create an interactive ride in visionOS.",
          "name" : "Swift Splash",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/swift-splash"
        },
        {
          "description" : "Design scenes for your visionOS app using Reality Composer Pro.",
          "name" : "Diorama",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/diorama"
        },
        {
          "description" : "Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.",
          "name" : "Building an immersive media viewing experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/building-an-immersive-media-viewing-experience"
        },
        {
          "description" : "Create a more immersive experience by adding video reflections in a custom environment.",
          "name" : "Enabling video reflections in an immersive environment",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/enabling-video-reflections-in-an-immersive-environment"
        },
        {
          "description" : "Use attachments to place 2D content relative to 3D content in your visionOS app.",
          "name" : "Combining 2D and 3D views in an immersive app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/combining-2d-and-3d-views-in-an-immersive-app"
        },
        {
          "description" : "Learn how everything fits together in RealityKit.",
          "name" : "Understanding the modular architecture of RealityKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/understanding-the-realitykit-modular-architecture"
        },
        {
          "description" : "Create screenshots and record high-quality video of your visionOS app and its surroundings for app previews.",
          "name" : "Capturing screenshots and video from Apple Vision Pro for 2D viewing",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/capturing-screenshots-and-video-from-your-apple-vision-pro-for-2d-viewing"
        },
        {
          "description" : "Create engaging interactions by training models to recognize and track real-world objects in your app.",
          "name" : "Implementing object tracking in your visionOS app",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/implementing-object-tracking-in-your-visionOS-app"
        },
        {
          "description" : "Query and react to changes in the position and rotation of Apple Vision Pro.",
          "name" : "Placing entities using head and device transform",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/placing-entities-using-head-and-device-transform"
        }
      ],
      "title" : "RealityKit and Reality Composer Pro"
    }
  ],
  "source" : "appleJSON",
  "title" : "Using transforms to move, scale, and rotate entities",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionos\/understanding-transforms"
}