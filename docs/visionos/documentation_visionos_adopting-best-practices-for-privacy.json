{
  "abstract" : "Minimize your use of sensitive information and provide a clear statement of what information you do use and how you use it.",
  "codeExamples" : [

  ],
  "contentHash" : "a38b45984da6fd4426f3620b5eac2b0cab7d011708926ddbbc713cc234b41c30",
  "crawledAt" : "2025-12-02T17:52:20Z",
  "id" : "DFD328E6-6ED2-4EBC-BDFC-53DA865D52FD",
  "kind" : "article",
  "language" : "swift",
  "overview" : "## Overview\n\nTo protect user privacy, the system handles camera and sensor inputs without passing the information to apps directly. Instead, the system enables your app to seamlessly interact with a user’s surroundings and to automatically receive input from the user. For example, the system handles the eye- and hand-position data needed to detect interactions with your app’s content. Similarly, the system provides a way to automatically alter a view’s appearance when someone looks at it, without your app ever knowing what the user is looking at.\n\nIn the few cases where you actually need access to hand position or information about the user’s surroundings, the system requires you to obtain authorization from the user first.\n\n\n\nFor information about how to specify the privacy data your app uses, see [doc:\/\/com.apple.documentation\/documentation\/BundleResources\/describing-data-use-in-privacy-manifests]. For general information about privacy, see [doc:\/\/com.apple.documentation\/documentation\/UIKit\/protecting-the-user-s-privacy].\n\n### Adopt the system-provided input mechanisms\n\nOn Apple Vision Pro, people use their eyes and hands to interact with the items they see in front of them. Where they look determines where the system applies focus, and a tap gesture with either hand generates a touch event on that focused item. The system can also detect when someone’s fingers interact with virtual items in the person’s field of vision. When you adopt the standard UIKit and SwiftUI event-handling mechanisms, you get all of these interactions automatically.\n\nFor most apps, the system-provided gesture recognizers are sufficient for responding to interactions. Although you can get the position of someone’s hands with ARKit, doing so isn’t necessary for most apps. Collect hand-position data only when the system doesn’t offer what you need. For example, you might use hand-position data to attach 3D content to the person’s hands. Some other things to remember about hand-position data:\n\nFor information about how to handle the standard-system events, see the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI] and [doc:\/\/com.apple.documentation\/documentation\/UIKit] documentation.\n\n### Provide clear messaging around privacy-sensitive features\n\nThe following ARKit features require you to provide a usage description string in your app’s `Info.plist` file:\n\nOther privacy-sensitive technologies in visionOS also require you to supply usage description strings. For example, you provide usage descriptions for the Core Location features you adopt. These strings communicate why your app needs the data, and how you plan to use the data to help the person using your app. The first time you request authorization to use the technology, the system prompts the person to grant or deny access to your app. The system includes your usage-description string in the dialog it displays.\n\nFor information about requesting access to ARKit data, see [doc:\/\/com.apple.documentation\/documentation\/ARKit]. For guidance on how to craft good messages around privacy-friendly features, see [doc:\/\/com.apple.documentation\/design\/Human-Interface-Guidelines\/privacy].",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionOS\/adopting-best-practices-for-privacy\ncrawled: 2025-12-02T17:52:20Z\n---\n\n# Adopting best practices for privacy and user preferences\n\n**Article**\n\nMinimize your use of sensitive information and provide a clear statement of what information you do use and how you use it.\n\n## Overview\n\nTo protect user privacy, the system handles camera and sensor inputs without passing the information to apps directly. Instead, the system enables your app to seamlessly interact with a user’s surroundings and to automatically receive input from the user. For example, the system handles the eye- and hand-position data needed to detect interactions with your app’s content. Similarly, the system provides a way to automatically alter a view’s appearance when someone looks at it, without your app ever knowing what the user is looking at.\n\nIn the few cases where you actually need access to hand position or information about the user’s surroundings, the system requires you to obtain authorization from the user first.\n\n\n\n\n\nFor information about how to specify the privacy data your app uses, see [doc:\/\/com.apple.documentation\/documentation\/BundleResources\/describing-data-use-in-privacy-manifests]. For general information about privacy, see [doc:\/\/com.apple.documentation\/documentation\/UIKit\/protecting-the-user-s-privacy].\n\n### Adopt the system-provided input mechanisms\n\nOn Apple Vision Pro, people use their eyes and hands to interact with the items they see in front of them. Where they look determines where the system applies focus, and a tap gesture with either hand generates a touch event on that focused item. The system can also detect when someone’s fingers interact with virtual items in the person’s field of vision. When you adopt the standard UIKit and SwiftUI event-handling mechanisms, you get all of these interactions automatically.\n\nFor most apps, the system-provided gesture recognizers are sufficient for responding to interactions. Although you can get the position of someone’s hands with ARKit, doing so isn’t necessary for most apps. Collect hand-position data only when the system doesn’t offer what you need. For example, you might use hand-position data to attach 3D content to the person’s hands. Some other things to remember about hand-position data:\n\n- People can deny your request for access to hand-position data. Be prepared to handle situations where the data isn’t available.\n- You must present an immersive space to access hand data. When you open an immersive space, the system hides other apps.\n\nFor information about how to handle the standard-system events, see the [doc:\/\/com.apple.documentation\/documentation\/SwiftUI] and [doc:\/\/com.apple.documentation\/documentation\/UIKit] documentation.\n\n### Provide clear messaging around privacy-sensitive features\n\nThe following ARKit features require you to provide a usage description string in your app’s `Info.plist` file:\n\n- World-tracking data\n- Hand-tracking data\n\nOther privacy-sensitive technologies in visionOS also require you to supply usage description strings. For example, you provide usage descriptions for the Core Location features you adopt. These strings communicate why your app needs the data, and how you plan to use the data to help the person using your app. The first time you request authorization to use the technology, the system prompts the person to grant or deny access to your app. The system includes your usage-description string in the dialog it displays.\n\nFor information about requesting access to ARKit data, see [doc:\/\/com.apple.documentation\/documentation\/ARKit]. For guidance on how to craft good messages around privacy-friendly features, see [doc:\/\/com.apple.documentation\/design\/Human-Interface-Guidelines\/privacy].\n\n## Design\n\n- **Designing for visionOS**: When people wear Apple Vision Pro, they enter an infinite 3D space where they can engage with your app or game while staying connected to their surroundings.\n- **Improving accessibility support in your visionOS app**: Update your code to ensure everyone can access your app’s content in visionOS.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "When people wear Apple Vision Pro, they enter an infinite 3D space where they can engage with your app or game while staying connected to their surroundings.",
          "name" : "Designing for visionOS"
        },
        {
          "description" : "Update your code to ensure everyone can access your app’s content in visionOS.",
          "name" : "Improving accessibility support in your visionOS app",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/improving-accessibility-support-in-your-app"
        }
      ],
      "title" : "Design"
    }
  ],
  "source" : "appleJSON",
  "title" : "Adopting best practices for privacy and user preferences",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/adopting-best-practices-for-privacy"
}