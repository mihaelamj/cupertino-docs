{
  "abstract" : "Increase the realism of an immersive experience by adding entities with invisible materials  real-world objects.",
  "codeExamples" : [
    {
      "code" : "import SwiftUI\nimport RealityKit\nimport ARKit\n\nclass MeshAnchorGenerator {\n    \/\/\/ The root to hold the meshes that the app detects.\n    var root: Entity?\n\n    \/\/\/ The collection that comprises the `MeshAnchor.id` and the entity associated with the anchors.\n    private var anchors: [UUID: Entity] = [:]\n\n    init(root: Entity) {\n        self.root = root\n    }\n\n    \/\/ ...\n}",
      "language" : "swift"
    },
    {
      "code" : "@MainActor\nfunc run(_ sceneRec: SceneReconstructionProvider) async {\n    \/\/ Loop to process all anchor updates that the provider detects.\n    for await update in sceneRec.anchorUpdates {\n        switch update.event {\n        case .added, .updated:\n            \/\/ Retrieves the entity from the anchor collection based on the anchor ID.\n            \/\/ If it doesn't exist, creates and adds a new entity to the collection.\n            let entity = anchors[update.anchor.id] ?? {\n                let entity = Entity()\n                root?.addChild(entity)\n                anchors[update.anchor.id] = entity\n                return entity\n            }()\n\n            \/\/\/ The occlusion material to apply to the entity.\n            let material = OcclusionMaterial()\n\n            \/\/\/ The mesh based on the detected anchor.\n            guard let mesh = try? await MeshResource(from: update.anchor) else { return }\n\n            await MainActor.run {\n                \/\/ Update the entity mesh and apply the occlusion material.\n                entity.components.set(ModelComponent(mesh: mesh, materials: [material]))\n\n                \/\/ Set the transform matrix on its position relative to the anchor.\n                entity.setTransformMatrix(update.anchor.originFromAnchorTransform, relativeTo: nil)\n            }\n        \n            \/\/ ...\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "@MainActor\nfunc run(_ sceneRec: SceneReconstructionProvider) async {\n    for await update in sceneRec.anchorUpdates {\n        \/\/ Handle different types of anchor update events.\n        switch update.event {\n\n        \/\/ ...\n\n        case .removed:\n            \/\/ Remove the entity from the root if it exists.\n            anchors[update.anchor.id]?.removeFromParent()\n\n            \/\/ Remove the anchor entry from the dictionary.\n            anchors[update.anchor.id] = nil\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import RealityKit\nimport ARKit\n\nfunc runSession(_ meshAnchors: Entity) {\n    \/\/\/ The ARKit session instance for scene reconstruction.\n    let arSession = ARKitSession()\n\n    \/\/\/ The provider instance for scene reconstruction.\n    let sceneReconstruction = SceneReconstructionProvider()\n\n    Task {\n        \/\/\/ The generator to use to replace the mesh on anchors.\n        let generator = MeshAnchorGenerator(root: meshAnchors)\n\n        \/\/ Check if the device can support `SceneReconstructionProvider`.\n        guard SceneReconstructionProvider.isSupported else {\n            print(\"SceneReconstructionProvider is not supported on this device.\")\n            return\n        }\n\n        do {\n            \/\/ Start the ARKit session to run the `SceneReconstructionProvider`.\n            try await arSession.run([sceneReconstruction])\n        } catch let error as ARKitSession.Error {\n            \/\/ Handle any ARKit session errors.\n            print(\"Encountered an error while running providers: \\(error.localizedDescription)\")\n        } catch let error {\n            \/\/ Handle other unexpected errors.\n            print(\"Encountered an unexpected error: \\(error.localizedDescription)\")\n        }\n\n        \/\/ Run the generator after the ARKit session runs successfully.\n        await generator.run(sceneReconstruction)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "var translationGesture: some Gesture {\n    DragGesture()\n        .targetedToAnyEntity()\n        .onChanged({ value in\n            \/\/\/ The entity that the drag gesture targets.\n            let targetEntity = value.entity\n\n            \/\/ Set `initialPosition` to the position of the entity if it is nil.\n            if initialPosition == nil {\n                initialPosition = targetEntity.position\n            }\n\n            \/\/ Convert the movement from the SwiftUI coordinate space to the reality view coordinate space.\n            let movement = value.convert(value.translation3D, from: .global, to: .scene)\n\n            \/\/ Apply the entity position to match the drag gesture,\n            \/\/ and set the movement to stay at the ground level.\n            targetEntity.position = (initialPosition ?? .zero) + movement.grounded\n        })\n        .onEnded({ _ in\n            \/\/ Reset the `initialPosition` back to `nil` after the gesture ends.\n            initialPosition = nil\n        })\n}",
      "language" : "swift"
    },
    {
      "code" : "import SwiftUI\nimport RealityKit\n\nstruct WorldOcclusionView: View {\n    \/\/ ...\n\n    var body: some View {\n        RealityView { content in\n            \/\/\/ The entity to hold anchors with occlusion materials.\n            let meshAnchors = Entity()\n\n            \/\/ Run the ARKit session.\n            runSession(meshAnchors)\n\n            \/\/ Add the root to the reality view.\n            content.add(meshAnchors)\n\n            \/\/\/ The filename of the chair model.\n            let fileName: String = \"chair_swan\"\n\n            \/\/ Load the chair model from the filename asynchronously.\n            guard let chair = try? await ModelEntity(named: fileName) else {\n                assertionFailure(\"Failed to load model: \\(fileName)\")\n                return\n            }\n\n            \/\/ Generate collision shapes to the chair for proper occlusion.\n            chair.generateCollisionShapes(recursive: true)\n\n            \/\/ Enable inputs for the app to detect the hand gestures.\n            chair.components.set(InputTargetComponent())\n\n            \/\/ Add the chair entity to the reality view.\n            content.add(chair)\n        }\n        \/\/ Set the `translationGesture` to the view.\n        .gesture(translationGesture)\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "c2ed948eef5d633a98e704b4dee1f2bead6431e8029425f60af3576115ff7036",
  "crawledAt" : "2025-12-02T17:30:12Z",
  "id" : "D1C4C1B9-E20A-4E55-BBE7-6F3FD96DA379",
  "kind" : "unknown",
  "language" : "swift",
  "overview" : "## Overview\n\nYou can create layered effects using an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/OcclusionMaterial], which is an invisible material that hides objects that render behind it. This sample project demonstrates how to hide entities behind real-world objects with [doc:\/\/com.apple.documentation\/documentation\/ARKit] by gathering live data about a person’s surroundings and applyng the `OcclusionMaterial` to them.\n\n### Capture the anchors from the scene\n\nThe sample uses the `MeshAnchorGenerator` class to retrieve anchor information from [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider]. In the following code snippet, the generator takes in the root entity from the reality view to perform actions on the entities and create a dictionary to store the collection of anchors:\n\nThe `run(_:)` method processes all anchor updates asynchronously from the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider]. When an anchor detects either an `.added` or an `.updated` event, it creates a new entity if one isn’t already present, and it updates its mesh, material, and transform properties:\n\nWhen an anchor detects a `.removed` event, the app removes the entity from the `root` and the anchor collection:\n\n### Start scene reconstruction\n\nTo track the anchors, the app starts an ARKit session. It uses `runSession(_:)` to initiate the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARKitSession] with [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider], to perform scene reconstruction:\n\nThe method constructs the `MeshAnchorGenerator` class with the `meshAnchors`. Then it initiates the ARKit session while handling any potential errors. Finally, the app proceeds with the generation process by invoking the `run(_:)` method with the `sceneReconstruction` instance.\n\n### Setting up the drag gesture\n\nIn the immersive scene, the app loads a chair model that is moveable with drag gestures. The app creates the `translationGesture` to convert the person’s gesture movements to the entity’s positions, so that a person can target the chair model and move it around the space:\n\n### Put it all together into a view\n\nThe app loads all of the content into a reality view. It creates the `meshAnchors` entity and calls the `runSession(_:)` method with it, which initiates the ARKit session and adds child entities of anchors with occlusion materials to `meshAnchors`. Then the app adds the `meshAnchors` into the reality view:\n\nFinally, the app creates a chair model and sets the chair to accept user input with [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/InputTargetComponent]. Then it sets the chair with `TargetModelComponent`, enabling the chair to work with `translationGesture`. The app then adds the chair model to the reality view.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionos\/obscuring-virtual-items-in-a-scene-behind-real-world-items\ncrawled: 2025-12-02T17:30:12Z\n---\n\n# Obscuring virtual items in a scene behind real-world items\n\n**Sample Code**\n\nIncrease the realism of an immersive experience by adding entities with invisible materials  real-world objects.\n\n## Overview\n\nYou can create layered effects using an [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/OcclusionMaterial], which is an invisible material that hides objects that render behind it. This sample project demonstrates how to hide entities behind real-world objects with [doc:\/\/com.apple.documentation\/documentation\/ARKit] by gathering live data about a person’s surroundings and applyng the `OcclusionMaterial` to them.\n\n\n\n### Capture the anchors from the scene\n\nThe sample uses the `MeshAnchorGenerator` class to retrieve anchor information from [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider]. In the following code snippet, the generator takes in the root entity from the reality view to perform actions on the entities and create a dictionary to store the collection of anchors:\n\n```swift\nimport SwiftUI\nimport RealityKit\nimport ARKit\n\nclass MeshAnchorGenerator {\n    \/\/\/ The root to hold the meshes that the app detects.\n    var root: Entity?\n\n    \/\/\/ The collection that comprises the `MeshAnchor.id` and the entity associated with the anchors.\n    private var anchors: [UUID: Entity] = [:]\n\n    init(root: Entity) {\n        self.root = root\n    }\n\n    \/\/ ...\n}\n```\n\nThe `run(_:)` method processes all anchor updates asynchronously from the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider]. When an anchor detects either an `.added` or an `.updated` event, it creates a new entity if one isn’t already present, and it updates its mesh, material, and transform properties:\n\n```swift\n@MainActor\nfunc run(_ sceneRec: SceneReconstructionProvider) async {\n    \/\/ Loop to process all anchor updates that the provider detects.\n    for await update in sceneRec.anchorUpdates {\n        switch update.event {\n        case .added, .updated:\n            \/\/ Retrieves the entity from the anchor collection based on the anchor ID.\n            \/\/ If it doesn't exist, creates and adds a new entity to the collection.\n            let entity = anchors[update.anchor.id] ?? {\n                let entity = Entity()\n                root?.addChild(entity)\n                anchors[update.anchor.id] = entity\n                return entity\n            }()\n\n            \/\/\/ The occlusion material to apply to the entity.\n            let material = OcclusionMaterial()\n\n            \/\/\/ The mesh based on the detected anchor.\n            guard let mesh = try? await MeshResource(from: update.anchor) else { return }\n\n            await MainActor.run {\n                \/\/ Update the entity mesh and apply the occlusion material.\n                entity.components.set(ModelComponent(mesh: mesh, materials: [material]))\n\n                \/\/ Set the transform matrix on its position relative to the anchor.\n                entity.setTransformMatrix(update.anchor.originFromAnchorTransform, relativeTo: nil)\n            }\n        \n            \/\/ ...\n        }\n    }\n}\n```\n\nWhen an anchor detects a `.removed` event, the app removes the entity from the `root` and the anchor collection:\n\n```swift\n@MainActor\nfunc run(_ sceneRec: SceneReconstructionProvider) async {\n    for await update in sceneRec.anchorUpdates {\n        \/\/ Handle different types of anchor update events.\n        switch update.event {\n\n        \/\/ ...\n\n        case .removed:\n            \/\/ Remove the entity from the root if it exists.\n            anchors[update.anchor.id]?.removeFromParent()\n\n            \/\/ Remove the anchor entry from the dictionary.\n            anchors[update.anchor.id] = nil\n        }\n    }\n}\n```\n\n\n\n### Start scene reconstruction\n\nTo track the anchors, the app starts an ARKit session. It uses `runSession(_:)` to initiate the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARKitSession] with [doc:\/\/com.apple.documentation\/documentation\/ARKit\/SceneReconstructionProvider], to perform scene reconstruction:\n\n```swift\nimport RealityKit\nimport ARKit\n\nfunc runSession(_ meshAnchors: Entity) {\n    \/\/\/ The ARKit session instance for scene reconstruction.\n    let arSession = ARKitSession()\n\n    \/\/\/ The provider instance for scene reconstruction.\n    let sceneReconstruction = SceneReconstructionProvider()\n\n    Task {\n        \/\/\/ The generator to use to replace the mesh on anchors.\n        let generator = MeshAnchorGenerator(root: meshAnchors)\n\n        \/\/ Check if the device can support `SceneReconstructionProvider`.\n        guard SceneReconstructionProvider.isSupported else {\n            print(\"SceneReconstructionProvider is not supported on this device.\")\n            return\n        }\n\n        do {\n            \/\/ Start the ARKit session to run the `SceneReconstructionProvider`.\n            try await arSession.run([sceneReconstruction])\n        } catch let error as ARKitSession.Error {\n            \/\/ Handle any ARKit session errors.\n            print(\"Encountered an error while running providers: \\(error.localizedDescription)\")\n        } catch let error {\n            \/\/ Handle other unexpected errors.\n            print(\"Encountered an unexpected error: \\(error.localizedDescription)\")\n        }\n\n        \/\/ Run the generator after the ARKit session runs successfully.\n        await generator.run(sceneReconstruction)\n    }\n}\n```\n\nThe method constructs the `MeshAnchorGenerator` class with the `meshAnchors`. Then it initiates the ARKit session while handling any potential errors. Finally, the app proceeds with the generation process by invoking the `run(_:)` method with the `sceneReconstruction` instance.\n\n### Setting up the drag gesture\n\nIn the immersive scene, the app loads a chair model that is moveable with drag gestures. The app creates the `translationGesture` to convert the person’s gesture movements to the entity’s positions, so that a person can target the chair model and move it around the space:\n\n```swift\nvar translationGesture: some Gesture {\n    DragGesture()\n        .targetedToAnyEntity()\n        .onChanged({ value in\n            \/\/\/ The entity that the drag gesture targets.\n            let targetEntity = value.entity\n\n            \/\/ Set `initialPosition` to the position of the entity if it is nil.\n            if initialPosition == nil {\n                initialPosition = targetEntity.position\n            }\n\n            \/\/ Convert the movement from the SwiftUI coordinate space to the reality view coordinate space.\n            let movement = value.convert(value.translation3D, from: .global, to: .scene)\n\n            \/\/ Apply the entity position to match the drag gesture,\n            \/\/ and set the movement to stay at the ground level.\n            targetEntity.position = (initialPosition ?? .zero) + movement.grounded\n        })\n        .onEnded({ _ in\n            \/\/ Reset the `initialPosition` back to `nil` after the gesture ends.\n            initialPosition = nil\n        })\n}\n```\n\n### Put it all together into a view\n\nThe app loads all of the content into a reality view. It creates the `meshAnchors` entity and calls the `runSession(_:)` method with it, which initiates the ARKit session and adds child entities of anchors with occlusion materials to `meshAnchors`. Then the app adds the `meshAnchors` into the reality view:\n\n```swift\nimport SwiftUI\nimport RealityKit\n\nstruct WorldOcclusionView: View {\n    \/\/ ...\n\n    var body: some View {\n        RealityView { content in\n            \/\/\/ The entity to hold anchors with occlusion materials.\n            let meshAnchors = Entity()\n\n            \/\/ Run the ARKit session.\n            runSession(meshAnchors)\n\n            \/\/ Add the root to the reality view.\n            content.add(meshAnchors)\n\n            \/\/\/ The filename of the chair model.\n            let fileName: String = \"chair_swan\"\n\n            \/\/ Load the chair model from the filename asynchronously.\n            guard let chair = try? await ModelEntity(named: fileName) else {\n                assertionFailure(\"Failed to load model: \\(fileName)\")\n                return\n            }\n\n            \/\/ Generate collision shapes to the chair for proper occlusion.\n            chair.generateCollisionShapes(recursive: true)\n\n            \/\/ Enable inputs for the app to detect the hand gestures.\n            chair.components.set(InputTargetComponent())\n\n            \/\/ Add the chair entity to the reality view.\n            content.add(chair)\n        }\n        \/\/ Set the `translationGesture` to the view.\n        .gesture(translationGesture)\n    }\n}\n```\n\nFinally, the app creates a chair model and sets the chair to accept user input with [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/InputTargetComponent]. Then it sets the chair with `TargetModelComponent`, enabling the chair to work with `translationGesture`. The app then adds the chair model to the reality view.\n\n## Integrating ARKit\n\n- **Creating a 3D painting space**: Implement a painting canvas entity, and update its mesh to represent a stroke.\n- **Tracking and visualizing hand movement**: Use hand-tracking anchors to display a visual representation of hand transforms in visionOS.\n- **Displaying an entity that follows a person’s view**: Create an entity that tracks and follows head movement in an immersive scene.\n- **Applying mesh to real-world surroundings**: Add a layer of mesh to objects in the real world, using scene reconstruction in ARKit.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Implement a painting canvas entity, and update its mesh to represent a stroke.",
          "name" : "Creating a 3D painting space",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/creating-a-painting-space-in-visionos"
        },
        {
          "description" : "Use hand-tracking anchors to display a visual representation of hand transforms in visionOS.",
          "name" : "Tracking and visualizing hand movement",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/tracking-and-visualizing-hand-movement"
        },
        {
          "description" : "Create an entity that tracks and follows head movement in an immersive scene.",
          "name" : "Displaying an entity that follows a person’s view",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/displaying-a-3D-object-that-moves-to-stay-in-a-person's-view"
        },
        {
          "description" : "Add a layer of mesh to objects in the real world, using scene reconstruction in ARKit.",
          "name" : "Applying mesh to real-world surroundings",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/applying-mesh-to-real-world-surroundings"
        }
      ],
      "title" : "Integrating ARKit"
    }
  ],
  "source" : "appleJSON",
  "title" : "Obscuring virtual items in a scene behind real-world items",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionos\/obscuring-virtual-items-in-a-scene-behind-real-world-items"
}