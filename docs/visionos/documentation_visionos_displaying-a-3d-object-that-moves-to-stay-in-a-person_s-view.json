{
  "abstract" : "Create an entity that tracks and follows head movement in an immersive scene.",
  "codeExamples" : [
    {
      "code" : "import Foundation\nimport simd\nimport RealityKit\n\n\/\/\/ The type alias to create a new name for `SIMD3<Float>`.\ntypealias Float3 = SIMD3<Float>\n\n\/\/\/ The type alias to create a new name for `SIMD4<Float>`.\ntypealias Float4 = SIMD4<Float>\n\n\/\/\/ The type alias to create a new name for `simd_float4x4`.\ntypealias Float4x4 = simd_float4x4",
      "language" : "swift"
    },
    {
      "code" : "import Foundation\nimport simd\nimport RealityKit\n\ntypealias Float3 = SIMD3<Float>\n\n\/\/ ...\n\nextension Float3 {\n    \/\/\/ The initializer of a `Float3` from a `Float4`.\n    init(_ float4: Float4) {\n        self.init()\n        \n        x = float4.x\n        y = float4.y\n        z = float4.z\n    }\n    \n    \/\/ Calculate the total length by taking the square root of the product of the provided float.\n    func length() -> Float {\n        sqrt(x * x + y * y + z * z)\n    }\n    \n    \/\/ Calculate the normalized vector of the float.\n    func normalized() -> Float3 {\n        self * 1 \/ length()\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import Foundation\nimport simd\nimport RealityKit\n\ntypealias Float4 = SIMD4<Float>\n\n\/\/ ...\n\nextension Float4 {\n    \/\/ Ignore the W value to convert a `Float4` into a `Float3`.\n    func toFloat3() -> Float3 {\n        Float3(self)\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import Foundation\nimport simd\nimport RealityKit\n\ntypealias Float4x4 = simd_float4x4\n\n\/\/ ...\n\nextension Float4x4 {\n    \/\/ Identify the translation value from the `float4x4` and convert to a `Float3`.\n    func translation() -> Float3 {\n        columns.3.toFloat3()\n    }\n    \n    \/\/ Identify the forward-facing vector and return a `Float3`.\n    func forward() -> Float3 {\n        columns.2.toFloat3().normalized()\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import SwiftUI\nimport RealityKit\n\nstruct ClosureComponent: Component {\n    \/\/\/ The closure that takes the time interval since the last update.\n    let closure: (TimeInterval) -> Void\n\n    init (closure: @escaping (TimeInterval) -> Void) {\n        self.closure = closure\n        ClosureSystem.registerSystem()\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import SwiftUI\nimport RealityKit\n\nstruct ClosureSystem: System {\n    \/\/\/ The query to check if the entity has the `ClosureComponent`.\n    static let query = EntityQuery(where: .has(ClosureComponent.self))\n    \n    init(scene: RealityKit.Scene) {}\n    \n    \/\/\/ Update entities with `ClosureComponent` at each render frame.\n    func update(context: SceneUpdateContext) {\n        for entity in context.entities(matching: Self.query, updatingSystemWhen: .rendering) {\n            guard let comp = entity.components[ClosureComponent.self] else { continue }\n            comp.closure(context.deltaTime)\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "import SwiftUI\nimport RealityKit\nimport ARKit\n\nclass HeadPositionTracker: ObservableObject {\n    \/\/\/ The instance of the `ARKitSession` for world tracking.\n    let arSession = ARKitSession()\n\n    \/\/\/ The instance of a new `WorldTrackingProvider` for world tracking.\n    let worldTracking = WorldTrackingProvider()\n\n    init() {\n        Task {\n            \/\/ Check whether the device supports world tracking.\n            guard WorldTrackingProvider.isSupported else {\n                print(\"WorldTrackingProvider is not supported on this device\")\n                return\n            }\n            do {\n                \/\/ Attempt to start an ARKit session with the world-tracking provider.\n                try await arSession.run([worldTracking])\n            } catch let error as ARKitSession.Error {\n                \/\/ Handle any potential ARKit session errors.\n                print(\"Encountered an error while running providers: \\(error.localizedDescription)\")\n            } catch let error {\n                \/\/ Handle any unexpected errors.    \n                print(\"Encountered an unexpected error: \\(error.localizedDescription)\")\n            }\n        }\n    }",
      "language" : "swift"
    },
    {
      "code" : "func originFromDeviceTransform() -> simd_float4x4? {\n    \/\/\/ The anchor of the device at the current time.\n    guard let deviceAnchor = worldTracking.queryDeviceAnchor(atTimestamp: CACurrentMediaTime()) else {\n        return nil\n    }\n\n    \/\/ Return the device's transform.\n    return deviceAnchor.originFromAnchorTransform\n}",
      "language" : "swift"
    },
    {
      "code" : "import SwiftUI\nimport RealityKit\n\nstruct HeadPositionView: View {\n    \/\/\/ The tracker that contains the logic to handle real-time transformations from the device.\n    @StateObject var headTracker = HeadPositionTracker()\n\n    var body: some View {\n        RealityView(make: { content in\n            \/\/\/ The entity representation of the world origin.\n            let root = Entity()\n\n            \/\/\/ The size of the floating sphere.\n            let radius: Float = 0.02\n\n            \/\/\/ The material for the floating sphere.\n            let material = SimpleMaterial(color: .cyan, isMetallic: false)\n\n            \/\/\/ The sphere mesh entity.\n            let floatingSphere = ModelEntity(\n                mesh: .generateSphere(radius: radius),\n                materials: [material]\n            )\n\n            \/\/ Add the floating sphere to the root.\n            root.addChild(floatingSphere)\n\n            \/\/ ...\n        }\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "var body: some View {\n    RealityView(make: { content in\n        \/\/ ...\n    \n        \/\/\/ The distance that the content extends out from the device.\n        let distance: Float = 1.0\n\n        root.components.set(ClosureComponent(closure: { deltaTime in\n            \/\/\/ The current position of the device.\n            guard let currentTransform = headTracker.originFromDeviceTransform() else {\n                return\n            }\n\n            \/\/\/ The target position in front of the device.\n            let targetPosition = currentTransform.translation() - distance * currentTransform.forward()\n\n            \/\/\/ The interpolation ratio for smooth movement.\n            let ratio = Float(pow(0.96, deltaTime \/ (16 * 1E-3)))\n\n            \/\/\/ The new position of the floating sphere.\n            let newPosition = ratio * floatingSphere.position(relativeTo: nil) + (1 - ratio) * targetPosition\n\n            \/\/ Update the position of the floating sphere.\n            floatingSphere.setPosition(newPosition, relativeTo: nil)\n        }))\n\n        \/\/ Add the root entity to the `RealityView`.\n        content.add(root)\n    }, update: { _ in })\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "9fcb152a295bd885f120105aa97a7e883fc906639c4aef73ce479d8c77f1b708",
  "crawledAt" : "2025-12-02T16:21:18Z",
  "id" : "556E9A7B-A321-4D73-B65B-0AC779F3B982",
  "kind" : "unknown",
  "language" : "swift",
  "overview" : "## Overview\n\nThis sample uses world-tracking data from [doc:\/\/com.apple.documentation\/documentation\/ARKit] in visionOS to create and display a 3D entity that dynamically moves in front of a person’s view. As the following video shows, the floating sphere’s position updates based on the person’s head movement, to ensure the object stays visible and smoothly follows their view:\n\n### Extend the floats to enable calculations\n\nThe sample adds functionality to existing class types by extending `SIMD3<Float>`, `SIMD4<Float>`, and `simd_float4x4`:\n\nTo include these data types in the extension to their associated class, the sample associates each of the entry points using a `typealias`.\n\nThe `Float3` extension includes the following methods:\n\nThe `Float4` extension contains the `toFloat3()` method that converts a `Float4` value to `Float3`:\n\nThe `Float4x4` extension includes the following methods:\n\n### Update the entities over time\n\nThe sample sets up a custom system and component to handle updates in real time:\n\nThe component contains the `closure` variable to track the time. On initialization, it registers `ClosureSystem` into the reality view.\n\nThe `ClosureSystem` constructs a query using the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/EntityQuery] to retrieve all entities with the `ClosureComponent` from the scene. Then it passes the delta time, which is the elapsed time since the last update, to the `closure` variable for each entity:\n\n### Implement head tracking\n\nvisionOS supports [doc:\/\/com.apple.documentation\/documentation\/ARKit\/WorldTrackingProvider] from ARKit to get live data about a device’s position. World tracking requires an [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARKitSession] and a device that supports world tracking. The sample uses the `HeadPositionTracker` to initialize the ARKit session and the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/WorldTrackingProvider]:\n\nThe `HeadPositionTracker` contains the `originFromDeviceTransform()` method to get the devices’s transform in real time:\n\n### Display the sphere that follows the view\n\nDevice tracking is accessible within immersive spaces. The sample creates a custom view that uses a reality view to place a 3D sphere in front of the device’s forward direction at a set distance.\n\nThe view creates two entities: the `root` and the `floatingSphere`.\n\nThe view sets the `ClosureComponent` to the `root`, creates the `currentTransform` property to determine the headset’s current location, and calculates a smooth target position for the floating sphere in front of the device:\n\nThe `setPosition()` method moves the sphere to the new position over a set rate of time, applying a smoothing effect to the sphere.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionOS\/displaying-a-3D-object-that-moves-to-stay-in-a-person's-view\ncrawled: 2025-12-02T16:21:18Z\n---\n\n# Displaying an entity that follows a person’s view\n\n**Sample Code**\n\nCreate an entity that tracks and follows head movement in an immersive scene.\n\n## Overview\n\nThis sample uses world-tracking data from [doc:\/\/com.apple.documentation\/documentation\/ARKit] in visionOS to create and display a 3D entity that dynamically moves in front of a person’s view. As the following video shows, the floating sphere’s position updates based on the person’s head movement, to ensure the object stays visible and smoothly follows their view:\n\n\n\n### Extend the floats to enable calculations\n\nThe sample adds functionality to existing class types by extending `SIMD3<Float>`, `SIMD4<Float>`, and `simd_float4x4`:\n\n```swift\nimport Foundation\nimport simd\nimport RealityKit\n\n\/\/\/ The type alias to create a new name for `SIMD3<Float>`.\ntypealias Float3 = SIMD3<Float>\n\n\/\/\/ The type alias to create a new name for `SIMD4<Float>`.\ntypealias Float4 = SIMD4<Float>\n\n\/\/\/ The type alias to create a new name for `simd_float4x4`.\ntypealias Float4x4 = simd_float4x4\n```\n\nTo include these data types in the extension to their associated class, the sample associates each of the entry points using a `typealias`.\n\nThe `Float3` extension includes the following methods:\n\n- `init(_:)`, to create a `Float3` from a `Float4`\n- `length()`, to calculate the total length of the `Float3`\n- `normalized()`, to calculate the normalized vector of the `Float3`\n\n```swift\nimport Foundation\nimport simd\nimport RealityKit\n\ntypealias Float3 = SIMD3<Float>\n\n\/\/ ...\n\nextension Float3 {\n    \/\/\/ The initializer of a `Float3` from a `Float4`.\n    init(_ float4: Float4) {\n        self.init()\n        \n        x = float4.x\n        y = float4.y\n        z = float4.z\n    }\n    \n    \/\/ Calculate the total length by taking the square root of the product of the provided float.\n    func length() -> Float {\n        sqrt(x * x + y * y + z * z)\n    }\n    \n    \/\/ Calculate the normalized vector of the float.\n    func normalized() -> Float3 {\n        self * 1 \/ length()\n    }\n}\n```\n\nThe `Float4` extension contains the `toFloat3()` method that converts a `Float4` value to `Float3`:\n\n```swift\nimport Foundation\nimport simd\nimport RealityKit\n\ntypealias Float4 = SIMD4<Float>\n\n\/\/ ...\n\nextension Float4 {\n    \/\/ Ignore the W value to convert a `Float4` into a `Float3`.\n    func toFloat3() -> Float3 {\n        Float3(self)\n    }\n}\n```\n\nThe `Float4x4` extension includes the following methods:\n\n- `translation()`, to get the transform information in the form of a `Float3`\n- `forward()`, to get the forward-facing vector\n\n```swift\nimport Foundation\nimport simd\nimport RealityKit\n\ntypealias Float4x4 = simd_float4x4\n\n\/\/ ...\n\nextension Float4x4 {\n    \/\/ Identify the translation value from the `float4x4` and convert to a `Float3`.\n    func translation() -> Float3 {\n        columns.3.toFloat3()\n    }\n    \n    \/\/ Identify the forward-facing vector and return a `Float3`.\n    func forward() -> Float3 {\n        columns.2.toFloat3().normalized()\n    }\n}\n```\n\n### Update the entities over time\n\nThe sample sets up a custom system and component to handle updates in real time:\n\n```swift\nimport SwiftUI\nimport RealityKit\n\nstruct ClosureComponent: Component {\n    \/\/\/ The closure that takes the time interval since the last update.\n    let closure: (TimeInterval) -> Void\n\n    init (closure: @escaping (TimeInterval) -> Void) {\n        self.closure = closure\n        ClosureSystem.registerSystem()\n    }\n}\n```\n\nThe component contains the `closure` variable to track the time. On initialization, it registers `ClosureSystem` into the reality view.\n\nThe `ClosureSystem` constructs a query using the [doc:\/\/com.apple.documentation\/documentation\/RealityKit\/EntityQuery] to retrieve all entities with the `ClosureComponent` from the scene. Then it passes the delta time, which is the elapsed time since the last update, to the `closure` variable for each entity:\n\n```swift\nimport SwiftUI\nimport RealityKit\n\nstruct ClosureSystem: System {\n    \/\/\/ The query to check if the entity has the `ClosureComponent`.\n    static let query = EntityQuery(where: .has(ClosureComponent.self))\n    \n    init(scene: RealityKit.Scene) {}\n    \n    \/\/\/ Update entities with `ClosureComponent` at each render frame.\n    func update(context: SceneUpdateContext) {\n        for entity in context.entities(matching: Self.query, updatingSystemWhen: .rendering) {\n            guard let comp = entity.components[ClosureComponent.self] else { continue }\n            comp.closure(context.deltaTime)\n        }\n    }\n}\n```\n\n### Implement head tracking\n\nvisionOS supports [doc:\/\/com.apple.documentation\/documentation\/ARKit\/WorldTrackingProvider] from ARKit to get live data about a device’s position. World tracking requires an [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ARKitSession] and a device that supports world tracking. The sample uses the `HeadPositionTracker` to initialize the ARKit session and the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/WorldTrackingProvider]:\n\n```swift\nimport SwiftUI\nimport RealityKit\nimport ARKit\n\nclass HeadPositionTracker: ObservableObject {\n    \/\/\/ The instance of the `ARKitSession` for world tracking.\n    let arSession = ARKitSession()\n\n    \/\/\/ The instance of a new `WorldTrackingProvider` for world tracking.\n    let worldTracking = WorldTrackingProvider()\n\n    init() {\n        Task {\n            \/\/ Check whether the device supports world tracking.\n            guard WorldTrackingProvider.isSupported else {\n                print(\"WorldTrackingProvider is not supported on this device\")\n                return\n            }\n            do {\n                \/\/ Attempt to start an ARKit session with the world-tracking provider.\n                try await arSession.run([worldTracking])\n            } catch let error as ARKitSession.Error {\n                \/\/ Handle any potential ARKit session errors.\n                print(\"Encountered an error while running providers: \\(error.localizedDescription)\")\n            } catch let error {\n                \/\/ Handle any unexpected errors.    \n                print(\"Encountered an unexpected error: \\(error.localizedDescription)\")\n            }\n        }\n    }\n```\n\nThe `HeadPositionTracker` contains the `originFromDeviceTransform()` method to get the devices’s transform in real time:\n\n```swift\nfunc originFromDeviceTransform() -> simd_float4x4? {\n    \/\/\/ The anchor of the device at the current time.\n    guard let deviceAnchor = worldTracking.queryDeviceAnchor(atTimestamp: CACurrentMediaTime()) else {\n        return nil\n    }\n\n    \/\/ Return the device's transform.\n    return deviceAnchor.originFromAnchorTransform\n}\n```\n\n### Display the sphere that follows the view\n\nDevice tracking is accessible within immersive spaces. The sample creates a custom view that uses a reality view to place a 3D sphere in front of the device’s forward direction at a set distance.\n\n\n\n```swift\nimport SwiftUI\nimport RealityKit\n\nstruct HeadPositionView: View {\n    \/\/\/ The tracker that contains the logic to handle real-time transformations from the device.\n    @StateObject var headTracker = HeadPositionTracker()\n\n    var body: some View {\n        RealityView(make: { content in\n            \/\/\/ The entity representation of the world origin.\n            let root = Entity()\n\n            \/\/\/ The size of the floating sphere.\n            let radius: Float = 0.02\n\n            \/\/\/ The material for the floating sphere.\n            let material = SimpleMaterial(color: .cyan, isMetallic: false)\n\n            \/\/\/ The sphere mesh entity.\n            let floatingSphere = ModelEntity(\n                mesh: .generateSphere(radius: radius),\n                materials: [material]\n            )\n\n            \/\/ Add the floating sphere to the root.\n            root.addChild(floatingSphere)\n\n            \/\/ ...\n        }\n    }\n}\n```\n\nThe view creates two entities: the `root` and the `floatingSphere`.\n\nThe view sets the `ClosureComponent` to the `root`, creates the `currentTransform` property to determine the headset’s current location, and calculates a smooth target position for the floating sphere in front of the device:\n\n```swift\nvar body: some View {\n    RealityView(make: { content in\n        \/\/ ...\n    \n        \/\/\/ The distance that the content extends out from the device.\n        let distance: Float = 1.0\n\n        root.components.set(ClosureComponent(closure: { deltaTime in\n            \/\/\/ The current position of the device.\n            guard let currentTransform = headTracker.originFromDeviceTransform() else {\n                return\n            }\n\n            \/\/\/ The target position in front of the device.\n            let targetPosition = currentTransform.translation() - distance * currentTransform.forward()\n\n            \/\/\/ The interpolation ratio for smooth movement.\n            let ratio = Float(pow(0.96, deltaTime \/ (16 * 1E-3)))\n\n            \/\/\/ The new position of the floating sphere.\n            let newPosition = ratio * floatingSphere.position(relativeTo: nil) + (1 - ratio) * targetPosition\n\n            \/\/ Update the position of the floating sphere.\n            floatingSphere.setPosition(newPosition, relativeTo: nil)\n        }))\n\n        \/\/ Add the root entity to the `RealityView`.\n        content.add(root)\n    }, update: { _ in })\n}\n```\n\nThe `setPosition()` method moves the sphere to the new position over a set rate of time, applying a smoothing effect to the sphere.\n\n## Integrating ARKit\n\n- **Creating a 3D painting space**: Implement a painting canvas entity, and update its mesh to represent a stroke.\n- **Tracking and visualizing hand movement**: Use hand-tracking anchors to display a visual representation of hand transforms in visionOS.\n- **Applying mesh to real-world surroundings**: Add a layer of mesh to objects in the real world, using scene reconstruction in ARKit.\n- **Obscuring virtual items in a scene behind real-world items**: Increase the realism of an immersive experience by adding entities with invisible materials  real-world objects.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Implement a painting canvas entity, and update its mesh to represent a stroke.",
          "name" : "Creating a 3D painting space",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/creating-a-painting-space-in-visionos"
        },
        {
          "description" : "Use hand-tracking anchors to display a visual representation of hand transforms in visionOS.",
          "name" : "Tracking and visualizing hand movement",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/tracking-and-visualizing-hand-movement"
        },
        {
          "description" : "Add a layer of mesh to objects in the real world, using scene reconstruction in ARKit.",
          "name" : "Applying mesh to real-world surroundings",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/applying-mesh-to-real-world-surroundings"
        },
        {
          "description" : "Increase the realism of an immersive experience by adding entities with invisible materials  real-world objects.",
          "name" : "Obscuring virtual items in a scene behind real-world items",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/obscuring-virtual-items-in-a-scene-behind-real-world-items"
        }
      ],
      "title" : "Integrating ARKit"
    }
  ],
  "source" : "appleJSON",
  "title" : "Displaying an entity that follows a person’s view",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/displaying-a-3D-object-that-moves-to-stay-in-a-person's-view"
}