{
  "abstract" : "Place content based on the current position of a known image in a person’s surroundings.",
  "codeExamples" : [
    {
      "code" : "let session = ARKitSession()\nlet imageInfo = ImageTrackingProvider(\n    referenceImages: ReferenceImage.loadReferenceImages(inGroupNamed: \"playingcard-photos\")\n)\n\nif ImageTrackingProvider.isSupported {\n    Task {\n        try await session.run([imageInfo])\n        for await update in imageInfo.anchorUpdates {\n            updateImage(update.anchor)\n        }\n    }\n}\n\nfunc updateImage(_ anchor: ImageAnchor) {\n    if imageAnchors[anchor.id] == nil {\n        \/\/ Add a new entity to represent this image.\n        let entity = ModelEntity(mesh: .generateSphere(radius: 0.05))\n        entityMap[anchor.id] = entity\n        rootEntity.addChild(entity)\n    }\n    \n    if anchor.isTracked {\n        entityMap[anchor.id]?.transform = Transform(matrix: anchor.originFromAnchorTransform)\n    }\n}",
      "language" : "swift"
    }
  ],
  "contentHash" : "580de4872f899a5a3831696469d0007bb7b12c6091d25d76f2674b52e19a07e1",
  "crawledAt" : "2025-12-02T16:05:22Z",
  "id" : "91B78923-F923-4D51-93EC-FE1703259D9F",
  "kind" : "article",
  "language" : "swift",
  "overview" : "## Overview\n\nUse ARKit’s support for tracking 2D images to place 3D content in a space. ARKit provides updates to the image’s location as it moves relative to the person. If you supply one or more reference images in your app’s asset catalog, people can use a real-world copy of that image to place virtual 3D content in your app. For example, if you design a set of movie posters and provide those assets to people in the form of real-world environments, they can view the trailer for the movie in a fully immersive experience.\n\nThe following example tracks a set of images loaded from an app’s asset catalog:\n\nIf you know the real-world dimensions of the images you’re tracking, use the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ReferenceImage\/physicalSize] property to improve tracking accuracy. The [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ImageAnchor\/estimatedScaleFactor] property provides information about how the scale of the tracked image differs from the expected physical size you provide.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionos\/tracking-images-in-3d-space\ncrawled: 2025-12-02T16:05:22Z\n---\n\n# Tracking preregistered images in 3D space\n\n**Article**\n\nPlace content based on the current position of a known image in a person’s surroundings.\n\n## Overview\n\nUse ARKit’s support for tracking 2D images to place 3D content in a space. ARKit provides updates to the image’s location as it moves relative to the person. If you supply one or more reference images in your app’s asset catalog, people can use a real-world copy of that image to place virtual 3D content in your app. For example, if you design a set of movie posters and provide those assets to people in the form of real-world environments, they can view the trailer for the movie in a fully immersive experience.\n\nThe following example tracks a set of images loaded from an app’s asset catalog:\n\n```swift\nlet session = ARKitSession()\nlet imageInfo = ImageTrackingProvider(\n    referenceImages: ReferenceImage.loadReferenceImages(inGroupNamed: \"playingcard-photos\")\n)\n\nif ImageTrackingProvider.isSupported {\n    Task {\n        try await session.run([imageInfo])\n        for await update in imageInfo.anchorUpdates {\n            updateImage(update.anchor)\n        }\n    }\n}\n\nfunc updateImage(_ anchor: ImageAnchor) {\n    if imageAnchors[anchor.id] == nil {\n        \/\/ Add a new entity to represent this image.\n        let entity = ModelEntity(mesh: .generateSphere(radius: 0.05))\n        entityMap[anchor.id] = entity\n        rootEntity.addChild(entity)\n    }\n    \n    if anchor.isTracked {\n        entityMap[anchor.id]?.transform = Transform(matrix: anchor.originFromAnchorTransform)\n    }\n}\n```\n\nIf you know the real-world dimensions of the images you’re tracking, use the [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ReferenceImage\/physicalSize] property to improve tracking accuracy. The [doc:\/\/com.apple.documentation\/documentation\/ARKit\/ImageAnchor\/estimatedScaleFactor] property provides information about how the scale of the tracked image differs from the expected physical size you provide.\n\n## ARKit\n\n- **Happy Beam**: Leverage a Full Space to create a fun game using ARKit.\n- **Setting up access to ARKit data**: Check whether your app can use ARKit and respect people’s privacy.\n- **Incorporating real-world surroundings in an immersive experience**: Create an immersive experience by making your app’s content respond to the local shape of the world.\n- **Placing content on detected planes**: Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.\n- **Tracking specific points in world space**: Retrieve the position and orientation of anchors your app stores in ARKit.\n- **Exploring object tracking with ARKit**: Find and track real-world objects in visionOS using reference objects trained with Create ML.\n- **Object tracking with Reality Composer Pro experiences**: Use object tracking in visionOS to attach digital content to real objects to create engaging experiences.\n- **Building local experiences with room tracking**: Use room tracking in visionOS to provide custom interactions with physical spaces.\n- **Placing entities using head and device transform**: Query and react to changes in the position and rotation of Apple Vision Pro.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Leverage a Full Space to create a fun game using ARKit.",
          "name" : "Happy Beam",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/happybeam"
        },
        {
          "description" : "Check whether your app can use ARKit and respect people’s privacy.",
          "name" : "Setting up access to ARKit data",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/setting-up-access-to-arkit-data"
        },
        {
          "description" : "Create an immersive experience by making your app’s content respond to the local shape of the world.",
          "name" : "Incorporating real-world surroundings in an immersive experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/incorporating-real-world-surroundings-in-an-immersive-experience"
        },
        {
          "description" : "Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.",
          "name" : "Placing content on detected planes",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/placing-content-on-detected-planes"
        },
        {
          "description" : "Retrieve the position and orientation of anchors your app stores in ARKit.",
          "name" : "Tracking specific points in world space",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/tracking-points-in-world-space"
        },
        {
          "description" : "Find and track real-world objects in visionOS using reference objects trained with Create ML.",
          "name" : "Exploring object tracking with ARKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/exploring_object_tracking_with_arkit"
        },
        {
          "description" : "Use object tracking in visionOS to attach digital content to real objects to create engaging experiences.",
          "name" : "Object tracking with Reality Composer Pro experiences",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/object-tracking-with-reality-composer-pro-experiences"
        },
        {
          "description" : "Use room tracking in visionOS to provide custom interactions with physical spaces.",
          "name" : "Building local experiences with room tracking",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/building-local-experiences-with-room-tracking"
        },
        {
          "description" : "Query and react to changes in the position and rotation of Apple Vision Pro.",
          "name" : "Placing entities using head and device transform",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/placing-entities-using-head-and-device-transform"
        }
      ],
      "title" : "ARKit"
    }
  ],
  "source" : "appleJSON",
  "title" : "Tracking preregistered images in 3D space",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionos\/tracking-images-in-3d-space"
}