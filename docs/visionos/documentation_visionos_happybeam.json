{
  "abstract" : "Leverage a Full Space to create a fun game using ARKit.",
  "codeExamples" : [

  ],
  "contentHash" : "3d79396a49592bc5c800e58fd9159aafc2dc4eced6acd8e0f866d6e17273ca3f",
  "crawledAt" : "2025-12-02T16:02:55Z",
  "declaration" : {
    "code" : "struct HappyBeam: View {\n    @Environment(\\.openImmersiveSpace) private var openImmersiveSpace\n    @Environment(GameModel.self) var gameModel\n    \n    @State private var session: GroupSession<HeartProjection>? = nil\n    @State private var timer = Timer.publish(every: 1, on: .main, in: .common).autoconnect()\n    @State private var subscriptions = Set<AnyCancellable>()\n    \n    var body: some View {\n        let gameState = GameScreen.from(state: gameModel)\n        VStack {\n            Spacer()\n            Group {\n                switch gameState {\n                case .start:\n                    Start()\n                case .soloPlay:\n                    SoloPlay()\n                case .lobby:\n                    Lobby()\n                case .soloScore:\n                    SoloScore()\n                case .multiPlay:\n                    MultiPlay()\n                case .multiScore:\n                    MultiScore()\n                }\n            }\n            .glassBackgroundEffect(\n                in: RoundedRectangle(\n                    cornerRadius: 32,\n                    style: .continuous\n                )\n            )\n        }\n    }\n}",
    "language" : "swift"
  },
  "id" : "6B79A9D3-F155-45CF-8757-7401ABBAFB91",
  "kind" : "unknown",
  "overview" : "visionOS  Happy Beam  Happy Beam Sample CodeHappy BeamLeverage a Full Space to create a fun game using ARKit. Download visionOS 2.0+Xcode 16.0+OverviewIn visionOS, you can create fun, dynamic games and apps using several different frameworks to create new kinds of spatial experiences: RealityKit, ARKit, SwiftUI, and Group Activities. This sample introduces Happy Beam, a game where you and your friends can hop on a FaceTime call and play together.\n\nYou’ll learn the mechanics of the game where grumpy clouds float around in the space, and people play by making a heart shape with their hands to project a beam. People aim the beam at the clouds to cheer them up, and a score counter keeps track of how well each player does cheering up the clouds.\n\nDesign the game interface in SwiftUIMost apps in visionOS launch as a window that opens different scene types depending on the needs of the app.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionos\/happybeam\ncrawled: 2025-12-02T16:02:55Z\n---\n\n# Happy Beam | Apple Developer Documentation\n\n- [ visionOS ](\/documentation\/visionos)\n\n- [ Happy Beam ](\/documentation\/visionos\/happybeam)\n\n-  Happy Beam \n\nSample Code# Happy Beam\n\nLeverage a Full Space to create a fun game using ARKit.[ Download ](https:\/\/docs-assets.developer.apple.com\/published\/e0790b45f9f4\/HappyBeam.zip)visionOS 2.0+Xcode 16.0+## [Overview](\/documentation\/visionos\/happybeam#Overview)\n\nIn visionOS, you can create fun, dynamic games and apps using several different frameworks to create new kinds of spatial experiences: RealityKit, ARKit, SwiftUI, and Group Activities. This sample introduces Happy Beam, a game where you and your friends can hop on a FaceTime call and play together.\n\nYou’ll learn the mechanics of the game where grumpy clouds float around in the space, and people play by making a heart shape with their hands to project a beam. People aim the beam at the clouds to cheer them up, and a score counter keeps track of how well each player does cheering up the clouds.\n\n Video with custom controls.  Content description: A video that shows the Happy Beam app. Someone navigates the interface and plays the 3D game by making a heart gesture with their hands to project a beam that cheers up grumpy clouds that appear in the room. Upbeat music plays throughout and the clouds make a cheerful sound when they make contact with the beam. [ Play ](#)## [Design the game interface in SwiftUI](\/documentation\/visionos\/happybeam#Design-the-game-interface-in-SwiftUI)\n\nMost apps in visionOS launch as a window that opens different scene types depending on the needs of the app.\n\nHere you see how Happy Beam presents a fun interface to people by using several SwiftUI views that display a welcome screen, a coaching screen that gives instructions, a scoreboard, and a game-ending screen.\n\nThe following shows you the primary view in the app that displays each phase of gameplay:\n\n\n\n```\nstruct HappyBeam: View {\n    @Environment(.openImmersiveSpace) private var openImmersiveSpace\n    @Environment(GameModel.self) var gameModel\n    \n    @State private var session: GroupSession<HeartProjection>? = nil\n    @State private var timer = Timer.publish(every: 1, on: .main, in: .common).autoconnect()\n    @State private var subscriptions = Set<AnyCancellable>()\n    \n    var body: some View {\n        let gameState = GameScreen.from(state: gameModel)\n        VStack {\n            Spacer()\n            Group {\n                switch gameState {\n                case .start:\n                    Start()\n                case .soloPlay:\n                    SoloPlay()\n                case .lobby:\n                    Lobby()\n                case .soloScore:\n                    SoloScore()\n                case .multiPlay:\n                    MultiPlay()\n                case .multiScore:\n                    MultiScore()\n                }\n            }\n            .glassBackgroundEffect(\n                in: RoundedRectangle(\n                    cornerRadius: 32,\n                    style: .continuous\n                )\n            )\n        }\n    }\n}\n\n```\n\nWhen 3D content starts to appear, the game opens an immersive space to present content outside of the main window and in a person’s surroundings.\n\n\n\n```\n@main\nstruct HappyBeamApp: App {\n    @State private var gameModel = GameModel()\n    @State private var immersionState: ImmersionStyle = .mixed\n    \n    var body: some SwiftUI.Scene {\n        WindowGroup(\"HappyBeam\", id: \"happyBeamApp\") {\n            HappyBeam()\n                .environmentObject(gameModel)\n        }\n        .windowStyle(.plain)\n        \n        ImmersiveSpace(id: \"happyBeam\") {\n            HappyBeamSpace(gestureModel: HeartGestureModelContainer.heartGestureModel)\n                .environmentObject(gameModel)\n        }\n        .immersionStyle(selection: $immersionState, in: .mixed)\n    }\n}\n\n```\n\nThe `HappyBeam` container view declares a dependency on `openImmersiveSpace`:\n\n\n\n```\n@Environment(.openImmersiveSpace) private var openImmersiveSpace\n\n```\n\nIt later uses that dependency to open the space from the app’s declaration when it’s time to start showing 3D content:\n\n\n\n```\nif gameModel.countDown == 0 {\n    Task {\n        await openImmersiveSpace(id: \"happyBeam\")\n    }\n}\n\n```\n\n## [Detect a heart gesture with ARKit](\/documentation\/visionos\/happybeam#Detect-a-heart-gesture-with-ARKit)\n\nThe Happy Beam app recognizes the central *heart-shaped hands* gesture using ARKit’s support for 3D hand tracking in visionOS. Using hand tracking requires a running session and authorization from the wearer. It uses the `NSHandsTrackingUsageDescription` user info key to explain to players why the app requests permission for hand tracking.\n\n\n\n```\nTask {\n    do {\n        try await session.run([handTrackingProvider])\n    } catch {\n        print(\"ARKitSession error:\", error)\n    }\n}\n\n```\n\nHand-tracking data isn’t available when your app is only displaying a window or volume. Instead, it’s available when you present an immersive space, as in the previous example.\n\nYou can detect gestures using ARKit data with a level of accuracy that depends on your use case and intended experience. For example, Happy Beam could require strict positioning of finger joints to closely resemble a heart shape. Instead, however, it prompts people to make a heart shape and uses a heuristic to indicate when the gesture is close enough.\n\nThe following checks whether a person’s thumbs and index fingers are almost touching:\n\n\n\n```\n\/\/ Get the position of all joints in world coordinates.\nlet originFromLeftHandThumbKnuckleTransform = matrix_multiply(\n    leftHandAnchor.originFromAnchorTransform, leftHandThumbKnuckle.anchorFromJointTransform\n).columns.3.xyz\nlet originFromLeftHandThumbTipTransform = matrix_multiply(\n    leftHandAnchor.originFromAnchorTransform, leftHandThumbTipPosition.anchorFromJointTransform\n).columns.3.xyz\nlet originFromLeftHandIndexFingerTipTransform = matrix_multiply(\n    leftHandAnchor.originFromAnchorTransform, leftHandIndexFingerTip.anchorFromJointTransform\n).columns.3.xyz\nlet originFromRightHandThumbKnuckleTransform = matrix_multiply(\n    rightHandAnchor.originFromAnchorTransform, rightHandThumbKnuckle.anchorFromJointTransform\n).columns.3.xyz\nlet originFromRightHandThumbTipTransform = matrix_multiply(\n    rightHandAnchor.originFromAnchorTransform, rightHandThumbTipPosition.anchorFromJointTransform\n).columns.3.xyz\nlet originFromRightHandIndexFingerTipTransform = matrix_multiply(\n    rightHandAnchor.originFromAnchorTransform, rightHandIndexFingerTip.anchorFromJointTransform\n).columns.3.xyz\n\n\nlet indexFingersDistance = distance(originFromLeftHandIndexFingerTipTransform, originFromRightHandIndexFingerTipTransform)\nlet thumbsDistance = distance(originFromLeftHandThumbTipTransform, originFromRightHandThumbTipTransform)\n\n\n\/\/ Heart gesture detection is true when the distance between the index finger tips centers\n\/\/ and the distance between the thumb tip centers is each less than four centimeters.\nlet isHeartShapeGesture = indexFingersDistance < 0.04 && thumbsDistance < 0.04\nif !isHeartShapeGesture {\n    return nil\n}\n\n\n\/\/ Compute a position in the middle of the heart gesture.\nlet halfway = (originFromRightHandIndexFingerTipTransform - originFromLeftHandThumbTipTransform) \/ 2\nlet heartMidpoint = originFromRightHandIndexFingerTipTransform - halfway\n\n\n\/\/ Compute the vector from left thumb knuckle to right thumb knuckle and normalize (X axis).\nlet xAxis = normalize(originFromRightHandThumbKnuckleTransform - originFromLeftHandThumbKnuckleTransform)\n\n\n\/\/ Compute the vector from right thumb tip to right index finger tip and normalize (Y axis).\nlet yAxis = normalize(originFromRightHandIndexFingerTipTransform - originFromRightHandThumbTipTransform)\n\n\nlet zAxis = normalize(cross(xAxis, yAxis))\n\n\n\/\/ Create the final transform for the heart gesture from the three axes and midpoint vector.\nlet heartMidpointWorldTransform = simd_matrix(\n    SIMD4(xAxis.x, xAxis.y, xAxis.z, 0),\n    SIMD4(yAxis.x, yAxis.y, yAxis.z, 0),\n    SIMD4(zAxis.x, zAxis.y, zAxis.z, 0),\n    SIMD4(heartMidpoint.x, heartMidpoint.y, heartMidpoint.z, 1)\n)\nreturn heartMidpointWorldTransform\n\n```\n\n## [Support several kinds of input](\/documentation\/visionos\/happybeam#Support-several-kinds-of-input)\n\nTo support accessibility features and general user preferences, include multiple kinds of input in an app that uses hand tracking as one form of input.\n\nHappy Beam supports several kinds of input:\n\nInteractive hands input from ARKit with the custom heart gesture.\n\nDrag gesture input to rotate the stationary beam on its platform.\n\nAccessibility components from RealityKit to support custom actions for cheering up the clouds.\n\nGame Controller support to make control over the beam more interactive from Switch Control.\n\n## [Display 3D content with RealityKit](\/documentation\/visionos\/happybeam#Display-3D-content-with-RealityKit)\n\nThe 3D content in the app comes in the form of assets that you can export from Reality Composer Pro. You place each asset in the `RealityView` that represents your immersive space.\n\nThe following shows how Happy Beam generates clouds when the game starts, as well as materials for the floor-based beam projector. Because the game uses collision detection to keep score — the beam cheers up grumpy clouds when they collide — you make collision shapes for each model that might be involved.\n\n\n\n```\n@MainActor\nfunc placeCloud(start: Point3D, end: Point3D, speed: Double) async throws -> Entity {\n    let cloud = await loadFromRealityComposerPro(\n        named: BundleAssets.cloudEntity,\n        fromSceneNamed: BundleAssets.cloudScene\n    )!\n        .clone(recursive: true)\n    \n    cloud.generateCollisionShapes(recursive: true)\n    cloud.components[PhysicsBodyComponent.self] = PhysicsBodyComponent()\n    \n    var accessibilityComponent = AccessibilityComponent()\n    accessibilityComponent.label = \"Cloud\"\n    accessibilityComponent.value = \"Grumpy\"\n    accessibilityComponent.isAccessibilityElement = true\n    accessibilityComponent.traits = [.button, .playsSound]\n    accessibilityComponent.systemActions = [.activate]\n    cloud.components[AccessibilityComponent.self] = accessibilityComponent\n    \n    let animation = cloudMovementAnimations[cloudPathsIndex]\n    \n    cloud.playAnimation(animation, transitionDuration: 1.0, startsPaused: false)\n    cloudAnimate(cloud, kind: .sadBlink, shouldRepeat: false)\n    spaceOrigin.addChild(cloud)\n    \n    return cloud\n}\n\n```\n\n## [Add SharePlay support for multiplayer gaming experiences](\/documentation\/visionos\/happybeam#Add-SharePlay-support-for-multiplayer-gaming-experiences)\n\nYou use the Group Activities framework in visionOS to support SharePlay during a FaceTime call. Happy Beam uses Group Activities to sync the score, active players list, and the position of each player’s projected beam.\n\nNote\n\nDevelopers using the [Apple Vision Pro developer kit](https:\/\/developer.apple.com\/visionos\/work-with-apple\/) can test spatial SharePlay experiences on-device by installing the [Persona Preview Profile](https:\/\/developer.apple.com\/download\/all\/?q=persona).\n\nUse a reliable channel to send information that’s important to be correct, even if it can be slightly delayed as a result. The following shows how Happy Beam updates the game model’s score state in response to a score message:\n\n\n\n```\nsessionInfo.reliableMessenger = GroupSessionMessenger(session: newSession, deliveryMode: .reliable)\n\n\nTask {\n    for await (message, sender) in sessionInfo!.reliableMessenger!.messages(of: ScoreMessage.self) {\n        gameModel.clouds[message.cloudID].isHappy = true\n        gameModel\n            .players\n            .filter { ___CODEBLOCK_2___.name == sender.source.id.asPlayerName }\n            .first!\n            .score += 1\n    }\n}\n\n```\n\nUse an unreliable messenger for sending data with low-latency requirements. Because the delivery mode is unreliable, some messages might not make it. Happy Beam uses the unreliable mode to send live updates to the position of the beam when each participant in the call chooses the Spatial option in FaceTime.\n\n\n\n```\nsessionInfo.messenger = GroupSessionMessenger(session: newSession, deliveryMode: .unreliable)\n\n```\n\nThe following shows how Happy Beam serializes beam data for each message:\n\n\n\n```\n\/\/ Send each player's beam data during FaceTime calls where players have selected the Spatial option.\nfunc sendBeamPositionUpdate(_ pose: Pose3D) {\n    if let sessionInfo = sessionInfo, let session = sessionInfo.session, let messenger = sessionInfo.messenger {\n        let everyoneElse = session.activeParticipants.subtracting([session.localParticipant])\n        \n        if isShowingBeam, gameModel.isSpatial {\n            messenger.send(BeamMessage(pose: pose), to: .only(everyoneElse)) { error in\n                if let error = error { print(\"Message failure:\", error) }\n            }\n        }\n    }\n}\n\n```\n\n## [See Also](\/documentation\/visionos\/happybeam#See-Also)\n\n#### [Related samples](\/documentation\/visionos\/happybeam#Related-samples)\n\n[Incorporating real-world surroundings in an immersive experience](\/documentation\/visionos\/incorporating-real-world-surroundings-in-an-immersive-experience)Create an immersive experience by making your app’s content respond to the local shape of the world.[Hello World](\/documentation\/visionos\/world)Use windows, volumes, and immersive spaces to teach people about the Earth.[Destination Video](\/documentation\/visionos\/destination-video)Leverage SwiftUI to build an immersive media experience in a multiplatform app.[Diorama](\/documentation\/visionos\/diorama)Design scenes for your visionOS app using Reality Composer Pro.#### [Related articles](\/documentation\/visionos\/happybeam#Related-articles)\n\n[Setting up access to ARKit data](\/documentation\/visionos\/setting-up-access-to-arkit-data)Check whether your app can use ARKit and respect people’s privacy.[Placing content on detected planes](\/documentation\/visionos\/placing-content-on-detected-planes)Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.[Tracking specific points in world space](\/documentation\/visionos\/tracking-points-in-world-space)Retrieve the position and orientation of anchors your app stores in ARKit.[Tracking preregistered images in 3D space](\/documentation\/visionos\/tracking-images-in-3d-space)Place content based on the current position of a known image in a person’s surroundings.#### [Related videos](\/documentation\/visionos\/happybeam#Related-videos)\n\n[ Meet ARKit for spatial computing ](https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10082)[ Build great games for spatial computing ](https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10096)[ Create accessible spatial experiences ](https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10034)[ Build spatial SharePlay experiences ](https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10087)",
  "sections" : [
    {
      "content" : "",
      "title" : "Overview"
    },
    {
      "content" : "",
      "title" : "Design the game interface in SwiftUI"
    },
    {
      "content" : "",
      "title" : "Detect a heart gesture with ARKit"
    },
    {
      "content" : "",
      "title" : "Support several kinds of input"
    },
    {
      "content" : "",
      "title" : "Display 3D content with RealityKit"
    },
    {
      "content" : "",
      "title" : "Add SharePlay support for multiplayer gaming experiences"
    },
    {
      "content" : "",
      "title" : "See Also"
    }
  ],
  "source" : "appleWebKit",
  "title" : "Happy Beam | Apple Developer Documentation",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionos\/happybeam"
}