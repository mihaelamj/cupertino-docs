{
  "abstract" : "Create screenshots and record high-quality video of your visionOS app and its surroundings for app previews.",
  "codeExamples" : [

  ],
  "contentHash" : "b7681322f1de4d9cce03ee9753d1a197b6d50553b209dfa43b446404d06a2894",
  "crawledAt" : "2025-12-02T17:51:57Z",
  "id" : "72394FDB-5259-4E7A-B2A2-DA92D68007BB",
  "kind" : "article",
  "language" : "swift",
  "overview" : "## Overview\n\nUse screenshots and short videos of your visionOS app to showcase your user interface, highlight functionality, and demonstrate usage. Help people understand what to expect from an immersive experience by recording content from Apple Vision Pro that includes your app and its surroundings.\n\nThe system renders content with spatial effects and optimizations for viewing during immersive experiences. One optimization, *foveated rendering*, displays higher resolution where an enrolled person is looking, while reducing image resolution in their periphery. The system only applies foveated rendering for enrolled users who calibrate the device for their eyes and hands. Techniques that improve rendering performance during normal operation are intended to be unnoticeable for enrolled people wearing Apple Vision Pro; however, they don’t translate well to 2D displays.\n\nTo produce high-resolution content for people to view on 2D displays, the system needs to render without these effects and drop some optimizations. Use Developer Capture in Reality Composer Pro to notify the system to reconfigure rendering, and capture screenshots or high-resolution video, including sound, from Apple Vision Pro. Because capturing high-resolution video from device is resource intensive, Reality Composer Pro limits the duration of device video capture.\n\n### Pair your Apple Vision Pro to Xcode\n\nBefore capturing screenshots and video from your device, pair it with a Mac that has Xcode and the visionOS SDK installed. For instructions on pairing your device, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/running-your-app-in-simulator-or-on-a-device].\n\n### Prepare to capture your app and its surroundings\n\nSelect a well-lit location that’s free from clutter. Avoid including objects that might distract the audience or get in the way of your app‘s windows and 3D content. Include enough detail in the scene to provide context and anchoring points. Avoid material that you don’t have permission to capture, including people, screens, branded products, logos, artwork, and other intellectual property.\n\nUse the version of your app that you intend to share with your audience. Build and install your app using a release configuration. This configuration enables code optimizations for better runtime performance and disables the generation of debugging information. Debug configurations typically disable code optimizations and might include UI you donʼt intend to share. Don’t use them to record video for previews you intend to share. Build schemes manage the build configuration Xcode uses during build actions, for more information see [https:\/\/developer.apple.com\/documentation\/xcode\/customizing-the-build-schemes-for-a-project].\n\nPlan the tasks you intend to capture ahead of time and keep them short and focused. Launch your app and go to the state where you plan to begin the capture. Reduce unnecessary processing overhead on Apple Vision Pro by quitting other apps and avoiding background tasks.\n\nTo capture screenshots or video from a device, select your device from the capture dialog in Reality Composer Pro:\n\n\n\nIf you see the message “Preparing, wait for the device to be ready”. You can click the info button that appears to the right of the pop-up menu for more information.\n\n### Capture screenshots\n\nTo begin capturing screenshots from Apple Vision Pro, click the button with the still camera icon in the capture dialog. The system begins your capture session:\n\n\n\nTo capture a screenshot immediately, without a countdown, press the spacebar. Click the countdown button to capture a screenshot after a 3 second countdown. Continue to keep relevant content centered and in frame for screenshots. The aspect ratio of screenshots crops content that appears at the sides of an experience.\n\nThe status area of the capture dialog displays the time remaining before the system ends the capture session. Click the stop button from your Mac to end the capture session yourself.\n\n### Capture video\n\nTo begin capturing video from the device, click the video camera button in the Developer Capture dialog, which begins a short countdown. When that countdown reaches `0`, the capture session begins, replacing the countdown with a capture session timer. As the capture process happens, the video changes because the system reconfigures to render content for viewing in 2D. You might notice reduced responsiveness from the device during the session as it devotes more processing to render and capture the video.\n\nWhile recording on the device, perform your planned interactions. Keep relevant content centered and in frame. The aspect ratio of the video you capture crops content that appears at the sides of an experience. Keep your head stable, and use slow, steady movement to transition the focus of the device when necessary. When viewing the video you capture in 2D, small head movements appear amplified and might be jarring to the audience.\n\nThe capture session ends when the capture session timer reaches `0`. You can click the record button again from your Mac to end the session sooner.\n\n### Review the captured video file\n\nEach recording session creates a QuickTime Movie file (`.mov`) and saves it to the desktop of your Mac. The file includes video captured at 30 FPS using 10-bit HEVC in HDTV Rec. 709 color space with system audio recorded in 32-bit floating-point linear PCM.\n\nReview the video to make sure that it includes all the content you planned and it doesn’t include any unexpected elements. Ensure that the transitions and animations are smooth and frame rates are consistent.\n\nUse additional video-editing tools to trim, edit, and apply post-processing, such as stabilization, to the video to create a high-quality preview.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionos\/capturing-screenshots-and-video-from-your-apple-vision-pro-for-2d-viewing\ncrawled: 2025-12-02T17:51:57Z\n---\n\n# Capturing screenshots and video from Apple Vision Pro for 2D viewing\n\n**Article**\n\nCreate screenshots and record high-quality video of your visionOS app and its surroundings for app previews.\n\n## Overview\n\nUse screenshots and short videos of your visionOS app to showcase your user interface, highlight functionality, and demonstrate usage. Help people understand what to expect from an immersive experience by recording content from Apple Vision Pro that includes your app and its surroundings.\n\nThe system renders content with spatial effects and optimizations for viewing during immersive experiences. One optimization, *foveated rendering*, displays higher resolution where an enrolled person is looking, while reducing image resolution in their periphery. The system only applies foveated rendering for enrolled users who calibrate the device for their eyes and hands. Techniques that improve rendering performance during normal operation are intended to be unnoticeable for enrolled people wearing Apple Vision Pro; however, they don’t translate well to 2D displays.\n\nTo produce high-resolution content for people to view on 2D displays, the system needs to render without these effects and drop some optimizations. Use Developer Capture in Reality Composer Pro to notify the system to reconfigure rendering, and capture screenshots or high-resolution video, including sound, from Apple Vision Pro. Because capturing high-resolution video from device is resource intensive, Reality Composer Pro limits the duration of device video capture.\n\n\n\n### Pair your Apple Vision Pro to Xcode\n\nBefore capturing screenshots and video from your device, pair it with a Mac that has Xcode and the visionOS SDK installed. For instructions on pairing your device, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/running-your-app-in-simulator-or-on-a-device].\n\n### Prepare to capture your app and its surroundings\n\nSelect a well-lit location that’s free from clutter. Avoid including objects that might distract the audience or get in the way of your app‘s windows and 3D content. Include enough detail in the scene to provide context and anchoring points. Avoid material that you don’t have permission to capture, including people, screens, branded products, logos, artwork, and other intellectual property.\n\nUse the version of your app that you intend to share with your audience. Build and install your app using a release configuration. This configuration enables code optimizations for better runtime performance and disables the generation of debugging information. Debug configurations typically disable code optimizations and might include UI you donʼt intend to share. Don’t use them to record video for previews you intend to share. Build schemes manage the build configuration Xcode uses during build actions, for more information see [https:\/\/developer.apple.com\/documentation\/xcode\/customizing-the-build-schemes-for-a-project].\n\nPlan the tasks you intend to capture ahead of time and keep them short and focused. Launch your app and go to the state where you plan to begin the capture. Reduce unnecessary processing overhead on Apple Vision Pro by quitting other apps and avoiding background tasks.\n\nTo capture screenshots or video from a device, select your device from the capture dialog in Reality Composer Pro:\n\n1. Launch Reality Composer Pro. Choose Open Developer Tool > Reality Composer Pro from the Xcode menu.\n2. Choose File > Developer Capture to bring up the Developer Capture dialog.\n3. Select the device to capture from the pop-up menu.\n\n\n\nIf you see the message “Preparing, wait for the device to be ready”. You can click the info button that appears to the right of the pop-up menu for more information.\n\n### Capture screenshots\n\nTo begin capturing screenshots from Apple Vision Pro, click the button with the still camera icon in the capture dialog. The system begins your capture session:\n\n\n\nTo capture a screenshot immediately, without a countdown, press the spacebar. Click the countdown button to capture a screenshot after a 3 second countdown. Continue to keep relevant content centered and in frame for screenshots. The aspect ratio of screenshots crops content that appears at the sides of an experience.\n\nThe status area of the capture dialog displays the time remaining before the system ends the capture session. Click the stop button from your Mac to end the capture session yourself.\n\n### Capture video\n\nTo begin capturing video from the device, click the video camera button in the Developer Capture dialog, which begins a short countdown. When that countdown reaches `0`, the capture session begins, replacing the countdown with a capture session timer. As the capture process happens, the video changes because the system reconfigures to render content for viewing in 2D. You might notice reduced responsiveness from the device during the session as it devotes more processing to render and capture the video.\n\nWhile recording on the device, perform your planned interactions. Keep relevant content centered and in frame. The aspect ratio of the video you capture crops content that appears at the sides of an experience. Keep your head stable, and use slow, steady movement to transition the focus of the device when necessary. When viewing the video you capture in 2D, small head movements appear amplified and might be jarring to the audience.\n\nThe capture session ends when the capture session timer reaches `0`. You can click the record button again from your Mac to end the session sooner.\n\n\n\n### Review the captured video file\n\nEach recording session creates a QuickTime Movie file (`.mov`) and saves it to the desktop of your Mac. The file includes video captured at 30 FPS using 10-bit HEVC in HDTV Rec. 709 color space with system audio recorded in 32-bit floating-point linear PCM.\n\nReview the video to make sure that it includes all the content you planned and it doesn’t include any unexpected elements. Ensure that the transitions and animations are smooth and frame rates are consistent.\n\nUse additional video-editing tools to trim, edit, and apply post-processing, such as stabilization, to the video to create a high-quality preview.\n\n## RealityKit and Reality Composer Pro\n\n- **Reality Composer Pro**: Build, create, and design 3D content for your RealityKit apps.\n- **Petite Asteroids: Building a volumetric visionOS game**: Use the latest RealityKit APIs to create a beautiful video game for visionOS.\n- **BOT-anist**: Build a multiplatform app that uses windows, volumes, and animations to create a robot botanist’s greenhouse.\n- **Swift Splash**: Use RealityKit to create an interactive ride in visionOS.\n- **Diorama**: Design scenes for your visionOS app using Reality Composer Pro.\n- **Building an immersive media viewing experience**: Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.\n- **Enabling video reflections in an immersive environment**: Create a more immersive experience by adding video reflections in a custom environment.\n- **Combining 2D and 3D views in an immersive app**: Use attachments to place 2D content relative to 3D content in your visionOS app.\n- **Understanding the modular architecture of RealityKit**: Learn how everything fits together in RealityKit.\n- **Using transforms to move, scale, and rotate entities**: Learn how to use Transforms to move, scale, and rotate entities in RealityKit.\n- **Implementing object tracking in your visionOS app**: Create engaging interactions by training models to recognize and track real-world objects in your app.\n- **Placing entities using head and device transform**: Query and react to changes in the position and rotation of Apple Vision Pro.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Build, create, and design 3D content for your RealityKit apps.",
          "name" : "Reality Composer Pro",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityComposerPro"
        },
        {
          "description" : "Use the latest RealityKit APIs to create a beautiful video game for visionOS.",
          "name" : "Petite Asteroids: Building a volumetric visionOS game",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/petite-asteroids-building-a-volumetric-visionos-game"
        },
        {
          "description" : "Build a multiplatform app that uses windows, volumes, and animations to create a robot botanist’s greenhouse.",
          "name" : "BOT-anist",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/BOT-anist"
        },
        {
          "description" : "Use RealityKit to create an interactive ride in visionOS.",
          "name" : "Swift Splash",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/swift-splash"
        },
        {
          "description" : "Design scenes for your visionOS app using Reality Composer Pro.",
          "name" : "Diorama",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/diorama"
        },
        {
          "description" : "Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.",
          "name" : "Building an immersive media viewing experience",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/building-an-immersive-media-viewing-experience"
        },
        {
          "description" : "Create a more immersive experience by adding video reflections in a custom environment.",
          "name" : "Enabling video reflections in an immersive environment",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/enabling-video-reflections-in-an-immersive-environment"
        },
        {
          "description" : "Use attachments to place 2D content relative to 3D content in your visionOS app.",
          "name" : "Combining 2D and 3D views in an immersive app",
          "url" : "https:\/\/developer.apple.com\/documentation\/RealityKit\/combining-2d-and-3d-views-in-an-immersive-app"
        },
        {
          "description" : "Learn how everything fits together in RealityKit.",
          "name" : "Understanding the modular architecture of RealityKit",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/understanding-the-realitykit-modular-architecture"
        },
        {
          "description" : "Learn how to use Transforms to move, scale, and rotate entities in RealityKit.",
          "name" : "Using transforms to move, scale, and rotate entities",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/understanding-transforms"
        },
        {
          "description" : "Create engaging interactions by training models to recognize and track real-world objects in your app.",
          "name" : "Implementing object tracking in your visionOS app",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/implementing-object-tracking-in-your-visionOS-app"
        },
        {
          "description" : "Query and react to changes in the position and rotation of Apple Vision Pro.",
          "name" : "Placing entities using head and device transform",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/placing-entities-using-head-and-device-transform"
        }
      ],
      "title" : "RealityKit and Reality Composer Pro"
    }
  ],
  "source" : "appleJSON",
  "title" : "Capturing screenshots and video from Apple Vision Pro for 2D viewing",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionos\/capturing-screenshots-and-video-from-your-apple-vision-pro-for-2d-viewing"
}