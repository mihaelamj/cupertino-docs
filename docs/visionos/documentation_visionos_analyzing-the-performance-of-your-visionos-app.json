{
  "abstract" : "Use the RealityKit Trace template in Instruments to evaluate and improve the performance of your visionOS app.",
  "codeExamples" : [

  ],
  "contentHash" : "0f846698cd07091c461a48053052cf6605b09c0a9321951366419e38e7b2da10",
  "crawledAt" : "2025-12-02T17:33:19Z",
  "id" : "4345A7EA-D4C1-40BE-A039-D1E20197E7E4",
  "kind" : "article",
  "language" : "swift",
  "overview" : "## Overview\n\nTo maintain the sense of immersion on Apple Vision Pro, the system attempts to provide the device displays with up-to-date imagery at a constant rate and respond to interactions with minimum latency. Any visual choppiness or delay in responsiveness interferes with the spatial experience. Higher power consumption over extended periods of time, or extreme power consumption over shorter periods of time, can trigger thermal mitigations that also impact the quality of the experience. It’s important to minimize your app’s use of system resources to ensure your app performs well on the platform. Many of the same best practices and optimization procedures you use developing for other Apple platforms apply when developing for visionOS as well. For more information about optimizing your app on other platforms, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/improving-your-app-s-performance].\n\nTo get useful information specific to rendering bottlenecks, high system power use, and other issues that effect the responsiveness of your visionOS app, profile your app with the RealityKit Trace template in Instruments. This template helps you identify:\n\n### Open a new trace document\n\nTo create a new trace document:\n\n\n\nAlternatively, launch Instruments and choose a target app from the template selection dialog.\n\nThe RealityKit Trace template includes the following instruments:\n\nConsider adding other instruments to your trace for specific investigations. For example, you can use the Thermal State instrument to record device thermal states to check if thermal pressures are throttling performance.\n\n### Profile your workflows\n\nClick the record button at the top left of the window to start capturing profile data. Perform the actions in your app that you want to investigate. When you complete the actions, click the record button again to stop recording.\n\nTo investigate performance issues or analyze system power impact, profile your app in isolation to understand your app’s impact on system performance and ensure you get the most actionable information. For apps that run alongside other apps, profile your app again with those other apps running to understand how people experience your app in conjunction with other apps.\n\n### Inspect frame rendering performance\n\nTo maintain a smooth visual experience, the system tries to render new frames for the Apple Vision Pro at 90 frames per second (FPS). The system renders at other frame rates depending on the content it displays and the current surroundings. Each frame has a deadline for rendering based on the target frame rate. Not meeting these deadlines results in dropped frames. This creates a poor spatial experience overall. People tend to notice it in the visual performance of Persona and SharePlay experiences, video playback, and scrolling. The RealityKit Frames instrument displays the time spent rendering each frame in the Frames section of its timeline:\n\n\n\nWhen you zoom out, you can identify areas with a high number of frame drops or with frames running close to the rendering deadline. The timeline uses green to identify frames that complete rendering before the deadline, orange for frames that complete rendering close to the deadline, and red for frames that don’t complete rendering that the renderer drops. Dropped frames contribute to a poor spatial experience, but frames that complete close to their rendering deadline indicate performance problems too. Hold the Option key and drag to zoom into a frame, or group of frames, to see their lifespan broken down in stages:\n\n\n\nThis provides you with insight into which portion of the rendering pipeline to investigate further. This timeline also includes sections that visualize the Average CPU Frame Time and Average GPU Frame Time to indicate the type of processing that computes the frames. A region of the timeline without a frame block indicates a period of time without changes to a person’s surroundings or app updates. The render server avoids computing new frames to send to the compositor during these periods which helps optimize power use.\n\n### Monitor system power usage\n\nWhen thermal levels rise to levels that trigger thermal mitigations in the system, performance degrades and negatively impacts the responsiveness of your app. Optimize for power to avoid this negative impact. The timeline for the RealityKit Metrics instrument includes a System Power Impact section to identify areas of high power usage in your app:\n\n\n\nIf the timeline displays green, the tool considers your app’s impact on system power low enough to sustain. Regions that display orange or red indicate the system power usage could cause thermal levels to rise and trigger thermal mitigations. This decreases the availability of system resources, which can cause visual interruptions and responsiveness issues.\n\n### Identify bottlenecks\n\nThe Bottlenecks section of the timeline for the RealityKit Metrics instrument contains markers that indicate high overhead in your app or the render server that contribute to dropped frames and high system power use. When you encounter either of these issues, check if the timeline identifies bottlenecks you can address. Double-click on any of the markers to display more information in the detail area at the bottom of the instruments window. If the detail area is hidden, choose View > Detail Area > Show Detail Area to reveal it. The render server encounters bottlenecks in either the CPU or GPU. The instrument categorizes bottlenecks by their severity and type.\n\nTo filter the bottlenecks listed in the detail area to a particular time period, drag inside the timeline to select the region. To see an outline view of the bottlenecks organized by severity and type, select Summary: RealityKit Bottlenecks from the menu at the top left of the detail area. Click the arrow button to the right of the severity or type in the outline view to show the list of bottlenecks in that category.\n\nWhen you select a specific bottleneck, the extended detail provides recommendations for you to address the bottleneck – choose View > Show Extended Detail to reveal the extended detail if it’s hidden.\n\n\n\n### Explore the metrics that relate to bottlenecks\n\nThe trace provides additional information you can use to identify changes to make in your app to address these bottlenecks. Click the expansion arrow for the RealityKit Metrics instrument timeline to reveal graphs specific to each major category of work. Use the metrics associated with these graphs to determine which RealityKit feature has the biggest impact on high CPU frame times in the app process or in the render server. When interpreting these graphs, lower indicates better performance and power. The metrics represent values from all apps running, so profile with just your app running when trying to optimize for these metrics.\n\n\n\nThe timeline for your app’s process helps summarize information from the instruments about your process and the work the render server completes for your process.\n\n\n\nChoose an option from the pop-up in the timeline header to show different graphs in the timeline:\n\nWhen you select the timeline for your app’s process, you can choose instrument summaries and profile data to display in the detail area from the popup-button at its top-left:\n\n\n\nTo filter the information in the detail area by time, select periods of time in the timeline  above.\n\n### Detect delays on the main thread\n\nSelect Hangs in your app’s process timeline to identify times in the trace that might have interaction delays. Use the RealityKit Metrics and Time Profiler summaries to better understand the work your app is doing. Choose the following options from the detail area pop-up menu:\n\nOptimize any 3D render updates, hit testing, and collision work you find. For more information about addressing hangs in your app, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/improving-app-responsiveness].\n\n### Manage audio overhead\n\nUse the Audio Playback section of your process’s timeline to identify areas of high audio overhead. The system defaults to using spatial audio for your app when running on visionOS. It processes information in real time about your position, surroundings, and the current location of audio sources to generate an immersive audio experience. If you include too many concurrent audio sources that require the system to adapt audio sources to their location within a large space, the increased demand on system resources can lead to delays in the audio output.\n\nTo reduce the spatial audio work, limit:\n\nConsider creating a pool of audio players to limit the maximum number of players your app uses. Place players on stationary entities, instead of moving entities, when appropriate. Initializing several audio players at the same time causes a high overhead that affects other aspects of the system, such as rendering performance. Consider the other tasks the system completes during these allocations and space them out over time. For more information, see [https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10070].\n\n### Profile custom materials for optimization\n\nUse the Metal System Trace template to profile your custom materials in isolation before adding more visual effects to them. Examine the Metal GPU cost and try to optimize for GPU ALU Instructions and GPU Texture reads and writes per frame. For more information on using this template, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/Analyzing-the-performance-of-your-Metal-app].\n\nIn order to use the Metal Application instrument to profile your custom materials accurately, set a fixed performance state:\n\n\n\nA person’s eye position, the distance from the person to the content, and the amount of content the app displays all impact the amount of GPU work done for custom materials from Reality Composer Pro. To compare traces, keep these factors as consistent as possible. For a custom material you use in a Fully Immersive Space, try to remove all other content from the scene while profiling to isolate the overhead of the material. For custom materials you use for other types of content, consider anchoring them to a person’s head in a test scene so the distance from the person remains fixed.",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/visionos\/analyzing-the-performance-of-your-visionos-app\ncrawled: 2025-12-02T17:33:19Z\n---\n\n# Analyzing the performance of your visionOS app\n\n**Article**\n\nUse the RealityKit Trace template in Instruments to evaluate and improve the performance of your visionOS app.\n\n## Overview\n\nTo maintain the sense of immersion on Apple Vision Pro, the system attempts to provide the device displays with up-to-date imagery at a constant rate and respond to interactions with minimum latency. Any visual choppiness or delay in responsiveness interferes with the spatial experience. Higher power consumption over extended periods of time, or extreme power consumption over shorter periods of time, can trigger thermal mitigations that also impact the quality of the experience. It’s important to minimize your app’s use of system resources to ensure your app performs well on the platform. Many of the same best practices and optimization procedures you use developing for other Apple platforms apply when developing for visionOS as well. For more information about optimizing your app on other platforms, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/improving-your-app-s-performance].\n\nTo get useful information specific to rendering bottlenecks, high system power use, and other issues that effect the responsiveness of your visionOS app, profile your app with the RealityKit Trace template in Instruments. This template helps you identify:\n\n- Complex content or content with frequent updates that cause the render server to miss deadlines and drop frames.\n- Content and tasks that result in high system power use.\n- Long running tasks on the the main thread that interfere with efficient processing of input events.\n- Tasks running on other threads that don’t complete in time to sync back to the main thread for view hierarchy updates.\n\n\n\n### Open a new trace document\n\nTo create a new trace document:\n\n1. Select your app’s scheme and a visionOS run destination from the Xcode project window.\n2. Choose Product > Profile.\n3. Choose RealityKit Trace template\n4. Select the Choose button.\n\n\n\nAlternatively, launch Instruments and choose a target app from the template selection dialog.\n\nThe RealityKit Trace template includes the following instruments:\n\n\n\nConsider adding other instruments to your trace for specific investigations. For example, you can use the Thermal State instrument to record device thermal states to check if thermal pressures are throttling performance.\n\n### Profile your workflows\n\nClick the record button at the top left of the window to start capturing profile data. Perform the actions in your app that you want to investigate. When you complete the actions, click the record button again to stop recording.\n\nTo investigate performance issues or analyze system power impact, profile your app in isolation to understand your app’s impact on system performance and ensure you get the most actionable information. For apps that run alongside other apps, profile your app again with those other apps running to understand how people experience your app in conjunction with other apps.\n\n### Inspect frame rendering performance\n\nTo maintain a smooth visual experience, the system tries to render new frames for the Apple Vision Pro at 90 frames per second (FPS). The system renders at other frame rates depending on the content it displays and the current surroundings. Each frame has a deadline for rendering based on the target frame rate. Not meeting these deadlines results in dropped frames. This creates a poor spatial experience overall. People tend to notice it in the visual performance of Persona and SharePlay experiences, video playback, and scrolling. The RealityKit Frames instrument displays the time spent rendering each frame in the Frames section of its timeline:\n\n\n\nWhen you zoom out, you can identify areas with a high number of frame drops or with frames running close to the rendering deadline. The timeline uses green to identify frames that complete rendering before the deadline, orange for frames that complete rendering close to the deadline, and red for frames that don’t complete rendering that the renderer drops. Dropped frames contribute to a poor spatial experience, but frames that complete close to their rendering deadline indicate performance problems too. Hold the Option key and drag to zoom into a frame, or group of frames, to see their lifespan broken down in stages:\n\n\n\nThis provides you with insight into which portion of the rendering pipeline to investigate further. This timeline also includes sections that visualize the Average CPU Frame Time and Average GPU Frame Time to indicate the type of processing that computes the frames. A region of the timeline without a frame block indicates a period of time without changes to a person’s surroundings or app updates. The render server avoids computing new frames to send to the compositor during these periods which helps optimize power use.\n\n### Monitor system power usage\n\nWhen thermal levels rise to levels that trigger thermal mitigations in the system, performance degrades and negatively impacts the responsiveness of your app. Optimize for power to avoid this negative impact. The timeline for the RealityKit Metrics instrument includes a System Power Impact section to identify areas of high power usage in your app:\n\n\n\nIf the timeline displays green, the tool considers your app’s impact on system power low enough to sustain. Regions that display orange or red indicate the system power usage could cause thermal levels to rise and trigger thermal mitigations. This decreases the availability of system resources, which can cause visual interruptions and responsiveness issues.\n\n\n\n### Identify bottlenecks\n\nThe Bottlenecks section of the timeline for the RealityKit Metrics instrument contains markers that indicate high overhead in your app or the render server that contribute to dropped frames and high system power use. When you encounter either of these issues, check if the timeline identifies bottlenecks you can address. Double-click on any of the markers to display more information in the detail area at the bottom of the instruments window. If the detail area is hidden, choose View > Detail Area > Show Detail Area to reveal it. The render server encounters bottlenecks in either the CPU or GPU. The instrument categorizes bottlenecks by their severity and type.\n\nTo filter the bottlenecks listed in the detail area to a particular time period, drag inside the timeline to select the region. To see an outline view of the bottlenecks organized by severity and type, select Summary: RealityKit Bottlenecks from the menu at the top left of the detail area. Click the arrow button to the right of the severity or type in the outline view to show the list of bottlenecks in that category.\n\nWhen you select a specific bottleneck, the extended detail provides recommendations for you to address the bottleneck – choose View > Show Extended Detail to reveal the extended detail if it’s hidden.\n\n\n\n### Explore the metrics that relate to bottlenecks\n\nThe trace provides additional information you can use to identify changes to make in your app to address these bottlenecks. Click the expansion arrow for the RealityKit Metrics instrument timeline to reveal graphs specific to each major category of work. Use the metrics associated with these graphs to determine which RealityKit feature has the biggest impact on high CPU frame times in the app process or in the render server. When interpreting these graphs, lower indicates better performance and power. The metrics represent values from all apps running, so profile with just your app running when trying to optimize for these metrics.\n\n\n\n\n\n\n\nThe timeline for your app’s process helps summarize information from the instruments about your process and the work the render server completes for your process.\n\n\n\nChoose an option from the pop-up in the timeline header to show different graphs in the timeline:\n\n\n\nWhen you select the timeline for your app’s process, you can choose instrument summaries and profile data to display in the detail area from the popup-button at its top-left:\n\n\n\nTo filter the information in the detail area by time, select periods of time in the timeline  above.\n\n### Detect delays on the main thread\n\nSelect Hangs in your app’s process timeline to identify times in the trace that might have interaction delays. Use the RealityKit Metrics and Time Profiler summaries to better understand the work your app is doing. Choose the following options from the detail area pop-up menu:\n\n\n\nOptimize any 3D render updates, hit testing, and collision work you find. For more information about addressing hangs in your app, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/improving-app-responsiveness].\n\n### Manage audio overhead\n\nUse the Audio Playback section of your process’s timeline to identify areas of high audio overhead. The system defaults to using spatial audio for your app when running on visionOS. It processes information in real time about your position, surroundings, and the current location of audio sources to generate an immersive audio experience. If you include too many concurrent audio sources that require the system to adapt audio sources to their location within a large space, the increased demand on system resources can lead to delays in the audio output.\n\nTo reduce the spatial audio work, limit:\n\n- The number of concurrently playing audio sources\n- The number of moving audio sources\n- The size of the soundstage\n\nConsider creating a pool of audio players to limit the maximum number of players your app uses. Place players on stationary entities, instead of moving entities, when appropriate. Initializing several audio players at the same time causes a high overhead that affects other aspects of the system, such as rendering performance. Consider the other tasks the system completes during these allocations and space them out over time. For more information, see [https:\/\/developer.apple.com\/videos\/play\/wwdc2023\/10070].\n\n### Profile custom materials for optimization\n\nUse the Metal System Trace template to profile your custom materials in isolation before adding more visual effects to them. Examine the Metal GPU cost and try to optimize for GPU ALU Instructions and GPU Texture reads and writes per frame. For more information on using this template, see [doc:\/\/com.apple.documentation\/documentation\/Xcode\/Analyzing-the-performance-of-your-Metal-app].\n\nIn order to use the Metal Application instrument to profile your custom materials accurately, set a fixed performance state:\n\n1. Click and hold the record button and select Recording Options.\n2. Select the options for the Metal Application instrument.\n3. Set the Counter Set to Performance Limiters.\n4. Set the Performance State to Minimum or Medium.\n\n\n\nA person’s eye position, the distance from the person to the content, and the amount of content the app displays all impact the amount of GPU work done for custom materials from Reality Composer Pro. To compare traces, keep these factors as consistent as possible. For a custom material you use in a Fully Immersive Space, try to remove all other content from the scene while profiling to isolate the overhead of the material. For custom materials you use for other types of content, consider anchoring them to a person’s head in a test scene so the distance from the person remains fixed.\n\n\n\n## Performance\n\n- **Creating a performance plan for your visionOS app**: Identify your app’s performance and power goals and create a plan to measure and assess them.\n- **Reducing the rendering cost of your UI on visionOS**: Optimize your 2D user interface rendering on visionOS.\n- **Reducing the rendering cost of RealityKit content on visionOS**: Optimize your app’s 3D augmented reality content to render efficiently on visionOS.\n- **Understanding the visionOS render pipeline**: Compare how visionOS handles events and manages its rendering loop differently from other Apple platforms.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Identify your app’s performance and power goals and create a plan to measure and assess them.",
          "name" : "Creating a performance plan for your visionOS app",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/creating-a-performance-plan-for-visionos-app"
        },
        {
          "description" : "Optimize your 2D user interface rendering on visionOS.",
          "name" : "Reducing the rendering cost of your UI on visionOS",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/reducing-the-rendering-cost-of-your-UI-on-visionOS"
        },
        {
          "description" : "Optimize your app’s 3D augmented reality content to render efficiently on visionOS.",
          "name" : "Reducing the rendering cost of RealityKit content on visionOS",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/reducing-the-rendering-cost-of-RealityKit-content-on-visionOS"
        },
        {
          "description" : "Compare how visionOS handles events and manages its rendering loop differently from other Apple platforms.",
          "name" : "Understanding the visionOS render pipeline",
          "url" : "https:\/\/developer.apple.com\/documentation\/visionOS\/understanding-the-visionos-render-pipeline"
        }
      ],
      "title" : "Performance"
    }
  ],
  "source" : "appleJSON",
  "title" : "Analyzing the performance of your visionOS app",
  "url" : "https:\/\/developer.apple.com\/documentation\/visionos\/analyzing-the-performance-of-your-visionos-app"
}