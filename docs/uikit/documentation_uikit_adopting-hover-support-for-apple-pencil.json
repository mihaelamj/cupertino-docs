{
  "abstract" : "Enhance user feedback for your iPadOS app with a hover preview for Apple Pencil input.",
  "codeExamples" : [
    {
      "code" : "class DrawGestureRecognizer: UILongPressGestureRecognizer {\n    \n    weak var currentTouch: UITouch?\n    weak var currentEvent: UIEvent?\n    \n    override func touchesBegan(_ touches: Set<UITouch>, with event: UIEvent) {\n        super.touchesBegan(touches, with: event)\n        currentTouch = touches.first\n        currentEvent = event\n    }\n    \n    override func reset() {\n        super.reset()\n        currentTouch = nil\n        currentEvent = nil\n    }\n}",
      "language" : "swift"
    },
    {
      "code" : "case .changed:\n    if let drawGR = drawGestureRecognizer,\n       let currentTouch = drawGR.currentTouch,\n       let currentEvent = drawGR.currentEvent,\n       let touches = currentEvent.coalescedTouches(for: currentTouch) {\n        for touch in touches {\n            let point = touch.preciseLocation(in: self)\n            updatePath(point: point)\n        }\n    } else {\n        updatePath(point: point)\n    }",
      "language" : "swift"
    },
    {
      "code" : "let hoverGesture = UIHoverGestureRecognizer(target: self, action: #selector(hoverGesture(_:)))",
      "language" : "swift"
    },
    {
      "code" : "guard !isDrawing else { return }",
      "language" : "swift"
    },
    {
      "code" : "previewAlpha = 1.0 - max(zOffset - fadeZOffset, 0.0) \/ (maxPreviewZOffset - fadeZOffset)",
      "language" : "swift"
    },
    {
      "code" : "\/\/ hoverGesture.allowedTouchTypes = [ UITouch.TouchType.pencil.rawValue as NSNumber ]",
      "language" : "swift"
    }
  ],
  "contentHash" : "0650a98eb521b3eeb4a1fa4815f98f471046824cc71c1aece659a6b8117681eb",
  "crawledAt" : "2025-12-02T15:33:56Z",
  "id" : "33E64872-78AC-4840-B472-F1B30D90FABB",
  "kind" : "unknown",
  "language" : "swift",
  "module" : "UIKit",
  "overview" : "## Overview\n\nThis sample shows how to add support for hover gestures with Apple Pencil. The app is a simple drawing tool that allows a person to draw strokes on a blank canvas. When a person hovers the Apple Pencil slightly above the drawing canvas, the app uses hover gestures to render a visual preview of where the Apple Pencil touches down to draw a stroke on the canvas.\n\n### Configure the sample code project\n\nAlthough the sample app’s basic functionality is available in Simulator, running the project with physical devices is recommended to demonstrate the full capabilities of the hardware. Run this project with the following devices:\n\nTo run the sample code project:\n\n### Create a gesture recognizer for drawing\n\nThe sample project uses a *long-press gesture recognizer*, which reacts when a person presses and holds a touch for a minimum period of time, to draw strokes with Apple Pencil.\n\nThe app implements the `DrawGestureRecognizer` subclass, which extends the capabilities of its superclass [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UILongPressGestureRecognizer] to track the `currentTouch` and `currentEvent`. These additional properties provide the information necessary to implement high-fidelity drawing.\n\nThe drawing implementation is in the `drawGesture(_:)` method. During the [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIGestureRecognizer\/State-swift.enum\/changed] state of the draw gesture, this method attempts to retrieve additional touches associated with the main touch `currentTouch` through [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIEvent\/coalescedTouches(for:)]. This extra touch data creates a smoother drawing experience with lower latency and higher precision.\n\nTo render the strokes on the canvas, the sample calls `updatePath(point: CGPoint)`, which updates the Bezier path associated with the current stroke and renders the visual output to a [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAShapeLayer].\n\n### Create a gesture recognizer for hover preview\n\nThe sample project uses a hover gesture recognizer to generate a visual preview of the stroke before Apple Pencil touches down on the iPad screen. A *hover gesture recognizer* reacts when a pointer from a pointing device such as Apple Pencil moves over a user-interface element. When a person hovers the Apple Pencil a short distance above the iPad screen, the app generates a preview.\n\nThe sample project creates an instance of [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIHoverGestureRecognizer] to handle the hover gesture.\n\nThe hover preview implementation is in the `hoverGesture(_:)` method. This method waits for the draw gesture to end before starting hover preview rendering. This delay ensures that drawing and previewing don’t occur at the same time to create overlapping visual effects in the UI.\n\n### Update the hover preview\n\nThe sample changes the opacity, or *alpha*, of the hover preview effect according to the distance the Apple Pencil hovers above the iPad screen. When Apple Pencil is farther from the screen, the preview alpha is lower, which makes the visual effect more subtle. When Apple Pencil is closer to the screen, the preview alpha is higher, which makes the visual effect more prominent.\n\nThe sample calculates the preview alpha value in the `hoverGesture(_:)` method using the following values:\n\nThis line of code calculates the preview alpha. When Apple Pencil is closer to the screen than `fadeZOffset`, the preview alpha is `1.0`, which makes the visual effect fully opaque. As Apple Pencil moves farther away than `fadeZOffset`, the alpha begins to decrease and eventually reaches `0.0`, which causes the visual preview to fade and disappear.\n\n### Configure different behaviors for input types\n\nBy default, hover gestures work with pointing devices such as trackpads as well as Apple Pencil. For example, running the sample code project on an iPad with a connected trackpad renders a hover preview when the pointer passes over the drawing canvas. However, this sample provides a different hover experience for Apple Pencil than for a trackpad, so the default behavior might be unsuitable for trackpad input.\n\nTo restrict the hover preview to Apple Pencil input only and disable it for trackpad, uncomment the following line of code and run the app again:",
  "rawMarkdown" : "---\nsource: https:\/\/developer.apple.com\/documentation\/UIKit\/adopting-hover-support-for-apple-pencil\ncrawled: 2025-12-02T15:33:56Z\n---\n\n# Adopting hover support for Apple Pencil\n\n**Sample Code**\n\nEnhance user feedback for your iPadOS app with a hover preview for Apple Pencil input.\n\n## Overview\n\nThis sample shows how to add support for hover gestures with Apple Pencil. The app is a simple drawing tool that allows a person to draw strokes on a blank canvas. When a person hovers the Apple Pencil slightly above the drawing canvas, the app uses hover gestures to render a visual preview of where the Apple Pencil touches down to draw a stroke on the canvas.\n\n### Configure the sample code project\n\nAlthough the sample app’s basic functionality is available in Simulator, running the project with physical devices is recommended to demonstrate the full capabilities of the hardware. Run this project with the following devices:\n\n- iPad Pro 11-inch (4th generation) or iPad Pro 12.9-inch (6th generation) running iPadOS 16.1 or later\n- Apple Pencil (2nd generation)\n\nTo run the sample code project:\n\n- Connect Apple Pencil with the iPad Pro, as described in [https:\/\/support.apple.com\/en-us\/HT205236].\n- Connect the iPad Pro to your Mac with a hardware cable.\n- Open the sample code project in Xcode.\n- In the Scheme menu, choose the connected iPad Pro.\n- Run the app, and use Apple Pencil to interact with the app.\n\n### Create a gesture recognizer for drawing\n\nThe sample project uses a *long-press gesture recognizer*, which reacts when a person presses and holds a touch for a minimum period of time, to draw strokes with Apple Pencil.\n\nThe app implements the `DrawGestureRecognizer` subclass, which extends the capabilities of its superclass [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UILongPressGestureRecognizer] to track the `currentTouch` and `currentEvent`. These additional properties provide the information necessary to implement high-fidelity drawing.\n\n```swift\nclass DrawGestureRecognizer: UILongPressGestureRecognizer {\n    \n    weak var currentTouch: UITouch?\n    weak var currentEvent: UIEvent?\n    \n    override func touchesBegan(_ touches: Set<UITouch>, with event: UIEvent) {\n        super.touchesBegan(touches, with: event)\n        currentTouch = touches.first\n        currentEvent = event\n    }\n    \n    override func reset() {\n        super.reset()\n        currentTouch = nil\n        currentEvent = nil\n    }\n}\n```\n\nThe drawing implementation is in the `drawGesture(_:)` method. During the [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIGestureRecognizer\/State-swift.enum\/changed] state of the draw gesture, this method attempts to retrieve additional touches associated with the main touch `currentTouch` through [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIEvent\/coalescedTouches(for:)]. This extra touch data creates a smoother drawing experience with lower latency and higher precision.\n\n```swift\ncase .changed:\n    if let drawGR = drawGestureRecognizer,\n       let currentTouch = drawGR.currentTouch,\n       let currentEvent = drawGR.currentEvent,\n       let touches = currentEvent.coalescedTouches(for: currentTouch) {\n        for touch in touches {\n            let point = touch.preciseLocation(in: self)\n            updatePath(point: point)\n        }\n    } else {\n        updatePath(point: point)\n    }\n```\n\nTo render the strokes on the canvas, the sample calls `updatePath(point: CGPoint)`, which updates the Bezier path associated with the current stroke and renders the visual output to a [doc:\/\/com.apple.documentation\/documentation\/QuartzCore\/CAShapeLayer].\n\n### Create a gesture recognizer for hover preview\n\nThe sample project uses a hover gesture recognizer to generate a visual preview of the stroke before Apple Pencil touches down on the iPad screen. A *hover gesture recognizer* reacts when a pointer from a pointing device such as Apple Pencil moves over a user-interface element. When a person hovers the Apple Pencil a short distance above the iPad screen, the app generates a preview.\n\nThe sample project creates an instance of [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIHoverGestureRecognizer] to handle the hover gesture.\n\n```swift\nlet hoverGesture = UIHoverGestureRecognizer(target: self, action: #selector(hoverGesture(_:)))\n```\n\nThe hover preview implementation is in the `hoverGesture(_:)` method. This method waits for the draw gesture to end before starting hover preview rendering. This delay ensures that drawing and previewing don’t occur at the same time to create overlapping visual effects in the UI.\n\n```swift\nguard !isDrawing else { return }\n```\n\n### Update the hover preview\n\nThe sample changes the opacity, or *alpha*, of the hover preview effect according to the distance the Apple Pencil hovers above the iPad screen. When Apple Pencil is farther from the screen, the preview alpha is lower, which makes the visual effect more subtle. When Apple Pencil is closer to the screen, the preview alpha is higher, which makes the visual effect more prominent.\n\nThe sample calculates the preview alpha value in the `hoverGesture(_:)` method using the following values:\n\n- [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIHoverGestureRecognizer\/zOffset]—A property of [doc:\/\/com.apple.uikit\/documentation\/UIKit\/UIHoverGestureRecognizer] that reports the current, normalized distance between the Apple Pencil and the iPad screen.\n- `maxPreviewZOffset`—A constant that represents the maximum distance between the Apple Pencil and the iPad screen. The sample uses the maximum distance `1.0` because `zOffset` is normalized.\n- `fadeZOffset`—A constant that represents the threshold distance at which the preview alpha switches between fully opaque and partially opaque, causing the visual preview effect to begin fading out.\n\n```swift\npreviewAlpha = 1.0 - max(zOffset - fadeZOffset, 0.0) \/ (maxPreviewZOffset - fadeZOffset)\n```\n\nThis line of code calculates the preview alpha. When Apple Pencil is closer to the screen than `fadeZOffset`, the preview alpha is `1.0`, which makes the visual effect fully opaque. As Apple Pencil moves farther away than `fadeZOffset`, the alpha begins to decrease and eventually reaches `0.0`, which causes the visual preview to fade and disappear.\n\n### Configure different behaviors for input types\n\nBy default, hover gestures work with pointing devices such as trackpads as well as Apple Pencil. For example, running the sample code project on an iPad with a connected trackpad renders a hover preview when the pointer passes over the drawing canvas. However, this sample provides a different hover experience for Apple Pencil than for a trackpad, so the default behavior might be unsuitable for trackpad input.\n\nTo restrict the hover preview to Apple Pencil input only and disable it for trackpad, uncomment the following line of code and run the app again:\n\n```swift\n\/\/ hoverGesture.allowedTouchTypes = [ UITouch.TouchType.pencil.rawValue as NSNumber ]\n```\n\n## Standard gestures\n\n- **Handling UIKit gestures**: Use gesture recognizers to simplify touch handling and create a consistent user experience.\n- **Coordinating multiple gesture recognizers**: Discover how to use multiple gesture recognizers on the same view.\n- **Supporting gesture interaction in your apps**: Enrich your app’s user experience by supporting standard and custom gesture interaction.\n- **UIHoverGestureRecognizer**: A continuous gesture recognizer that interprets pointer movement over a view.\n- **UILongPressGestureRecognizer**: A continuous gesture recognizer that interprets long-press gestures.\n- **UIPanGestureRecognizer**: A continuous gesture recognizer that interprets panning gestures.\n- **UIPinchGestureRecognizer**: A continuous gesture recognizer that interprets pinching gestures involving two touches.\n- **UIRotationGestureRecognizer**: A continuous gesture recognizer that interprets rotation gestures involving two touches.\n- **UIScreenEdgePanGestureRecognizer**: A continuous gesture recognizer that interprets panning gestures that start near an edge of the screen.\n- **UISwipeGestureRecognizer**: A discrete gesture recognizer that interprets swiping gestures in one or more directions.\n- **UITapGestureRecognizer**: A discrete gesture recognizer that interprets single or multiple taps.\n\n",
  "sections" : [
    {
      "content" : "",
      "items" : [
        {
          "description" : "Use gesture recognizers to simplify touch handling and create a consistent user experience.",
          "name" : "Handling UIKit gestures",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/handling-uikit-gestures"
        },
        {
          "description" : "Discover how to use multiple gesture recognizers on the same view.",
          "name" : "Coordinating multiple gesture recognizers",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/coordinating-multiple-gesture-recognizers"
        },
        {
          "description" : "Enrich your app’s user experience by supporting standard and custom gesture interaction.",
          "name" : "Supporting gesture interaction in your apps",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/supporting-gesture-interaction-in-your-apps"
        },
        {
          "description" : "A continuous gesture recognizer that interprets pointer movement over a view.",
          "name" : "UIHoverGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UIHoverGestureRecognizer"
        },
        {
          "description" : "A continuous gesture recognizer that interprets long-press gestures.",
          "name" : "UILongPressGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UILongPressGestureRecognizer"
        },
        {
          "description" : "A continuous gesture recognizer that interprets panning gestures.",
          "name" : "UIPanGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UIPanGestureRecognizer"
        },
        {
          "description" : "A continuous gesture recognizer that interprets pinching gestures involving two touches.",
          "name" : "UIPinchGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UIPinchGestureRecognizer"
        },
        {
          "description" : "A continuous gesture recognizer that interprets rotation gestures involving two touches.",
          "name" : "UIRotationGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UIRotationGestureRecognizer"
        },
        {
          "description" : "A continuous gesture recognizer that interprets panning gestures that start near an edge of the screen.",
          "name" : "UIScreenEdgePanGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UIScreenEdgePanGestureRecognizer"
        },
        {
          "description" : "A discrete gesture recognizer that interprets swiping gestures in one or more directions.",
          "name" : "UISwipeGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UISwipeGestureRecognizer"
        },
        {
          "description" : "A discrete gesture recognizer that interprets single or multiple taps.",
          "name" : "UITapGestureRecognizer",
          "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/UITapGestureRecognizer"
        }
      ],
      "title" : "Standard gestures"
    }
  ],
  "source" : "appleJSON",
  "title" : "Adopting hover support for Apple Pencil",
  "url" : "https:\/\/developer.apple.com\/documentation\/UIKit\/adopting-hover-support-for-apple-pencil"
}